{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78a41cde-9a88-41fa-a461-bf4093e2cdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyterlab in c:\\users\\giovani\\anaconda3\\lib\\site-packages (4.2.5)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\giovani\\anaconda3\\lib\\site-packages (0.3.0)\n",
      "Requirement already satisfied: langchain in c:\\users\\giovani\\anaconda3\\lib\\site-packages (0.3.14)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-1.0.15-cp39-abi3-win_amd64.whl.metadata (7.1 kB)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-5.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting unstructured\n",
      "  Downloading unstructured-0.18.5-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\giovani\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyterlab) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyterlab) (0.27.2)\n",
      "Requirement already satisfied: ipykernel>=6.5.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyterlab) (6.28.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyterlab) (3.1.4)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyterlab) (5.7.2)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyterlab) (2.2.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyterlab) (2.14.1)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyterlab) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyterlab) (0.2.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyterlab) (24.1)\n",
      "Requirement already satisfied: setuptools>=40.1.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyterlab) (75.1.0)\n",
      "Requirement already satisfied: tornado>=6.2.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyterlab) (6.4.1)\n",
      "Requirement already satisfied: traitlets in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyterlab) (5.14.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain-openai) (0.3.29)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain-openai) (1.61.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain-openai) (0.8.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain) (3.10.5)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain) (0.3.5)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.17 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain) (0.2.10)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain) (2.10.5)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Collecting langchain-core<0.4.0,>=0.3.29 (from langchain-openai)\n",
      "  Downloading langchain_core-0.3.68-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.26-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain-community) (2.6.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting pybase64>=1.4.1 (from chromadb)\n",
      "  Downloading pybase64-1.4.1-cp312-cp312-win_amd64.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from chromadb) (3.7.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from chromadb) (4.12.2)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.22.1-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.35.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from chromadb) (0.19.1)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from chromadb) (4.66.5)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from chromadb) (7.4.0)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from chromadb) (1.69.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.3.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from chromadb) (0.9.0)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.1.0-cp312-cp312-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from chromadb) (3.10.14)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from chromadb) (13.7.1)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from chromadb) (4.23.0)\n",
      "Requirement already satisfied: chardet in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from unstructured) (4.0.0)\n",
      "Requirement already satisfied: filetype in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from unstructured) (1.2.0)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: lxml in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from unstructured) (5.3.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from unstructured) (3.9.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from unstructured) (4.12.3)\n",
      "Collecting emoji (from unstructured)\n",
      "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Downloading python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langdetect (from unstructured)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     ------------------------------------- 981.5/981.5 kB 11.4 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting rapidfuzz (from unstructured)\n",
      "  Downloading rapidfuzz-3.13.0-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: backoff in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from unstructured) (2.2.1)\n",
      "Collecting unstructured-client (from unstructured)\n",
      "  Downloading unstructured_client-0.38.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: wrapt in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from unstructured) (1.14.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from unstructured) (5.9.0)\n",
      "Collecting python-oxmsg (from unstructured)\n",
      "  Downloading python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting html5lib (from unstructured)\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.0)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from httpx>=0.25.0->jupyterlab) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from httpx>=0.25.0->jupyterlab) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from httpx>=0.25.0->jupyterlab) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from httpx>=0.25.0->jupyterlab) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from httpx>=0.25.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab) (0.14.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab) (0.2.1)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab) (1.6.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab) (8.27.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab) (8.6.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab) (1.6.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab) (25.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jinja2>=3.0.3->jupyterlab) (2.1.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.10.6)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyter-core->jupyterlab) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyter-core->jupyterlab) (305.1)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (21.3.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.4.4)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.16.4)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (5.10.4)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.14.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (2.0.10)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.17.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.16.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (0.9.6)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.37.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting langsmith>=0.1.125 (from langchain-community)\n",
      "  Downloading langsmith-0.4.5-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-openai) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.6)\n",
      "Requirement already satisfied: sympy in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (7.0.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.35.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.35.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.35.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.35.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading protobuf-6.31.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting opentelemetry-semantic-conventions==0.56b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.15.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2023.12.25)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.28.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.4-cp312-cp312-win_amd64.whl.metadata (3.7 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.1.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-15.0.1-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from beautifulsoup4->unstructured) (2.5)\n",
      "Requirement already satisfied: webencodings in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from html5lib->unstructured) (0.5.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from nltk->unstructured) (1.4.2)\n",
      "Collecting olefile (from python-oxmsg->unstructured)\n",
      "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from unstructured-client->unstructured) (24.1.0)\n",
      "Requirement already satisfied: cryptography>=3.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from unstructured-client->unstructured) (43.0.0)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached protobuf-5.29.5-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: filelock in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (3.0.43)\n",
      "Requirement already satisfied: stack-data in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain-openai) (2.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.0)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.8.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.16.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.21)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.8.3)\n",
      "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab)\n",
      "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab)\n",
      "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab)\n",
      "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting webcolors>=24.6.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab)\n",
      "  Downloading webcolors-24.11.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.5)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n",
      "Requirement already satisfied: executing in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.2)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.2.3)\n",
      "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 18.1 MB/s eta 0:00:00\n",
      "Downloading langchain-0.3.26-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 24.2 MB/s eta 0:00:00\n",
      "Downloading chromadb-1.0.15-cp39-abi3-win_amd64.whl (19.5 MB)\n",
      "   ---------------------------------------- 0.0/19.5 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 8.1/19.5 MB 38.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 17.8/19.5 MB 43.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  19.4/19.5 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 19.5/19.5 MB 24.2 MB/s eta 0:00:00\n",
      "Downloading pypdf-5.8.0-py3-none-any.whl (309 kB)\n",
      "Downloading unstructured-0.18.5-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/1.8 MB 16.3 MB/s eta 0:00:00\n",
      "Downloading bcrypt-4.3.0-cp39-abi3-win_amd64.whl (152 kB)\n",
      "Downloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.9/1.9 MB 35.7 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.68-py3-none-any.whl (441 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading langsmith-0.4.5-py3-none-any.whl (367 kB)\n",
      "Downloading mmh3-5.1.0-cp312-cp312-win_amd64.whl (41 kB)\n",
      "Downloading onnxruntime-1.22.1-cp312-cp312-win_amd64.whl (12.7 MB)\n",
      "   ---------------------------------------- 0.0/12.7 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 6.6/12.7 MB 33.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.7 MB 34.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.7/12.7 MB 28.4 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_api-1.35.0-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.35.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.35.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.35.0-py3-none-any.whl (72 kB)\n",
      "Downloading opentelemetry_sdk-1.35.0-py3-none-any.whl (119 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl (201 kB)\n",
      "Downloading pybase64-1.4.1-cp312-cp312-win_amd64.whl (36 kB)\n",
      "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "   ---------------------------------------- 0.0/590.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 590.6/590.6 kB 10.6 MB/s eta 0:00:00\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
      "Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
      "Downloading rapidfuzz-3.13.0-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 28.8 MB/s eta 0:00:00\n",
      "Downloading unstructured_client-0.38.1-py3-none-any.whl (212 kB)\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 36.0 MB/s eta 0:00:00\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading httptools-0.6.4-cp312-cp312-win_amd64.whl (88 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Using cached protobuf-5.29.5-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading watchfiles-1.1.0-cp312-cp312-win_amd64.whl (292 kB)\n",
      "Downloading websockets-15.0.1-cp312-cp312-win_amd64.whl (176 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading webcolors-24.11.1-py3-none-any.whl (14 kB)\n",
      "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: pypika, langdetect\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53916 sha256=88986612cbfd8c4cfd5264d8db4e1ec1bed0ed31d67dbae47b1dae40d3f24dd1\n",
      "  Stored in directory: c:\\users\\giovani\\appdata\\local\\pip\\cache\\wheels\\d5\\3d\\69\\8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993251 sha256=1fcd098624e9bf9e517be4a404c9f84ed1928f1ce5b6934cb32e85715a57b9b2\n",
      "  Stored in directory: c:\\users\\giovani\\appdata\\local\\pip\\cache\\wheels\\c1\\67\\88\\e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
      "Successfully built pypika langdetect\n",
      "Installing collected packages: pypika, durationpy, websockets, webcolors, uri-template, typing-inspection, typing-inspect, rapidfuzz, python-magic, python-iso639, pyreadline3, pyproject_hooks, pypdf, pydantic-core, pybase64, protobuf, olefile, oauthlib, mmh3, marshmallow, langdetect, importlib-resources, httptools, html5lib, fqdn, emoji, bcrypt, watchfiles, requests-oauthlib, python-oxmsg, pydantic, opentelemetry-proto, opentelemetry-api, humanfriendly, dataclasses-json, build, unstructured-client, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, langsmith, kubernetes, isoduration, coloredlogs, unstructured, opentelemetry-sdk, onnxruntime, langchain-core, opentelemetry-exporter-otlp-proto-grpc, langchain-text-splitters, langchain, chromadb, langchain-community\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.27.2\n",
      "    Uninstalling pydantic_core-2.27.2:\n",
      "      Successfully uninstalled pydantic_core-2.27.2\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.6\n",
      "    Uninstalling protobuf-4.25.6:\n",
      "      Successfully uninstalled protobuf-4.25.6\n",
      "  Attempting uninstall: bcrypt\n",
      "    Found existing installation: bcrypt 3.2.0\n",
      "    Uninstalling bcrypt-3.2.0:\n",
      "      Successfully uninstalled bcrypt-3.2.0\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.10.5\n",
      "    Uninstalling pydantic-2.10.5:\n",
      "      Successfully uninstalled pydantic-2.10.5\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.2.10\n",
      "    Uninstalling langsmith-0.2.10:\n",
      "      Successfully uninstalled langsmith-0.2.10\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.29\n",
      "    Uninstalling langchain-core-0.3.29:\n",
      "      Successfully uninstalled langchain-core-0.3.29\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 0.3.5\n",
      "    Uninstalling langchain-text-splitters-0.3.5:\n",
      "      Successfully uninstalled langchain-text-splitters-0.3.5\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.3.14\n",
      "    Uninstalling langchain-0.3.14:\n",
      "      Successfully uninstalled langchain-0.3.14\n",
      "Successfully installed bcrypt-4.3.0 build-1.2.2.post1 chromadb-1.0.15 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.10 emoji-2.14.1 fqdn-1.5.1 html5lib-1.1 httptools-0.6.4 humanfriendly-10.0 importlib-resources-6.5.2 isoduration-20.11.0 kubernetes-33.1.0 langchain-0.3.26 langchain-community-0.3.27 langchain-core-0.3.68 langchain-text-splitters-0.3.8 langdetect-1.0.9 langsmith-0.4.5 marshmallow-3.26.1 mmh3-5.1.0 oauthlib-3.3.1 olefile-0.47 onnxruntime-1.22.1 opentelemetry-api-1.35.0 opentelemetry-exporter-otlp-proto-common-1.35.0 opentelemetry-exporter-otlp-proto-grpc-1.35.0 opentelemetry-proto-1.35.0 opentelemetry-sdk-1.35.0 opentelemetry-semantic-conventions-0.56b0 protobuf-5.29.5 pybase64-1.4.1 pydantic-2.11.7 pydantic-core-2.33.2 pypdf-5.8.0 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 python-iso639-2025.2.18 python-magic-0.4.27 python-oxmsg-0.0.2 rapidfuzz-3.13.0 requests-oauthlib-2.0.0 typing-inspect-0.9.0 typing-inspection-0.4.1 unstructured-0.18.5 unstructured-client-0.38.1 uri-template-1.3.0 watchfiles-1.1.0 webcolors-24.11.1 websockets-15.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Giovani\\anaconda3\\Lib\\site-packages\\~ydantic_core'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.37.1 requires pillow<11,>=7.1.0, but you have pillow 11.0.0 which is incompatible.\n",
      "tensorflow-intel 2.16.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.5 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install jupyterlab langchain-openai langchain langchain-community chromadb pypdf unstructured python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286b4d3e-01cf-4524-a9e2-5da7003766f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "\n",
    "# --- Configuration ---\n",
    "# This script will create a set of rich, interconnected dummy data\n",
    "# to populate the data/raw folder of the project structure.\n",
    "\n",
    "# Root directory for all raw data\n",
    "RAW_DATA_PATH = 'data/raw'\n",
    "\n",
    "# --- Data Definitions ---\n",
    "\n",
    "# 1. Product Catalog\n",
    "product_catalog_data = [\n",
    "    {'sku': 'C9300-24P', 'name': 'Catalyst 9300 24-port PoE+', 'category': 'Switch', 'description': 'Enterprise-grade stackable access switch, foundational for SD-Access.'},\n",
    "    {'sku': 'C9300-DNA-A-3Y', 'name': 'Cisco DNA Advantage, 3Y', 'category': 'Software License', 'description': '3-year DNA Advantage subscription for Catalyst 9300 series.'},\n",
    "    {'sku': 'FPR1120-ASA-K9', 'name': 'Firepower 1120 ASA', 'category': 'Firewall', 'description': 'NGFW for small to medium-sized businesses and branch offices.'},\n",
    "    {'sku': 'MER-MR46-HW', 'name': 'Meraki MR46', 'category': 'Access Point', 'description': 'Cloud-managed Wi-Fi 6 access point with 4x4:4 MIMO.'},\n",
    "    {'sku': 'LIC-MR-ENT-1Y', 'name': 'Meraki MR Enterprise License, 1Y', 'category': 'Cloud License', 'description': '1-year enterprise cloud management license for MR access points.'},\n",
    "    {'sku': 'CP-8841-K9', 'name': 'IP Phone 8841', 'category': 'Collaboration', 'description': '5-inch widescreen VGA display IP phone with 5 programmable line keys.'},\n",
    "    {'sku': 'GLC-TE', 'name': '1000BASE-T SFP Transceiver', 'category': 'Transceiver', 'description': 'SFP transceiver module for Category 5 copper wire.'}\n",
    "]\n",
    "\n",
    "# 2. Price List\n",
    "price_list_data = [\n",
    "    {'sku': 'C9300-24P', 'list_price_usd': 4500, 'partner_price_usd': 2700},\n",
    "    {'sku': 'C9300-DNA-A-3Y', 'list_price_usd': 1200, 'partner_price_usd': 720},\n",
    "    {'sku': 'FPR1120-ASA-K9', 'list_price_usd': 2800, 'partner_price_usd': 1680},\n",
    "    {'sku': 'MER-MR46-HW', 'list_price_usd': 950, 'partner_price_usd': 665},\n",
    "    {'sku': 'LIC-MR-ENT-1Y', 'list_price_usd': 150, 'partner_price_usd': 120},\n",
    "    {'sku': 'CP-8841-K9', 'list_price_usd': 320, 'partner_price_usd': 240},\n",
    "    {'sku': 'GLC-TE', 'list_price_usd': 100, 'partner_price_usd': 55}\n",
    "]\n",
    "\n",
    "# 3. Compatibility Rules\n",
    "compatibility_rules_data = {\n",
    "    \"C9300-24P\": {\n",
    "        \"requires\": [\"C9300-DNA-A-3Y\"],\n",
    "        \"supports\": [\"GLC-TE\"],\n",
    "        \"incompatible_with\": []\n",
    "    },\n",
    "    \"MER-MR46-HW\": {\n",
    "        \"requires\": [\"LIC-MR-ENT-1Y\"],\n",
    "        \"supports\": [],\n",
    "        \"incompatible_with\": [\"C9300-DNA-A-3Y\"]\n",
    "    },\n",
    "    \"FPR1120-ASA-K9\": {\n",
    "        \"requires\": [],\n",
    "        \"supports\": [\"GLC-TE\"],\n",
    "        \"incompatible_with\": []\n",
    "    }\n",
    "}\n",
    "\n",
    "# 4. Solution Guide for Healthcare\n",
    "healthcare_guide_content = \"\"\"\n",
    "# Solution Guide: Healthcare Clinic Network Refresh\n",
    "\n",
    "## Overview\n",
    "A healthcare clinic requires a highly reliable, secure, and HIPAA-compliant network infrastructure. Key requirements include secure Wi-Fi for staff and guests, robust firewalling to protect patient data (EHR), and reliable voice communication.\n",
    "\n",
    "## Recommended Components\n",
    "- **Switching:** The Catalyst 9300 series (e.g., C9300-24P) is recommended for the core network due to its advanced security features and stacking capabilities. A Cisco DNA Advantage license is mandatory for full functionality.\n",
    "- **Wireless:** For clinical areas, Meraki cloud-managed Wi-Fi 6 access points like the MR46 provide secure and easy-to-manage wireless connectivity. A separate guest SSID can be configured with traffic shaping rules.\n",
    "- **Security:** A next-generation firewall such as the Firepower 1000 series (e.g., FPR1120-ASA-K9) is essential for threat defense and intrusion prevention.\n",
    "- **Collaboration:** Cisco IP Phones from the 8800 series (e.g., CP-8841-K9) offer reliable voice and video communication suitable for reception and clinical staff.\n",
    "\"\"\"\n",
    "\n",
    "# 5. Enterprise Agreement for Healthcare\n",
    "healthcare_ea_data = {\n",
    "    \"agreement_name\": \"Healthcare Kickstart EA\",\n",
    "    \"target_segment\": \"Healthcare\",\n",
    "    \"minimum_user_count\": 50,\n",
    "    \"included_product_families\": [\"Catalyst 9300 Series\", \"Meraki MR Series\", \"Firepower 1000 Series\"],\n",
    "    \"default_discount_percentage\": {\n",
    "        \"hardware\": 45,\n",
    "        \"software\": 30\n",
    "    },\n",
    "    \"included_support_tier\": \"Solution Support\"\n",
    "}\n",
    "\n",
    "# 6. Historical Quotes for ML Training\n",
    "historical_quotes_data = [\n",
    "    {'quote_id': 'Q1-2023-001', 'customer_segment': 'Healthcare', 'total_list_price': 8500, 'final_discount_pct': 42, 'products_sku': 'C9300-24P;FPR1120-ASA-K9', 'won': 'Yes'},\n",
    "    {'quote_id': 'Q1-2023-002', 'customer_segment': 'Retail', 'total_list_price': 3500, 'final_discount_pct': 35, 'products_sku': 'MER-MR46-HW;LIC-MR-ENT-1Y', 'won': 'Yes'},\n",
    "    {'quote_id': 'Q1-2023-003', 'customer_segment': 'Healthcare', 'total_list_price': 9500, 'final_discount_pct': 50, 'products_sku': 'C9300-24P;FPR1120-ASA-K9', 'won': 'No'},\n",
    "    {'quote_id': 'Q2-2023-004', 'customer_segment': 'Finance', 'total_list_price': 15000, 'final_discount_pct': 40, 'products_sku': 'C9300-24P;C9300-DNA-A-3Y;CP-8841-K9', 'won': 'Yes'}\n",
    "]\n",
    "\n",
    "\n",
    "# --- File Writing Logic ---\n",
    "\n",
    "def create_files():\n",
    "    \"\"\"Creates the directories and files with the defined data.\"\"\"\n",
    "    print(f\"Creating dummy data in '{RAW_DATA_PATH}'...\")\n",
    "\n",
    "    # Define paths for all subdirectories\n",
    "    paths = {\n",
    "        \"guides\": os.path.join(RAW_DATA_PATH, 'solution_guides'),\n",
    "        \"eas\": os.path.join(RAW_DATA_PATH, 'enterprise_agreements'),\n",
    "        \"quotes\": os.path.join(RAW_DATA_PATH, 'historical_quotes')\n",
    "    }\n",
    "\n",
    "    # Create directories if they don't exist\n",
    "    for path in paths.values():\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    # 1. Write product_catalog.csv\n",
    "    with open(os.path.join(RAW_DATA_PATH, 'product_catalog.csv'), 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=product_catalog_data[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(product_catalog_data)\n",
    "    print(\" -> 'product_catalog.csv' created.\")\n",
    "    \n",
    "    # 2. Write price_list.csv\n",
    "    with open(os.path.join(RAW_DATA_PATH, 'price_list.csv'), 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=price_list_data[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(price_list_data)\n",
    "    print(\" -> 'price_list.csv' created.\")\n",
    "\n",
    "    # 3. Write compatibility_rules.json\n",
    "    with open(os.path.join(RAW_DATA_PATH, 'compatibility_rules.json'), 'w', encoding='utf-8') as f:\n",
    "        json.dump(compatibility_rules_data, f, indent=4)\n",
    "    print(\" -> 'compatibility_rules.json' created.\")\n",
    "\n",
    "    # 4. Write healthcare_solution.txt\n",
    "    with open(os.path.join(paths['guides'], 'healthcare_solution.txt'), 'w', encoding='utf-8') as f:\n",
    "        f.write(healthcare_guide_content)\n",
    "    print(\" -> 'healthcare_solution.txt' created.\")\n",
    "\n",
    "    # 5. Write healthcare_ea.json\n",
    "    with open(os.path.join(paths['eas'], 'healthcare_ea.json'), 'w', encoding='utf-8') as f:\n",
    "        json.dump(healthcare_ea_data, f, indent=4)\n",
    "    print(\" -> 'healthcare_ea.json' created.\")\n",
    "\n",
    "    # 6. Write historical_quotes.csv\n",
    "    with open(os.path.join(paths['quotes'], 'quotes_2023.csv'), 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=historical_quotes_data[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(historical_quotes_data)\n",
    "    print(\" -> 'quotes_2023.csv' created.\")\n",
    "    \n",
    "    print(\"\\nDummy data creation complete!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a63efeaa-6188-4a55-93f5-16606808f419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Carregando, dividindo e vetorizando os dados... ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "100%|| 1/1 [00:09<00:00,  9.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos carregados: 8\n",
      "Documentos divididos em 10 chunks.\n",
      "Base de conhecimento criada e salva em 'data/processed/vector_store'.\n"
     ]
    }
   ],
   "source": [
    "# Define os caminhos relativos  raiz do projeto\n",
    "raw_data_path = 'data/raw'\n",
    "vector_store_path = 'data/processed/vector_store'\n",
    "\n",
    "print(\"--- Carregando, dividindo e vetorizando os dados... ---\")\n",
    "\n",
    "# 1. Carrega os documentos\n",
    "csv_loader = CSVLoader(file_path=f'{raw_data_path}/product_catalog.csv')\n",
    "text_loader = DirectoryLoader(path=f'{raw_data_path}/solution_guides/', glob=\"**/*.txt\", show_progress=True)\n",
    "all_docs = csv_loader.load() + text_loader.load()\n",
    "print(f\"Documentos carregados: {len(all_docs)}\")\n",
    "\n",
    "# 2. Divide os documentos\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "splits = text_splitter.split_documents(all_docs)\n",
    "print(f\"Documentos divididos em {len(splits)} chunks.\")\n",
    "\n",
    "# 3. Cria e persiste o Vector Store\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    "    persist_directory=vector_store_path  # Salva o DB no disco para uso futuro\n",
    ")\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "print(f\"Base de conhecimento criada e salva em '{vector_store_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2cb45a-396e-4129-a1bd-b1849ee77a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "919b5226-40fd-46f0-b272-950108e395e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Construindo a cadeia RAG e testando... ---\n",
      "\n",
      "--- Question ---\n",
      "What do you recommend for a small office that needs security and easy management?\n",
      "\n",
      "--- Generating AI Response ---\n",
      "For a small office that needs security and easy management, I recommend the following Cisco products:\n",
      "\n",
      "1. **Security:** The Firepower 1120 ASA (SKU: FPR1120-ASA-K9) is a next-generation firewall suitable for small to medium-sized businesses. It provides essential threat defense and intrusion prevention capabilities.\n",
      "\n",
      "2. **Wireless:** Consider using Meraki cloud-managed Wi-Fi 6 access points like the MR46. These access points offer secure and easy-to-manage wireless connectivity, which is ideal for small office environments.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Construindo a cadeia RAG e testando... ---\")\n",
    "\n",
    "# Define o LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.1)\n",
    "\n",
    "# Define o Prompt\n",
    "prompt_template = \"\"\"\n",
    "You are an expert Cisco product assistant. Your role is to help a salesperson create a quote.\n",
    "Use ONLY the context provided below to answer the question. Do not make up products or information.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Salesperson's Question:\n",
    "{question}\n",
    "\n",
    "Expert Answer:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# Constri a cadeia RAG\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# ---- TESTE ----\n",
    "query = \"What do you recommend for a small office that needs security and easy management?\"\n",
    "print(f\"\\n--- Question ---\\n{query}\\n\")\n",
    "print(\"--- Generating AI Response ---\")\n",
    "\n",
    "# Invoca a cadeia\n",
    "response = rag_chain.invoke(query)\n",
    "\n",
    "# Imprime a resposta\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1129bd92-cb67-4c19-aa91-96bab2647829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91858f3d-9a9e-42b6-ac67-a15387217bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90443b44-2288-43c9-bafe-1fead085012c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26d12bc9-9023-42ae-979a-e87d762439a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chave da OpenAI carregada com sucesso.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import CSVLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Carrega as variveis do arquivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Verifica se a chave foi carregada com sucesso\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\"Chave da OpenAI (OPENAI_API_KEY) no encontrada. Verifique seu arquivo .env na raiz do projeto.\")\n",
    "else:\n",
    "    print(\"Chave da OpenAI carregada com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7d1804-f492-4450-b981-4d7ea5fb9696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7829fa79-da3a-477c-b8f8-8af7a49dda99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 12:19:27,497 - INFO - Initializing CiscoRAGService...\n",
      "2025-07-13 12:19:27,498 - INFO - Loading documents from source...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initializing the full AI Service ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]2025-07-13 12:19:27,506 - WARNING - libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "100%|| 1/1 [00:00<00:00, 78.52it/s]\n",
      "2025-07-13 12:19:27,518 - INFO - Loaded 8 documents.\n",
      "2025-07-13 12:19:27,518 - INFO - Splitting documents into chunks...\n",
      "2025-07-13 12:19:27,521 - INFO - Documents split into 10 chunks.\n",
      "2025-07-13 12:19:27,522 - INFO - Creating and persisting Vector Store...\n",
      "2025-07-13 12:19:29,244 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "2025-07-13 12:19:30,899 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-07-13 12:19:31,378 - INFO - Vector Store created at: data/processed/vector_store\n",
      "2025-07-13 12:19:32,458 - INFO - RAG Service initialized successfully.\n",
      "2025-07-13 12:19:32,458 - INFO - Received new query: What do you recommend for a small office that needs security and easy management?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Service Initialized ---\n",
      "\n",
      "--- Sending Query to the Service ---\n",
      "What do you recommend for a small office that needs security and easy management?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 12:19:32,987 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-07-13 12:19:36,783 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-13 12:19:36,802 - INFO - Response generated successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- AI Response ---\n",
      "For a small office that requires security and easy management, I recommend the following components:\n",
      "\n",
      "1. **Switching:** Use the **Catalyst 9300 series** (e.g., **C9300-24P**) for the core network. This switch offers advanced security features and stacking capabilities, which are beneficial for managing network traffic efficiently.\n",
      "\n",
      "2. **Wireless:** Implement **Meraki cloud-managed Wi-Fi 6 access points** like the **MR46**. These access points provide secure wireless connectivity and are easy to manage through the Meraki dashboard. Additionally, you can configure a separate guest SSID with traffic shaping rules to enhance network performance.\n",
      "\n",
      "3. **Security:** Deploy a **next-generation firewall** such as the **Firepower 1000 series** (e.g., **FPR1120-ASA-K9**). This firewall is essential for threat defense and intrusion prevention, ensuring that your office network remains secure.\n",
      "\n",
      "These recommendations focus on providing robust security while ensuring ease of management, making them ideal for a small office environment.\n"
     ]
    }
   ],
   "source": [
    "# Importa a classe usando o novo nome da pasta com underscore\n",
    "from services.ai_engine.app.core.rag_service import CiscoRAGService\n",
    "\n",
    "print(\"--- Initializing the full AI Service ---\")\n",
    "# Cria uma instncia do nosso servio.\n",
    "rag_service = CiscoRAGService()\n",
    "print(\"--- Service Initialized ---\")\n",
    "\n",
    "\n",
    "# Agora, vamos testar o servio\n",
    "query = \"What do you recommend for a small office that needs security and easy management?\"\n",
    "print(f\"\\n--- Sending Query to the Service ---\\n{query}\\n\")\n",
    "\n",
    "# Usa o mtodo da nossa classe para gerar a resposta\n",
    "response = rag_service.generate_response(query)\n",
    "\n",
    "print(\"--- AI Response ---\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea23d354-6664-4d6d-885d-51020acea4cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27560c9e-8b65-4099-a6d3-6a61b83c857c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5506c425-2cf2-4d2c-8352-a500b27f6464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 1: Instalar as bibliotecas necessrias\n",
    "# beautifulsoup4  usado pelo WebBaseLoader para processar o HTML\n",
    "!pip install -q -U langchain-openai langchain chromadb beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb46a8ae-acd1-4a22-8989-f62b3619deb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Usando como base de conhecimento a URL: https://meraki.cisco.com/products/security-sd-wan/ ---\n",
      "1. Carregando contedo da web...\n",
      "2. Criando base de conhecimento em memria...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 13:39:39,384 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Construindo a cadeia de IA...\n",
      "4. Executando a consulta...\n",
      "\n",
      "--- Pergunta ---\n",
      "What are the main features of the Meraki MX security appliances according to this page?\n",
      "\n",
      "--- Gerando Resposta da IA ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 13:39:41,559 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-07-13 13:39:43,317 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# --- CONFIGURAO ---\n",
    "#  Cole sua chave de API da OpenAI aqui\n",
    "OPENAI_API_KEY = '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'\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "\n",
    "# URL da pgina da Cisco que usaremos como base de conhecimento\n",
    "# Exemplo: pgina da famlia de firewalls Meraki MX\n",
    "url = \"https://meraki.cisco.com/products/security-sd-wan/\"\n",
    "print(f\"--- Usando como base de conhecimento a URL: {url} ---\")\n",
    "\n",
    "\n",
    "# --- INCIO DO PROCESSO RAG ---\n",
    "\n",
    "# 1. Carregar o contedo da pgina web\n",
    "print(\"1. Carregando contedo da web...\")\n",
    "loader = WebBaseLoader(url)\n",
    "docs = loader.load()\n",
    "\n",
    "# 2. Dividir o contedo em pedaos e criar a base vetorial em memria\n",
    "print(\"2. Criando base de conhecimento em memria...\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 3. Construir a cadeia de resposta\n",
    "print(\"3. Construindo a cadeia de IA...\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "prompt_template = \"\"\"You are a helpful assistant. Answer the user's question based ONLY on the following context.\n",
    "If the information is not in the context, say that you don't know.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | llm | StrOutputParser()\n",
    "\n",
    "# 4. Fazer a pergunta e obter a resposta\n",
    "print(\"4. Executando a consulta...\")\n",
    "query = \"What are the main features of the Meraki MX security appliances according to this page?\"\n",
    "\n",
    "print(f\"\\n--- Pergunta ---\\n{query}\")\n",
    "print(\"\\n--- Gerando Resposta da IA ---\")\n",
    "response = rag_chain.invoke(query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca14ad85-0fcc-47a0-84f8-84160bf3f70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Carregando contedo da web...\n",
      "\n",
      "--- INCIO DO CONTEDO BRUTO EXTRADO (primeiros 2000 caracteres) ---\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Enterprise Network Security and SD-WAN | Cloud-Managed Solutions | Cisco Meraki\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Skip to primary navigation Skip to main content\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to content\n",
      "Skip to footer\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "United States (English)\n",
      "\n",
      "\n",
      "Australia (English)Brazil (Portugus)Canada (Franais)China ()France (Franais)Germany (Deutsch)Japan ()Korea ()Latin America (Espaol)United Kingdom (English)United States (English)Contact usLog In\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Experiences\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Technologies\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Touchpoints\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Resources\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                        Get a Demo\n",
      "                    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Quick Links\n",
      "\n",
      "\n",
      "All\n",
      "Product\n",
      "Case\n",
      "Collateral\n",
      "Webinars\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Experiences\n",
      "From hybrid workforces to smarter workspaces, bring together technology and touchpoints to deliver exceptional experiences.\n",
      " LEARN MORE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Experiences\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Workforce\n",
      "\n",
      "\n",
      "\n",
      "Hybrid WorkforceEnable teams with superior performance no matter the environment. \n",
      "\n",
      "\n",
      "\n",
      "Remote WorkforceEnable your workforce with the tools for success.Workspace\n",
      "\n",
      "\n",
      "\n",
      "Safe EnvironmentsProtect and securely connect what matters most, regardless of location.\n",
      "\n",
      "\n",
      "\n",
      "Smart SpacesFrom contact tracing to footpath optimization, create the office of the future. \n",
      "\n",
      "\n",
      "Cloud-managed IT\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Technologies\n",
      "Deliver exceptional experiences to people, places, and things with best-in-class Meraki technologies.\n",
      " LEARN MORE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Technologies\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Platform\n",
      "\n",
      "\n",
      "\n",
      "PlatformThe cloud-first foundation for your entire network.\n",
      "\n",
      "\n",
      "\n",
      "Meraki DashboardMonitor, manage, and optimize your network.  \n",
      "\n",
      "\n",
      "\n",
      "SASEConverge networking and security stacks.Access Products\n",
      "\n",
      "\n",
      "\n",
      "Wireless\n",
      "\n",
      "\n",
      "\n",
      "Switching\n",
      "\n",
      "\n",
      "\n",
      "Mobile Device ManagementIoT Products\n",
      "\n",
      "\n",
      "\n",
      "Smart Cameras\n",
      "\n",
      "\n",
      "\n",
      "SensorsSecure SD-WAN Products\n",
      "\n",
      "\n",
      "\n",
      "Security and SD-WAN\n",
      "\n",
      "\n",
      "\n",
      "Assurance\n",
      "\n",
      "\n",
      "\n",
      "Hybrid Cloud\n",
      "\n",
      "\n",
      "\n",
      "Unified SASE\n",
      "\n",
      "\n",
      "\n",
      "Cellular Gateways\n",
      "\n",
      "\n",
      "View all products\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Touchpoints\n",
      "Think beyond endpoint devices to all the people, places, and things connecting with the web.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "To\n",
      "--- FIM DO CONTEDO BRUTO EXTRADO ---\n",
      "\n",
      "2. Criando base de conhecimento em memria...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 13:42:08,744 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- CONTEXTO RECUPERADO PARA A PERGUNTA: 'What are the main features of the Meraki MX security appliances according to this page?' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 13:42:10,251 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- CHUNK RELEVANTE 1 ---\n",
      "\n",
      "Instant, always-on visibility for critical SaaS apps at scale.\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tProactive monitoring \t\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\t\t\t\tIdentify problems before users are impacted, whether apps are in use or not.\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tSmart root-cause analysis \t\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\t\t\t\tML-powered corrective recommendations, including confidence ratings across LAN, WAN, and app servers.\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\tTRY IT ON \t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Resource Hub\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Datasheet\n",
      "\n",
      "\n",
      "MX family datasheet\n",
      "\n",
      "Learn more about the multifunctional network security and SD-WAN building blocks of a SASE architecture.\n",
      "\n",
      "\n",
      "Learn more\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Webinar\n",
      "\n",
      "\n",
      "Introduction to Cisco Meraki Security and SD-WAN\n",
      "\n",
      "Hear about the security and SD-WAN features of Meraki MX appliances and get a deep-dive demo.\n",
      "\n",
      "\n",
      "Learn More \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "At-a-Glance\n",
      "\n",
      "\n",
      "Cisco SD-WAN powered by Meraki overview\n",
      "\n",
      "--- CHUNK RELEVANTE 2 ---\n",
      "\n",
      "Instant, always-on visibility for critical SaaS apps at scale.\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tProactive monitoring \t\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\t\t\t\tIdentify problems before users are impacted, whether apps are in use or not.\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tSmart root-cause analysis \t\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\t\t\t\tML-powered corrective recommendations, including confidence ratings across LAN, WAN, and app servers.\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\tTRY IT ON \t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Resource Hub\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Datasheet\n",
      "\n",
      "\n",
      "MX family datasheet\n",
      "\n",
      "Learn more about the multifunctional network security and SD-WAN building blocks of a SASE architecture.\n",
      "\n",
      "\n",
      "Learn more\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Webinar\n",
      "\n",
      "\n",
      "Introduction to Cisco Meraki Security and SD-WAN\n",
      "\n",
      "Hear about the security and SD-WAN features of Meraki MX appliances and get a deep-dive demo.\n",
      "\n",
      "\n",
      "Learn More \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "At-a-Glance\n",
      "\n",
      "\n",
      "Cisco SD-WAN powered by Meraki overview\n",
      "\n",
      "--- CHUNK RELEVANTE 3 ---\n",
      "\n",
      "Hear about the security and SD-WAN features of Meraki MX appliances and get a deep-dive demo.\n",
      "\n",
      "\n",
      "Learn More \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "At-a-Glance\n",
      "\n",
      "\n",
      "Cisco SD-WAN powered by Meraki overview\n",
      "\n",
      "Get SD-WAN defined along with key use cases and a view of how SD-WAN powered by Meraki works.\n",
      "\n",
      "\n",
      "Learn more\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Blog\n",
      "\n",
      "\n",
      "When to use on-premises or cloud security?\n",
      "\n",
      "Discover the best practices for building a cloud-enabled network security model.\n",
      "\n",
      "\n",
      "Learn more\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Nothing but the best for all your locations\n",
      "Choose a best-fit mix of secure Cisco Meraki and Catalyst SD-WAN, and streamline management with a single dashboard.\n",
      "\n",
      "\n",
      "Try it now\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Keeping 150+ locations secure and connected while reducing costs with SD-WAN.\n",
      "\n",
      "Cisco SD-WAN powered by Meraki provides branches with 20x more bandwidth and 4G backup\n",
      "20% savings on WAN after replacing costly MPLS with broadband and fiber\n",
      "\n",
      "Drove 40% cost savings across 42 financial services sites.\n",
      "Watch case study\n",
      "\n",
      "--- CHUNK RELEVANTE 4 ---\n",
      "\n",
      "NEXT CASE STUDY                                        \n",
      "Drove 40% cost savings across 42 financial services sites.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A complete tool kit to build a complete experience.\n",
      "Meraki security and SD-WAN appliances are uniquely designed to work with our teleworker and cellular gateways, wireless access points, switches, MDM, and IoT. Build experiences at scale with one platform.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Explore remote work\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Explore cellular gateways\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "EXPLORE HYBRID CLOUD\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Experience secure SD-WAN in three clicks.\n",
      "Mouse not included.\n",
      "\n",
      "Start Your Free Trial\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\tCOMPANY\n",
      "\t\t\t\t\t\t\t\n",
      "\n",
      "About Meraki\n",
      "\n",
      "\n",
      "Careers\n",
      "\n",
      "\n",
      "Privacy Statement\n",
      "\n",
      "\n",
      "Trust\n",
      "\n",
      "\n",
      "GDPR\n",
      "\n",
      "\n",
      "Terms of Use\n",
      "\n",
      "\n",
      "Cookies\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\tPARTNERS\n",
      "\t\t\t\t\t\t\t\n",
      "\n",
      "Meraki Partner Portal Login\n",
      "\n",
      "\n",
      "Cisco Partner Program\n",
      "\n",
      "\n",
      "Managed service providers\n",
      "\n",
      "\n",
      "Service provider\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\tGET STARTED\n",
      "\t\t\t\t\t\t\t\n",
      "\n",
      "Contact us\n",
      "\n",
      "\n",
      "Demo\n",
      "\n",
      "\n",
      "Start your trial\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\tRESOURCES\n",
      "\t\t\t\t\t\t\t\n",
      "\n",
      "Webinars\n",
      "--- FIM DO CONTEXTO RECUPERADO ---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "\n",
    "# --- INCIO DO PROCESSO DE DEPURAO ---\n",
    "\n",
    "# 1. Carregar o contedo da pgina web\n",
    "print(\"1. Carregando contedo da web...\")\n",
    "loader = WebBaseLoader(url)\n",
    "docs = loader.load()\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO DE DEPURAO 1: IMPRIMIR O CONTEDO BRUTO CARREGADO\n",
    "# Vamos ver o que o WebBaseLoader realmente \"viu\" na pgina.\n",
    "# ==============================================================================\n",
    "print(\"\\n--- INCIO DO CONTEDO BRUTO EXTRADO (primeiros 2000 caracteres) ---\")\n",
    "if docs:\n",
    "    print(docs[0].page_content[:2000])\n",
    "else:\n",
    "    print(\"Nenhum contedo foi extrado da pgina.\")\n",
    "print(\"--- FIM DO CONTEDO BRUTO EXTRADO ---\\n\")\n",
    "\n",
    "\n",
    "# 2. Dividir e criar a base vetorial\n",
    "print(\"2. Criando base de conhecimento em memria...\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 3. Fazer a pergunta e inspecionar o contexto recuperado\n",
    "query = \"What are the main features of the Meraki MX security appliances according to this page?\"\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO DE DEPURAO 2: VERIFICAR O CONTEXTO RECUPERADO ANTES DE ENVIAR AO LLM\n",
    "# Vamos ver exatamente quais pedaos de texto foram selecionados para responder  pergunta.\n",
    "# ==============================================================================\n",
    "print(f\"--- CONTEXTO RECUPERADO PARA A PERGUNTA: '{query}' ---\")\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"\\n--- CHUNK RELEVANTE {i+1} ---\\n\")\n",
    "    print(doc.page_content)\n",
    "print(\"--- FIM DO CONTEXTO RECUPERADO ---\")\n",
    "\n",
    "# 4. (Opcional) Voc pode comentar o resto do cdigo se quiser apenas depurar,\n",
    "# ou deix-lo para ver se com algum ajuste o LLM agora responde.\n",
    "\n",
    "# print(\"\\n--- Gerando Resposta Final da IA ---\")\n",
    "# llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "# prompt_template = \"Answer the question based ONLY on the following context:\\n{context}\\nQuestion: {question}\\nAnswer:\"\n",
    "# prompt = PromptTemplate.from_template(prompt_template)\n",
    "# rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | llm | StrOutputParser()\n",
    "# response = rag_chain.invoke(query)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990ab2b8-e636-4097-9b71-2918dde5df28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ad7c9f-2abd-416f-912c-60ec5b3c59a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7a861b-e404-4e75-a32a-fa5217f8c7d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31d95ad0-5055-4ee7-ad33-f3e729c2f677",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U langchain-openai tavily-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f28731-cc5f-476c-8620-2f8d6006e0d1",
   "metadata": {},
   "source": [
    "## Editando meu agente de IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f986eb5-64e4-4abf-abaf-72684e1bdbbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "144f70f0-b59b-4e5e-a00d-b9e94f9f5ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Giovani\\AppData\\Local\\Temp\\ipykernel_8032\\1128514704.py:23: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  search_tool = TavilySearchResults(max_results=3)\n",
      "C:\\Users\\Giovani\\anaconda3\\Lib\\site-packages\\langsmith\\client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pergunta para o Agente ---\n",
      "What are the latest security advisories for Cisco Firepower 1000 series published in 2025?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 13:47:33,314 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'Cisco Firepower 1000 series security advisories 2025'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Cisco Adaptive Security Appliance Software, Firepower Threat ...', 'url': 'https://sec.cloudapps.cisco.com/security/center/content/CiscoSecurityAdvisory/cisco-sa-multiprod-ikev2-dos-gPctUqv2', 'content': 'advisory is available at the following link: advisory is part of the May 2025 release of the Cisco IOS and IOS XE Software Security Advisory Bundled Publication. For a complete list of the advisories and links to them, seeCisco Event Response: May 2025 Semiannual Cisco IOS and IOS XE Software Security Advisory Bundled Publication.Affected ProductsVulnerable ProductsThis vulnerability affects Cisco products if they are running a vulnerable release of Cisco ASA, FTD, IOS, or IOS XE Software and [...] This advisory is available at the following link:\\n\\nThis advisory is part of the May 2025 release of the Cisco IOS and IOS XE Software Security Advisory Bundled Publication. For a complete list of the advisories and links to them, see Cisco Event Response: May 2025 Semiannual Cisco IOS and IOS XE Software Security Advisory Bundled Publication.\\n\\nAffected Products\\n\\nVulnerable Products [...] NotificationsSubscribeRelated to This AdvisoryCisco Event Response: May 2025 Semiannual Cisco IOS and IOS XE Software Security Advisory Bundled Publication | Cisco Security AdvisoryCisco Adaptive Security Appliance Software, Firepower Threat Defense Software, IOS Software, and IOS XE Software IKEv2 Denial of Service VulnerabilityHighAdvisory ID:cisco-sa-multiprod-ikev2-dos-gPctUqv2First Published:2025 May 7 16:00 GMTVersion 1.0:FinalWorkarounds:No workarounds availableCisco Bug', 'score': 0.8145405}, {'title': 'Cisco security advisory (AV25-356)', 'url': 'https://www.cyber.gc.ca/en/alerts-advisories/cisco-security-advisory-av25-356', 'content': 'Cisco security advisory (AV25-356)\\n==================================\\n\\nSerial number:AV25-356\\n\\nDate:June 18, 2025\\n\\nOn June 18, 2025, Cisco published security advisories to address vulnerabilities in the following products: [...] The Cyber Centre encourages users and administrators to review the provided web links, perform the suggested mitigations and apply the necessary updates if available.\\n\\n   ClamAV UDF File Parsing Out-of-Bounds Read Information Disclosure Vulnerability\\n   Cisco Meraki MX and Z Series AnyConnect VPN with Client Certificate Authentication Denial of Service Vulnerability\\n   Cisco Security Advisories\\n\\nDate modified: 2025-06-18\\n\\nAbout this site\\n---------------\\n\\n### Government of Canada', 'score': 0.7763013}, {'title': 'Cisco Security Advisories', 'url': 'https://sec.cloudapps.cisco.com/security/center/publicationListing.x', 'content': '| Image 14Multiple Cisco Products Unauthenticated Remote Code Execution in Erlang/OTP SSH Server: April 2025Critical CVE-2025-32433  on an affected device.The vulnerability is due to a flaw in the handling of SSH messages Read More... | [...] | Image 17Cisco Integrated Management Controller Privilege Escalation VulnerabilityHigh CVE-2025-20261  for Cisco UCS B-Series, UCS C-Series, UCS S-Series, and UCS X-Series Servers could allow an authenticated, remote attacker to access internal services with elevated privileges.This Read More... | [...] | Image 9Cisco Identity Services Engine Unauthenticated Remote Code Execution VulnerabilitiesCritical CVE-2025-20281 CVE-2025-20282  and Cisco ISE Passive Identity Connector (ISE-PIC) could allow an unauthenticated, remote attacker to issue commands on the underlying operating system as the root user.For more information about these Read More... |', 'score': 0.6202772}]\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 13:47:39,485 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mHere are some of the latest security advisories for the Cisco Firepower 1000 series published in 2025:\n",
      "\n",
      "1. **Cisco Adaptive Security Appliance Software, Firepower Threat Defense Software, IOS Software, and IOS XE Software IKEv2 Denial of Service Vulnerability**\n",
      "   - **Advisory ID:** cisco-sa-multiprod-ikev2-dos-gPctUqv2\n",
      "   - **Published:** May 7, 2025\n",
      "   - **Description:** This advisory is part of the May 2025 release of the Cisco IOS and IOS XE Software Security Advisory Bundled Publication. It addresses a vulnerability affecting Cisco products running a vulnerable release of Cisco ASA, FTD, IOS, or IOS XE Software.\n",
      "   - **Link:** [Cisco Security Advisory](https://sec.cloudapps.cisco.com/security/center/content/CiscoSecurityAdvisory/cisco-sa-multiprod-ikev2-dos-gPctUqv2)\n",
      "\n",
      "2. **Cisco Security Advisory (AV25-356)**\n",
      "   - **Published:** June 18, 2025\n",
      "   - **Description:** This advisory addresses vulnerabilities in various Cisco products, including ClamAV UDF File Parsing Out-of-Bounds Read Information Disclosure Vulnerability and Cisco Meraki MX and Z Series AnyConnect VPN with Client Certificate Authentication Denial of Service Vulnerability.\n",
      "   - **Link:** [Cisco Security Advisory AV25-356](https://www.cyber.gc.ca/en/alerts-advisories/cisco-security-advisory-av25-356)\n",
      "\n",
      "For more detailed information, you can visit the Cisco Security Advisories page or the specific links provided.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "--- Resposta Final do Agente ---\n",
      "Here are some of the latest security advisories for the Cisco Firepower 1000 series published in 2025:\n",
      "\n",
      "1. **Cisco Adaptive Security Appliance Software, Firepower Threat Defense Software, IOS Software, and IOS XE Software IKEv2 Denial of Service Vulnerability**\n",
      "   - **Advisory ID:** cisco-sa-multiprod-ikev2-dos-gPctUqv2\n",
      "   - **Published:** May 7, 2025\n",
      "   - **Description:** This advisory is part of the May 2025 release of the Cisco IOS and IOS XE Software Security Advisory Bundled Publication. It addresses a vulnerability affecting Cisco products running a vulnerable release of Cisco ASA, FTD, IOS, or IOS XE Software.\n",
      "   - **Link:** [Cisco Security Advisory](https://sec.cloudapps.cisco.com/security/center/content/CiscoSecurityAdvisory/cisco-sa-multiprod-ikev2-dos-gPctUqv2)\n",
      "\n",
      "2. **Cisco Security Advisory (AV25-356)**\n",
      "   - **Published:** June 18, 2025\n",
      "   - **Description:** This advisory addresses vulnerabilities in various Cisco products, including ClamAV UDF File Parsing Out-of-Bounds Read Information Disclosure Vulnerability and Cisco Meraki MX and Z Series AnyConnect VPN with Client Certificate Authentication Denial of Service Vulnerability.\n",
      "   - **Link:** [Cisco Security Advisory AV25-356](https://www.cyber.gc.ca/en/alerts-advisories/cisco-security-advisory-av25-356)\n",
      "\n",
      "For more detailed information, you can visit the Cisco Security Advisories page or the specific links provided.\n"
     ]
    }
   ],
   "source": [
    "# 1. Instala as bibliotecas necessrias\n",
    "#!pip install -q -U langchain-openai tavily-python\n",
    "\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_tools_agent, AgentExecutor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- CONFIGURAO DAS CHAVES DE API ---\n",
    "#  Cole suas chaves aqui. Use o gerenciador de segredos do Colab se preferir.\n",
    "OPENAI_API_KEY = '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'\n",
    "TAVILY_API_KEY = \"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\" # <-- SUA CHAVE DA TAVILY AQUI\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY\n",
    "\n",
    "\n",
    "# --- CONSTRUO DO AGENTE ---\n",
    "\n",
    "# 2. Defina as ferramentas que o agente pode usar\n",
    "# Neste caso, apenas a busca na web da Tavily. `max_results=3` limita a 3 resultados.\n",
    "search_tool = TavilySearchResults(max_results=3)\n",
    "tools = [search_tool]\n",
    "\n",
    "# 3. Crie o agente\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# Puxa um prompt pr-construdo da comunidade LangChain, otimizado para agentes\n",
    "# Este prompt instrui o LLM sobre como pensar e usar as ferramentas\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "\n",
    "# Cria o agente, unindo o LLM, as ferramentas e o prompt\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "\n",
    "# Cria o \"Executor\", que  o que de fato roda o ciclo de pensamento do agente\n",
    "# verbose=True  MUITO importante para vermos o \"raciocnio\" do agente\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "# --- TESTE DO AGENTE ---\n",
    "query = \"What are the latest security advisories for Cisco Firepower 1000 series published in 2025?\"\n",
    "\n",
    "print(f\"--- Pergunta para o Agente ---\\n{query}\")\n",
    "\n",
    "# Invoca o agente e aguarda a resposta final\n",
    "response = agent_executor.invoke({\"input\": query})\n",
    "\n",
    "print(\"\\n--- Resposta Final do Agente ---\")\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79792347-39d5-4cc4-8fc0-f048ac98ed97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d448cc62-0118-498c-902a-2521cc72d961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4029a433-7ff0-48be-97b8-30eca1f59c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfce1c81-bf60-411d-97e2-75f9974c0da7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4df406d-421e-4859-b5bf-cf8c1c7ae872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eff00a-f4aa-4583-9c8a-b858c3dc7043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343219a7-7257-4cfe-a60c-fde064d26316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40d8e67-288b-44cd-90d3-6b9e3f845994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38ed038-3824-4782-a8cd-f4884dba41fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1036e5-1ae6-4872-9a51-6f7d342d5b26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "668b1ba5-866e-499a-b306-4b6a9fc3db39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instalaes necessrias\n",
    "#!pip install -q -U langchain-openai tavily-python langchain beautifulsoup4 chromadb pypdf unstructured\n",
    "\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_tools_agent, AgentExecutor\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- CONFIGURAO DAS CHAVES DE API ---\n",
    "#  Cole suas chaves aqui.\n",
    "OPENAI_API_KEY = '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'\n",
    "TAVILY_API_KEY = \"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\" # <-- SUA CHAVE DA TAVILY AQUI\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fea07ad3-91fa-4fdf-95f4-8e4f1a6a1e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Criando ferramenta de busca de arquivos locais... ---\n",
      "Ferramenta de busca de arquivos criada com sucesso.\n",
      "\n",
      "\n",
      "--- EXECUTANDO TESTE 1 (usando o arquivo local) ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `cisco_pricelist_search` with `{'query': 'C9200L-24P-4G-A'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCategory;Sub_Category;Part Number;Desc;price;Elig %: Hardware;Switches;C9200L-24PXG4X-EDU;Catalyst 9200L 24-p\n",
      "None: 8xmGig,16x1G,4x10G uplinks,K12;$6.740,00;100%\n",
      "\n",
      "Category;Sub_Category;Part Number;Desc;price;Elig %: Hardware;Switches;C9200L-24PXG2Y-EDU;Catalyst 9200L 24-p\n",
      "None: 8xmGig,16x1G,2x25G uplinks,K12;$7.290,00;100%\n",
      "\n",
      "Category;Sub_Category;Part Number;Desc;price;Elig %: Hardware;Switches;C9200L-48PXG4X-EDU;Catalyst 9200L 48-p\n",
      "None: 12xmGig,36x1G,4x10G uplinks,K12;$10.380,00;100%\n",
      "\n",
      "Category;Sub_Category;Part Number;Desc;price;Elig %: Hardware;Switches;C9200L-48PXG2Y-EDU;Catalyst 9200L 48-p\n",
      "None: 12xmGig,36x1G,2x25G uplinks,K12;$10.930,00;100%\u001b[0m\u001b[32;1m\u001b[1;3mI couldn't find the list price for the specific part number C9200L-24P-4G-A in the available data. If you have any other questions or need further assistance, feel free to ask!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "--- Resposta Final (do arquivo) ---\n",
      "I couldn't find the list price for the specific part number C9200L-24P-4G-A in the available data. If you have any other questions or need further assistance, feel free to ask!\n",
      "\n",
      "\n",
      "--- EXECUTANDO TESTE 2 (usando a busca na web) ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_search` with `{'query': 'Cisco quarterly earnings October 2023'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m[{'title': 'Investor Relations - CISCO REPORTS FIRST QUARTER EARNINGS', 'url': 'https://investor.cisco.com/news/news-details/2023/CISCO-REPORTS-FIRST-QUARTER-EARNINGS/default.aspx', 'content': 'Cisco today reported first quarter results for the period ended October 28, 2023. Cisco reported first quarter revenue of $14.7 billion, net income on a generally accepted accounting principles (GAAP) basis of $3.6 billion or $0.89 per share, and non-GAAP net income of $4.5 billion or $1.11 per share. [...] Three Months Ended\\nOctober 28, 2023\\nGross Margin Percentage:\\nAmericas 66.2%\\nEMEA 69.5%\\nAPJC 67.0%\\n\\nCISCO SYSTEMS, INC.\\nREVENUE FOR GROUPS OF SIMILAR PRODUCTS AND SERVICES\\n(In millions, except percentages)\\n\\nThree Months Ended\\nOctober 28, 2023\\nAmount Y/Y %\\nRevenue:\\nNetworking$ 8,822 10%\\nSecurity 1,010 4%\\nCollaboration 1,117 3%\\nObservability 190 21%\\nTotal Product 11,139 9%\\nServices 3,529 4%\\nTotal$ 14,668 8%\\n\\nAmounts may not sum and percentages may not recalculate due to rounding. [...] Net income per share:\\nBasic$ 0.90$ 0.65\\nDiluted$ 0.89$ 0.65\\nShares used in per-share calculation:\\nBasic 4,057 4,108\\nDiluted 4,087 4,116\\n\\nCISCO SYSTEMS, INC.\\nREVENUE BY SEGMENT\\n(In millions, except percentages)\\n\\nThree Months Ended\\nOctober 28, 2023\\nAmount Y/Y %\\nRevenue:\\nAmericas$ 9,022 14%\\nEMEA 3,664%\\nAPJC 1,982(3)%\\nTotal$ 14,668 8%\\n\\nAmounts may not sum and percentages may not recalculate due to rounding.\\n\\nCISCO SYSTEMS, INC.\\nGROSS MARGIN PERCENTAGE BY SEGMENT\\n(In percentages)', 'score': 0.9485422}, {'title': 'Cisco Reports Fourth Quarter And Fiscal Year 2023 Earnings', 'url': 'https://newsroom.cisco.com/c/r/newsroom/en/us/a/y2023/m08/cisco-reports-fourth-quarter-and-fiscal-year-2023-earnings.html', 'content': 'Cisco has declared a quarterly dividend of $0.39 per common share to be paid on October 25, 2023, to all stockholders of record as of the close of business on October 4, 2023. Future dividends will be subject to Board approval.\\n\\nFinancial Summary\\n\\nAll comparative percentages are on a year-over-year basis unless otherwise noted.\\n\\nQ4 FY 2023 Highlights [...] | Current | $       13,908 |  | $       13,249 |  | $       12,784 |\\n| Noncurrent | 11,642 |  | 11,011 |  | 10,480 |\\n| Total | $       25,550 |  | $       24,260 |  | $       23,264 | [...] | Services |  | 3,553 |  | 4 % |  | 13,856 |  | 2 % |\\n| Total |  | $       15,203 |  | 16 % |  | $       56,998 |  | 11 % |', 'score': 0.92731744}, {'title': 'Investor Relations - CISCO REPORTS THIRD QUARTER EARNINGS', 'url': 'https://investor.cisco.com/news/news-details/2025/CISCO-REPORTS-THIRD-QUARTER-EARNINGS/default.aspx', 'content': 'per Share Amount Amount\\nFiscal 2025\\nApril 26, 2025$ 0.41$ 1,627 25$ 59.78$ 1,504$ 3,131\\nJanuary 25, 2025$ 0.40$ 1,593 21$ 58.58$ 1,236$ 2,829\\nOctober 26, 2024$ 0.40$ 1,592 40$ 49.56$ 2,003$ 3,595\\n\\nFiscal 2024\\nJuly 27, 2024$ 0.40$ 1,606 43$ 46.80$ 2,002$ 3,608\\nApril 27, 2024$ 0.40$ 1,615 26$ 49.22$ 1,256$ 2,871\\nJanuary 27, 2024$ 0.39$ 1,583 25$ 49.54$ 1,254$ 2,837\\nOctober 28, 2023$ 0.39$ 1,580 23$ 54.53$ 1,252$ 2,832\\n\\nCISCO SYSTEMS, INC.\\n\\nRECONCILIATIONS OF GAAP TO NON-GAAP MEASURES', 'score': 0.8479807}]\u001b[0m\u001b[32;1m\u001b[1;3mCisco recently reported its first quarter earnings for the period ending October 28, 2023. The company announced a revenue of $14.7 billion, with a net income of $3.6 billion on a GAAP basis, translating to $0.89 per share. On a non-GAAP basis, the net income was $4.5 billion or $1.11 per share.\n",
      "\n",
      "Here are some additional details from the report:\n",
      "\n",
      "- **Revenue by Product and Service:**\n",
      "  - Networking: $8.822 billion (10% increase year-over-year)\n",
      "  - Security: $1.010 billion (4% increase)\n",
      "  - Collaboration: $1.117 billion (3% increase)\n",
      "  - Observability: $190 million (21% increase)\n",
      "  - Total Product Revenue: $11.139 billion (9% increase)\n",
      "  - Services Revenue: $3.529 billion (4% increase)\n",
      "\n",
      "- **Revenue by Region:**\n",
      "  - Americas: $9.022 billion (14% increase)\n",
      "  - EMEA: $3.664 billion (no change)\n",
      "  - APJC: $1.982 billion (3% decrease)\n",
      "\n",
      "- **Gross Margin Percentage:**\n",
      "  - Americas: 66.2%\n",
      "  - EMEA: 69.5%\n",
      "  - APJC: 67.0%\n",
      "\n",
      "For more detailed information, you can view the full report on Cisco's [Investor Relations page](https://investor.cisco.com/news/news-details/2023/CISCO-REPORTS-FIRST-QUARTER-EARNINGS/default.aspx).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "--- Resposta Final (da web) ---\n",
      "Cisco recently reported its first quarter earnings for the period ending October 28, 2023. The company announced a revenue of $14.7 billion, with a net income of $3.6 billion on a GAAP basis, translating to $0.89 per share. On a non-GAAP basis, the net income was $4.5 billion or $1.11 per share.\n",
      "\n",
      "Here are some additional details from the report:\n",
      "\n",
      "- **Revenue by Product and Service:**\n",
      "  - Networking: $8.822 billion (10% increase year-over-year)\n",
      "  - Security: $1.010 billion (4% increase)\n",
      "  - Collaboration: $1.117 billion (3% increase)\n",
      "  - Observability: $190 million (21% increase)\n",
      "  - Total Product Revenue: $11.139 billion (9% increase)\n",
      "  - Services Revenue: $3.529 billion (4% increase)\n",
      "\n",
      "- **Revenue by Region:**\n",
      "  - Americas: $9.022 billion (14% increase)\n",
      "  - EMEA: $3.664 billion (no change)\n",
      "  - APJC: $1.982 billion (3% decrease)\n",
      "\n",
      "- **Gross Margin Percentage:**\n",
      "  - Americas: 66.2%\n",
      "  - EMEA: 69.5%\n",
      "  - APJC: 67.0%\n",
      "\n",
      "For more detailed information, you can view the full report on Cisco's [Investor Relations page](https://investor.cisco.com/news/news-details/2023/CISCO-REPORTS-FIRST-QUARTER-EARNINGS/default.aspx).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# --- PASSO A: CRIAR A FERRAMENTA DE BUSCA NOS SEUS ARQUIVOS ---\n",
    "\n",
    "print(\"--- Criando ferramenta de busca de arquivos locais... ---\")\n",
    "# Carrega os dados do seu arquivo CSV\n",
    "# Certifique-se de que o arquivo 'Pricelist.csv' est na pasta 'data/raw/'\n",
    "loader = CSVLoader(file_path='data/raw/Pricelist.csv')\n",
    "docs = loader.load()\n",
    "\n",
    "# Divide os documentos e cria o vector store\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Cria a ferramenta de busca de arquivos (RAG)\n",
    "# A 'description'  MUITO importante.  como o agente sabe quando usar esta ferramenta.\n",
    "file_search_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"cisco_pricelist_search\",\n",
    "    \"Use this tool when you need to find information about Cisco product part numbers, descriptions, or list prices from the NCDPI pricelist file.\"\n",
    ")\n",
    "print(\"Ferramenta de busca de arquivos criada com sucesso.\\n\")\n",
    "\n",
    "\n",
    "# --- PASSO B: DEFINIR A FERRAMENTA DE BUSCA NA WEB ---\n",
    "web_search_tool = TavilySearchResults(name=\"web_search\", max_results=3)\n",
    "\n",
    "\n",
    "# --- PASSO C: MONTAR O AGENTE COM AS DUAS FERRAMENTAS ---\n",
    "\n",
    "# Agora, a lista de ferramentas contm tanto a busca em arquivos quanto a busca na web\n",
    "tools = [file_search_tool, web_search_tool]\n",
    "\n",
    "# O restante da criao do agente  igual, mas agora ele  mais poderoso\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "# --- PASSO D: TESTAR O AGENTE HBRIDO ---\n",
    "\n",
    "# Teste 1: Uma pergunta que deve ser respondida pelo ARQUIVO CSV\n",
    "print(\"\\n--- EXECUTANDO TESTE 1 (usando o arquivo local) ---\")\n",
    "query_local = \"What is the list price for part number C9200L-24P-4G-A?\"\n",
    "response_local = agent_executor.invoke({\"input\": query_local})\n",
    "print(\"\\n--- Resposta Final (do arquivo) ---\")\n",
    "print(response_local['output'])\n",
    "\n",
    "# Teste 2: Uma pergunta que precisa da INTERNET\n",
    "print(\"\\n\\n--- EXECUTANDO TESTE 2 (usando a busca na web) ---\")\n",
    "query_web = \"What is the latest news about Cisco's quarterly earnings?\"\n",
    "response_web = agent_executor.invoke({\"input\": query_web})\n",
    "print(\"\\n--- Resposta Final (da web) ---\")\n",
    "print(response_web['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5a2ce7-76e2-4942-936a-382be56e1489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccdfa3b4-122a-4c1f-ae63-c7b13e8f85da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando o processo de indexao ---\n",
      "Documento CSV carregado com 4267 linhas.\n",
      "Documento dividido em 4267 chunks.\n",
      "Criando e salvando o banco de dados vetorial em: 'data/processed/cisco_pricelist_db'...\n",
      "\n",
      "--- Processo de Indexao Concludo! ---\n",
      "Sua base de conhecimento foi criada e salva no disco.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "print(\"--- Iniciando o processo de indexao ---\")\n",
    "\n",
    "# --- Carregar o documento ---\n",
    "# Certifique-se de que o seu arquivo est no caminho correto\n",
    "loader = CSVLoader(file_path='data/raw/Pricelist.csv') \n",
    "docs = loader.load()\n",
    "print(f\"Documento CSV carregado com {len(docs)} linhas.\")\n",
    "\n",
    "# --- Dividir em chunks ---\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "print(f\"Documento dividido em {len(splits)} chunks.\")\n",
    "\n",
    "# --- Criar e Salvar o Banco de Dados Vetorial ---\n",
    "# Define o local onde o banco de dados ser salvo\n",
    "vector_db_path = 'data/processed/cisco_pricelist_db'\n",
    "\n",
    "print(f\"Criando e salvando o banco de dados vetorial em: '{vector_db_path}'...\")\n",
    "# Cria o vector store e usa 'persist_directory' para salv-lo\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    persist_directory=vector_db_path\n",
    ")\n",
    "\n",
    "print(\"\\n--- Processo de Indexao Concludo! ---\")\n",
    "print(\"Sua base de conhecimento foi criada e salva no disco.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c0e0fe2-95c5-4c7a-b56f-1395185856f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Carregando a base de conhecimento do disco... ---\n",
      "Base de conhecimento carregada.\n",
      "\n",
      "--- Executando a pergunta: What is the price for part number C9200L-24P-4G-A? ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `cisco_product_and_price_search` with `{'query': 'C9200L-24P-4G-A'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCategory;Sub_Category;Part Number;Desc;price;Elig %: Hardware;Switches;C9200L-24PXG4X-EDU;Catalyst 9200L 24-p\n",
      "None: 8xmGig,16x1G,4x10G uplinks,K12;$6.740,00;100%\n",
      "\n",
      "Category;Sub_Category;Part Number;Desc;price;Elig %: Hardware;Switches;C9200L-24PXG2Y-EDU;Catalyst 9200L 24-p\n",
      "None: 8xmGig,16x1G,2x25G uplinks,K12;$7.290,00;100%\n",
      "\n",
      "Category;Sub_Category;Part Number;Desc;price;Elig %: Hardware;Switches;C9200L-48PXG4X-EDU;Catalyst 9200L 48-p\n",
      "None: 12xmGig,36x1G,4x10G uplinks,K12;$10.380,00;100%\n",
      "\n",
      "Category;Sub_Category;Part Number;Desc;price;Elig %: Hardware;Switches;C9200L-48PXG2Y-EDU;Catalyst 9200L 48-p\n",
      "None: 12xmGig,36x1G,2x25G uplinks,K12;$10.930,00;100%\u001b[0m\u001b[32;1m\u001b[1;3mI couldn't find the exact part number C9200L-24P-4G-A in the database. However, I found similar part numbers for the Catalyst 9200L series:\n",
      "\n",
      "1. **C9200L-24PXG4X-EDU**: $6,740.00\n",
      "2. **C9200L-24PXG2Y-EDU**: $7,290.00\n",
      "3. **C9200L-48PXG4X-EDU**: $10,380.00\n",
      "4. **C9200L-48PXG2Y-EDU**: $10,930.00\n",
      "\n",
      "If you need more specific information or a different part number, please let me know!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "--- Resposta Final do Agente ---\n",
      "I couldn't find the exact part number C9200L-24P-4G-A in the database. However, I found similar part numbers for the Catalyst 9200L series:\n",
      "\n",
      "1. **C9200L-24PXG4X-EDU**: $6,740.00\n",
      "2. **C9200L-24PXG2Y-EDU**: $7,290.00\n",
      "3. **C9200L-48PXG4X-EDU**: $10,380.00\n",
      "4. **C9200L-48PXG2Y-EDU**: $10,930.00\n",
      "\n",
      "If you need more specific information or a different part number, please let me know!\n"
     ]
    }
   ],
   "source": [
    "# --- PASSO A: CARREGAR O BANCO DE DADOS VETORIAL EXISTENTE ---\n",
    "print(\"--- Carregando a base de conhecimento do disco... ---\")\n",
    "vector_db_path = 'data/processed/cisco_pricelist_db'\n",
    "\n",
    "# Carrega o banco de dados vetorial que foi salvo no passo anterior\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=vector_db_path,\n",
    "    embedding_function=OpenAIEmbeddings()\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "print(\"Base de conhecimento carregada.\\n\")\n",
    "\n",
    "\n",
    "# --- PASSO B: CRIAR A FERRAMENTA DE BUSCA DE ARQUIVOS ---\n",
    "file_search_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"cisco_product_and_price_search\",\n",
    "    \"Use this tool when you need to find information about Cisco product part numbers, descriptions, or prices. It contains a detailed price.\"\n",
    ")\n",
    "\n",
    "\n",
    "# --- PASSO C: DEFINIR A FERRAMENTA DE BUSCA NA WEB E MONTAR O AGENTE ---\n",
    "web_search_tool = TavilySearchResults(name=\"web_search\", max_results=3)\n",
    "tools = [file_search_tool, web_search_tool]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "# --- PASSO D: TESTAR O AGENTE HBRIDO ---\n",
    "query = \"What is the price for part number C9200L-24P-4G-A?\"\n",
    "print(f\"--- Executando a pergunta: {query} ---\")\n",
    "\n",
    "response = agent_executor.invoke({\"input\": query})\n",
    "\n",
    "print(\"\\n--- Resposta Final do Agente ---\")\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14512d5-de55-4a8e-9437-c9f8f61b41ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1e789ffa-064c-4079-9b63-02dd5b1ead19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tentando carregar o arquivo Excel de: data/raw/Attachment_3_NCDPI_eRate_IFB_Pricelist.xlsx\n",
      "Arquivo Excel carregado com sucesso.\n",
      "Arquivo convertido com sucesso e salvo como: data/raw/Pricelist_corrigido.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Define os caminhos para os arquivos de entrada e sada\n",
    "# Certifique-se de que o nome do arquivo de entrada est correto\n",
    "input_excel_path = 'data/raw/Attachment_3_NCDPI_eRate_IFB_Pricelist.xlsx'\n",
    "output_csv_path = 'data/raw/Pricelist_corrigido.csv'\n",
    "\n",
    "print(f\"Tentando carregar o arquivo Excel de: {input_excel_path}\")\n",
    "\n",
    "try:\n",
    "    # Carrega o arquivo .xlsx para um DataFrame do Pandas\n",
    "    df = pd.read_excel(input_excel_path)\n",
    "    print(\"Arquivo Excel carregado com sucesso.\")\n",
    "\n",
    "    # Salva o DataFrame como um novo arquivo .csv\n",
    "    # A parte mais importante  o 'quoting=csv.QUOTE_ALL'\n",
    "    df.to_csv(\n",
    "        output_csv_path, \n",
    "        index=False,                  # No salva o ndice do DataFrame como uma coluna\n",
    "        encoding='utf-8',             # Define a codificao para evitar erros de caracteres\n",
    "        quoting=csv.QUOTE_ALL         # Fora que todos os campos sejam envoltos por aspas duplas\n",
    "    )\n",
    "\n",
    "    print(f\"Arquivo convertido com sucesso e salvo como: {output_csv_path}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRO: Arquivo no encontrado em '{input_excel_path}'. Por favor, verifique se o arquivo est no local correto.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu um erro inesperado: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6152fb2-8c69-4fa1-8f0c-1ab737d4dc5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9ec15309-2f44-4948-87c5-c20808baec6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo Pricelist.csv carregado com sucesso no Pandas.\n"
     ]
    }
   ],
   "source": [
    "# 1. Instalaes necessrias\n",
    "#!pip install -q -U langchain-openai tavily-python langchain pandas\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.agents import tool\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_tools_agent, AgentExecutor\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# --- CARREGAR OS DADOS COM PANDAS ---\n",
    "# Carrega o CSV em um DataFrame para acesso rpido e direto\n",
    "try:\n",
    "    pricelist_df = pd.read_csv('data/raw/Pricelist_corrigido.csv', engine='python', on_bad_lines='warn')\n",
    "    print(\"Arquivo Pricelist.csv carregado com sucesso no Pandas.\")\n",
    "    # Converte a coluna de Part Number para string para garantir correspondncias exatas\n",
    "    pricelist_df['Part Number'] = pricelist_df['Part Number'].astype(str)\n",
    "except FileNotFoundError:\n",
    "    print(\"ERRO: O arquivo 'data/raw/Pricelist.csv' no foi encontrado.\")\n",
    "    pricelist_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "83e5e52e-e5bc-4f83-a2cc-a2a3f6f3abd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub_Category</th>\n",
       "      <th>Part Number</th>\n",
       "      <th>Desc</th>\n",
       "      <th>price</th>\n",
       "      <th>Elig %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>Hardware</td>\n",
       "      <td>Switches</td>\n",
       "      <td>C9200L-24P-4G-A</td>\n",
       "      <td>Catalyst 9200L 24-port PoE+, 4 x 1G, Network A...</td>\n",
       "      <td>2745.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category Sub_Category      Part Number  \\\n",
       "1597  Hardware     Switches  C9200L-24P-4G-A   \n",
       "\n",
       "                                                   Desc   price Elig %  \n",
       "1597  Catalyst 9200L 24-port PoE+, 4 x 1G, Network A...  2745.0      1  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pricelist_df[pricelist_df['Part Number']==\"C9200L-24P-4G-A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dc688a-246a-43ed-b2d2-5f495c3c8379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cb308617-e850-4ef7-af93-c1464a492ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Executando a pergunta: What is the list price for Part Number C9200L-24P-4G-A ? ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_product_price` with `{'part_number': 'C9200L-24P-4G-A'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mFound information for Part Number 'C9200L-24P-4G-A':\n",
      "- Description: N/A\n",
      "- List Price: $N/A\u001b[0m\u001b[32;1m\u001b[1;3mThe list price for Part Number C9200L-24P-4G-A is not available at this time, and the description is also not provided.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "--- Resposta Final do Agente ---\n",
      "The list price for Part Number C9200L-24P-4G-A is not available at this time, and the description is also not provided.\n"
     ]
    }
   ],
   "source": [
    "# --- PASSO A: CRIAR A FERRAMENTA DE BUSCA DIRETA ---\n",
    "\n",
    "@tool\n",
    "def search_product_price(part_number: str) -> str:\n",
    "    \"\"\"\n",
    "    Use this tool to find the exact list price and description for a specific Cisco Part Number.\n",
    "    The input must be the exact Part Number string.\n",
    "    \"\"\"\n",
    "    if pricelist_df is None:\n",
    "        return \"Error: Pricelist data is not available.\"\n",
    "    \n",
    "    # Busca exata (case-insensitive) no DataFrame\n",
    "    result = pricelist_df[pricelist_df['Part Number'].str.lower() == part_number.lower()]\n",
    "    \n",
    "    if result.empty:\n",
    "        return f\"Part Number '{part_number}' not found in the pricelist.\"\n",
    "    \n",
    "    # Formata a resposta\n",
    "    product_info = result.iloc[0]\n",
    "    return (\n",
    "        f\"Found information for Part Number '{part_number}':\\n\"\n",
    "        f\"- Description: {product_info.get('Description', 'N/A')}\\n\"\n",
    "        f\"- List Price: ${product_info.get('List Price', 'N/A')}\"\n",
    "    )\n",
    "\n",
    "\n",
    "# --- PASSO B: DEFINIR A FERRAMENTA DE BUSCA NA WEB E MONTAR O AGENTE ---\n",
    "\n",
    "web_search_tool = TavilySearchResults(name=\"web_search\", max_results=3)\n",
    "\n",
    "# Agora a lista de ferramentas contm nossa nova ferramenta de busca direta e a de busca na web\n",
    "tools = [search_product_price, web_search_tool]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "# --- PASSO C: TESTAR O AGENTE COM A NOVA FERRAMENTA ---\n",
    "\n",
    "# Pergunta que antes falhava, mas agora deve funcionar perfeitamente\n",
    "query = \"What is the list price for Part Number C9200L-24P-4G-A ?\"\n",
    "print(f\"--- Executando a pergunta: {query} ---\")\n",
    "\n",
    "response = agent_executor.invoke({\"input\": query})\n",
    "\n",
    "print(\"\\n--- Resposta Final do Agente ---\")\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fe8e17-8542-4ce4-a6f6-7098cfb29c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd61b58-fe5f-4fa6-8984-d13c17e25f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a831d81-c2cc-4ff9-961e-74a622959ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eda8635-399b-4110-93ef-20413a5ab1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2b1917-2920-4750-a59f-de269ebff913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7ac9972f-53ec-484a-b134-df9a2dd8208d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 16 products from data/raw/pricelist.json.\n",
      "Tool 'get_product_price_and_description' created and ready.\n"
     ]
    }
   ],
   "source": [
    "# --- Load the JSON data ---\n",
    "product_list = []\n",
    "try:\n",
    "    # Path to your JSON file\n",
    "    pricelist_path = 'data/raw/pricelist.json'\n",
    "    \n",
    "    with open(pricelist_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "        # --- CORREO AQUI ---\n",
    "        # Como o JSON j  uma lista, atribumos diretamente.\n",
    "        if isinstance(data, list):\n",
    "            product_list = data\n",
    "        else:\n",
    "            # Caso o formato mude no futuro, ainda tentamos pegar a chave 'products'\n",
    "            product_list = data.get('products', [])\n",
    "            \n",
    "    print(f\"Successfully loaded {len(product_list)} products from {pricelist_path}.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: The file '{pricelist_path}' was not found.\")\n",
    "    product_list = []\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"ERROR: The file '{pricelist_path}' is not a valid JSON file.\")\n",
    "    product_list = []\n",
    "\n",
    "# --- Create the specialized Pricing Agent Tool ---\n",
    "@tool\n",
    "def get_product_price_and_description(part_number: str) -> str:\n",
    "    \"\"\"\n",
    "    Use this tool to find the exact list price, description, and manufacturer\n",
    "    for a specific Cisco Part Number from the JSON pricelist.\n",
    "    The input must be the exact Part Number string.\n",
    "    \"\"\"\n",
    "    if not product_list:\n",
    "        return \"Error: Product list data is not available.\"\n",
    "    \n",
    "    # Search for the product in the list of dictionaries (case-insensitive)\n",
    "    found_product = next((p for p in product_list if p.get('part_number', '').lower() == part_number.lower()), None)\n",
    "    \n",
    "    if not found_product:\n",
    "        return f\"Part Number '{part_number}' not found in the pricelist.\"\n",
    "    \n",
    "    # Format a clean response string from the found product dictionary\n",
    "    return (\n",
    "        f\"Info for '{found_product['part_number']}':\\n\"\n",
    "        f\"  Manufacturer: {found_product.get('manufacturer', 'N/A')}\\n\"\n",
    "        f\"  Description: {found_product.get('description', 'N/A')}\\n\"\n",
    "        f\"  List Price: ${found_product.get('list_price', 'N/A')}\"\n",
    "    )\n",
    "\n",
    "print(\"Tool 'get_product_price_and_description' created and ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3282edc1-e76c-4885-afc4-bb7f4d1eecfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technical Agent (SKU extractor) created correctly.\n"
     ]
    }
   ],
   "source": [
    "# Importa o ChatPromptTemplate que estava faltando\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# A definio do Pydantic (Skus) e do LLM (llm, structured_llm) continua a mesma\n",
    "class Skus(BaseModel):\n",
    "    \"\"\"A list of product SKUs extracted from the user's query.\"\"\"\n",
    "    sku_list: List[str] = Field(description=\"A list of part numbers mentioned in the query.\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "structured_llm = llm.with_structured_output(Skus)\n",
    "\n",
    "\n",
    "# --- CORREO AQUI ---\n",
    "# 1. Criamos um template de prompt para instruir o LLM sobre o que fazer com a query.\n",
    "technical_prompt = ChatPromptTemplate.from_template(\n",
    "    \"From the following user query, extract all and only the product cisco_product_id. If no part numbers are mentioned, return an empty list.\\n\\nUser Query: {query}\"\n",
    ")\n",
    "\n",
    "# 2. A cadeia agora inclui o prompt para formatar a entrada para o LLM.\n",
    "technical_agent_chain = (\n",
    "    # O primeiro passo ainda cria um dicionrio com a query do usurio\n",
    "    {\"query\": lambda x: x} \n",
    "    # O segundo passo (novo) usa o prompt para formatar o dicionrio em um texto de instruo\n",
    "    | technical_prompt\n",
    "    # O terceiro passo envia o prompt formatado para o LLM\n",
    "    | structured_llm\n",
    ")\n",
    "\n",
    "print(\"Technical Agent (SKU extractor) created correctly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7a7f8c50-c693-41a9-ad81-75ca00202f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_quote_flow(user_query: str):\n",
    "    \"\"\"\n",
    "    Orchestrates the two-agent flow to process a user query.\n",
    "    \"\"\"\n",
    "    print(\"--- STARTING QUOTE FLOW ---\")\n",
    "    \n",
    "    # 1. Call Technical Agent to identify SKUs\n",
    "    print(f\"\\n[Orchestrator] Sending to Technical Agent: '{user_query}'\")\n",
    "    skus_result = technical_agent_chain.invoke(user_query)\n",
    "    extracted_skus = skus_result.sku_list\n",
    "    \n",
    "    if not extracted_skus:\n",
    "        print(\"[Orchestrator] No SKUs identified. Ending flow.\")\n",
    "        return \"I could not identify any specific Part Numbers in your request.\"\n",
    "        \n",
    "    print(f\"[Orchestrator] Technical Agent identified SKUs: {extracted_skus}\")\n",
    "    \n",
    "    # 2. Call Pricing Agent (our tool) for each SKU\n",
    "    final_quote_details = []\n",
    "    print(\"\\n[Orchestrator] Querying Pricing Agent for each SKU...\")\n",
    "    for sku in extracted_skus:\n",
    "        print(f\"  - Looking up price for: {sku}\")\n",
    "        price_info = get_product_price_and_description.invoke(sku)\n",
    "        final_quote_details.append(price_info)\n",
    "        \n",
    "    # 3. Synthesize the final response\n",
    "    print(\"\\n--- FLOW COMPLETE. GENERATING FINAL RESPONSE ---\")\n",
    "    final_response = \"\\n\\n\".join(final_quote_details)\n",
    "    return f\"Here is the information you requested:\\n\\n{final_response}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e2620338-0b5c-49cb-a001-c92d6ed9071d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING QUOTE FLOW ---\n",
      "\n",
      "[Orchestrator] Sending to Technical Agent: 'I need a price for the Catalyst switch C9200L-24P-4G-A and also for the Meraki access point QSFP-100G-SR4-S.'\n",
      "[Orchestrator] Technical Agent identified SKUs: ['C9200L-24P-4G-A', 'QSFP-100G-SR4-S']\n",
      "\n",
      "[Orchestrator] Querying Pricing Agent for each SKU...\n",
      "  - Looking up price for: C9200L-24P-4G-A\n",
      "  - Looking up price for: QSFP-100G-SR4-S\n",
      "\n",
      "--- FLOW COMPLETE. GENERATING FINAL RESPONSE ---\n",
      "\n",
      "==================================================\n",
      "FINAL RESPONSE TO USER:\n",
      "==================================================\n",
      "Here is the information you requested:\n",
      "\n",
      "Part Number 'C9200L-24P-4G-A' not found in the pricelist.\n",
      "\n",
      "Part Number 'QSFP-100G-SR4-S' not found in the pricelist.\n"
     ]
    }
   ],
   "source": [
    "# --- EXECUTE THE TEST ---\n",
    "# Query containing Part Numbers from your JSON file\n",
    "user_query = \"I need a price for the Catalyst switch C9200L-24P-4G-A and also for the Meraki access point QSFP-100G-SR4-S.\"\n",
    "\n",
    "final_quote = run_quote_flow(user_query)\n",
    "\n",
    "# Print the final, user-facing result\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL RESPONSE TO USER:\")\n",
    "print(\"=\"*50)\n",
    "print(final_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac47c8b-7588-4084-b342-885409536d62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53655b5-3171-4f64-a545-6d03111f87c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe2b6bb-45ea-448d-8fa5-d0ac0c3f019c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109d5b7d-0fa1-4b2a-914c-b6427a5fd4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a3f52f57-5d77-4673-93b6-6f622f41a4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converso concluda! 4267 produtos convertidos.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from typing import Dict, Any\n",
    "\n",
    "def normalize_price(price_str: str) -> float:\n",
    "    \"\"\"Converte strings de preo no formato '$1.099,00' para float 1099.00\"\"\"\n",
    "    if not isinstance(price_str, str) or price_str.strip() == \"\":\n",
    "        return 0.0\n",
    "        \n",
    "    clean_str = price_str.replace('$', '').replace('.', '').replace(',', '.')\n",
    "    try:\n",
    "        return float(clean_str)\n",
    "    except ValueError:\n",
    "        return 0.0\n",
    "\n",
    "def extract_tech_specs(category: str, sub_category: str, description: str) -> Dict[str, Any]:\n",
    "    \"\"\"Extrai especificaes tcnicas baseadas na descrio do produto\"\"\"\n",
    "    specs = {}\n",
    "    description = description.lower()\n",
    "    \n",
    "    # Mapeamento de categorias para atributos\n",
    "    category_map = {\n",
    "        'Antennas': {\n",
    "            'category': 'antenna',\n",
    "            'subcategory': lambda d: 'sector' if 'sector' in d else 'omni' if 'omni' in d else 'patch'\n",
    "        },\n",
    "        'Cabling': {\n",
    "            'category': 'cable',\n",
    "            'connector_type': lambda d: re.search(r'(BNC|DB15|MPO|LC|RJ-45)', d, re.I).group(0) if re.search(r'(BNC|DB15|MPO|LC|RJ-45)', d, re.I) else None,\n",
    "            'length': lambda d: re.search(r'(\\d+ ?m)', d, re.I).group(0) if re.search(r'(\\d+ ?m)', d, re.I) else None\n",
    "        },\n",
    "        'Connectors': {\n",
    "            'category': 'transceiver',\n",
    "            'standard': lambda d: re.search(r'(\\d+G?BASE?-?[\\w\\d]+)', d, re.I).group(0) if re.search(r'(\\d+G?BASE?-?[\\w\\d]+)', d, re.I) else None,\n",
    "            'fiber_type': lambda d: 'SMF' if 'smf' in d else 'MMF' if 'mmf' in d else None,\n",
    "            'max_distance': lambda d: re.search(r'(\\d+ ?km|\\d+ ?m)', d, re.I).group(0) if re.search(r'(\\d+ ?km|\\d+ ?m)', d, re.I) else None\n",
    "        },\n",
    "        'Firewall': {\n",
    "            'category': 'firewall',\n",
    "            'model': lambda d: re.search(r'(ASA ?[\\d\\-X]+)', d, re.I).group(0) if re.search(r'(ASA ?[\\d\\-X]+)', d, re.I) else None,\n",
    "            'throughput': lambda d: re.search(r'(\\d+ ?Gbps|\\d+ ?Mbps)', d, re.I).group(0) if re.search(r'(\\d+ ?Gbps|\\d+ ?Mbps)', d, re.I) else None\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Aplica regras baseadas na categoria principal\n",
    "    if category in category_map:\n",
    "        category_rules = category_map[category]\n",
    "        specs = {'category': category, 'subcategory': sub_category}\n",
    "        \n",
    "        for attr, rule in category_rules.items():\n",
    "            if attr in ['category', 'subcategory']:\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                if callable(rule):\n",
    "                    result = rule(description)\n",
    "                    if result:\n",
    "                        specs[attr] = result\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "        # Adiciona atributos especficos para firewalls\n",
    "        if category == 'Firewall':\n",
    "            specs['encryption'] = '3DES/AES' if '3DES/AES' in description else 'DES' if 'DES' in description else None\n",
    "    \n",
    "    return specs\n",
    "\n",
    "def convert_to_unified_format(input_csv: str, output_json: str):\n",
    "    \"\"\"Converte CSV de produtos para formato JSON estruturado\"\"\"\n",
    "    # Carrega dados do CSV\n",
    "    df = pd.read_csv(input_csv, sep=',')  # Assumindo separador tabular\n",
    "    \n",
    "    # Lista para armazenar produtos convertidos\n",
    "    unified_products = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        # Extrai campos bsicos\n",
    "        product = {\n",
    "            \"cisco_product_id\": row['Part Number'].strip(),\n",
    "            \"commercial_name\": row['Desc'].strip(),\n",
    "            \"product_type\": \"hardware\",\n",
    "            \"lifecycle\": {\n",
    "                \"status\": \"active\",\n",
    "                \"eos_announced\": \"2028-12-31\" if 'ASA' in row['Desc'] else \"2026-12-31\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Adiciona perfil tcnico\n",
    "        tech_specs = extract_tech_specs(\n",
    "            row['Category'],\n",
    "            row['Sub_Category'],\n",
    "            row['Desc']\n",
    "        )\n",
    "        product[\"technical_profile\"] = {\"hardware_attributes\": tech_specs}\n",
    "        \n",
    "        # Modelo de precificao\n",
    "        normalized_price = normalize_price(row['price'])\n",
    "        product[\"pricing_model\"] = {\n",
    "            \"type\": \"one_time\",\n",
    "            \"currency\": \"USD\",\n",
    "            \"base_price\": normalized_price,\n",
    "            \"pricing_tiers\": [\n",
    "                {\n",
    "                    \"min_quantity\": 1,\n",
    "                    \"price\": normalized_price,\n",
    "                    \"effective\": \"2025-01-01\",\n",
    "                    \"discount_rules\": [\n",
    "                        {\"type\": \"volume\", \"threshold\": 5, \"discount_pct\": 10},\n",
    "                        {\"type\": \"volume\", \"threshold\": 20, \"discount_pct\": 20}\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Dependncias (preenchidas para firewalls)\n",
    "        if row['Category'] == 'Firewall':\n",
    "            product[\"dependencies\"] = {\n",
    "                \"optional_accessories\": [],\n",
    "                \"required_services\": [\"Smart Net Total Care\"]\n",
    "            }\n",
    "            \n",
    "            # Adiciona SSD como dependncia quando mencionado\n",
    "            if 'SSD' in row['Desc']:\n",
    "                ssd_part = row['Part Number'].replace('=', '') + '-SSD'\n",
    "                product[\"dependencies\"][\"required_components\"] = [ssd_part]\n",
    "        \n",
    "        unified_products.append(product)\n",
    "    \n",
    "    # Salva resultado em JSON\n",
    "    with open(output_json, 'w', encoding='utf-8') as f:\n",
    "        json.dump(unified_products, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"Converso concluda! {len(unified_products)} produtos convertidos.\")\n",
    "\n",
    "# Uso\n",
    "if __name__ == \"__main__\":\n",
    "    INPUT_CSV = \"data/raw/Pricelist_corrigido.csv\"  # Seu arquivo de entrada\n",
    "    OUTPUT_JSON = \"cisco_products_unified.json\"  # Arquivo de sada\n",
    "    \n",
    "    convert_to_unified_format(INPUT_CSV, OUTPUT_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06601027-3e18-4878-9ec8-224837e0cf89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5603845-c082-4674-8800-be04547cd232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999a0564-b7ff-4829-9281-64beb0f3080b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1e4285-0776-4be1-8138-7b3bccea4905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "97a75b17-66bf-4ee9-bfd8-55d2da8c1f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in c:\\users\\giovani\\anaconda3\\lib\\site-packages (0.5.3)\n",
      "Requirement already satisfied: langchain-core>=0.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langgraph) (0.3.68)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langgraph) (2.1.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.6.0,>=0.5.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langgraph) (0.5.2)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langgraph) (0.1.73)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langgraph) (2.11.7)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain-core>=0.1->langgraph) (0.4.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain-core>=0.1->langgraph) (8.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain-core>=0.1->langgraph) (6.0.1)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain-core>=0.1->langgraph) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain-core>=0.1->langgraph) (4.12.2)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.27.2)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.14)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (2.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "66a403cc-482d-4081-aa62-5bb9f89ae85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dados carregados: 16 produtos\n",
      "\n",
      "==================================================\n",
      " INICIANDO COTAO PARA: 'Preo para o firewall ASA5516-FPWR-K9 e o access point MR53E-HW'\n",
      "==================================================\n",
      "\n",
      " Identificando SKUs na consulta: 'Preo para o firewall ASA5516-FPWR-K9 e o access p...'\n",
      " SKUs identificados: ['ASA5516-FPWR-K9', 'MR53E-HW']\n",
      "\n",
      " Consultando preos para 2 SKUs...\n",
      "  - ASA5516-FPWR-K9: Encontrado\n",
      "  - MR53E-HW: Encontrado\n",
      "\n",
      "==================================================\n",
      " COTAO FINALIZADA\n",
      "==================================================\n",
      "\n",
      " RESULTADO 1:\n",
      "Aqui esto as informaes solicitadas:\n",
      "\n",
      "Consulta para ASA5516-FPWR-K9:\n",
      " ASA5516-FPWR-K9: ASA 5516-X with FirePOWER Services\n",
      " Preo: USD 5995.00\n",
      " Categoria: security\n",
      "\n",
      "Consulta para MR53E-HW:\n",
      " MR53E-HW: Meraki MR53E Access Point\n",
      " Preo: USD 1699.00\n",
      " Categoria: wireless\n",
      "\n",
      "==================================================\n",
      " INICIANDO COTAO PARA: 'Preciso de um switch Cisco de 24 portas'\n",
      "==================================================\n",
      "\n",
      " Identificando SKUs na consulta: 'Preciso de um switch Cisco de 24 portas...'\n",
      " SKUs identificados: []\n",
      " Nenhum SKU para consultar\n",
      "\n",
      "==================================================\n",
      " COTAO FINALIZADA\n",
      "==================================================\n",
      "\n",
      " RESULTADO 2:\n",
      "No consegui encontrar informaes para os produtos solicitados.\n",
      "\n",
      "==================================================\n",
      " INICIANDO COTAO PARA: 'Quanto custa o QSFP-100G-SR4?'\n",
      "==================================================\n",
      "\n",
      " Identificando SKUs na consulta: 'Quanto custa o QSFP-100G-SR4?...'\n",
      " SKUs identificados: ['QSFP-100G-SR4']\n",
      "\n",
      " Consultando preos para 1 SKUs...\n",
      "  - QSFP-100G-SR4: Encontrado\n",
      "\n",
      "==================================================\n",
      " COTAO FINALIZADA\n",
      "==================================================\n",
      "\n",
      " RESULTADO 3:\n",
      "Aqui esto as informaes solicitadas:\n",
      "\n",
      "Consulta para QSFP-100G-SR4:\n",
      " QSFP-100G-SR4-S: 100GBASE SR4 QSFP Transceiver\n",
      " Preo: USD 1995.00\n",
      " Categoria: transceiver\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain.tools import tool\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "# ==============================\n",
    "# 1. Carregar dados dos produtos\n",
    "# ==============================\n",
    "product_list = []\n",
    "try:\n",
    "    pricelist_path = 'data/raw/pricelist.json'\n",
    "    with open(pricelist_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        product_list = data if isinstance(data, list) else data.get('products', [])\n",
    "    print(f\" Dados carregados: {len(product_list)} produtos\")\n",
    "except Exception as e:\n",
    "    print(f\" Erro ao carregar dados: {str(e)}\")\n",
    "    product_list = []\n",
    "\n",
    "# ===================================\n",
    "# 2. Ferramenta do Agente de Preos\n",
    "# ===================================\n",
    "@tool\n",
    "def get_product_price_and_description(part_number: str) -> str:\n",
    "    \"\"\"\n",
    "    Busca preo e descrio para um nmero de parte Cisco.\n",
    "    Retorna informaes detalhadas sobre o produto.\n",
    "    \"\"\"\n",
    "    if not product_list:\n",
    "        return \"Erro: Base de produtos no carregada\"\n",
    "    \n",
    "    # Busca insensvel a maisculas/minsculas\n",
    "    part_number_clean = part_number.strip().upper()\n",
    "    \n",
    "    # Primeiro busca por correspondncia exata\n",
    "    exact_match = next(\n",
    "        (p for p in product_list if p.get('cisco_product_id', '').upper() == part_number_clean),\n",
    "        None\n",
    "    )\n",
    "    \n",
    "    # Se no encontrar, busca por correspondncia parcial\n",
    "    if not exact_match:\n",
    "        partial_match = next(\n",
    "            (p for p in product_list if part_number_clean in p.get('cisco_product_id', '').upper()),\n",
    "            None\n",
    "        )\n",
    "        if partial_match:\n",
    "            exact_match = partial_match\n",
    "    \n",
    "    if not exact_match:\n",
    "        return f\"Produto '{part_number}' no encontrado\"\n",
    "    \n",
    "    # Formata resposta\n",
    "    price = exact_match['pricing_model']['base_price']\n",
    "    currency = exact_match['pricing_model'].get('currency', 'USD')\n",
    "    description = exact_match['commercial_name']\n",
    "    \n",
    "    return (f\" {exact_match['cisco_product_id']}: {description}\\n\"\n",
    "            f\" Preo: {currency} {price:.2f}\\n\"\n",
    "            f\" Categoria: {exact_match['technical_profile']['hardware_attributes'].get('category', 'N/A')}\")\n",
    "\n",
    "# ======================================\n",
    "# 3. Modelo Pydantic para extrao de SKUs\n",
    "# ======================================\n",
    "class ProductSKUs(BaseModel):\n",
    "    \"\"\"Lista de nmeros de parte extrados da consulta do usurio\"\"\"\n",
    "    skus: List[str] = Field(description=\"Lista de identificadores de produtos Cisco (ex: MR53E-HW, ASA5516)\")\n",
    "\n",
    "# ======================================\n",
    "# 4. Agente Tcnico (Identificador de SKUs)\n",
    "# ======================================\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "tech_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Voc  um especialista em produtos Cisco. Sua tarefa  extrair TODOS os nmeros de parte de produtos Cisco \"\n",
    "    \"mencionados na consulta do usurio. Retorne APENAS os nmeros de parte vlidos, mesmo que escritos de forma incompleta.\\n\\n\"\n",
    "    \"Dicas importantes:\\n\"\n",
    "    \"- Cisco Part Numbers geralmente seguem padres como: 'MR53E-HW', 'ASA5516', 'QSFP-100G-SR4-S'\\n\"\n",
    "    \"- Ignore palavras genricas como 'switch', 'firewall', 'router'\\n\"\n",
    "    \"- Se no encontrar nenhum, retorne lista vazia\\n\\n\"\n",
    "    \"Consulta do usurio: {input}\"\n",
    ")\n",
    "\n",
    "tech_agent = tech_prompt | llm.with_structured_output(ProductSKUs)\n",
    "\n",
    "# ======================================\n",
    "# 5. Estado do Fluxo (LangGraph)\n",
    "# ======================================\n",
    "class AgentState(BaseModel):\n",
    "    user_query: str\n",
    "    identified_skus: List[str] = Field(default_factory=list)\n",
    "    price_results: List[str] = Field(default_factory=list)\n",
    "    final_response: str = \"\"\n",
    "\n",
    "# ======================================\n",
    "# 6. Definindo Ns do Grafo (CORRIGIDOS)\n",
    "# ======================================\n",
    "def identify_skus_node(state: AgentState) -> dict:\n",
    "    \"\"\"N: Identifica SKUs usando o agente tcnico\"\"\"\n",
    "    print(f\"\\n Identificando SKUs na consulta: '{state.user_query[:50]}...'\")\n",
    "    result = tech_agent.invoke({\"input\": state.user_query})\n",
    "    print(f\" SKUs identificados: {result.skus}\")\n",
    "    return {\"identified_skus\": result.skus}\n",
    "\n",
    "def price_lookup_node(state: AgentState) -> dict:\n",
    "    \"\"\"N: Busca preos para cada SKU identificado\"\"\"\n",
    "    if not state.identified_skus:\n",
    "        print(\" Nenhum SKU para consultar\")\n",
    "        return {\"final_response\": \"No identifiquei produtos especficos na sua solicitao.\"}\n",
    "    \n",
    "    print(f\"\\n Consultando preos para {len(state.identified_skus)} SKUs...\")\n",
    "    price_results = []\n",
    "    for sku in state.identified_skus:\n",
    "        try:\n",
    "            result = get_product_price_and_description(sku)\n",
    "            price_results.append(f\"Consulta para {sku}:\\n{result}\")\n",
    "            print(f\"  - {sku}: Encontrado\")\n",
    "        except Exception as e:\n",
    "            price_results.append(f\" Erro ao consultar {sku}: {str(e)}\")\n",
    "            print(f\"  - {sku}: Erro - {str(e)}\")\n",
    "    \n",
    "    return {\"price_results\": price_results}\n",
    "\n",
    "def synthesize_response_node(state: AgentState) -> dict:\n",
    "    \"\"\"N: Sintetiza resposta final\"\"\"\n",
    "    if not state.price_results:\n",
    "        return {\"final_response\": \"No consegui encontrar informaes para os produtos solicitados.\"}\n",
    "    \n",
    "    response = \"Aqui esto as informaes solicitadas:\\n\\n\"\n",
    "    response += \"\\n\\n\".join(state.price_results)\n",
    "    return {\"final_response\": response}\n",
    "\n",
    "# ======================================\n",
    "# 7. Construindo o Grafo de Fluxo\n",
    "# ======================================\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Adiciona ns\n",
    "workflow.add_node(\"identify_skus\", identify_skus_node)\n",
    "workflow.add_node(\"price_lookup\", price_lookup_node)\n",
    "workflow.add_node(\"synthesize\", synthesize_response_node)\n",
    "\n",
    "# Define fluxo\n",
    "workflow.set_entry_point(\"identify_skus\")\n",
    "workflow.add_edge(\"identify_skus\", \"price_lookup\")\n",
    "workflow.add_edge(\"price_lookup\", \"synthesize\")\n",
    "workflow.add_edge(\"synthesize\", END)\n",
    "\n",
    "# Compila o grafo\n",
    "app = workflow.compile()\n",
    "\n",
    "# ======================================\n",
    "# 8. Funo para Executar o Fluxo (CORRIGIDA)\n",
    "# ======================================\n",
    "def run_quote_flow(user_query: str) -> str:\n",
    "    \"\"\"Orquestra todo o fluxo de cotao\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\" INICIANDO COTAO PARA: '{user_query}'\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Executa o fluxo com o estado inicial\n",
    "    final_state = app.invoke(AgentState(user_query=user_query))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\" COTAO FINALIZADA\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Acessa a resposta final corretamente\n",
    "    return final_state[\"final_response\"]\n",
    "\n",
    "# ======================================\n",
    "# 9. Teste do Sistema (CORRIGIDO)\n",
    "# ======================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Caso de teste 1: Consulta com SKUs vlidos\n",
    "    test_query_1 = \"Preo para o firewall ASA5516-FPWR-K9 e o access point MR53E-HW\"\n",
    "    result_1 = run_quote_flow(test_query_1)\n",
    "    print(\"\\n RESULTADO 1:\")\n",
    "    print(result_1)\n",
    "    \n",
    "    # Caso de teste 2: Consulta sem SKUs especficos\n",
    "    test_query_2 = \"Preciso de um firewall com throughput de 10 Gbps \"\n",
    "    result_2 = run_quote_flow(test_query_2)\n",
    "    print(\"\\n RESULTADO 2:\")\n",
    "    print(result_2)\n",
    "    \n",
    "    # Caso de teste 3: SKU parcial\n",
    "    test_query_3 = \"Quanto custa o QSFP-100G-SR4?\"\n",
    "    result_3 = run_quote_flow(test_query_3)\n",
    "    print(\"\\n RESULTADO 3:\")\n",
    "    print(result_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c5a220-9c7b-4ce2-a9d8-5572f1bc9f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3074384c-125d-48e7-b151-c52aea6ed2d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aad9949-96f8-49af-85d7-053251785bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instalaes necessrias\n",
    "#!pip install -q -U langchain-openai tavily-python langchain beautifulsoup4 chromadb pypdf unstructured\n",
    "\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_tools_agent, AgentExecutor\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- CONFIGURAO DAS CHAVES DE API ---\n",
    "#  Cole suas chaves aqui.\n",
    "OPENAI_API_KEY = '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'\n",
    "TAVILY_API_KEY = \"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\" # <-- SUA CHAVE DA TAVILY AQUI\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "38df52a0-655c-4daa-967c-bf19eca8343a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data loaded: 16 products\n",
      "\n",
      "============================================================\n",
      " STARTING QUOTE PROCESSING: 'I need technical specs for ASA5516-FPWR-K9 and pricing for MR53E-HW'\n",
      "============================================================\n",
      "\n",
      " [Orchestrator] Analyzing query: 'I need technical specs for ASA5516-FPWR-K9 and pricing for MR53E-HW'\n",
      " Routing decision: Technical=True Pricing=True\n",
      "Query parts: {'technical': 'technical specs for ASA5516-FPWR-K9', 'pricing': 'pricing for MR53E-HW'}\n",
      "\n",
      " [Technical Agent] Processing: 'technical specs for ASA5516-FPWR-K9'\n",
      " Searching technical specs for: ASA5516-FPWR-K9\n",
      "   ASA5516-FPWR-K9: Error retrieving technical specs: 'part_number'\n",
      "\n",
      " [Pricing Agent] Processing 1 products...\n",
      " Searching price for: ASA5516-FPWR-K9\n",
      "   ASA5516-FPWR-K9: Error retrieving price: 'part_number'\n",
      "\n",
      " [Synthesizer] Combining agent results\n",
      "\n",
      "============================================================\n",
      " QUOTE PROCESSING COMPLETE\n",
      "============================================================\n",
      "\n",
      " CLIENT RESPONSE 1:\n",
      "Here's the information you requested:\n",
      "\n",
      " Pricing Information:\n",
      "\n",
      " ASA5516-FPWR-K9: Error retrieving price: 'part_number'\n",
      "\n",
      "\n",
      " Technical Specifications:\n",
      "\n",
      " ASA5516-FPWR-K9: Error retrieving technical specs: 'part_number'\n",
      "\n",
      "============================================================\n",
      " STARTING QUOTE PROCESSING: 'How much does QSFP-100G-SR4-S cost?'\n",
      "============================================================\n",
      "\n",
      " [Orchestrator] Analyzing query: 'How much does QSFP-100G-SR4-S cost?'\n",
      " Routing decision: Technical=False Pricing=True\n",
      "Query parts: {'pricing': 'QSFP-100G-SR4-S cost'}\n",
      " No technical results, extracting from pricing query: 'QSFP-100G-SR4-S cost'\n",
      "\n",
      " [Pricing Agent] Processing 1 products...\n",
      " Searching price for: QSFP-100G-SR4-S\n",
      "   QSFP-100G-SR4-S: Error retrieving price: 'part_number'\n",
      "\n",
      " [Synthesizer] Combining agent results\n",
      "\n",
      "============================================================\n",
      " QUOTE PROCESSING COMPLETE\n",
      "============================================================\n",
      "\n",
      " CLIENT RESPONSE 2:\n",
      "Here's the information you requested:\n",
      "\n",
      " Pricing Information:\n",
      "\n",
      " QSFP-100G-SR4-S: Error retrieving price: 'part_number'\n",
      "\n",
      "============================================================\n",
      " STARTING QUOTE PROCESSING: 'What are the specifications for the Catalyst 9300 switch?'\n",
      "============================================================\n",
      "\n",
      " [Orchestrator] Analyzing query: 'What are the specifications for the Catalyst 9300 switch?'\n",
      " Routing decision: Technical=True Pricing=False\n",
      "Query parts: {'technical': 'specifications for the Catalyst 9300 switch'}\n",
      "\n",
      " [Technical Agent] Processing: 'specifications for the Catalyst 9300 switch'\n",
      " No SKUs found in technical query part\n",
      " Searching technical specs for: UNKNOWN\n",
      "   UNKNOWN: Error retrieving technical specs: 'part_number'\n",
      "\n",
      " [Synthesizer] Combining agent results\n",
      "\n",
      "============================================================\n",
      " QUOTE PROCESSING COMPLETE\n",
      "============================================================\n",
      "\n",
      " CLIENT RESPONSE 3:\n",
      "Here's the information you requested:\n",
      "\n",
      "\n",
      " Technical Specifications:\n",
      "\n",
      " UNKNOWN: Error retrieving technical specs: 'part_number'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain.tools import tool\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, StateGraph\n",
    "from typing import List, Dict, TypedDict, Annotated, Literal, Union\n",
    "\n",
    "# ==============================\n",
    "# 1. Load Product Data\n",
    "# ==============================\n",
    "product_list = []\n",
    "try:\n",
    "    pricelist_path = 'data/raw/pricelist.json'\n",
    "    with open(pricelist_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        product_list = data if isinstance(data, list) else data.get('products', [])\n",
    "    print(f\" Data loaded: {len(product_list)} products\")\n",
    "except Exception as e:\n",
    "    print(f\" Error loading data: {str(e)}\")\n",
    "    product_list = []\n",
    "\n",
    "# ===================================\n",
    "# 2. Agent Tools\n",
    "# ===================================\n",
    "@tool\n",
    "def get_product_price(part_number: str) -> Dict:\n",
    "    \"\"\"Retrieves pricing information for Cisco products\"\"\"\n",
    "    print(f\" Searching price for: {part_number}\")\n",
    "    try:\n",
    "        # Busca o produto\n",
    "        for product in product_list:\n",
    "            if product['part_number'] == part_number:\n",
    "                return {\n",
    "                    'price': product.get('price', 0.0),\n",
    "                    'currency': product.get('currency', 'USD'),\n",
    "                    'description': product.get('description', ''),\n",
    "                    'part_number': part_number\n",
    "                }\n",
    "        \n",
    "        # Se no encontrou\n",
    "        return {\n",
    "            'error': f\"Product {part_number} not found in pricelist\",\n",
    "            'part_number': part_number\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'error': f\"Error retrieving price: {str(e)}\",\n",
    "            'part_number': part_number\n",
    "        }\n",
    "\n",
    "@tool\n",
    "def get_technical_specs(part_number: str) -> Dict:\n",
    "    \"\"\"Retrieves detailed technical specifications for Cisco products\"\"\"\n",
    "    print(f\" Searching technical specs for: {part_number}\")\n",
    "    try:\n",
    "        # Busca o produto na lista\n",
    "        for product in product_list:\n",
    "            if product['part_number'] == part_number:\n",
    "                # Retorna as especificaes tcnicas, se existirem\n",
    "                specs = product.get('specifications', {})\n",
    "                if not specs:\n",
    "                    return {\n",
    "                        'error': f\"No technical specifications available for {part_number}\",\n",
    "                        'part_number': part_number\n",
    "                    }\n",
    "                return {\n",
    "                    'part_number': part_number,\n",
    "                    'specifications': specs,\n",
    "                    'description': product.get('description', '')\n",
    "                }\n",
    "        \n",
    "        # Se no encontrou o produto\n",
    "        return {\n",
    "            'error': f\"Product {part_number} not found in database\",\n",
    "            'part_number': part_number\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'error': f\"Error retrieving technical specs: {str(e)}\",\n",
    "            'part_number': part_number\n",
    "        }\n",
    "\n",
    "# ======================================\n",
    "# 3. Pydantic Models\n",
    "# ======================================\n",
    "class AgentRoutingDecision(BaseModel):\n",
    "    \"\"\"Orchestrator's decision about agent routing\"\"\"\n",
    "    needs_technical: bool = Field(description=\"Whether technical agent is required\")\n",
    "    needs_pricing: bool = Field(description=\"Whether pricing agent is required\")\n",
    "    needs_compliance: bool = Field(False, description=\"Whether compliance agent is required\")\n",
    "    query_parts: Dict[str, str] = Field(\n",
    "        default_factory=dict,  # Valor padro vazio\n",
    "        description=\"Decomposed query parts for each agent\"\n",
    "    )\n",
    "\n",
    "class ProductInfo(BaseModel):\n",
    "    \"\"\"Unified product information model\"\"\"\n",
    "    part_number: str\n",
    "    description: str\n",
    "    price: Union[float, None]\n",
    "    technical_specs: Dict[str, str]\n",
    "\n",
    "# ======================================\n",
    "# 4. Agent Definitions\n",
    "# ======================================\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# Orchestrator Agent\n",
    "orchestrator_prompt = ChatPromptTemplate.from_template(\n",
    "    \"You are a Cisco sales orchestration system. Analyze the user query and:\\n\"\n",
    "    \"1. Determine which specialized agents are needed\\n\"\n",
    "    \"2. Decompose the query into specific parts for each agent\\n\"\n",
    "    \"3. ALWAYS include a 'query_parts' dictionary with agent names as keys\\n\\n\"\n",
    "    \"Example structure for output:\\n\"\n",
    "    \"{{\\n\"\n",
    "    \"  \\\"needs_technical\\\": true,\\n\"\n",
    "    \"  \\\"needs_pricing\\\": true,\\n\"\n",
    "    \"  \\\"query_parts\\\": {{\\n\"\n",
    "    \"    \\\"technical\\\": \\\"part numbers and specs\\\",\\n\"\n",
    "    \"    \\\"pricing\\\": \\\"part numbers for pricing\\\"\\n\"\n",
    "    \"  }}\\n\"\n",
    "    \"}}\\n\\n\"\n",
    "    \"User Query: {query}\\n\\n\"\n",
    "    \"Output Instructions: {format_instructions}\"\n",
    ")\n",
    "orchestrator_agent = orchestrator_prompt | llm.with_structured_output(AgentRoutingDecision)\n",
    "\n",
    "# Technical Agent (SKU Extraction + Specs)\n",
    "tech_prompt = ChatPromptTemplate.from_template(\n",
    "    \"You are a Cisco technical specialist. From the following query segment, \"\n",
    "    \"extract ALL product identifiers and retrieve their specifications:\\n\\n\"\n",
    "    \"Query Segment: {query_part}\\n\\n\"\n",
    "    \"Output Instructions: {format_instructions}\"\n",
    ")\n",
    "\n",
    "# Pricing Agent\n",
    "def pricing_agent(products: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"Retrieves pricing for multiple products\"\"\"\n",
    "    results = []\n",
    "    for product in products:\n",
    "        result = get_product_price(product['part_number'])\n",
    "        if 'error' not in result:\n",
    "            product.update(result)\n",
    "        results.append(product)\n",
    "    return results\n",
    "\n",
    "# ======================================\n",
    "# 5. State Definition\n",
    "# ======================================\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"State of the agent workflow\"\"\"\n",
    "    user_query: str\n",
    "    orchestrator_decision: Union[AgentRoutingDecision, None]\n",
    "    technical_results: List[Dict]  # Removido Annotated\n",
    "    pricing_results: List[Dict]    # Removido Annotated\n",
    "    final_response: str\n",
    "\n",
    "# ======================================\n",
    "# 6. Graph Nodes Implementation\n",
    "# ======================================\n",
    "def orchestrator_node(state: AgentState) -> AgentState:\n",
    "    print(f\"\\n [Orchestrator] Analyzing query: '{state['user_query']}'\")\n",
    "    \n",
    "    try:\n",
    "        decision = orchestrator_agent.invoke({\n",
    "            \"query\": state[\"user_query\"],\n",
    "            \"format_instructions\": AgentRoutingDecision.schema()\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\" Orchestrator error: {str(e)}\")\n",
    "        # Fallback decision if parsing fails\n",
    "        decision = AgentRoutingDecision(\n",
    "            needs_technical=\"technical\" in state[\"user_query\"].lower(),\n",
    "            needs_pricing=\"price\" in state[\"user_query\"].lower(),\n",
    "            query_parts={}\n",
    "        )\n",
    "    \n",
    "    state[\"orchestrator_decision\"] = decision\n",
    "    \n",
    "    # Logging melhorado\n",
    "    print(f\" Routing decision: \"\n",
    "          f\"Technical={decision.needs_technical} \"\n",
    "          f\"Pricing={decision.needs_pricing}\")\n",
    "    \n",
    "    if decision.query_parts:\n",
    "        print(f\"Query parts: {decision.query_parts}\")\n",
    "    else:\n",
    "        print(\" No query parts decomposed, using full query\")\n",
    "        decision.query_parts = {\n",
    "            \"technical\": state[\"user_query\"],\n",
    "            \"pricing\": state[\"user_query\"]\n",
    "        }\n",
    "    \n",
    "    return state\n",
    "\n",
    "def technical_agent_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Handles technical aspects of products\"\"\"\n",
    "    if not state[\"orchestrator_decision\"].needs_technical:\n",
    "        print(\" Skipping technical agent (not required)\")\n",
    "        return state\n",
    "        \n",
    "    query_part = state[\"orchestrator_decision\"].query_parts.get(\"technical\", \"\")\n",
    "    print(f\"\\n [Technical Agent] Processing: '{query_part}'\")\n",
    "    \n",
    "    # Extrai SKUs da query usando regex (poderia ser substitudo por LLM em produo)\n",
    "    import re\n",
    "    skus = re.findall(r'[A-Z0-9\\-]+', query_part)\n",
    "    skus = [sku for sku in skus if len(sku) > 5]  # Filtra strings curtas\n",
    "    \n",
    "    if not skus:\n",
    "        print(\" No SKUs found in technical query part\")\n",
    "        skus = [\"UNKNOWN\"]\n",
    "    \n",
    "    state[\"technical_results\"] = []\n",
    "    for sku in skus:\n",
    "        # Busca as especificaes tcnicas\n",
    "        result = get_technical_specs(sku)\n",
    "        state[\"technical_results\"].append(result)\n",
    "    \n",
    "    # Log dos resultados\n",
    "    for result in state[\"technical_results\"]:\n",
    "        status = \"\" if \"specifications\" in result else \"\"\n",
    "        print(f\"  {status} {result.get('part_number', 'Unknown')}: \"\n",
    "              f\"{result.get('error', 'Specs found')}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "def pricing_agent(products: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"Retrieves pricing for multiple products\"\"\"\n",
    "    results = []\n",
    "    for product in products:\n",
    "        # Garante que temos um nmero de pea\n",
    "        pn = product.get('part_number', 'UNKNOWN')\n",
    "        if not pn or pn == 'UNKNOWN':\n",
    "            results.append({\n",
    "                'error': 'Missing part number',\n",
    "                'details': product\n",
    "            })\n",
    "            continue\n",
    "            \n",
    "        # Busca preo\n",
    "        result = get_product_price(pn)\n",
    "        \n",
    "        # Combina resultados\n",
    "        combined = {**product, **result}\n",
    "        results.append(combined)\n",
    "        \n",
    "    return results\n",
    "\n",
    "def pricing_agent_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Handles pricing aspects of products\"\"\"\n",
    "    if not state[\"orchestrator_decision\"].needs_pricing:\n",
    "        print(\" Skipping pricing agent (not required)\")\n",
    "        return state\n",
    "        \n",
    "    # Use technical results if available\n",
    "    products = state[\"technical_results\"] if state[\"technical_results\"] else []\n",
    "    \n",
    "    # Se no tem resultados tcnicos, tenta extrair da query\n",
    "    if not products:\n",
    "        query_part = state[\"orchestrator_decision\"].query_parts.get(\"pricing\", \"\")\n",
    "        print(f\" No technical results, extracting from pricing query: '{query_part}'\")\n",
    "        \n",
    "        # Simulao de extrao de SKUs - na implementao real, usaramos um LLM\n",
    "        # Aqui apenas para demonstrao\n",
    "        if \"MR53E-HW\" in query_part:\n",
    "            products = [{\"part_number\": \"MR53E-HW\"}]\n",
    "        elif \"QSFP\" in query_part:\n",
    "            products = [{\"part_number\": \"QSFP-100G-SR4-S\"}]\n",
    "        else:\n",
    "            # Tenta extrair qualquer coisa que parea um SKU\n",
    "            import re\n",
    "            skus = re.findall(r'[A-Z0-9\\-]+', query_part)\n",
    "            products = [{\"part_number\": sku} for sku in skus if len(sku) > 5]\n",
    "            \n",
    "        if not products:\n",
    "            products = [{\"part_number\": \"UNKNOWN\", \"error\": \"No SKUs extracted\"}]\n",
    "    \n",
    "    print(f\"\\n [Pricing Agent] Processing {len(products)} products...\")\n",
    "    state[\"pricing_results\"] = pricing_agent(products)\n",
    "    \n",
    "    for result in state[\"pricing_results\"]:\n",
    "        status = \"\" if \"price\" in result and not result.get('error') else \"\"\n",
    "        print(f\"  {status} {result.get('part_number', 'Unknown')}: \"\n",
    "              f\"{result.get('price', result.get('error', 'No info'))}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "def synthesize_response_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Creates final response by combining agent outputs\"\"\"\n",
    "    print(\"\\n [Synthesizer] Combining agent results\")\n",
    "    \n",
    "    response = [\"Here's the information you requested:\"]\n",
    "    \n",
    "    # Mostrar resultados de preos se disponveis\n",
    "    if state[\"pricing_results\"]:\n",
    "        response.append(\"\\n Pricing Information:\")\n",
    "        for product in state[\"pricing_results\"]:\n",
    "            if \"error\" in product:\n",
    "                response.append(f\"\\n {product.get('part_number', 'Unknown')}: {product['error']}\")\n",
    "            else:\n",
    "                response.append(\n",
    "                    f\"\\n    {product['part_number']}\"\n",
    "                    f\"\\n      Description: {product.get('description', 'N/A')}\"\n",
    "                    f\"\\n       Price: {product.get('currency', 'USD')} {product.get('price', 'N/A')}\"\n",
    "                )\n",
    "    \n",
    "    # Mostrar resultados tcnicos se disponveis\n",
    "    if state[\"technical_results\"]:\n",
    "        response.append(\"\\n\\n Technical Specifications:\")\n",
    "        for product in state[\"technical_results\"]:\n",
    "            if \"error\" in product:\n",
    "                response.append(f\"\\n {product.get('part_number', 'Unknown')}: {product['error']}\")\n",
    "            else:\n",
    "                specs = product.get('specifications', {})\n",
    "                if specs:\n",
    "                    specs_str = \"\\n      \".join([f\"{k}: {v}\" for k, v in specs.items()])\n",
    "                    response.append(f\"\\n    {product['part_number']}:\\n      {specs_str}\")\n",
    "                else:\n",
    "                    response.append(f\"\\n    {product['part_number']}: No specifications available\")\n",
    "    \n",
    "    # Se no houver resultados\n",
    "    if not state[\"pricing_results\"] and not state[\"technical_results\"]:\n",
    "        response.append(\"\\n No relevant information found for your query\")\n",
    "    \n",
    "    state[\"final_response\"] = \"\\n\".join(response)\n",
    "    return state\n",
    "\n",
    "# ======================================\n",
    "# 7. Conditional Routing Logic\n",
    "# ======================================\n",
    "def route_after_orchestrator(state: AgentState) -> str:\n",
    "    \"\"\"Decides which agent to call first based on orchestrator decision\"\"\"\n",
    "    decision = state[\"orchestrator_decision\"]\n",
    "    \n",
    "    if decision.needs_technical:\n",
    "        return \"technical_agent\"\n",
    "    elif decision.needs_pricing:\n",
    "        return \"pricing_agent\"\n",
    "    else:\n",
    "        return \"synthesize\"\n",
    "\n",
    "def route_after_technical(state: AgentState) -> str:\n",
    "    \"\"\"Decides next step after technical agent\"\"\"\n",
    "    decision = state[\"orchestrator_decision\"]\n",
    "    \n",
    "    if decision.needs_pricing:\n",
    "        return \"pricing_agent\"\n",
    "    else:\n",
    "        return \"synthesize\"\n",
    "\n",
    "def route_after_pricing(state: AgentState) -> str:\n",
    "    \"\"\"Always goes to synthesizer after pricing\"\"\"\n",
    "    return \"synthesize\"\n",
    "\n",
    "# ======================================\n",
    "# 8. Build Agent Workflow Graph\n",
    "# ======================================\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"orchestrator\", orchestrator_node)\n",
    "workflow.add_node(\"technical_agent\", technical_agent_node)\n",
    "workflow.add_node(\"pricing_agent\", pricing_agent_node)\n",
    "workflow.add_node(\"synthesize\", synthesize_response_node)\n",
    "\n",
    "# Define workflow with conditional routing\n",
    "workflow.set_entry_point(\"orchestrator\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"orchestrator\",\n",
    "    route_after_orchestrator,\n",
    "    {\n",
    "        \"technical_agent\": \"technical_agent\",\n",
    "        \"pricing_agent\": \"pricing_agent\",\n",
    "        \"synthesize\": \"synthesize\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"technical_agent\",\n",
    "    route_after_technical,\n",
    "    {\n",
    "        \"pricing_agent\": \"pricing_agent\",\n",
    "        \"synthesize\": \"synthesize\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"pricing_agent\",\n",
    "    route_after_pricing,\n",
    "    {\n",
    "        \"synthesize\": \"synthesize\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"synthesize\", END)\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "\n",
    "# ======================================\n",
    "# 9. Run the Agent Workflow\n",
    "# ======================================\n",
    "def run_sales_quote(user_query: str) -> str:\n",
    "    \"\"\"Execute the full agent workflow\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\" STARTING QUOTE PROCESSING: '{user_query}'\")\n",
    "    print(\"=\"*60)\n",
    "    initial_state = {\n",
    "        \"user_query\": user_query,\n",
    "        \"orchestrator_decision\": None,\n",
    "        \"technical_results\": [],  # Inicializado aqui\n",
    "        \"pricing_results\": [],    # Inicializado aqui\n",
    "        \"final_response\": \"\"\n",
    "    }\n",
    "    final_state = app.invoke(initial_state)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\" QUOTE PROCESSING COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    return final_state[\"final_response\"]\n",
    "    \n",
    "\n",
    "# ======================================\n",
    "# 10. Test Cases\n",
    "# ======================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Test 1: Technical + Pricing request\n",
    "    test_query_1 = \"I need technical specs for ASA5516-FPWR-K9 and pricing for MR53E-HW\"\n",
    "    result_1 = run_sales_quote(test_query_1)\n",
    "    print(\"\\n CLIENT RESPONSE 1:\")\n",
    "    print(result_1)\n",
    "    \n",
    "    # Test 2: Pricing-only request\n",
    "    test_query_2 = \"How much does QSFP-100G-SR4-S cost?\"\n",
    "    result_2 = run_sales_quote(test_query_2)\n",
    "    print(\"\\n CLIENT RESPONSE 2:\")\n",
    "    print(result_2)\n",
    "    \n",
    "    # Test 3: Technical-only request\n",
    "    test_query_3 = \"What are the specifications for the Catalyst 9300 switch?\"\n",
    "    result_3 = run_sales_quote(test_query_3)\n",
    "    print(\"\\n CLIENT RESPONSE 3:\")\n",
    "    print(result_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5cadf3-7a27-48bc-aa66-ffbfb7ef121f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "52b989f7-57cf-4e4f-bbec-84e1eca6917d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Recommendation data prepared\n",
      " Data loaded: 16 products\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain.tools import tool\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, StateGraph\n",
    "from typing import List, Dict, TypedDict, Union, Optional\n",
    "import re\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# ==============================\n",
    "# 1. Load Product Data (CORRIGIDO)\n",
    "# ==============================\n",
    "# ======================================\n",
    "# 1. Pr-processamento de Dados para Recomendaes\n",
    "# ======================================\n",
    "# Prepara embeddings para busca semntica\n",
    "def prepare_recommendation_data():\n",
    "    product_texts = []\n",
    "    for product_id, product in product_dict.items():\n",
    "        commercial_name = product.get('commercial_name', '')\n",
    "        product_type = product.get('product_type', '')\n",
    "        tech_profile = product.get('technical_profile', {})\n",
    "        hardware = tech_profile.get('hardware_attributes', {})\n",
    "        \n",
    "        # Cria texto descritivo para embeddings\n",
    "        text = f\"{commercial_name} {product_type} \"\n",
    "        if hardware:\n",
    "            text += \" \".join([f\"{k}={v}\" for k,v in hardware.items()])\n",
    "        product_texts.append(text.strip())\n",
    "    \n",
    "    # Cria vetores TF-IDF\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = vectorizer.fit_transform(product_texts)\n",
    "    \n",
    "    return vectorizer, tfidf_matrix\n",
    "\n",
    "# Pr-processa dados uma vez no incio\n",
    "vectorizer, tfidf_matrix = prepare_recommendation_data()\n",
    "print(\" Recommendation data prepared\")\n",
    "\n",
    "# Criar dicionrio para acesso rpido por ID\n",
    "product_dict = {}\n",
    "try:\n",
    "    pricelist_path = 'data/raw/pricelist.json'\n",
    "    with open(pricelist_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        products = data if isinstance(data, list) else data.get('products', [])\n",
    "        \n",
    "        # Criar dicionrio de produtos indexado por ID\n",
    "        for product in products:\n",
    "            product_id = product.get('cisco_product_id')\n",
    "            if product_id:\n",
    "                product_dict[product_id] = product\n",
    "        \n",
    "    print(f\" Data loaded: {len(product_dict)} products\")\n",
    "except Exception as e:\n",
    "    print(f\" Error loading data: {str(e)}\")\n",
    "    product_dict = {}\n",
    "\n",
    "# ===================================\n",
    "# 2. Agent Tools (COMPLETO E CORRIGIDO)\n",
    "# ===================================\n",
    "@tool\n",
    "def get_product_price(part_number: str) -> Dict:\n",
    "    \"\"\"Retrieves pricing information for Cisco products\"\"\"\n",
    "    print(f\" Searching price for: {part_number}\")\n",
    "    try:\n",
    "        product = product_dict.get(part_number)\n",
    "        if not product:\n",
    "            return {\n",
    "                'error': f\"Product {part_number} not found\",\n",
    "                'part_number': part_number\n",
    "            }\n",
    "        \n",
    "        pricing = product.get('pricing_model', {})\n",
    "        return {\n",
    "            'price': pricing.get('base_price', 0.0),\n",
    "            'currency': pricing.get('currency', 'USD'),\n",
    "            'description': product.get('commercial_name', ''),\n",
    "            'part_number': part_number,\n",
    "            'product_type': product.get('product_type', '')\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'error': f\"Error retrieving price: {str(e)}\",\n",
    "            'part_number': part_number\n",
    "        }\n",
    "\n",
    "@tool\n",
    "def get_technical_specs(part_number: str) -> Dict:\n",
    "    \"\"\"Retrieves technical specifications for Cisco products\"\"\"\n",
    "    print(f\" Searching specs for: {part_number}\")\n",
    "    try:\n",
    "        product = product_dict.get(part_number)\n",
    "        if not product:\n",
    "            return {\n",
    "                'error': f\"Product {part_number} not found\",\n",
    "                'part_number': part_number\n",
    "            }\n",
    "        \n",
    "        tech_profile = product.get('technical_profile', {})\n",
    "        hardware = tech_profile.get('hardware_attributes', {})\n",
    "        \n",
    "        if not hardware:\n",
    "            return {\n",
    "                'error': f\"No technical specs available for {part_number}\",\n",
    "                'part_number': part_number\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            'specifications': hardware,\n",
    "            'description': product.get('commercial_name', ''),\n",
    "            'part_number': part_number,\n",
    "            'product_type': product.get('product_type', '')\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'error': f\"Error retrieving specs: {str(e)}\",\n",
    "            'part_number': part_number\n",
    "        }\n",
    "\n",
    "\n",
    "# ======================================\n",
    "# 2. Nova Ferramenta de Recomendao\n",
    "# ======================================\n",
    "@tool\n",
    "def recommend_products(requirements: str, max_results: int = 3) -> List[Dict]:\n",
    "    \"\"\"Recommends Cisco products based on technical requirements\"\"\"\n",
    "    print(f\" Recommending products for: {requirements}\")\n",
    "    \n",
    "    try:\n",
    "        # Transforma a consulta no mesmo espao vetorial\n",
    "        query_vec = vectorizer.transform([requirements])\n",
    "        \n",
    "        # Calcula similaridade de cosseno\n",
    "        cosine_similarities = cosine_similarity(query_vec, tfidf_matrix).flatten()\n",
    "        \n",
    "        # Obtm os ndices dos produtos mais relevantes\n",
    "        top_indices = np.argsort(cosine_similarities)[::-1][:max_results]\n",
    "        \n",
    "        recommendations = []\n",
    "        product_list = list(product_dict.values())\n",
    "        for idx in top_indices:\n",
    "            product = product_list[idx]\n",
    "            recommendations.append({\n",
    "                'part_number': product['cisco_product_id'],\n",
    "                'commercial_name': product['commercial_name'],\n",
    "                'product_type': product['product_type'],\n",
    "                'similarity_score': float(cosine_similarities[idx]),\n",
    "                'description': f\"{product['commercial_name']} ({product['cisco_product_id']})\"\n",
    "            })\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    except Exception as e:\n",
    "        return [{\n",
    "            'error': f\"Recommendation error: {str(e)}\",\n",
    "            'requirements': requirements\n",
    "        }]\n",
    "\n",
    "# ======================================\n",
    "# 3. Pydantic Models (ATUALIZADO)\n",
    "# ======================================\n",
    "class AgentRoutingDecision(BaseModel):\n",
    "    \"\"\"Orchestrator's decision about agent routing\"\"\"\n",
    "    needs_technical: bool = Field(description=\"Whether technical agent is required\")\n",
    "    needs_pricing: bool = Field(description=\"Whether pricing agent is required\")\n",
    "    needs_design: bool = Field(False, description=\"Whether solution design is required\")  # Novo campo\n",
    "    query_parts: Dict[str, str] = Field(\n",
    "        default_factory=dict,\n",
    "        description=\"Decomposed query parts for each agent\"\n",
    "    )\n",
    "\n",
    "class SolutionComponent(BaseModel):\n",
    "    part_number: str = Field(description=\"Cisco product ID\")\n",
    "    quantity: int = Field(description=\"Quantity required\", default=1)\n",
    "    role: str = Field(description=\"Role in the solution\")\n",
    "\n",
    "class SolutionDesign(BaseModel):\n",
    "    \"\"\"Comprehensive solution design for customer requirements\"\"\"\n",
    "    summary: str = Field(description=\"High-level solution summary\")\n",
    "    components: List[SolutionComponent] = Field(description=\"List of required products\")\n",
    "    justification: str = Field(description=\"Technical and business justification\")\n",
    "\n",
    "# ======================================\n",
    "# 4. Agent Definitions (ATUALIZADO)\n",
    "# ======================================\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Orchestrator Agent\n",
    "orchestrator_prompt = ChatPromptTemplate.from_template(\n",
    "    \"You are a Cisco sales orchestration system. Analyze the user query and:\\n\"\n",
    "    \"1. Determine which specialized agents are needed\\n\"\n",
    "    \"2. Decompose the query into specific parts for each agent\\n\"\n",
    "    \"3. ALWAYS include a 'query_parts' dictionary with agent names as keys\\n\\n\"\n",
    "    \"Special handling for solution design requests:\\n\"\n",
    "    \"- If the user asks for a complete solution, architecture, or system design, set needs_design=True\\n\"\n",
    "    \"- Examples: 'design a solution for...', 'how to implement...', 'architecture for...'\\n\\n\"\n",
    "    \"Example structure for output:\\n\"\n",
    "    \"{{\\n\"\n",
    "    \"  \\\"needs_design\\\": true,\\n\"\n",
    "    \"  \\\"needs_technical\\\": false,\\n\"\n",
    "    \"  \\\"needs_pricing\\\": true,\\n\"\n",
    "    \"  \\\"query_parts\\\": {{\\n\"\n",
    "    \"    \\\"design\\\": \\\"secure cloud infrastructure for healthcare\\\"\\n\"\n",
    "    \"  }}\\n\"\n",
    "    \"}}\\n\\n\"\n",
    "    \"User Query: {query}\\n\\n\"\n",
    "    \"Output Instructions: {format_instructions}\"\n",
    ")\n",
    "orchestrator_agent = orchestrator_prompt | llm.with_structured_output(AgentRoutingDecision)\n",
    "\n",
    "# (nova instncia, obrigatria depois de adicionar needs_design)\n",
    "orchestrator_agent = (\n",
    "    orchestrator_prompt\n",
    "    | llm.with_structured_output(AgentRoutingDecision)  #  agora inclui needs_design\n",
    ")\n",
    "\n",
    "# Agente de Design de Soluo\n",
    "design_prompt = ChatPromptTemplate.from_template(\n",
    "    \"You are a Cisco Solution Architect. Design a complete solution based on the customer requirements:\\n\\n\"\n",
    "    \"Customer Requirements: {requirements}\\n\\n\"\n",
    "    \"Available Cisco Products:\\n{product_list}\\n\\n\"\n",
    "    \"Output Instructions: {format_instructions}\"\n",
    ")\n",
    "\n",
    "# Gerar lista de produtos para contexto (resumida)\n",
    "def get_product_list_str():\n",
    "    return \"\\n\".join([f\"- {p['cisco_product_id']}: {p['commercial_name']} ({p['product_type']})\" \n",
    "                      for p in product_dict.values()])\n",
    "\n",
    "design_agent = (\n",
    "    {\n",
    "        \"requirements\": lambda x: x[\"requirements\"],\n",
    "        \"product_list\": RunnableLambda(get_product_list_str),\n",
    "        \"format_instructions\": lambda x: x[\"format_instructions\"]\n",
    "    }\n",
    "    | design_prompt\n",
    "    | llm.with_structured_output(SolutionDesign)\n",
    ")\n",
    "# ======================================\n",
    "# 5. State Definition (SIMPLIFICADO)\n",
    "# ======================================\n",
    "class AgentState(TypedDict):\n",
    "    user_query: str\n",
    "    orchestrator_decision: Optional[AgentRoutingDecision]\n",
    "    technical_results: List[Dict]\n",
    "    pricing_results: List[Dict]\n",
    "    solution_design: Optional[SolutionDesign]  # Novo campo\n",
    "    final_response: str\n",
    "\n",
    "# ======================================\n",
    "# 6. Graph Nodes Implementation (COMPLETO E CORRIGIDO)\n",
    "# ======================================\n",
    "def orchestrator_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Analyzes query and plans agent workflow\"\"\"\n",
    "    print(f\"\\n [Orchestrator] Analyzing query: '{state['user_query']}'\")\n",
    "    \n",
    "    try:\n",
    "        decision = orchestrator_agent.invoke({\n",
    "            \"query\": state[\"user_query\"],\n",
    "            \"format_instructions\": AgentRoutingDecision.schema()\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\" Orchestrator error: {str(e)}\")\n",
    "        # Fallback decision\n",
    "        decision = AgentRoutingDecision(\n",
    "            needs_technical=\"spec\" in state[\"user_query\"].lower(),\n",
    "            needs_pricing=\"price\" in state[\"user_query\"].lower() or \"cost\" in state[\"user_query\"].lower(),\n",
    "            query_parts={}\n",
    "        )\n",
    "    \n",
    "    state[\"orchestrator_decision\"] = decision\n",
    "    print(f\" Routing decision: \"\n",
    "          f\"Technical={decision.needs_technical} \"\n",
    "          f\"Pricing={decision.needs_pricing}\")\n",
    "    \n",
    "    if decision.query_parts:\n",
    "        print(f\"Query parts: {decision.query_parts}\")\n",
    "    else:\n",
    "        print(\" No query parts decomposed, using fallback\")\n",
    "        decision.query_parts = {\n",
    "            \"technical\": state[\"user_query\"],\n",
    "            \"pricing\": state[\"user_query\"]\n",
    "        }\n",
    "    \n",
    "    return state\n",
    "\n",
    "# ======================================\n",
    "# 3. Atualizao do Agente Tcnico\n",
    "# ======================================\n",
    "def technical_agent_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Handles technical aspects including recommendations\"\"\"\n",
    "    if not state[\"orchestrator_decision\"].needs_technical:\n",
    "        print(\" Skipping technical agent (not required)\")\n",
    "        return state\n",
    "        \n",
    "    query_part = state[\"orchestrator_decision\"].query_parts.get(\"technical\", \"\")\n",
    "    print(f\"\\n [Technical Agent] Processing: '{query_part}'\")\n",
    "    \n",
    "    # Verifica se  uma solicitao de recomendao\n",
    "    is_recommendation_request = any(word in query_part.lower() \n",
    "                                   for word in [\"recommend\", \"suggest\", \"what\", \"which\", \"choose\"])\n",
    "    \n",
    "    # Extrai produtos especficos se mencionados\n",
    "    found_ids = []\n",
    "    pattern = r'\\b([A-Z]{2,}\\d+[A-Z]?-\\w+-\\w+)\\b'\n",
    "    found_ids = re.findall(pattern, query_part)\n",
    "    \n",
    "    # Se for solicitao de recomendao ou no encontrou produtos especficos\n",
    "    if is_recommendation_request or not found_ids:\n",
    "        print(\" Detected recommendation request\")\n",
    "        recommendations = recommend_products.invoke({\"requirements\": query_part, \"max_results\": 5})\n",
    "        \n",
    "        if recommendations:\n",
    "            state[\"technical_results\"] = []\n",
    "            for rec in recommendations:\n",
    "                if 'error' not in rec:\n",
    "                    # Obtm especificaes completas para os recomendados\n",
    "                    specs = get_technical_specs(rec['part_number'])\n",
    "                    if 'error' not in specs:\n",
    "                        specs['recommendation_score'] = rec.get('similarity_score', 0)\n",
    "                        state[\"technical_results\"].append(specs)\n",
    "            \n",
    "            print(f\" Generated {len(state['technical_results'])} recommendations\")\n",
    "        else:\n",
    "            state[\"technical_results\"] = [{\n",
    "                'error': 'No products match your requirements',\n",
    "                'query': query_part\n",
    "            }]\n",
    "    else:\n",
    "        # Busca produtos especficos mencionados\n",
    "        state[\"technical_results\"] = []\n",
    "        for product_id in set(found_ids):\n",
    "            result = get_technical_specs(product_id)\n",
    "            state[\"technical_results\"].append(result)\n",
    "        \n",
    "        print(f\" Found {len(found_ids)} specific products\")\n",
    "    \n",
    "    # Log dos resultados\n",
    "    for result in state[\"technical_results\"]:\n",
    "        if 'error' in result:\n",
    "            print(f\"   {result.get('part_number', 'Unknown')}: {result['error']}\")\n",
    "        else:\n",
    "            score = result.get('recommendation_score', '')\n",
    "            score_str = f\" [Score: {score:.2f}]\" if score else \"\"\n",
    "            print(f\"   {result.get('part_number', 'Unknown')}: Specs found{score_str}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "\n",
    "def pricing_agent_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Handles pricing aspects of products\"\"\"\n",
    "    if not state[\"orchestrator_decision\"].needs_pricing:\n",
    "        print(\" Skipping pricing agent (not required)\")\n",
    "        return state\n",
    "        \n",
    "    # Usar resultados tcnicos se disponveis\n",
    "    products = []\n",
    "    if state[\"technical_results\"]:\n",
    "        products = [{\n",
    "            'part_number': item.get('part_number', '')\n",
    "        } for item in state[\"technical_results\"]]\n",
    "    \n",
    "    # Se no tem resultados tcnicos, extrair da query de preos\n",
    "    if not products:\n",
    "        query_part = state[\"orchestrator_decision\"].query_parts.get(\"pricing\", \"\")\n",
    "        print(f\" No technical results, extracting from pricing query: '{query_part}'\")\n",
    "        \n",
    "        # Extrair todos os IDs de produto conhecidos\n",
    "        known_ids = list(product_dict.keys())\n",
    "        \n",
    "        # Encontrar IDs mencionados na query\n",
    "        for product_id in known_ids:\n",
    "            if product_id in query_part:\n",
    "                products.append({'part_number': product_id})\n",
    "        \n",
    "        # Se no encontrou, tentar padres Cisco\n",
    "        if not products:\n",
    "            pattern = r'\\b([A-Z]{2,}\\d+[A-Z]?-\\w+-\\w+)\\b'\n",
    "            found_ids = re.findall(pattern, query_part)\n",
    "            products = [{'part_number': pid} for pid in found_ids]\n",
    "    \n",
    "    if not products:\n",
    "        print(\" No products identified for pricing\")\n",
    "        products = [{'part_number': 'UNKNOWN'}]\n",
    "    \n",
    "    print(f\"\\n [Pricing Agent] Processing {len(products)} products...\")\n",
    "    state[\"pricing_results\"] = []\n",
    "    \n",
    "    for product in products:\n",
    "        pn = product.get('part_number', 'UNKNOWN')\n",
    "        result = get_product_price(pn)\n",
    "        state[\"pricing_results\"].append(result)\n",
    "    \n",
    "    # Log dos resultados\n",
    "    for result in state[\"pricing_results\"]:\n",
    "        status = \"\" if \"price\" in result and not result.get('error') else \"\"\n",
    "        print(f\"  {status} {result.get('part_number', 'Unknown')}: \"\n",
    "              f\"{result.get('price', result.get('error', 'No info'))}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "def synthesize_response_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Creates final response with solution designs\"\"\"\n",
    "    print(\"\\n [Synthesizer] Combining agent results\")\n",
    "    \n",
    "    response = []\n",
    "    \n",
    "    # Tratar designs de soluo\n",
    "    if state.get(\"solution_design\"):\n",
    "        design = state[\"solution_design\"]\n",
    "        response.append(\" Solution Design:\")\n",
    "        response.append(f\"\\n{design.summary}\")\n",
    "        \n",
    "        response.append(\"\\n\\n Solution Components:\")\n",
    "        for i, comp in enumerate(design.components, 1):\n",
    "            # Buscar informaes tcnicas deste componente\n",
    "            tech_info = next((t for t in state[\"technical_results\"] \n",
    "                            if t.get('part_number') == comp.part_number), {})\n",
    "            \n",
    "            desc = tech_info.get('description', comp.part_number)\n",
    "            response.append(f\"\\n{i}. {desc} ({comp.quantity}x) - {comp.role}\")\n",
    "            \n",
    "            # Adicionar especificaes se disponveis\n",
    "            specs = tech_info.get('specifications', {})\n",
    "            if specs:\n",
    "                for key, value in specs.items():\n",
    "                    response.append(f\"   - {key.replace('_', ' ').title()}: {value}\")\n",
    "        \n",
    "        response.append(f\"\\n\\n Justification:\\n{design.justification}\")\n",
    "        \n",
    "        # Adicionar preos se disponveis\n",
    "        if state[\"pricing_results\"]:\n",
    "            total = 0\n",
    "            response.append(\"\\n\\n Pricing Breakdown:\")\n",
    "            for product in state[\"pricing_results\"]:\n",
    "                if \"error\" not in product:\n",
    "                    qty = next((c.quantity for c in design.components \n",
    "                               if c.part_number == product['part_number']), 1)\n",
    "                    price = product.get('price', 0) * qty\n",
    "                    total += price\n",
    "                    response.append(\n",
    "                        f\"\\n- {product['description']} ({product['part_number']}) \"\n",
    "                        f\"{qty}x: {product['currency']} {price:.2f}\"\n",
    "                    )\n",
    "            response.append(f\"\\n\\n TOTAL ESTIMATED COST: {product['currency']} {total:.2f}\")\n",
    "    \n",
    "    # Restante da lgica anterior (para consultas no relacionadas a design)\n",
    "    else:\n",
    "        # ... (manter lgica anterior para consultas tcnicas e de preo)\n",
    "        pass\n",
    "    \n",
    "    # Sem resultados\n",
    "    if not response:\n",
    "        response.append(\" No relevant information found for your query\")\n",
    "    \n",
    "    state[\"final_response\"] = \"\\n\".join(response)\n",
    "    return state\n",
    "\n",
    "\n",
    "def solution_design_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Designs comprehensive solutions based on requirements\"\"\"\n",
    "    print(f\"\\n [Solution Architect] Designing solution for: {state['user_query']}\")\n",
    "    \n",
    "    try:\n",
    "        design = design_agent.invoke({\n",
    "            \"requirements\": state[\"user_query\"],\n",
    "            \"format_instructions\": SolutionDesign.schema()\n",
    "        })\n",
    "        state[\"solution_design\"] = design\n",
    "        print(f\" Solution design created with {len(design.components)} components\")\n",
    "        \n",
    "        # Extrai componentes para processamento tcnico e de preos\n",
    "        components = [{\"part_number\": c.part_number, \"quantity\": c.quantity} for c in design.components]\n",
    "        state[\"technical_results\"] = []\n",
    "        for comp in components:\n",
    "            # Busca especificaes tcnicas para cada componente\n",
    "            result = get_technical_specs(comp['part_number'])\n",
    "            if 'error' not in result:\n",
    "                result['quantity'] = comp['quantity']\n",
    "            state[\"technical_results\"].append(result)\n",
    "        \n",
    "        print(f\" Technical specs retrieved for {len(components)} components\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        state[\"solution_design\"] = {\n",
    "            \"error\": f\"Solution design failed: {str(e)}\"\n",
    "        }\n",
    "        print(f\" Solution design error: {str(e)}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "# ======================================\n",
    "# 7. Conditional Routing Logic (MANTIDO)\n",
    "# ======================================\n",
    "def route_after_orchestrator(state: AgentState) -> str:\n",
    "    decision = state[\"orchestrator_decision\"]\n",
    "    \n",
    "    if decision.needs_design:\n",
    "        return \"solution_designer\"\n",
    "    elif decision.needs_technical:\n",
    "        return \"technical_agent\"\n",
    "    elif decision.needs_pricing:\n",
    "        return \"pricing_agent\"\n",
    "    else:\n",
    "        return \"synthesize\"\n",
    "\n",
    "def route_after_designer(state: AgentState) -> str:\n",
    "    \"\"\"After solution design, always go to technical agent first\"\"\"\n",
    "    return \"technical_agent\"\n",
    "\n",
    "def route_after_technical(state: AgentState) -> str:\n",
    "    decision = state[\"orchestrator_decision\"]\n",
    "    if decision.needs_pricing:\n",
    "        return \"pricing_agent\"\n",
    "    else:\n",
    "        return \"synthesize\"\n",
    "\n",
    "def route_after_pricing(state: AgentState) -> str:\n",
    "    return \"synthesize\"\n",
    "\n",
    "# ======================================\n",
    "# 8. Build Agent Workflow Graph (MANTIDO)\n",
    "# ======================================\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Adicionar ns (incluindo o novo designer de solues)\n",
    "workflow.add_node(\"orchestrator\", orchestrator_node)\n",
    "workflow.add_node(\"solution_designer\", solution_design_node)  # Novo n\n",
    "workflow.add_node(\"technical_agent\", technical_agent_node)\n",
    "workflow.add_node(\"pricing_agent\", pricing_agent_node)\n",
    "workflow.add_node(\"synthesize\", synthesize_response_node)\n",
    "\n",
    "\n",
    "workflow.set_entry_point(\"orchestrator\")\n",
    "\n",
    "# Roteamento do orquestrador\n",
    "workflow.add_conditional_edges(\n",
    "    \"orchestrator\",\n",
    "    route_after_orchestrator,\n",
    "    {\n",
    "        \"solution_designer\": \"solution_designer\",\n",
    "        \"technical_agent\": \"technical_agent\",\n",
    "        \"pricing_agent\": \"pricing_agent\",\n",
    "        \"synthesize\": \"synthesize\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Roteamento do designer de solues\n",
    "workflow.add_conditional_edges(\n",
    "    \"solution_designer\",\n",
    "    route_after_designer,\n",
    "    {\n",
    "        \"technical_agent\": \"technical_agent\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Roteamento do agente tcnico\n",
    "workflow.add_conditional_edges(\n",
    "    \"technical_agent\",\n",
    "    route_after_technical,\n",
    "    {\n",
    "        \"pricing_agent\": \"pricing_agent\",\n",
    "        \"synthesize\": \"synthesize\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Roteamento do agente de preos\n",
    "workflow.add_conditional_edges(\n",
    "    \"pricing_agent\",\n",
    "    route_after_pricing,\n",
    "    {\n",
    "        \"synthesize\": \"synthesize\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"synthesize\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "# ======================================\n",
    "# 9. Run the Agent Workflow (ATUALIZADO)\n",
    "# ======================================\n",
    "def run_sales_quote(user_query: str) -> str:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\" STARTING QUOTE PROCESSING: '{user_query}'\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    initial_state = {\n",
    "        \"user_query\": user_query,\n",
    "        \"orchestrator_decision\": None,\n",
    "        \"technical_results\": [],\n",
    "        \"pricing_results\": [],\n",
    "        \"final_response\": \"\"\n",
    "    }\n",
    "    \n",
    "    final_state = app.invoke(initial_state)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\" QUOTE PROCESSING COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return final_state[\"final_response\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43801131-eb92-4a20-aaf2-0da35c69bec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b28eeb-c56c-4790-b36d-0152b875ce4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# 10. Test Cases (ATUALIZADO)\n",
    "# ======================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Test 1: Solicitao tcnica + preo\n",
    "    test_query_1 = \"I need technical specs for ASA5516-FPWR-K9 and pricing for MR53E-HW\"\n",
    "    result_1 = run_sales_quote(test_query_1)\n",
    "    print(\"\\n CLIENT RESPONSE 1:\")\n",
    "    print(result_1)\n",
    "    \n",
    "    # Test 2: Solicitao de preo com nome comercial\n",
    "    test_query_2 = \"How much does QSFP-100G-SR4-S cost?\"\n",
    "    result_2 = run_sales_quote(test_query_2)\n",
    "    print(\"\\n CLIENT RESPONSE 2:\")\n",
    "    print(result_2)\n",
    "    \n",
    "    # Test 3: Solicitao tcnica com nome comercial\n",
    "    test_query_3 = \"What are the specifications for the Catalyst 9300 switch?\"\n",
    "    result_3 = run_sales_quote(test_query_3)\n",
    "    print(\"\\n CLIENT RESPONSE 3:\")\n",
    "    print(result_3)\n",
    "    \n",
    "    # Test 4: Produto no encontrado\n",
    "    test_query_4 = \"Price for NONEXISTENT-PRODUCT-123\"\n",
    "    result_4 = run_sales_quote(test_query_4)\n",
    "    print(\"\\n CLIENT RESPONSE 4:\")\n",
    "    print(result_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1178bd78-43df-456e-ab12-64d077a5ccbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "4bdf6650-b554-42a1-99cc-1a4a11af2059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " STARTING QUOTE PROCESSING: 'How can I create a quote for a healthcare client with 200 users who needs cloud security and hybrid infrastructure?'\n",
      "============================================================\n",
      "\n",
      " [Orchestrator] Analyzing query: 'How can I create a quote for a healthcare client with 200 users who needs cloud security and hybrid infrastructure?'\n",
      " Routing decision: Technical=True Pricing=True\n",
      "Query parts: {'technical': 'cloud security and hybrid infrastructure', 'pricing': 'quote for a healthcare client with 200 users'}\n",
      "\n",
      " [Technical Agent] Processing: 'cloud security and hybrid infrastructure'\n",
      " Detected recommendation request\n",
      " Recommending products for: cloud security and hybrid infrastructure\n",
      " Searching specs for: ASA5555-X\n",
      " Searching specs for: ASA5525-X\n",
      " Searching specs for: ASA5516-FPWR-K9\n",
      " Searching specs for: QSFP-100G-SR4-S\n",
      " Searching specs for: QSFP-100G-LR4-S\n",
      " Generated 5 recommendations\n",
      "   ASA5555-X: Specs found [Score: 0.21]\n",
      "   ASA5525-X: Specs found [Score: 0.20]\n",
      "   ASA5516-FPWR-K9: Specs found [Score: 0.20]\n",
      "   QSFP-100G-SR4-S: Specs found\n",
      "   QSFP-100G-LR4-S: Specs found\n",
      "\n",
      " [Pricing Agent] Processing 5 products...\n",
      " Searching price for: ASA5555-X\n",
      " Searching price for: ASA5525-X\n",
      " Searching price for: ASA5516-FPWR-K9\n",
      " Searching price for: QSFP-100G-SR4-S\n",
      " Searching price for: QSFP-100G-LR4-S\n",
      "   ASA5555-X: 28738.01\n",
      "   ASA5525-X: 10225.02\n",
      "   ASA5516-FPWR-K9: 5995.0\n",
      "   QSFP-100G-SR4-S: 1995.0\n",
      "   QSFP-100G-LR4-S: 29995.0\n",
      "\n",
      " [Synthesizer] Combining agent results\n",
      "\n",
      "============================================================\n",
      " QUOTE PROCESSING COMPLETE\n",
      "============================================================\n",
      " No relevant information found for your query\n"
     ]
    }
   ],
   "source": [
    "# Teste de design de soluo\n",
    "test_query = \"How can I create a quote for a healthcare client with 200 users who needs cloud security and hybrid infrastructure?\"\n",
    "result = run_sales_quote(test_query)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ac97b3-2642-4918-aac4-1875f714d0f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "514dd37a-7bf4-46ab-82b6-fc3c808130ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " STARTING QUOTE PROCESSING: 'I need technical specs for ASA5516-FPWR-K9 and pricing for MR53E-HW'\n",
      "============================================================\n",
      "\n",
      " [Orchestrator] Analyzing query: 'I need technical specs for ASA5516-FPWR-K9 and pricing for MR53E-HW'\n",
      " Routing decision: Technical=True Pricing=True\n",
      "Query parts: {'technical': 'technical specs for ASA5516-FPWR-K9', 'pricing': 'pricing for MR53E-HW'}\n",
      "\n",
      " [Technical Agent] Processing: 'technical specs for ASA5516-FPWR-K9'\n",
      " Searching specs for: ASA5516-FPWR-K9\n",
      " Found 1 specific products\n",
      "   ASA5516-FPWR-K9: Specs found\n",
      "\n",
      " [Pricing Agent] Processing 1 products...\n",
      " Searching price for: ASA5516-FPWR-K9\n",
      "   ASA5516-FPWR-K9: 5995.0\n",
      "\n",
      " [Synthesizer] Combining agent results\n",
      "\n",
      "============================================================\n",
      " QUOTE PROCESSING COMPLETE\n",
      "============================================================\n",
      "\n",
      " CLIENT RESPONSE 1:\n",
      "\n",
      " Technical Specifications:\n",
      "\n",
      " ASA 5516-X with FirePOWER Services (ASA5516-FPWR-K9)\n",
      "  - Category: security\n",
      "  - Subcategory: firewall\n",
      "  - Throughput: 4 Gbps\n",
      "  - Interfaces: 8x GE\n",
      "  - Vpn Throughput: 1 Gbps\n",
      "  - Threat Throughput: 500 Mbps\n",
      "  - Encryption: 3DES/AES\n",
      "\n",
      "\n",
      " Pricing Information:\n",
      "\n",
      " ASA 5516-X with FirePOWER Services (ASA5516-FPWR-K9)\n",
      "   Price: USD 5995.0\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Solicitao tcnica + preo\n",
    "test_query_1 = \"I need technical specs for ASA5516-FPWR-K9 and pricing for MR53E-HW\"\n",
    "result_1 = run_sales_quote(test_query_1)\n",
    "print(\"\\n CLIENT RESPONSE 1:\")\n",
    "print(result_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5920ee-2c5c-4091-826c-88a8e93a4399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64628d4a-827c-4e80-9eba-22e17ee1870a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "bb8bc4ab-1ef0-458c-bb9f-e672a27af70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " STARTING QUOTE PROCESSING: 'I need some firewall with throughput of only 4 Gbps and a price igual to 5995.00, what do  you recommend?'\n",
      "============================================================\n",
      "\n",
      " [Orchestrator] Analyzing query: 'I need some firewall with throughput of only 4 Gbps and a price igual to 5995.00, what do  you recommend?'\n",
      " Routing decision: Technical=True Pricing=True\n",
      "Query parts: {'technical': 'firewall recommendations with throughput of 4 Gbps', 'pricing': 'price equal to 5995.00'}\n",
      "\n",
      " [Technical Agent] Processing: 'firewall recommendations with throughput of 4 Gbps'\n",
      " Detected recommendation request\n",
      " Recommending products for: firewall recommendations with throughput of 4 Gbps\n",
      " Searching specs for: ASA5555-X\n",
      " Searching specs for: ASA5525-X\n",
      " Searching specs for: ASA5516-FPWR-K9\n",
      " Searching specs for: MR53E-HW\n",
      " Searching specs for: MR42E-HW\n",
      " Generated 5 recommendations\n",
      "   ASA5555-X: Specs found [Score: 0.64]\n",
      "   ASA5525-X: Specs found [Score: 0.62]\n",
      "   ASA5516-FPWR-K9: Specs found [Score: 0.40]\n",
      "   MR53E-HW: Specs found [Score: 0.20]\n",
      "   MR42E-HW: Specs found [Score: 0.19]\n",
      "\n",
      " [Pricing Agent] Processing 5 products...\n",
      " Searching price for: ASA5555-X\n",
      " Searching price for: ASA5525-X\n",
      " Searching price for: ASA5516-FPWR-K9\n",
      " Searching price for: MR53E-HW\n",
      " Searching price for: MR42E-HW\n",
      "   ASA5555-X: 28738.01\n",
      "   ASA5525-X: 10225.02\n",
      "   ASA5516-FPWR-K9: 5995.0\n",
      "   MR53E-HW: 1699.0\n",
      "   MR42E-HW: 1099.0\n",
      "\n",
      " [Synthesizer] Combining agent results\n",
      "\n",
      "============================================================\n",
      " QUOTE PROCESSING COMPLETE\n",
      "============================================================\n",
      "\n",
      " CLIENT RESPONSE 2:\n",
      " Based on your requirements, I recommend these products:\n",
      "\n",
      " #1: ASA 5555-X Firewall (Match: 63.9%)\n",
      "   Key Specifications:\n",
      "   - Category: security\n",
      "   - Subcategory: firewall\n",
      "   - Throughput: 20 Gbps\n",
      "   - Interfaces: 8x GE + expansion\n",
      "   - Vpn Throughput: 5 Gbps\n",
      "   - Threat Throughput: 4 Gbps\n",
      "\n",
      " #2: ASA 5525-X Firewall (Match: 62.3%)\n",
      "   Key Specifications:\n",
      "   - Category: security\n",
      "   - Subcategory: firewall\n",
      "   - Throughput: 10 Gbps\n",
      "   - Interfaces: 8x GE + 1x Mgmt\n",
      "   - Vpn Throughput: 2 Gbps\n",
      "   - Threat Throughput: 1.5 Gbps\n",
      "\n",
      " #3: ASA 5516-X with FirePOWER Services (Match: 39.8%)\n",
      "   Key Specifications:\n",
      "   - Category: security\n",
      "   - Subcategory: firewall\n",
      "   - Throughput: 4 Gbps\n",
      "   - Interfaces: 8x GE\n",
      "   - Vpn Throughput: 1 Gbps\n",
      "   - Threat Throughput: 500 Mbps\n",
      "   - Encryption: 3DES/AES\n",
      "\n",
      " #4: Meraki MR53E Access Point (Match: 19.9%)\n",
      "   Key Specifications:\n",
      "   - Category: wireless\n",
      "   - Subcategory: access_point\n",
      "   - Wifi Standard: 802.11ax\n",
      "   - Throughput: 2.5 Gbps\n",
      "   - Antenna Type: external\n",
      "   - Mounting: indoor\n",
      "   - Power Requirements: PoE+\n",
      "\n",
      " #5: Meraki MR42E Access Point (Match: 19.2%)\n",
      "   Key Specifications:\n",
      "   - Category: wireless\n",
      "   - Subcategory: access_point\n",
      "   - Wifi Standard: 802.11ac Wave 2\n",
      "   - Throughput: 1.7 Gbps\n",
      "   - Antenna Type: external\n",
      "   - Mounting: indoor\n",
      "   - Power Requirements: PoE+\n",
      "\n",
      "\n",
      " Pricing Information:\n",
      "\n",
      " ASA 5555-X Firewall (ASA5555-X)\n",
      "   Price: USD 28738.01\n",
      "\n",
      " ASA 5525-X Firewall (ASA5525-X)\n",
      "   Price: USD 10225.02\n",
      "\n",
      " ASA 5516-X with FirePOWER Services (ASA5516-FPWR-K9)\n",
      "   Price: USD 5995.0\n",
      "\n",
      " Meraki MR53E Access Point (MR53E-HW)\n",
      "   Price: USD 1699.0\n",
      "\n",
      " Meraki MR42E Access Point (MR42E-HW)\n",
      "   Price: USD 1099.0\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Solicitao de preo com nome comercial\n",
    "test_query_2 = \"I need some firewall with throughput of only 4 Gbps and a price igual to 5995.00, what do  you recommend?\"\n",
    "result_2 = run_sales_quote(test_query_2)\n",
    "print(\"\\n CLIENT RESPONSE 2:\")\n",
    "print(result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c2599e-3e59-4a34-b78d-4d7edebd0a12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c73b9a7-ca7f-4177-8285-ad583dae464c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500f2e20-b2bf-4a7a-bae8-7a3ea040e552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3ab2a2-6599-4be4-8db5-b6b708f1fded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05e4a6e-c49f-4dff-b9c3-40d66ebc6627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65795d1-5401-4b4a-bc5f-7a1946df5c48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f59fca-96e5-4831-a1a9-c82c37eaa239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "926f5f4e-4e08-476e-911a-fe75a13bd008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data loaded: 16 products\n",
      " Recommendation data prepared\n",
      "\n",
      " [Orchestrator] Design a secure branchoffice solution for 50 users with WiFi6, firewall and PoE switches. Provide pricing.\n",
      "\n",
      " [Solution Designer]\n",
      " Technical Agent skipped (solution design already provides specs)\n",
      "\n",
      " [Pricing Agent]\n",
      "\n",
      " [Synthesizer]\n",
      " Solution Design\n",
      "Design a secure branch-office solution for 50 users with Wi-Fi 6, firewall, and PoE switches.\n",
      "\n",
      " Components:\n",
      "1. ASA 5516-X with FirePOWER Services (1)  Firewall with FirePOWER Services\n",
      "2. Meraki MR53E Access Point (3)  Wi-Fi 6 Access Points for coverage and capacity\n",
      "3. ASA 5555-X Firewall (1)  Additional Firewall for redundancy and security\n",
      "\n",
      " Justification:\n",
      "The ASA5516-FPWR-K9 provides robust firewall capabilities with FirePOWER services, suitable for securing the branch office. The MR53E-HW access points support Wi-Fi 6, ensuring high performance and capacity for 50 users. The additional ASA5555-X firewall offers redundancy and enhanced security features.\n",
      "\n",
      " Pricing:\n",
      "- ASA 5516-X with FirePOWER Services (1): USD 5995.00\n",
      "- Meraki MR53E Access Point (3): USD 5097.00\n",
      "- ASA 5555-X Firewall (1): USD 28738.01\n",
      "\n",
      "TOTAL ESTIMATED: USD 39830.01\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# Cisco Sales Assistant  fluxo completo (julho/2025)\n",
    "# =============================================================\n",
    "\"\"\"\n",
    "Cria um agente LangGraph capaz de:\n",
    "   analisar a consulta do cliente\n",
    "   projetar uma soluo (Solution Designer)\n",
    "   buscar especificaes tcnicas\n",
    "   precificar os componentes\n",
    "   sintetizar tudo em uma resposta final\n",
    "\n",
    "Requisitos:\n",
    "  pip install langchain langgraph langchain-openai scikit-learn numpy\n",
    "\"\"\"\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 0. Imports\n",
    "# -------------------------------------------------------------\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict, TypedDict, Optional\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from langchain.tools import tool\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1. Carregar catlogo Cisco\n",
    "# -------------------------------------------------------------\n",
    "product_dict: Dict[str, Dict] = {}\n",
    "PRICELIST_PATH = \"data/raw/pricelist.json\"      # ajuste se necessrio\n",
    "\n",
    "try:\n",
    "    with open(PRICELIST_PATH, encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        products = data if isinstance(data, list) else data.get(\"products\", [])\n",
    "        for p in products:\n",
    "            pid = p.get(\"cisco_product_id\")\n",
    "            if pid:\n",
    "                product_dict[pid] = p\n",
    "    print(f\" Data loaded: {len(product_dict)} products\")\n",
    "except Exception as e:\n",
    "    print(f\" Error loading product data: {e}\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2. Preparar embeddings TFIDF para recomendaes\n",
    "# -------------------------------------------------------------\n",
    "def prepare_recommendation_data():\n",
    "    \"\"\"Gera matriz TFIDF a partir do catlogo para busca semntica.\"\"\"\n",
    "    texts: List[str] = []\n",
    "    for p in product_dict.values():\n",
    "        hw = p.get(\"technical_profile\", {}).get(\"hardware_attributes\", {})\n",
    "        txt = (\n",
    "            f\"{p.get('commercial_name', '')} {p.get('product_type', '')} \"\n",
    "            + \" \".join(f\"{k}={v}\" for k, v in hw.items())\n",
    "        ).strip()\n",
    "        texts.append(txt)\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "    matrix = vectorizer.fit_transform(texts) if texts else None\n",
    "    return vectorizer, matrix\n",
    "\n",
    "\n",
    "vectorizer, tfidf_matrix = prepare_recommendation_data()\n",
    "print(\" Recommendation data prepared\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3. Helper  lista enxuta de produtos (TOPK)\n",
    "# -------------------------------------------------------------\n",
    "def get_product_list_str(requirements: str, top_k: int = 50) -> str:\n",
    "    if tfidf_matrix is None:\n",
    "        return \"(catalog empty)\"\n",
    "    vec = vectorizer.transform([requirements])\n",
    "    sims = cosine_similarity(vec, tfidf_matrix).flatten()\n",
    "    idxs = sims.argsort()[::-1][:top_k]\n",
    "    prods = [list(product_dict.values())[i] for i in idxs]\n",
    "    return \"\\n\".join(\n",
    "        f\"- {p['cisco_product_id']}: {p['commercial_name']} \"\n",
    "        f\"({p['product_type']})\"\n",
    "        for p in prods\n",
    "    )\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4. Ferramentas (LangChain@tool)\n",
    "# -------------------------------------------------------------\n",
    "@tool\n",
    "def get_product_price(part_number: str) -> Dict:\n",
    "    \"\"\"Retrieve pricing information for a Cisco product.\"\"\"\n",
    "    prod = product_dict.get(part_number)\n",
    "    if not prod:\n",
    "        return {\"error\": f\"Product {part_number} not found\", \"part_number\": part_number}\n",
    "    pricing = prod.get(\"pricing_model\", {})\n",
    "    return {\n",
    "        \"price\": pricing.get(\"base_price\", 0.0),\n",
    "        \"currency\": pricing.get(\"currency\", \"USD\"),\n",
    "        \"description\": prod.get(\"commercial_name\", \"\"),\n",
    "        \"part_number\": part_number,\n",
    "        \"product_type\": prod.get(\"product_type\", \"\"),\n",
    "    }\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_technical_specs(part_number: str) -> Dict:\n",
    "    \"\"\"Retrieve hardware specifications for a Cisco product.\"\"\"\n",
    "    prod = product_dict.get(part_number)\n",
    "    if not prod:\n",
    "        return {\"error\": f\"Product {part_number} not found\", \"part_number\": part_number}\n",
    "    hw = prod.get(\"technical_profile\", {}).get(\"hardware_attributes\", {})\n",
    "    if not hw:\n",
    "        return {\"error\": f\"No technical specs for {part_number}\", \"part_number\": part_number}\n",
    "    return {\n",
    "        \"specifications\": hw,\n",
    "        \"description\": prod.get(\"commercial_name\", \"\"),\n",
    "        \"part_number\": part_number,\n",
    "        \"product_type\": prod.get(\"product_type\", \"\"),\n",
    "    }\n",
    "\n",
    "\n",
    "@tool\n",
    "def recommend_products(requirements: str, max_results: int = 3) -> List[Dict]:\n",
    "    \"\"\"Recommend Cisco products that best match the given requirements.\"\"\"\n",
    "    if tfidf_matrix is None:\n",
    "        return [{\"error\": \"Catalog not indexed\"}]\n",
    "    vec = vectorizer.transform([requirements])\n",
    "    sims = cosine_similarity(vec, tfidf_matrix).flatten()\n",
    "    idxs = sims.argsort()[::-1][:max_results]\n",
    "    base = list(product_dict.values())\n",
    "    return [\n",
    "        {\n",
    "            \"part_number\": base[i][\"cisco_product_id\"],\n",
    "            \"commercial_name\": base[i][\"commercial_name\"],\n",
    "            \"product_type\": base[i][\"product_type\"],\n",
    "            \"similarity_score\": float(sims[i]),\n",
    "        }\n",
    "        for i in idxs\n",
    "    ]\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 5. Pydanticmodels\n",
    "# -------------------------------------------------------------\n",
    "class SolutionComponent(BaseModel):\n",
    "    part_number: str = Field(description=\"Cisco product ID\")\n",
    "    quantity: int = Field(default=1, description=\"Quantity required\")\n",
    "    role: str = Field(description=\"Role in the solution\")\n",
    "\n",
    "\n",
    "class SolutionDesign(BaseModel):\n",
    "    summary: str\n",
    "    components: List[SolutionComponent]\n",
    "    justification: str\n",
    "\n",
    "\n",
    "class AgentRoutingDecision(BaseModel):\n",
    "    needs_design: bool = False\n",
    "    needs_technical: bool = False\n",
    "    needs_pricing: bool = False\n",
    "    query_parts: Dict[str, str] = Field(default_factory=dict)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 6. LLMeprompts\n",
    "# -------------------------------------------------------------\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "#  Orchestrator (corrigido)\n",
    "orchestrator_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a Cisco sales orchestration system.\n",
    "\n",
    "Analyse the user query and decide which specialised agents are needed:\n",
    "   Solution Designer    needs_design\n",
    "   Technical Agent      needs_technical\n",
    "   Pricing Agent        needs_pricing\n",
    "\n",
    "ALWAYS output a JSON object that matches the schema shown in\n",
    "{{format_instructions}}.\n",
    "\n",
    "User query: {{query}}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "orchestrator_agent = orchestrator_prompt | llm.with_structured_output(\n",
    "    AgentRoutingDecision\n",
    ")\n",
    "\n",
    "#  SolutionDesigner\n",
    "design_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a Cisco Solution Architect. Design a complete solution.\n",
    "\n",
    "Customer Requirements:\n",
    "{requirements}\n",
    "\n",
    "Available Cisco Products:\n",
    "{product_list}\n",
    "\n",
    "Return only part_numbers that appear above.\n",
    "Output as JSON in the schema provided.\"\"\"\n",
    ")\n",
    "design_agent = (\n",
    "    {\n",
    "        \"requirements\": lambda x: x[\"requirements\"],\n",
    "        \"product_list\": lambda x: get_product_list_str(x[\"requirements\"]),\n",
    "        \"format_instructions\": lambda x: x[\"format_instructions\"],\n",
    "    }\n",
    "    | design_prompt\n",
    "    | llm.with_structured_output(SolutionDesign)\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 7. Statetype\n",
    "# -------------------------------------------------------------\n",
    "class AgentState(TypedDict):\n",
    "    user_query: str\n",
    "    orchestrator_decision: Optional[AgentRoutingDecision]\n",
    "    solution_design: Optional[SolutionDesign]\n",
    "    technical_results: List[Dict]\n",
    "    pricing_results: List[Dict]\n",
    "    final_response: str\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 8. NOrchestrator\n",
    "# -------------------------------------------------------------\n",
    "def orchestrator_node(state: AgentState) -> AgentState:\n",
    "    print(f\"\\n [Orchestrator] {state['user_query']}\")\n",
    "\n",
    "    q = state[\"user_query\"]\n",
    "\n",
    "    # 1) tentativa normal com o LLM\n",
    "    try:\n",
    "        decision = orchestrator_agent.invoke(\n",
    "            {\n",
    "                \"query\": q,\n",
    "                \"format_instructions\": AgentRoutingDecision.schema(),\n",
    "            }\n",
    "        )\n",
    "    except Exception:\n",
    "        print(\" LLM parse fail  empty decision\")\n",
    "        decision = AgentRoutingDecision()\n",
    "\n",
    "    # 2) heurstica se vier tudo falso\n",
    "    if not any([decision.needs_design, decision.needs_technical, decision.needs_pricing]):\n",
    "        q_low = q.lower()\n",
    "        decision = AgentRoutingDecision(\n",
    "            needs_design=any(w in q_low for w in [\"design\", \"architecture\", \"solution\"]),\n",
    "            needs_technical=\"spec\" in q_low,\n",
    "            needs_pricing=any(w in q_low for w in [\"price\", \"cost\", \"quote\", \"pricing\"]),\n",
    "            query_parts={},\n",
    "        )\n",
    "\n",
    "    # 3) salva no estado e retorna\n",
    "    state[\"orchestrator_decision\"] = decision\n",
    "    return state\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 9. NSolutionDesigner\n",
    "# -------------------------------------------------------------\n",
    "def solution_design_node(state: AgentState) -> AgentState:\n",
    "    print(\"\\n [Solution Designer]\")\n",
    "    design = design_agent.invoke(\n",
    "        {\"requirements\": state[\"user_query\"], \"format_instructions\": SolutionDesign.schema()}\n",
    "    )\n",
    "    state[\"solution_design\"] = design\n",
    "    # fora que o agente de preo rode depois\n",
    "    state[\"orchestrator_decision\"].needs_pricing = True\n",
    "\n",
    "    # specs de cada componente\n",
    "    state[\"technical_results\"] = []\n",
    "    for comp in design.components:\n",
    "        res = get_technical_specs(comp.part_number)\n",
    "        if \"error\" not in res:\n",
    "            res[\"quantity\"] = comp.quantity\n",
    "        state[\"technical_results\"].append(res)\n",
    "    return state\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 10. N  Technical Agent  (substitua TODO o bloco)\n",
    "# -------------------------------------------------------------\n",
    "### helper: extrai possveis Cisco partnumbers do texto\n",
    "PART_RE = re.compile(r\"[A-Z]{2,}\\d+[A-Z]*-[A-Za-z0-9]+(?:-[A-Za-z0-9]+)*\")\n",
    "\n",
    "def extract_part_numbers(text: str) -> List[str]:\n",
    "    return list({m.group(0) for m in PART_RE.finditer(text)})\n",
    "\n",
    "def technical_agent_node(state: AgentState) -> AgentState:\n",
    "    # pula se j h design\n",
    "    if state.get(\"solution_design\") is not None:\n",
    "        print(\" Technical Agent skipped (solution design already provides specs)\")\n",
    "        return state\n",
    "\n",
    "    query_part = state[\"orchestrator_decision\"].query_parts.get(\n",
    "        \"technical\", state[\"user_query\"]\n",
    "    )\n",
    "    ids = extract_part_numbers(query_part)\n",
    "\n",
    "    if ids:\n",
    "        print(f\"\\n [Technical Agent] Found explicit IDs: {ids}\")\n",
    "        state[\"technical_results\"] = [get_technical_specs(pid) for pid in ids]\n",
    "        return state\n",
    "\n",
    "    # fallback para recomendao sem IDs\n",
    "    if not state[\"orchestrator_decision\"].needs_technical:\n",
    "        print(\" Technical Agent skipped (flag false & no IDs)\")\n",
    "        return state\n",
    "\n",
    "    print(f\"\\n [Technical Agent] Generating recommendations for {query_part}\")\n",
    "    recs = recommend_products.invoke({\"requirements\": query_part, \"max_results\": 5})\n",
    "    state[\"technical_results\"] = []\n",
    "    for r in recs:\n",
    "        spec = get_technical_specs(r[\"part_number\"])\n",
    "        if \"error\" not in spec:\n",
    "            spec[\"recommendation_score\"] = r.get(\"similarity_score\", 0)\n",
    "        state[\"technical_results\"].append(spec)\n",
    "    return state\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 11. N  Pricing Agent  (substitua TODO o bloco)\n",
    "# -------------------------------------------------------------\n",
    "def pricing_agent_node(state: AgentState) -> AgentState:\n",
    "    if not state[\"orchestrator_decision\"].needs_pricing:\n",
    "        print(\" Pricing Agent skipped\")\n",
    "        return state\n",
    "\n",
    "    print(\"\\n [Pricing Agent]\")\n",
    "\n",
    "    # 1) Se houver design  componentes do design\n",
    "    if isinstance(state.get(\"solution_design\"), SolutionDesign):\n",
    "        items = [\n",
    "            {\"part_number\": c.part_number, \"quantity\": c.quantity}\n",
    "            for c in state[\"solution_design\"].components\n",
    "        ]\n",
    "    else:\n",
    "        # 2) Extrai IDs mencionados na parte de preo da query\n",
    "        pricing_part = state[\"orchestrator_decision\"].query_parts.get(\"pricing\", state[\"user_query\"])\n",
    "        ids = extract_part_numbers(pricing_part)\n",
    "        if ids:\n",
    "            items = [{\"part_number\": pid, \"quantity\": 1} for pid in ids]\n",
    "        else:\n",
    "            # 3) fallback: usa IDs de technical_results\n",
    "            items = [\n",
    "                {\"part_number\": t.get(\"part_number\"), \"quantity\": t.get(\"quantity\", 1)}\n",
    "                for t in state[\"technical_results\"] if t.get(\"part_number\")\n",
    "            ]\n",
    "\n",
    "    # deduplicar\n",
    "    dedup: Dict[str, int] = {}\n",
    "    for it in items:\n",
    "        dedup[it[\"part_number\"]] = dedup.get(it[\"part_number\"], 0) + it[\"quantity\"]\n",
    "\n",
    "    state[\"pricing_results\"] = []\n",
    "    for pn, qty in dedup.items():\n",
    "        price_info = get_product_price(pn)\n",
    "        price_info.update(\n",
    "            {\n",
    "                \"quantity\": qty,\n",
    "                \"subtotal\": price_info.get(\"price\", 0) * qty,\n",
    "            }\n",
    "        )\n",
    "        state[\"pricing_results\"].append(price_info)\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 12. NSynthesizer\n",
    "# -------------------------------------------------------------\n",
    "def synthesize_node(state: AgentState) -> AgentState:\n",
    "    print(\"\\n [Synthesizer]\")\n",
    "    lines: List[str] = []\n",
    "\n",
    "    # caso haja Solution Design\n",
    "    if isinstance(state.get(\"solution_design\"), SolutionDesign):\n",
    "        d = state[\"solution_design\"]\n",
    "        lines.append(\" Solution Design\\n\" + d.summary)\n",
    "        lines.append(\"\\n Components:\")\n",
    "        for i, c in enumerate(d.components, 1):\n",
    "            desc = next(\n",
    "                (\n",
    "                    t.get(\"description\")\n",
    "                    for t in state[\"technical_results\"]\n",
    "                    if t.get(\"part_number\") == c.part_number\n",
    "                ),\n",
    "                c.part_number,\n",
    "            )\n",
    "            lines.append(f\"{i}. {desc} ({c.quantity})  {c.role}\")\n",
    "        lines.append(\"\\n Justification:\\n\" + d.justification)\n",
    "\n",
    "    # preos\n",
    "    if state[\"pricing_results\"]:\n",
    "        total = 0.0\n",
    "        currency = \"USD\"\n",
    "        lines.append(\"\\n Pricing:\")\n",
    "        for p in state[\"pricing_results\"]:\n",
    "            if \"error\" in p:\n",
    "                lines.append(f\"- {p.get('part_number')}: {p['error']}\")\n",
    "                continue\n",
    "            currency = p[\"currency\"]\n",
    "            total += p[\"subtotal\"]\n",
    "            lines.append(\n",
    "                f\"- {p['description']} ({p['quantity']}): \"\n",
    "                f\"{currency} {p['subtotal']:.2f}\"\n",
    "            )\n",
    "        lines.append(f\"\\nTOTAL ESTIMATED: {currency} {total:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "    if not lines:\n",
    "        lines.append(\" No relevant information found\")\n",
    "\n",
    "    state[\"final_response\"] = \"\\n\".join(lines)\n",
    "    return state\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 13. Roteamento\n",
    "# -------------------------------------------------------------\n",
    "def route_after_orch(state: AgentState) -> str:\n",
    "    dec = state[\"orchestrator_decision\"]\n",
    "    if dec.needs_design:\n",
    "        return \"designer\"\n",
    "    if dec.needs_technical:\n",
    "        return \"tech\"\n",
    "    if dec.needs_pricing:\n",
    "        return \"price\"\n",
    "    return \"synth\"\n",
    "\n",
    "\n",
    "def route_after_designer(_):  # sempre vai para specs\n",
    "    return \"tech\"\n",
    "\n",
    "\n",
    "def route_after_tech(state: AgentState) -> str:\n",
    "    return \"price\" if state[\"orchestrator_decision\"].needs_pricing else \"synth\"\n",
    "\n",
    "\n",
    "def route_after_price(_):\n",
    "    return \"synth\"\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 14. Construir ografo\n",
    "# -------------------------------------------------------------\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"orch\", orchestrator_node)\n",
    "workflow.add_node(\"designer\", solution_design_node)\n",
    "workflow.add_node(\"tech\", technical_agent_node)\n",
    "workflow.add_node(\"price\", pricing_agent_node)\n",
    "workflow.add_node(\"synth\", synthesize_node)\n",
    "\n",
    "workflow.set_entry_point(\"orch\")\n",
    "workflow.add_conditional_edges(\"orch\", route_after_orch, {\n",
    "    \"designer\": \"designer\",\n",
    "    \"tech\": \"tech\",\n",
    "    \"price\": \"price\",\n",
    "    \"synth\": \"synth\",\n",
    "})\n",
    "workflow.add_conditional_edges(\"designer\", route_after_designer, {\"tech\": \"tech\"})\n",
    "workflow.add_conditional_edges(\"tech\", route_after_tech, {\"price\": \"price\", \"synth\": \"synth\"})\n",
    "workflow.add_conditional_edges(\"price\", route_after_price, {\"synth\": \"synth\"})\n",
    "workflow.add_edge(\"synth\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 15. Helper para executar\n",
    "# -------------------------------------------------------------\n",
    "def run_sales_quote(query: str) -> str:\n",
    "    init: AgentState = {\n",
    "        \"user_query\": query,\n",
    "        \"orchestrator_decision\": None,\n",
    "        \"solution_design\": None,\n",
    "        \"technical_results\": [],\n",
    "        \"pricing_results\": [],\n",
    "        \"final_response\": \"\",\n",
    "    }\n",
    "    final_state = app.invoke(init)\n",
    "    return final_state[\"final_response\"]\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 16. Exemplo\n",
    "# -------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    q = (\n",
    "        \"Design a secure branchoffice solution for 50 users with WiFi6, \"\n",
    "        \"firewall and PoE switches. Provide pricing.\"\n",
    "    )\n",
    "    print(run_sales_quote(q))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b18ee1d-d16d-4660-a22a-e0f413a3bf86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cd2657-f877-48a3-b598-09f1ca273737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5508823-c487-4785-b615-dc49a65072d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "235f53dd-7415-4513-836a-acb7d9448cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to read the file: data/raw/pricelist.json\n",
      " Success! File has been re-saved with correct UTF-8 encoding at: data/raw/pricelist_corrected.json\n",
      "\n",
      "Please update your 'tools.py' and 'scripts/ingest_data.py' files to use this new filename.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the path to your problematic JSON file\n",
    "# NOTE: The file name might be different on your end. Please double-check.\n",
    "problem_file_path = 'data/raw/pricelist.json' \n",
    "corrected_file_path = 'data/raw/pricelist_corrected.json' # We'll save it as a new file\n",
    "\n",
    "try:\n",
    "    print(f\"Attempting to read the file: {problem_file_path}\")\n",
    "    \n",
    "    # Read the file using 'latin-1' encoding, which is a common fallback\n",
    "    with open(problem_file_path, 'r', encoding='latin-1') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # Write the content back out using the standard 'utf-8' encoding\n",
    "    with open(corrected_file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "        \n",
    "    print(f\" Success! File has been re-saved with correct UTF-8 encoding at: {corrected_file_path}\")\n",
    "    print(\"\\nPlease update your 'tools.py' and 'scripts/ingest_data.py' files to use this new filename.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\" ERROR: Could not find the file at '{problem_file_path}'. Please check the path and filename.\")\n",
    "except Exception as e:\n",
    "    print(f\" An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "327c8de0-721e-4390-95a1-a90aab0b5e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- lendo data\\processed\\vector_store\\docstore.json ---\n",
      "OK:  JSON UTF-8 vlido\n",
      "\n",
      "--- lendo data\\processed\\vector_store\\index_store.json ---\n",
      "OK:  JSON UTF-8 vlido\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "paths = [\n",
    "    Path(\"data/processed/vector_store/docstore.json\"),\n",
    "    Path(\"data/processed/vector_store/index_store.json\"),\n",
    "]\n",
    "\n",
    "for p in paths:\n",
    "    print(f\"\\n--- lendo {p} ---\")\n",
    "    if not p.exists():\n",
    "        print(\"no existe\")\n",
    "        continue\n",
    "    try:\n",
    "        with open(p, encoding=\"utf-8\") as f:\n",
    "            _ = json.load(f)\n",
    "        print(\"OK:  JSON UTF-8 vlido\")\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(\"Erro de decodificao UTF-8:\", e)\n",
    "        try:\n",
    "            with open(p, encoding=\"latin-1\") as f:\n",
    "                sample = f.read(500)\n",
    "            print(\"Contedo inicial (latin-1):\", repr(sample))\n",
    "        except Exception as e2:\n",
    "            print(\"No conseguiu ler nem em latin-1:\", e2)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Arquivo  texto mas no  JSON vlido:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6cdc928-109c-4fbc-ba48-4673c01f3d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo j  UTF-8 vlido.\n",
      "Arquivo limpo salvo em data\\raw\\pricelist_cleaned.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "RAW = Path(\"data/raw/pricelist.json\")\n",
    "CLEAN = Path(\"data/raw/pricelist_cleaned.json\")\n",
    "\n",
    "def clean_input_json():\n",
    "    # 1. Leia em binrio e decodifique com replacement para mostrar/neutralizar bytes invlidos\n",
    "    raw_bytes = RAW.read_bytes()\n",
    "    try:\n",
    "        text = raw_bytes.decode(\"utf-8\")\n",
    "        print(\"Arquivo j  UTF-8 vlido.\")\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"Decoding error: {e}; repondo bytes invlidos com replacement.\")\n",
    "        text = raw_bytes.decode(\"utf-8\", errors=\"replace\")  # substitui os invlidos por \n",
    "\n",
    "    # 2. Tente carregar como JSON (isso tambm valida estrutura)\n",
    "    try:\n",
    "        data = json.loads(text)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Erro de JSON: {e}. Pode haver problemas estruturais alm do encoding.\")\n",
    "        raise\n",
    "\n",
    "    # 3. Reescreve de forma limpa com UTF-8 sem BOM, indentado (opcional)\n",
    "    with CLEAN.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"Arquivo limpo salvo em {CLEAN}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    clean_input_json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5fcc800-896c-4aba-ad49-37ef5977990f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'product' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m unicodedata\u001b[38;5;241m.\u001b[39mnormalize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNFKC\u001b[39m\u001b[38;5;124m\"\u001b[39m, s)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# ao montar text_content:\u001b[39;00m\n\u001b[0;32m      9\u001b[0m text_content \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProduct: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnormalize_text(product\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommercial_name\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (SKU: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnormalize_text(product\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcisco_product_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDescription: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnormalize_text(product\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCategory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnormalize_text(product\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtechnical_profile\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m{})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     13\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'product' is not defined"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    return unicodedata.normalize(\"NFKC\", s)\n",
    "\n",
    "# ao montar text_content:\n",
    "text_content = (\n",
    "    f\"Product: {normalize_text(product.get('commercial_name', ''))} (SKU: {normalize_text(product.get('cisco_product_id', ''))})\\n\"\n",
    "    f\"Description: {normalize_text(product.get('description', ''))}\\n\"\n",
    "    f\"Category: {normalize_text(product.get('technical_profile', {}).get('category', ''))}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80ce7151-ca71-49a5-ac29-395af3095d7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'products' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# dentro do loop de criao dos documentos:\u001b[39;00m\n\u001b[0;32m      9\u001b[0m documents \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m product \u001b[38;5;129;01min\u001b[39;00m products:\n\u001b[0;32m     11\u001b[0m     text_content \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProduct: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnormalize_text(product\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommercial_name\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(SKU: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnormalize_text(product\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcisco_product_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDescription: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnormalize_text(product\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCategory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnormalize_text(product\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtechnical_profile\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m{})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     16\u001b[0m     )\n\u001b[0;32m     17\u001b[0m     doc \u001b[38;5;241m=\u001b[39m Document(\n\u001b[0;32m     18\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext_content,\n\u001b[0;32m     19\u001b[0m         metadata\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m         }\n\u001b[0;32m     24\u001b[0m     )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'products' is not defined"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    return unicodedata.normalize(\"NFKC\", s)\n",
    "\n",
    "# dentro do loop de criao dos documentos:\n",
    "documents = []\n",
    "for product in products:\n",
    "    text_content = (\n",
    "        f\"Product: {normalize_text(product.get('commercial_name', ''))} \"\n",
    "        f\"(SKU: {normalize_text(product.get('cisco_product_id', ''))})\\n\"\n",
    "        f\"Description: {normalize_text(product.get('description', ''))}\\n\"\n",
    "        f\"Category: {normalize_text(product.get('technical_profile', {}).get('category', ''))}\"\n",
    "    )\n",
    "    doc = Document(\n",
    "        text=text_content,\n",
    "        metadata={\n",
    "            \"sku\": normalize_text(product.get('cisco_product_id', '')),\n",
    "            \"name\": normalize_text(product.get('commercial_name', '')),\n",
    "            \"full_data_json\": json.dumps(product)  # esse pode ficar cru se quiser\n",
    "        }\n",
    "    )\n",
    "    documents.append(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2815e2f7-c12e-4ad7-ad45-a6c2980ea8d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61e15911-0b08-44a6-9915-abeb2aa72b19",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (1827490101.py, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[13], line 26\u001b[1;36m\u001b[0m\n\u001b[1;33m    return\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import unicodedata\n",
    "from pathlib import Path\n",
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    return unicodedata.normalize(\"NFKC\", s)\n",
    "\n",
    "# --- 2. Load & clean data (em memria, sem renomear o arquivo) ---\n",
    "try:\n",
    "    raw_path = Path(\"data/raw/pricelist.json\")\n",
    "    raw_bytes = raw_path.read_bytes()\n",
    "    try:\n",
    "        text = raw_bytes.decode(\"utf-8\")\n",
    "    except UnicodeDecodeError:\n",
    "        # substitui caracteres invlidos para no quebrar o JSON\n",
    "        text = raw_bytes.decode(\"utf-8\", errors=\"replace\")\n",
    "        logging.warning(\"Encontrados bytes invlidos no JSON de input; corrigidos com replacement.\")\n",
    "\n",
    "    data = json.loads(text)\n",
    "    products = data if isinstance(data, list) else data.get(\"products\", [])\n",
    "    logging.info(f\"Successfully loaded {len(products)} products from {raw_path}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Failed to load or parse data/raw/pricelist.json: {e}\")\n",
    "    return\n",
    "\n",
    "# --- 3. Create LlamaIndex Document Objects com normalizao ---\n",
    "documents = []\n",
    "for product in products:\n",
    "    commercial_name = normalize_text(product.get(\"commercial_name\", \"\"))\n",
    "    sku = normalize_text(product.get(\"cisco_product_id\", \"\"))\n",
    "    description = normalize_text(product.get(\"description\", \"\"))\n",
    "    category = normalize_text(product.get(\"technical_profile\", {}).get(\"category\", \"\"))\n",
    "\n",
    "    text_content = (\n",
    "        f\"Product: {commercial_name} (SKU: {sku})\\n\"\n",
    "        f\"Description: {description}\\n\"\n",
    "        f\"Category: {category}\"\n",
    "    )\n",
    "    doc = Document(\n",
    "        text=text_content,\n",
    "        metadata={\n",
    "            \"sku\": sku,\n",
    "            \"name\": commercial_name,\n",
    "            \"full_data_json\": json.dumps(product, ensure_ascii=False)\n",
    "        }\n",
    "    )\n",
    "    documents.append(doc)\n",
    "logging.info(f\"Created {len(documents)} LlamaIndex Document objects.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0aec6cdd-9b35-4e7f-bf49-be0fa2e0f6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo corrigido salvo como pricelist_fixed.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def fix_json_errors(data):\n",
    "    for product in data:\n",
    "        # Correo para QSFP-100G-SR4-S\n",
    "        if product.get(\"cisco_product_id\") == \"QSFP-100G-SR4-S\":\n",
    "            # Corrigir preo inconsistente\n",
    "            if \"pricing_model\" in product:\n",
    "                base_price = product[\"pricing_model\"][\"base_price\"]\n",
    "                for tier in product[\"pricing_model\"].get(\"pricing_tiers\", []):\n",
    "                    tier[\"price\"] = base_price\n",
    "            \n",
    "            # Remover dependncias incorretas\n",
    "            if \"dependencies\" in product:\n",
    "                del product[\"dependencies\"]\n",
    "        \n",
    "        # Correo para ASA5555-X\n",
    "        elif product.get(\"cisco_product_id\") == \"ASA5555-X\":\n",
    "            if \"pricing_model\" in product:\n",
    "                for tier in product[\"pricing_model\"].get(\"pricing_tiers\", []):\n",
    "                    for rule in tier.get(\"discount_rules\", []):\n",
    "                        if rule.get(\"type\") == \"enterprise\":\n",
    "                            rule[\"type\"] = \"partner\"\n",
    "                            rule[\"level\"] = \"enterprise\"\n",
    "\n",
    "# Carregar o arquivo original\n",
    "with open(\"data/raw/pricelist_cleaned.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Aplicar correes\n",
    "fix_json_errors(data)\n",
    "\n",
    "# Salvar arquivo corrigido\n",
    "with open(\"data/raw/pricelist_fixed.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Arquivo corrigido salvo como pricelist_fixed.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f729251-2c37-4f78-860b-67d1dfefd787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f20198-ce2b-4b7b-b721-074e2884d006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7f3ebd-2b3d-44ab-a705-2c45e98b73a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f08ade87-28d0-43e5-ae69-3a94957513bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hardware': 0, 'software': 0, 'files': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Notebook cell: Normalizador v2 com enriquecimento por SKU ---\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json, re\n",
    "from datetime import date\n",
    "from typing import Optional, Dict, List, Any\n",
    "\n",
    "# ================= CONFIG =================\n",
    "XLSX_PATH   = Path(\"data/raw/Cisco_Pricing.xlsx\")\n",
    "OUT_BASE    = Path(\"data/normalized\")\n",
    "CURRENCY    = \"USD\"\n",
    "\n",
    "ENRICH_WITH_LLM = True      # >>> troque para True se quiser enriquecer\n",
    "OPENAI_MODEL    = \"gpt-4o-mini\"\n",
    "\n",
    "# ================= OpenAI (opcional) =================\n",
    "client = None\n",
    "if ENRICH_WITH_LLM:\n",
    "    from openai import OpenAI\n",
    "    client = OpenAI()\n",
    "\n",
    "# ================= Helpers =================\n",
    "def find_col(df: pd.DataFrame, substrs: list[str]) -> Optional[str]:\n",
    "    for col in df.columns:\n",
    "        lc = str(col).strip().lower()\n",
    "        if any(s in lc for s in substrs):\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "def clean_price(val: Any) -> float:\n",
    "    s = str(val)\n",
    "    s = re.sub(r\"[^\\d,\\.]\", \"\", s)\n",
    "    s = re.sub(r\"\\.(?=\\d{3},)\", \"\", s)  # 1.234,56 -> 1234,56\n",
    "    s = s.replace(\",\", \".\")\n",
    "    try:\n",
    "        return round(float(s), 2)\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def clean_pct(val: Any) -> float:\n",
    "    s = re.sub(r\"[^\\d,\\.]\", \"\", str(val)).replace(\",\", \".\")\n",
    "    try:\n",
    "        return float(s)/100.0\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def term_months_from_text(text: str) -> Optional[int]:\n",
    "    if not text: return None\n",
    "    t = text.upper()\n",
    "    m = re.search(r\"(\\d+)\\s*Y(R|EARS?)?\", t) or re.search(r\"(\\d+)\\s*YR\", t)\n",
    "    if m: return int(m.group(1)) * 12\n",
    "    m = re.search(r\"(\\d+)\\s*MONTH\", t)\n",
    "    if m: return int(m.group(1))\n",
    "    m = re.search(r\"-(\\d+)YR\\b\", t)\n",
    "    if m: return int(m.group(1)) * 12\n",
    "    return None\n",
    "\n",
    "def load_json_list(path: Path) -> List[dict]:\n",
    "    if path.exists():\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            try:\n",
    "                return json.load(f)\n",
    "            except Exception:\n",
    "                return []\n",
    "    return []\n",
    "\n",
    "def save_json_list(path: Path, data: List[dict]):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# ================= Categorias & Blueprints =================\n",
    "# Campos esperados por categoria (hardware/software).\n",
    "HW_ATTR_BLUEPRINT = {\n",
    "    \"switches\":   [\"port_count\",\"poe_budget_w\",\"uplinks\",\"uplink_speed\",\"layer\",\"stacking\",\"throughput_gbps\"],\n",
    "    \"routers\":    [\"wan_ports\",\"lan_ports\",\"throughput_gbps\",\"sdwan_support\",\"vpn_tps\",\"modules_supported\"],\n",
    "    \"wireless\":   [\"wifi_standard\",\"spatial_streams\",\"mimo\",\"antenna_type\",\"indoor_outdoor\",\"ip_rating\",\"poe_class\"],\n",
    "    \"firewall\":   [\"fw_throughput_gbps\",\"ips_gbps\",\"max_sessions\",\"interfaces\",\"ha_supported\",\"vpn_peers\"],\n",
    "    \"antennas\":   [\"bands\",\"gain_dbi\",\"connector_type\",\"polarization\",\"beamwidth\",\"ip_rating\"],\n",
    "    \"cabling\":    [\"type\",\"length_m\",\"connector_a\",\"connector_b\",\"shielding\"],\n",
    "    \"connectors\": [\"type\",\"gender\",\"impedance_ohm\",\"application\"],\n",
    "}\n",
    "\n",
    "SW_ATTR_BLUEPRINT = {\n",
    "    \"wireless\":           {\"features\": [], \"bundles\": []},\n",
    "    \"switches\":           {\"features\": [], \"bundles\": []},\n",
    "    \"routers\":            {\"features\": [], \"bundles\": []},\n",
    "    \"firewall\":           {\"features\": [], \"bundles\": []},\n",
    "    \"sw_support_license\": {\"support_level\": None, \"sla_hrs\": None, \"on_site\": None}\n",
    "}\n",
    "\n",
    "# Mapeamento de categoria da planilha -> slug final\n",
    "CANON = {\n",
    "    \"hardware\": {\n",
    "        \"antennas\": \"antennas\",\n",
    "        \"cabling\": \"cabling\",\n",
    "        \"connectors\": \"connectors\",\n",
    "        \"firewall\": \"firewall\",\n",
    "        \"routers\": \"routers\",\n",
    "        \"switches\": \"switches\",\n",
    "        \"wireless\": \"wireless\",\n",
    "    },\n",
    "    \"software\": {\n",
    "        \"firewall\": \"firewall\",\n",
    "        \"routers\": \"routers\",\n",
    "        \"sw support license\": \"sw_support_license\",\n",
    "        \"switches\": \"switches\",\n",
    "        \"wireless\": \"wireless\",\n",
    "    }\n",
    "}\n",
    "\n",
    "def canon_hw(raw: str) -> str:\n",
    "    k = raw.strip().lower()\n",
    "    return CANON[\"hardware\"].get(k, re.sub(r\"[^a-z0-9]+\",\"_\", k))\n",
    "\n",
    "def canon_sw(raw: str) -> str:\n",
    "    k = raw.strip().lower()\n",
    "    return CANON[\"software\"].get(k, re.sub(r\"[^a-z0-9]+\",\"_\", k))\n",
    "\n",
    "# ================= Templates de registro =================\n",
    "def base_product(sku: str, name: str, ptype: str) -> Dict:\n",
    "    return {\n",
    "        \"cisco_product_id\": sku,\n",
    "        \"commercial_name\": name,\n",
    "        \"product_type\": ptype,\n",
    "        \"lifecycle\": {\"status\": \"active\", \"eos_announced\": None, \"last_support_date\": None},\n",
    "        \"regulatory\": {\"certifications\": []}\n",
    "    }\n",
    "\n",
    "def hardware_record(sku: str, name: str, category: str, price: float, elig_frac: float) -> Dict:\n",
    "    return {\n",
    "        **base_product(sku, name, \"hardware\"),\n",
    "        \"technical_profile\": {\n",
    "            \"category\": category,\n",
    "            \"subcategory\": \"\",\n",
    "            \"hardware_attributes\": {k: None for k in HW_ATTR_BLUEPRINT.get(category, [])}\n",
    "        },\n",
    "        \"pricing_model\": {\n",
    "            \"type\": \"one_time\",\n",
    "            \"currency\": CURRENCY,\n",
    "            \"base_price\": price,\n",
    "            \"elig_pct\": elig_frac,\n",
    "            \"pricing_tiers\": [{\n",
    "                \"min_quantity\": 1,\n",
    "                \"price\": price,\n",
    "                \"effective\": str(date.today()),\n",
    "                \"discount_rules\": []\n",
    "            }]\n",
    "        },\n",
    "        \"dependencies\": {\"required_components\": [], \"compatible_with\": []}\n",
    "    }\n",
    "\n",
    "def software_record(sku: str, name: str, category: str, price: float, elig_frac: float, desc: str) -> Dict:\n",
    "    term = term_months_from_text(sku) or term_months_from_text(name) or term_months_from_text(desc) or 12\n",
    "    needs_hw = bool(re.search(r\"(meraki|lic-)\", f\"{sku} {name} {desc}\", re.I))\n",
    "    profile = {\"category\": category, \"license_model\": \"term\", \"term_months\": int(term), \"seat_unit\": \"device\", \"requires_hardware\": needs_hw}\n",
    "\n",
    "    # preenche os campos per-category\n",
    "    if category in SW_ATTR_BLUEPRINT:\n",
    "        blueprint = SW_ATTR_BLUEPRINT[category]\n",
    "        profile.update(blueprint)\n",
    "\n",
    "    return {\n",
    "        **base_product(sku, name, \"software\"),\n",
    "        \"software_profile\": profile,\n",
    "        \"entitlement\": {\"smart_account_required\": needs_hw, \"partner_tier_pricing\": {}},\n",
    "        \"pricing_model\": {\n",
    "            \"type\": \"subscription\",\n",
    "            \"currency\": CURRENCY,\n",
    "            \"list_price\": price,\n",
    "            \"elig_pct\": elig_frac,\n",
    "            \"billing\": \"prepaid\",\n",
    "            \"term_months\": int(term),\n",
    "            \"pricing_tiers\": [{\n",
    "                \"min_quantity\": 1,\n",
    "                \"price\": price,\n",
    "                \"term_months\": int(term),\n",
    "                \"effective\": str(date.today()),\n",
    "                \"discount_rules\": []\n",
    "            }]\n",
    "        }\n",
    "    }\n",
    "\n",
    "# ================= Enriquecimento 1-a-1 (opcional) =================\n",
    "def llm_enrich_attributes(product: Dict) -> Dict:\n",
    "    \"\"\"Enriquece APENAS os campos previstos no blueprint, 1 SKU por vez.\"\"\"\n",
    "    if not (ENRICH_WITH_LLM and client):\n",
    "        return product\n",
    "\n",
    "    if product[\"product_type\"] == \"hardware\":\n",
    "        cat = product[\"technical_profile\"][\"category\"]\n",
    "        allowed = HW_ATTR_BLUEPRINT.get(cat, [])\n",
    "        if not allowed:\n",
    "            return product\n",
    "\n",
    "        schema_hint = {k: \"<value>\" for k in allowed}\n",
    "        prompt = f\"\"\"\n",
    "Return JSON ONLY. Fill the keys in \"hardware_attributes\" using the allowed keys below.\n",
    "Do not invent SKU/price. If unknown, keep null. No extra keys.\n",
    "\n",
    "SKU: {product['cisco_product_id']}\n",
    "Name: {product['commercial_name']}\n",
    "Category: {cat}\n",
    "\n",
    "Allowed keys: {allowed}\n",
    "\n",
    "Respond exactly as:\n",
    "{{\n",
    "  \"hardware_attributes\": {json.dumps(schema_hint)}\n",
    "}}\n",
    "\"\"\".strip()\n",
    "        try:\n",
    "            resp = client.chat.completions.create(\n",
    "                model=OPENAI_MODEL,\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "                messages=[{\"role\":\"user\",\"content\": prompt}],\n",
    "                temperature=0.1\n",
    "            )\n",
    "            data = json.loads(resp.choices[0].message.content)\n",
    "            attrs = data.get(\"hardware_attributes\", {})\n",
    "            # filtra apenas keys permitidas\n",
    "            filtered = {k: attrs.get(k, None) for k in allowed}\n",
    "            product[\"technical_profile\"][\"hardware_attributes\"].update(filtered)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    else:  # software\n",
    "        cat = product[\"software_profile\"][\"category\"]\n",
    "        # duas modalidades: features/bundles OU suporte\n",
    "        if cat == \"sw_support_license\":\n",
    "            allowed = list(SW_ATTR_BLUEPRINT[\"sw_support_license\"].keys())\n",
    "            schema_hint = {k: \"<value>\" for k in allowed}\n",
    "            prompt = f\"\"\"\n",
    "Return JSON ONLY. Fill the keys in \"support\" using the allowed keys below.\n",
    "If unknown, keep null. No extra keys.\n",
    "\n",
    "SKU: {product['cisco_product_id']}\n",
    "Name: {product['commercial_name']}\n",
    "Category: {cat}\n",
    "\n",
    "Allowed keys: {allowed}\n",
    "\n",
    "Respond exactly as:\n",
    "{{\n",
    "  \"support\": {json.dumps(schema_hint)}\n",
    "}}\n",
    "\"\"\".strip()\n",
    "            try:\n",
    "                resp = client.chat.completions.create(\n",
    "                    model=OPENAI_MODEL,\n",
    "                    response_format={\"type\": \"json_object\"},\n",
    "                    messages=[{\"role\":\"user\",\"content\": prompt}],\n",
    "                    temperature=0.1\n",
    "                )\n",
    "                data = json.loads(resp.choices[0].message.content)\n",
    "                s = data.get(\"support\", {})\n",
    "                product[\"software_profile\"][\"support_level\"] = s.get(\"support_level\")\n",
    "                product[\"software_profile\"][\"sla_hrs\"] = s.get(\"sla_hrs\")\n",
    "                product[\"software_profile\"][\"on_site\"] = s.get(\"on_site\")\n",
    "            except Exception:\n",
    "                pass\n",
    "        else:\n",
    "            prompt = f\"\"\"\n",
    "Return JSON ONLY. Provide \"features\" (list of short feature names) and optional \"bundles\" (e.g., DNA Essentials/Advantage, MR Enterprise).\n",
    "If unknown, return empty arrays.\n",
    "\n",
    "SKU: {product['cisco_product_id']}\n",
    "Name: {product['commercial_name']}\n",
    "Category: {cat}\n",
    "\n",
    "Respond exactly as:\n",
    "{{\n",
    "  \"features\": [],\n",
    "  \"bundles\": []\n",
    "}}\n",
    "\"\"\".strip()\n",
    "            try:\n",
    "                resp = client.chat.completions.create(\n",
    "                    model=OPENAI_MODEL,\n",
    "                    response_format={\"type\": \"json_object\"},\n",
    "                    messages=[{\"role\":\"user\",\"content\": prompt}],\n",
    "                    temperature=0.1\n",
    "                )\n",
    "                data = json.loads(resp.choices[0].message.content)\n",
    "                if isinstance(data.get(\"features\"), list):\n",
    "                    product[\"software_profile\"][\"features\"] = data[\"features\"]\n",
    "                if isinstance(data.get(\"bundles\"), list):\n",
    "                    product[\"software_profile\"][\"bundles\"] = data[\"bundles\"]\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    return product\n",
    "\n",
    "# ================= Pipeline principal =================\n",
    "def normalize_catalog_per_item(xlsx_path: Path, out_dir: Path) -> Dict[str, int]:\n",
    "    df = pd.read_excel(xlsx_path, engine=\"openpyxl\")\n",
    "\n",
    "    c_type = find_col(df, [\"category-type\", \"category type\"])\n",
    "    c_cat  = find_col(df, [\"category\"])\n",
    "    c_sku  = find_col(df, [\"sku\", \"part\"])\n",
    "    c_desc = find_col(df, [\"desc\", \"description\", \"name\"])\n",
    "    c_price= find_col(df, [\"pri\",\"price\",\"list\"])\n",
    "    c_elig = find_col(df, [\"elig\"])\n",
    "\n",
    "    missing = [n for n,c in [(\"Category-Type\",c_type),(\"Category\",c_cat),(\"SKU\",c_sku),(\"Desc\",c_desc),(\"Price\",c_price),(\"Elig_%\",c_elig)] if c is None]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Colunas ausentes: {missing}\")\n",
    "\n",
    "    df[\"_type\"]   = df[c_type].astype(str).str.strip().str.lower()\n",
    "    df[\"_catraw\"] = df[c_cat].astype(str).str.strip()\n",
    "    df[\"_sku\"]    = df[c_sku].astype(str).str.strip()\n",
    "    df[\"_name\"]   = df[c_desc].astype(str).str.strip()\n",
    "    df[\"_price\"]  = df[c_price].apply(clean_price)\n",
    "    df[\"_eligf\"]  = df[c_elig].apply(clean_pct)\n",
    "\n",
    "    (out_dir/\"hardware\").mkdir(parents=True, exist_ok=True)\n",
    "    (out_dir/\"software\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    counts = {\"hardware\":0, \"software\":0, \"files\":0}\n",
    "\n",
    "    # --- HARDWARE: processa 1 a 1 e grava por categoria ---\n",
    "    hw = df[df[\"_type\"]==\"hardware\"]\n",
    "    for raw_cat, chunk in hw.groupby(\"_catraw\"):\n",
    "        cat = canon_hw(raw_cat)\n",
    "        out_file = out_dir/\"hardware\"/f\"hw_{cat}.json\"\n",
    "        existing = load_json_list(out_file)\n",
    "        seen = {p.get(\"cisco_product_id\") for p in existing}\n",
    "\n",
    "        for _, r in chunk.iterrows():\n",
    "            sku = r[\"_sku\"]\n",
    "            if sku in seen: \n",
    "                continue\n",
    "            prod = hardware_record(sku, r[\"_name\"], cat, r[\"_price\"], r[\"_eligf\"])\n",
    "            prod = llm_enrich_attributes(prod)  # 1 chamada por SKU (se habilitado)\n",
    "            existing.append(prod)\n",
    "            counts[\"hardware\"] += 1\n",
    "\n",
    "        save_json_list(out_file, existing)\n",
    "        counts[\"files\"] += 1\n",
    "\n",
    "    # --- SOFTWARE: idem ---\n",
    "    sw = df[df[\"_type\"]==\"software\"]\n",
    "    for raw_cat, chunk in sw.groupby(\"_catraw\"):\n",
    "        cat = canon_sw(raw_cat)\n",
    "        out_file = out_dir/\"software\"/f\"sw_{cat}.json\"\n",
    "        existing = load_json_list(out_file)\n",
    "        seen = {p.get(\"cisco_product_id\") for p in existing}\n",
    "\n",
    "        for _, r in chunk.iterrows():\n",
    "            sku = r[\"_sku\"]\n",
    "            if sku in seen:\n",
    "                continue\n",
    "            prod = software_record(sku, r[\"_name\"], cat, r[\"_price\"], r[\"_eligf\"], r[\"_name\"])\n",
    "            prod = llm_enrich_attributes(prod)  # 1 chamada por SKU (se habilitado)\n",
    "            existing.append(prod)\n",
    "            counts[\"software\"] += 1\n",
    "\n",
    "        save_json_list(out_file, existing)\n",
    "        counts[\"files\"] += 1\n",
    "\n",
    "    return counts\n",
    "\n",
    "# ================= Run =================\n",
    "OUT_BASE.mkdir(parents=True, exist_ok=True)\n",
    "stats = normalize_catalog_per_item(XLSX_PATH, OUT_BASE)\n",
    "stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75262e3a-8421-4e7b-b79f-72ede065b324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Columns detected: {'type': 'Category-Type', 'category': 'Category-Type', 'sku': 'SKU', 'desc': 'Desc', 'price': 'price', 'elig': 'Elig_%'}\n",
      " Type counts: {'hardware': 3004, 'software': 1263}\n",
      " Sample categories: {'hardware': 3004, 'software': 1263}\n",
      " Done: {'hardware': 3004, 'software': 1263, 'files': 2}\n",
      " Output folders: data\\normalized\\hardware and data\\normalized\\software\n"
     ]
    }
   ],
   "source": [
    "import os, json, re, math\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# ====== CONFIG ======\n",
    "XLSX_PATH = \"data/raw/Cisco_Pricing.xlsx\"   # ajuste se necessrio\n",
    "OUT_DIR   = Path(\"data/normalized\")\n",
    "ENRICH_WITH_LLM = True                     # mantenha False por enquanto\n",
    "\n",
    "# Mapeamento cannico de categorias (o que vimos nas telas)\n",
    "CANON_HW = {\n",
    "    \"antennas\": \"antennas\",\n",
    "    \"antenna\": \"antennas\",\n",
    "    \"cabling\": \"cabling\",\n",
    "    \"connectors\": \"connectors\",\n",
    "    \"firewall\": \"firewall\",\n",
    "    \"firewalls\": \"firewall\",\n",
    "    \"routers\": \"routers\",\n",
    "    \"router\": \"routers\",\n",
    "    \"switches\": \"switches\",\n",
    "    \"switch\": \"switches\",\n",
    "    \"wireless\": \"wireless\",\n",
    "}\n",
    "\n",
    "CANON_SW = {\n",
    "    \"wireless\": \"wireless\",\n",
    "    \"switches\": \"switches\",\n",
    "    \"routers\": \"routers\",\n",
    "    \"firewall\": \"firewall\",\n",
    "    \"firewalls\": \"firewall\",\n",
    "    \"sw support license\": \"sw_support_license\",\n",
    "    \"support license\": \"sw_support_license\",\n",
    "}\n",
    "\n",
    "# Blueprints MUITO resumidos (use os completos que combinamos se quiser)\n",
    "HW_ATTR_BLUEPRINT = {\n",
    "    \"switches\":    {\"port_count\": None, \"poe_budget_w\": None, \"layer\": None},\n",
    "    \"routers\":     {\"wan_ports\": None},\n",
    "    \"firewall\":    {\"throughput_gbps\": None},\n",
    "    \"wireless\":    {\"wifi_standard\": None, \"antenna_type\": None},\n",
    "    \"antennas\":    {\"connector_type\": None, \"gain_dbi\": None},\n",
    "    \"cabling\":     {\"cable_type\": None, \"length_m\": None},\n",
    "    \"connectors\":  {\"connector_type\": None},\n",
    "}\n",
    "SW_ATTR_BLUEPRINT = {\n",
    "    \"wireless\":           {\"features\": [], \"term_months\": None},\n",
    "    \"switches\":           {\"features\": [], \"term_months\": None},\n",
    "    \"routers\":            {\"features\": [], \"term_months\": None},\n",
    "    \"firewall\":           {\"features\": [], \"term_months\": None},\n",
    "    \"sw_support_license\": {\"support_level\": None, \"sla_hrs\": None, \"on_site\": None, \"term_months\": None},\n",
    "}\n",
    "\n",
    "def _find_col(df, *candidates):\n",
    "    cols = {str(c).strip().lower(): c for c in df.columns}\n",
    "    for want in candidates:\n",
    "        for k, orig in cols.items():\n",
    "            if want in k:\n",
    "                return orig\n",
    "    return None\n",
    "\n",
    "def _norm_text(x):\n",
    "    return str(x).strip()\n",
    "\n",
    "def _norm_price(x):\n",
    "    if pd.isna(x):\n",
    "        return 0.0\n",
    "    s = str(x)\n",
    "    s = re.sub(r\"[^\\d,\\.]\", \"\", s)\n",
    "    # trata formatos comuns: 1.234,56  1234.56 ; 1234,56  1234.56\n",
    "    if s.count(\",\") == 1 and s.count(\".\") >= 1 and s.rfind(\",\") > s.rfind(\".\"):\n",
    "        s = s.replace(\".\", \"\").replace(\",\", \".\")\n",
    "    elif s.count(\",\") == 1 and s.count(\".\") == 0:\n",
    "        s = s.replace(\",\", \".\")\n",
    "    try:\n",
    "        return float(s)\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def _canon_category(raw, typ):\n",
    "    base = _norm_text(raw).lower()\n",
    "    if typ == \"hardware\":\n",
    "        for k in CANON_HW:\n",
    "            if k in base:\n",
    "                return CANON_HW[k]\n",
    "    else:\n",
    "        for k in CANON_SW:\n",
    "            if k in base:\n",
    "                return CANON_SW[k]\n",
    "    # fallback: slug simples\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"_\", base) or \"uncategorized\"\n",
    "\n",
    "def _hardware_record(row, sku, name, cat_slug, price, elig):\n",
    "    rec = {\n",
    "        \"cisco_product_id\": sku,\n",
    "        \"commercial_name\": name,\n",
    "        \"product_type\": \"hardware\",\n",
    "        \"lifecycle\": {\"status\": \"unknown\"},\n",
    "        \"technical_profile\": {\n",
    "            \"hardware_attributes\": {}\n",
    "        },\n",
    "        \"pricing_model\": {\n",
    "            \"type\": \"one_time\",\n",
    "            \"currency\": \"USD\",\n",
    "            \"base_price\": price,\n",
    "            \"elig_pct\": elig\n",
    "        }\n",
    "    }\n",
    "    # aplica blueprint da categoria se existir\n",
    "    attrs = HW_ATTR_BLUEPRINT.get(cat_slug)\n",
    "    if attrs:\n",
    "        rec[\"technical_profile\"][\"hardware_attributes\"].update(attrs)\n",
    "    return rec\n",
    "\n",
    "def _software_record(row, sku, name, cat_slug, price, elig):\n",
    "    rec = {\n",
    "        \"cisco_product_id\": sku,\n",
    "        \"commercial_name\": name,\n",
    "        \"product_type\": \"software\",\n",
    "        \"software_profile\": {\n",
    "            \"edition\": None,\n",
    "            \"license_type\": \"subscription\",\n",
    "            \"term_months\": 12,\n",
    "            \"features\": [],\n",
    "            \"bundles\": []\n",
    "        },\n",
    "        \"pricing_model\": {\n",
    "            \"type\": \"term_subscription\",\n",
    "            \"currency\": \"USD\",\n",
    "            \"base_price\": price,\n",
    "            \"elig_pct\": elig\n",
    "        }\n",
    "    }\n",
    "    bp = SW_ATTR_BLUEPRINT.get(cat_slug)\n",
    "    if bp:\n",
    "        rec[\"software_profile\"].update({k: v for k, v in bp.items() if k not in rec[\"software_profile\"]})\n",
    "    return rec\n",
    "\n",
    "def normalize_and_export(xlsx_path, out_dir):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    df = pd.read_excel(xlsx_path, engine=\"openpyxl\")\n",
    "    # descoberta robusta de colunas\n",
    "    col_type = _find_col(df, \"category-type\", \"category type\")\n",
    "    col_cat  = _find_col(df, \"category\")\n",
    "    col_sku  = _find_col(df, \"sku\", \"part\", \"part number\")\n",
    "    col_desc = _find_col(df, \"desc\", \"description\", \"name\")\n",
    "    col_pri  = _find_col(df, \"pri\", \"price\", \"list price\")\n",
    "    col_elig = _find_col(df, \"elig\", \"eligibility\")\n",
    "\n",
    "    print(\" Columns detected:\", {\n",
    "        \"type\": col_type, \"category\": col_cat, \"sku\": col_sku, \"desc\": col_desc, \"price\": col_pri, \"elig\": col_elig\n",
    "    })\n",
    "    if not all([col_type, col_cat, col_sku, col_desc, col_pri, col_elig]):\n",
    "        raise ValueError(\"No encontrei todas as colunas necessrias. Confira os nomes no Excel.\")\n",
    "\n",
    "    # normalizaes bsicas\n",
    "    df[\"_type\"] = df[col_type].astype(str).str.strip().str.lower()\n",
    "    df[\"_cat\"]  = df[col_cat].astype(str).str.strip()\n",
    "    df[\"_sku\"]  = df[col_sku].astype(str).str.strip()\n",
    "    df[\"_desc\"] = df[col_desc].astype(str).str.strip()\n",
    "    df[\"_pri\"]  = df[col_pri].apply(_norm_price)\n",
    "    df[\"_elig\"] = df[col_elig].astype(str).str.strip().str.replace(\"%\",\"\", regex=False)\n",
    "    df[\"_elig\"] = pd.to_numeric(df[\"_elig\"].str.replace(\",\", \".\", regex=False), errors=\"coerce\").fillna(0)/100.0\n",
    "\n",
    "    # diagnstico de valores\n",
    "    print(\" Type counts:\", df[\"_type\"].value_counts().to_dict())\n",
    "    print(\" Sample categories:\", df[\"_cat\"].dropna().astype(str).str.strip().str.lower().value_counts().head(15).to_dict())\n",
    "\n",
    "    # coletores por categoria\n",
    "    buckets_hw = {}\n",
    "    buckets_sw = {}\n",
    "\n",
    "    hw_rows = df[df[\"_type\"].str.contains(\"hard\")]\n",
    "    sw_rows = df[df[\"_type\"].str.contains(\"soft\")]\n",
    "\n",
    "    for _, r in hw_rows.iterrows():\n",
    "        cat_slug = _canon_category(r[\"_cat\"], \"hardware\")\n",
    "        rec = _hardware_record(r, r[\"_sku\"], r[\"_desc\"], cat_slug, r[\"_pri\"], r[\"_elig\"])\n",
    "        buckets_hw.setdefault(cat_slug, []).append(rec)\n",
    "\n",
    "    for _, r in sw_rows.iterrows():\n",
    "        cat_slug = _canon_category(r[\"_cat\"], \"software\")\n",
    "        rec = _software_record(r, r[\"_sku\"], r[\"_desc\"], cat_slug, r[\"_pri\"], r[\"_elig\"])\n",
    "        buckets_sw.setdefault(cat_slug, []).append(rec)\n",
    "\n",
    "    # salvar\n",
    "    hw_dir = out_dir / \"hardware\"\n",
    "    sw_dir = out_dir / \"software\"\n",
    "    hw_dir.mkdir(parents=True, exist_ok=True)\n",
    "    sw_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    files = 0\n",
    "    for cat, items in buckets_hw.items():\n",
    "        p = hw_dir / f\"hw_{cat}.json\"\n",
    "        p.write_text(json.dumps(items, indent=2))\n",
    "        files += 1\n",
    "    for cat, items in buckets_sw.items():\n",
    "        p = sw_dir / f\"sw_{cat}.json\"\n",
    "        p.write_text(json.dumps(items, indent=2))\n",
    "        files += 1\n",
    "\n",
    "    print(\" Done:\", {\"hardware\": sum(len(v) for v in buckets_hw.values()),\n",
    "                       \"software\": sum(len(v) for v in buckets_sw.values()),\n",
    "                       \"files\": files})\n",
    "    print(\" Output folders:\", hw_dir, \"and\", sw_dir)\n",
    "\n",
    "normalize_and_export(XLSX_PATH, OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8093bff3-7e43-4b5f-82f8-0710c4a571a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4495a97f-2e05-4d9a-9860-259c30c42941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Columns detected: {'type': 'Category-Type', 'category': 'Category-Type', 'sku': 'SKU', 'desc': 'Desc', 'price': 'price', 'elig': 'Elig_%'}\n",
      " Type counts: {'hardware': 3004, 'software': 1263}\n",
      " Sample categories: {'hardware': 3004, 'software': 1263}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HW] hardware:  18%|        | 539/3004 [04:30<20:38,  1.99sku/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 544\u001b[0m\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Done:\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\n\u001b[0;32m    537\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhardware\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mlen\u001b[39m(json\u001b[38;5;241m.\u001b[39mloads((hw_dir\u001b[38;5;241m/\u001b[39mf)\u001b[38;5;241m.\u001b[39mread_text(encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m))) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(hw_dir) \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[0;32m    538\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftware\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mlen\u001b[39m(json\u001b[38;5;241m.\u001b[39mloads((sw_dir\u001b[38;5;241m/\u001b[39mf)\u001b[38;5;241m.\u001b[39mread_text(encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m))) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(sw_dir) \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[0;32m    539\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles\u001b[39m\u001b[38;5;124m\"\u001b[39m: files_written,\n\u001b[0;32m    540\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(out_dir)\n\u001b[0;32m    541\u001b[0m     })\n\u001b[0;32m    543\u001b[0m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[1;32m--> 544\u001b[0m normalize_and_export_by_category(XLSX_PATH, OUT_DIR)\n",
      "Cell \u001b[1;32mIn[14], line 481\u001b[0m, in \u001b[0;36mnormalize_and_export_by_category\u001b[1;34m(xlsx_path, out_dir)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ENRICH_WITH_LLM:\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;66;03m# preenche somente os campos null do blueprint\u001b[39;00m\n\u001b[0;32m    480\u001b[0m     _ \u001b[38;5;241m=\u001b[39m enrich_product_with_llm(prod, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhardware\u001b[39m\u001b[38;5;124m\"\u001b[39m, cat)\n\u001b[1;32m--> 481\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(RATE_LIMIT_SLEEP)\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# se j existia, update lista; se no, append\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sku \u001b[38;5;129;01min\u001b[39;00m index:\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;66;03m# atualiza no array existente\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# Normalizador + Enriquecimento (por categoria / por SKU)\n",
    "# L Cisco_Pricing.xlsx, cria JSONs por categoria (hardware/software),\n",
    "# e opcionalmente enriquece campos faltantes com a LLM (um produto por vez).\n",
    "\n",
    "# %%\n",
    "import os, json, re, time, math\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# OpenAI v1\n",
    "try:\n",
    "    from openai import OpenAI\n",
    "    _openai_available = True\n",
    "except Exception:\n",
    "    _openai_available = False\n",
    "\n",
    "# =================== CONFIG ===================\n",
    "XLSX_PATH = \"data/raw/Cisco_Pricing.xlsx\"    # <<< ajuste se necessrio\n",
    "OUT_DIR   = Path(\"data/normalized\")\n",
    "\n",
    "# Toggle de enriquecimento\n",
    "ENRICH_WITH_LLM   = True     # <<< defina para True quando quiser enriquecer\n",
    "REFRESH_ENRICHMENT= True    # True = reprocessa/enriquece mesmo se j existir no JSON\n",
    "OPENAI_MODEL      = \"gpt-4o-mini\"\n",
    "OPENAI_API_KEY    = os.getenv(\"OPENAI_API_KEY\")  # pode setar aqui string literal se preferir\n",
    "RATE_LIMIT_SLEEP  = 0.5      # seconds entre chamadas, ajuste conforme necessrio\n",
    "\n",
    "# =================== MAPEAMENTOS ===================\n",
    "# Canonicalizao das categorias (use os nomes do seu Excel)\n",
    "CANON_HW = {\n",
    "    \"antennas\": \"antennas\", \"antenna\": \"antennas\",\n",
    "    \"cabling\": \"cabling\",\n",
    "    \"connectors\": \"connectors\", \"connector\": \"connectors\",\n",
    "    \"firewall\": \"firewall\", \"firewalls\": \"firewall\",\n",
    "    \"routers\": \"routers\", \"router\": \"routers\",\n",
    "    \"switches\": \"switches\", \"switch\": \"switches\",\n",
    "    \"wireless\": \"wireless\", \"access point\": \"wireless\", \"access points\": \"wireless\",\n",
    "}\n",
    "CANON_SW = {\n",
    "    \"wireless\": \"wireless\",\n",
    "    \"switches\": \"switches\",\n",
    "    \"routers\": \"routers\",\n",
    "    \"firewall\": \"firewall\", \"firewalls\": \"firewall\",\n",
    "    \"sw support license\": \"sw_support_license\", \"support license\": \"sw_support_license\",\n",
    "}\n",
    "\n",
    "# Blueprints de atributos por categoria (pode estender quando quiser)\n",
    "HW_ATTR_BLUEPRINT: Dict[str, Dict[str, Any]] = {\n",
    "    \"switches\": {\n",
    "        \"category\": \"switch\",\n",
    "        \"subcategory\": None,\n",
    "        \"port_count\": None,\n",
    "        \"poe_budget_w\": None,\n",
    "        \"layer\": None,                  # L2/L3\n",
    "        \"uplink\": None,                 # ex: \"2x10G SFP+\"\n",
    "        \"stacking\": None,               # True/False/None\n",
    "        \"mounting\": None,               # rack/desktop\n",
    "        \"throughput_gbps\": None,\n",
    "        \"power_requirements\": None,\n",
    "    },\n",
    "    \"routers\": {\n",
    "        \"category\": \"router\",\n",
    "        \"wan_ports\": None,\n",
    "        \"sdwan_capable\": None,\n",
    "        \"vpn_throughput_mbps\": None,\n",
    "        \"throughput_gbps\": None,\n",
    "        \"power_requirements\": None,\n",
    "    },\n",
    "    \"firewall\": {\n",
    "        \"category\": \"firewall\",\n",
    "        \"throughput_gbps\": None,\n",
    "        \"ngfw_features\": [],\n",
    "        \"vpn_throughput_mbps\": None,\n",
    "        \"ha_supported\": None,\n",
    "        \"power_requirements\": None,\n",
    "    },\n",
    "    \"wireless\": {\n",
    "        \"category\": \"wireless\",\n",
    "        \"subcategory\": \"access_point\",\n",
    "        \"wifi_standard\": None,          # ex: 802.11ac/ax\n",
    "        \"throughput\": None,             # ex: \"1.7 Gbps\"\n",
    "        \"antenna_type\": None,           # internal/external\n",
    "        \"mounting\": None,               # indoor/outdoor\n",
    "        \"power_requirements\": None,     # PoE/PoE+\n",
    "        \"mu_mimo\": None,                # True/False/None\n",
    "    },\n",
    "    \"antennas\": {\n",
    "        \"category\": \"antenna\",\n",
    "        \"connector_type\": None,\n",
    "        \"gain_dbi\": None,\n",
    "        \"polarity\": None,               # single/dual\n",
    "        \"mounting\": None,\n",
    "        \"band\": None,                   # 2.4/5/6 GHz\n",
    "    },\n",
    "    \"cabling\": {\n",
    "        \"category\": \"cable\",\n",
    "        \"cable_type\": None,             # cat5e/cat6/sfp+/dac/etc\n",
    "        \"length_m\": None,\n",
    "        \"connector_a\": None,\n",
    "        \"connector_b\": None,\n",
    "        \"shielding\": None,              # UTP/STP\n",
    "    },\n",
    "    \"connectors\": {\n",
    "        \"category\": \"connector\",\n",
    "        \"connector_type\": None,         # rj45/sfp/sfp+/qsfp\n",
    "        \"gender\": None,\n",
    "        \"plating\": None,\n",
    "    }\n",
    "}\n",
    "\n",
    "SW_ATTR_BLUEPRINT: Dict[str, Dict[str, Any]] = {\n",
    "    # subscriptions \"funcionais\"\n",
    "    \"wireless\": {\n",
    "        \"edition\": None,\n",
    "        \"license_type\": \"subscription\",\n",
    "        \"term_months\": None,\n",
    "        \"features\": [],\n",
    "        \"bundles\": [],\n",
    "        \"per_device_or_site\": None      # per_device/per_site/unknown\n",
    "    },\n",
    "    \"switches\": {\n",
    "        \"edition\": None,\n",
    "        \"license_type\": \"subscription\",\n",
    "        \"term_months\": None,\n",
    "        \"features\": [],\n",
    "        \"bundles\": [],\n",
    "        \"per_device_or_site\": None\n",
    "    },\n",
    "    \"routers\": {\n",
    "        \"edition\": None,\n",
    "        \"license_type\": \"subscription\",\n",
    "        \"term_months\": None,\n",
    "        \"features\": [],\n",
    "        \"bundles\": [],\n",
    "        \"per_device_or_site\": None\n",
    "    },\n",
    "    \"firewall\": {\n",
    "        \"edition\": None,\n",
    "        \"license_type\": \"subscription\",\n",
    "        \"term_months\": None,\n",
    "        \"features\": [],\n",
    "        \"bundles\": [],\n",
    "        \"per_device_or_site\": None\n",
    "    },\n",
    "    # licenas de suporte\n",
    "    \"sw_support_license\": {\n",
    "        \"support_level\": None,          # base/enterprise/24x7 etc\n",
    "        \"sla_hrs\": None,                # 8x5/24x7\n",
    "        \"on_site\": None,                # True/False/None\n",
    "        \"term_months\": None\n",
    "    }\n",
    "}\n",
    "\n",
    "# =================== HELPERS ===================\n",
    "def _find_col(df: pd.DataFrame, *candidates) -> str | None:\n",
    "    cols = {str(c).strip().lower(): c for c in df.columns}\n",
    "    for want in candidates:\n",
    "        for k, orig in cols.items():\n",
    "            if want in k:\n",
    "                return orig\n",
    "    return None\n",
    "\n",
    "def _slugify(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"_\", str(s).strip().lower()).strip(\"_\") or \"uncategorized\"\n",
    "\n",
    "def _norm_price(x) -> float:\n",
    "    if pd.isna(x): return 0.0\n",
    "    s = str(x)\n",
    "    s = re.sub(r\"[^\\d,\\.]\", \"\", s)\n",
    "    if s.count(\",\") == 1 and s.count(\".\") >= 1 and s.rfind(\",\") > s.rfind(\".\"):\n",
    "        s = s.replace(\".\", \"\").replace(\",\", \".\")\n",
    "    elif s.count(\",\") == 1 and s.count(\".\") == 0:\n",
    "        s = s.replace(\",\", \".\")\n",
    "    try:\n",
    "        return float(s)\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def _canon_category(raw: str, typ: str) -> str:\n",
    "    base = str(raw or \"\").strip().lower()\n",
    "    mapping = CANON_HW if typ == \"hardware\" else CANON_SW\n",
    "    for k in mapping:\n",
    "        if k in base:\n",
    "            return mapping[k]\n",
    "    return _slugify(base)\n",
    "\n",
    "def _hardware_record(sku: str, name: str, cat_slug: str, price: float, elig: float) -> Dict:\n",
    "    rec = {\n",
    "        \"cisco_product_id\": sku,\n",
    "        \"commercial_name\": name,\n",
    "        \"product_type\": \"hardware\",\n",
    "        \"lifecycle\": {\"status\": \"unknown\"},\n",
    "        \"technical_profile\": {\n",
    "            \"hardware_attributes\": {}\n",
    "        },\n",
    "        \"pricing_model\": {\n",
    "            \"type\": \"one_time\",\n",
    "            \"currency\": \"USD\",\n",
    "            \"base_price\": price,\n",
    "            \"elig_pct\": float(elig)\n",
    "        }\n",
    "    }\n",
    "    attrs = HW_ATTR_BLUEPRINT.get(cat_slug)\n",
    "    if attrs:\n",
    "        rec[\"technical_profile\"][\"hardware_attributes\"].update(attrs)\n",
    "    return rec\n",
    "\n",
    "def _software_record(sku: str, name: str, cat_slug: str, price: float, elig: float) -> Dict:\n",
    "    # subs vs suporte\n",
    "    if cat_slug == \"sw_support_license\":\n",
    "        profile = {\n",
    "            \"support_level\": None,\n",
    "            \"sla_hrs\": None,\n",
    "            \"on_site\": None,\n",
    "            \"term_months\": None\n",
    "        }\n",
    "        pricing = {\n",
    "            \"type\": \"term_subscription\",\n",
    "            \"currency\": \"USD\",\n",
    "            \"base_price\": price,\n",
    "            \"elig_pct\": float(elig)\n",
    "        }\n",
    "        rec = {\n",
    "            \"cisco_product_id\": sku,\n",
    "            \"commercial_name\": name,\n",
    "            \"product_type\": \"software\",\n",
    "            \"software_profile\": profile,\n",
    "            \"pricing_model\": pricing\n",
    "        }\n",
    "    else:\n",
    "        profile = {\n",
    "            \"edition\": None,\n",
    "            \"license_type\": \"subscription\",\n",
    "            \"term_months\": 12,\n",
    "            \"features\": [],\n",
    "            \"bundles\": [],\n",
    "            \"per_device_or_site\": None\n",
    "        }\n",
    "        # merge com blueprint\n",
    "        bp = SW_ATTR_BLUEPRINT.get(cat_slug)\n",
    "        if bp:\n",
    "            for k, v in bp.items():\n",
    "                profile.setdefault(k, v)\n",
    "        rec = {\n",
    "            \"cisco_product_id\": sku,\n",
    "            \"commercial_name\": name,\n",
    "            \"product_type\": \"software\",\n",
    "            \"software_profile\": profile,\n",
    "            \"pricing_model\": {\n",
    "                \"type\": \"term_subscription\",\n",
    "                \"currency\": \"USD\",\n",
    "                \"base_price\": price,\n",
    "                \"elig_pct\": float(elig)\n",
    "            }\n",
    "        }\n",
    "    return rec\n",
    "\n",
    "def _load_existing(path: Path) -> List[Dict]:\n",
    "    if path.exists():\n",
    "        try:\n",
    "            return json.loads(path.read_text(encoding=\"utf-8\"))\n",
    "        except Exception:\n",
    "            return []\n",
    "    return []\n",
    "\n",
    "def _index_by_sku(items: List[Dict]) -> Dict[str, Dict]:\n",
    "    out = {}\n",
    "    for it in items:\n",
    "        sku = str(it.get(\"cisco_product_id\") or \"\").strip()\n",
    "        if sku:\n",
    "            out[sku] = it\n",
    "    return out\n",
    "\n",
    "# =================== LLM ENRICHMENT ===================\n",
    "def _llm_client():\n",
    "    if not _openai_available:\n",
    "        raise RuntimeError(\"Pacote 'openai' no encontrado. Instale com: pip install openai\")\n",
    "    key = OPENAI_API_KEY or os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not key:\n",
    "        raise RuntimeError(\"OPENAI_API_KEY no definido.\")\n",
    "    client = OpenAI(api_key=key)\n",
    "    return client\n",
    "\n",
    "def _llm_prompt_for_enrichment(product: Dict, product_type: str, cat_slug: str) -> str:\n",
    "    # Seleciona quais campos podem ser preenchidos\n",
    "    if product_type == \"hardware\":\n",
    "        allowed = list((HW_ATTR_BLUEPRINT.get(cat_slug) or {}).keys())\n",
    "        path = \"technical_profile.hardware_attributes\"\n",
    "    else:\n",
    "        if cat_slug == \"sw_support_license\":\n",
    "            allowed = list(SW_ATTR_BLUEPRINT[\"sw_support_license\"].keys())\n",
    "            path = \"software_profile\"\n",
    "        else:\n",
    "            allowed = list((SW_ATTR_BLUEPRINT.get(cat_slug) or {}).keys())\n",
    "            # software funcional tem software_profile como raiz\n",
    "            path = \"software_profile\"\n",
    "\n",
    "    skeleton = {\n",
    "        \"fill_path\": path,\n",
    "        \"allowed_fields\": allowed,\n",
    "        \"only_fill_nulls\": True,\n",
    "        \"return_unknown_as_null\": True\n",
    "    }\n",
    "\n",
    "    name = product.get(\"commercial_name\", \"\")\n",
    "    sku  = product.get(\"cisco_product_id\", \"\")\n",
    "    return (\n",
    "        \"You are a data normalizer for Cisco product catalog.\\n\"\n",
    "        \"STRICT RULES:\\n\"\n",
    "        \" - Fill ONLY the fields listed in 'allowed_fields' below.\\n\"\n",
    "        \" - Fill ONLY when you are reasonably certain from the product name/SKU semantics.\\n\"\n",
    "        \" - If unsure, set the value to null (do NOT guess).\\n\"\n",
    "        \" - Return a single valid JSON object with only the keys to update (no prose).\\n\\n\"\n",
    "        f\"PRODUCT_NAME: {name}\\n\"\n",
    "        f\"SKU: {sku}\\n\\n\"\n",
    "        f\"FILL_INSTRUCTIONS_JSON:\\n{json.dumps(skeleton, indent=2)}\\n\"\n",
    "        \"Output JSON example:\\n\"\n",
    "        \"{ \\\"<field1>\\\": <value or null>, \\\"<field2>\\\": <value or null> }\\n\"\n",
    "    )\n",
    "\n",
    "def enrich_product_with_llm(product: Dict, product_type: str, cat_slug: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Chama a LLM para preencher APENAS os campos null do blueprint da categoria.\n",
    "    Retorna um dicionrio com as chaves atualizadas (ou {} se nada a fazer).\n",
    "    \"\"\"\n",
    "    # Detecta se h algo para preencher\n",
    "    if product_type == \"hardware\":\n",
    "        path = (\"technical_profile\", \"hardware_attributes\")\n",
    "        bp   = HW_ATTR_BLUEPRINT.get(cat_slug) or {}\n",
    "    else:\n",
    "        if cat_slug == \"sw_support_license\":\n",
    "            path = (\"software_profile\",)\n",
    "            bp   = SW_ATTR_BLUEPRINT[\"sw_support_license\"]\n",
    "        else:\n",
    "            path = (\"software_profile\",)\n",
    "            bp   = SW_ATTR_BLUEPRINT.get(cat_slug) or {}\n",
    "\n",
    "    # verifica nulls\n",
    "    node = product\n",
    "    for p in path:\n",
    "        node = node.get(p, {})\n",
    "    needs = False\n",
    "    for k in bp.keys():\n",
    "        if node.get(k, None) in (None, [], \"\"):\n",
    "            needs = True\n",
    "            break\n",
    "    if not needs:\n",
    "        return {}\n",
    "\n",
    "    client = _llm_client()\n",
    "    prompt = _llm_prompt_for_enrichment(product, product_type, cat_slug)\n",
    "\n",
    "    try:\n",
    "        resp = client.chat.completions.create(\n",
    "            model=OPENAI_MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a strict JSON filler that never hallucinates.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            temperature=0.0,\n",
    "        )\n",
    "        raw = resp.choices[0].message.content.strip()\n",
    "        data = json.loads(raw)\n",
    "        # filtra apenas campos permitidos\n",
    "        allowed = set((HW_ATTR_BLUEPRINT if product_type==\"hardware\" else SW_ATTR_BLUEPRINT.get(cat_slug, {})).keys()) \\\n",
    "                  if product_type==\"hardware\" else \\\n",
    "                  (set(SW_ATTR_BLUEPRINT[\"sw_support_license\"].keys()) if cat_slug==\"sw_support_license\"\n",
    "                   else set(SW_ATTR_BLUEPRINT.get(cat_slug, {}).keys()))\n",
    "        cleaned = {k: v for k, v in data.items() if k in allowed}\n",
    "        # aplica no produto\n",
    "        target = product\n",
    "        for p in path:\n",
    "            if p not in target:\n",
    "                target[p] = {}\n",
    "            target = target[p]\n",
    "        for k, v in cleaned.items():\n",
    "            if target.get(k) in (None, [], \"\"):\n",
    "                target[k] = v\n",
    "        return cleaned\n",
    "    except Exception as e:\n",
    "        # Falha de parsing ou de chamada -> no enriquece\n",
    "        # Voc pode logar se quiser\n",
    "        return {}\n",
    "\n",
    "# =================== PIPELINE ===================\n",
    "def normalize_and_export_by_category(xlsx_path: str, out_dir: Path):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    df = pd.read_excel(xlsx_path, engine=\"openpyxl\")\n",
    "\n",
    "    # Detecta colunas\n",
    "    col_type = _find_col(df, \"category-type\", \"category type\", \"type\")\n",
    "    col_cat  = _find_col(df, \"category\")\n",
    "    col_sku  = _find_col(df, \"sku\", \"part\", \"part number\")\n",
    "    col_desc = _find_col(df, \"desc\", \"description\", \"name\")\n",
    "    col_pri  = _find_col(df, \"pri\", \"price\", \"list price\")\n",
    "    col_elig = _find_col(df, \"elig\", \"eligibility\", \"elig_%\", \"eligibility %\")\n",
    "\n",
    "    print(\" Columns detected:\", {\n",
    "        \"type\": col_type, \"category\": col_cat, \"sku\": col_sku, \"desc\": col_desc, \"price\": col_pri, \"elig\": col_elig\n",
    "    })\n",
    "    if not all([col_type, col_cat, col_sku, col_desc, col_pri, col_elig]):\n",
    "        raise ValueError(\"No encontrei todas as colunas necessrias. Confira os nomes no Excel.\")\n",
    "\n",
    "    # Normaliza campos base\n",
    "    df[\"_type\"] = df[col_type].astype(str).str.strip().str.lower()\n",
    "    df[\"_cat\"]  = df[col_cat].astype(str).str.strip()\n",
    "    df[\"_sku\"]  = df[col_sku].astype(str).str.strip()\n",
    "    df[\"_desc\"] = df[col_desc].astype(str).str.strip()\n",
    "    df[\"_pri\"]  = df[col_pri].apply(_norm_price)\n",
    "    df[\"_elig\"] = (\n",
    "        df[col_elig].astype(str).str.strip().str.replace(\"%\",\"\", regex=False)\n",
    "        .str.replace(\",\", \".\", regex=False)\n",
    "    )\n",
    "    df[\"_elig\"] = pd.to_numeric(df[\"_elig\"], errors=\"coerce\").fillna(0.0) / 100.0\n",
    "\n",
    "    print(\" Type counts:\", df[\"_type\"].value_counts().to_dict())\n",
    "    print(\" Sample categories:\", df[\"_cat\"].str.lower().value_counts().head(15).to_dict())\n",
    "\n",
    "    # Buckets por categoria\n",
    "    buckets_hw: Dict[str, List[Dict]] = {}\n",
    "    buckets_sw: Dict[str, List[Dict]] = {}\n",
    "\n",
    "    # Separa\n",
    "    hw_rows = df[df[\"_type\"].str.contains(\"hard\", na=False)]\n",
    "    sw_rows = df[df[\"_type\"].str.contains(\"soft\", na=False)]\n",
    "\n",
    "    # Monta registros iniciais\n",
    "    for _, r in hw_rows.iterrows():\n",
    "        sku, name = r[\"_sku\"], r[\"_desc\"]\n",
    "        cat_slug = _canon_category(r[\"_cat\"], \"hardware\")\n",
    "        rec = _hardware_record(sku, name, cat_slug, float(r[\"_pri\"]), float(r[\"_elig\"]))\n",
    "        buckets_hw.setdefault(cat_slug, []).append(rec)\n",
    "\n",
    "    for _, r in sw_rows.iterrows():\n",
    "        sku, name = r[\"_sku\"], r[\"_desc\"]\n",
    "        cat_slug = _canon_category(r[\"_cat\"], \"software\")\n",
    "        rec = _software_record(sku, name, cat_slug, float(r[\"_pri\"]), float(r[\"_elig\"]))\n",
    "        buckets_sw.setdefault(cat_slug, []).append(rec)\n",
    "\n",
    "    # Salva por categoria (merge com existentes + enriquecimento)\n",
    "    hw_dir = out_dir / \"hardware\"\n",
    "    sw_dir = out_dir / \"software\"\n",
    "    hw_dir.mkdir(parents=True, exist_ok=True)\n",
    "    sw_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    files_written = 0\n",
    "\n",
    "    # ---------- HARDWARE ----------\n",
    "    for cat, items in buckets_hw.items():\n",
    "        path = hw_dir / f\"hw_{cat}.json\"\n",
    "        existing = _load_existing(path)\n",
    "        index    = _index_by_sku(existing)\n",
    "\n",
    "        # Merge + enrich\n",
    "        to_save: List[Dict] = existing[:]  # start with existing\n",
    "        seen = set(s.get(\"cisco_product_id\") for s in existing)\n",
    "\n",
    "        for prod in tqdm(items, desc=f\"[HW] {cat}\", unit=\"sku\"):\n",
    "            sku = prod[\"cisco_product_id\"]\n",
    "            if sku in seen and not REFRESH_ENRICHMENT:\n",
    "                # j existe  mantm\n",
    "                continue\n",
    "\n",
    "            # Se j existia e vamos refresh, substitui\n",
    "            if sku in index and REFRESH_ENRICHMENT:\n",
    "                # mantm campos j preenchidos\n",
    "                merged = index[sku]\n",
    "                # sobrepe preo/desc se mudou\n",
    "                merged[\"commercial_name\"] = prod[\"commercial_name\"]\n",
    "                merged[\"pricing_model\"][\"base_price\"] = prod[\"pricing_model\"][\"base_price\"]\n",
    "                merged[\"pricing_model\"][\"elig_pct\"]   = prod[\"pricing_model\"][\"elig_pct\"]\n",
    "                prod = merged\n",
    "\n",
    "            if ENRICH_WITH_LLM:\n",
    "                # preenche somente os campos null do blueprint\n",
    "                _ = enrich_product_with_llm(prod, \"hardware\", cat)\n",
    "                time.sleep(RATE_LIMIT_SLEEP)\n",
    "\n",
    "            # se j existia, update lista; se no, append\n",
    "            if sku in index:\n",
    "                # atualiza no array existente\n",
    "                for i, old in enumerate(to_save):\n",
    "                    if old.get(\"cisco_product_id\") == sku:\n",
    "                        to_save[i] = prod\n",
    "                        break\n",
    "            else:\n",
    "                to_save.append(prod)\n",
    "                index[sku] = prod\n",
    "                seen.add(sku)\n",
    "\n",
    "        path.write_text(json.dumps(to_save, indent=2), encoding=\"utf-8\")\n",
    "        files_written += 1\n",
    "\n",
    "    # ---------- SOFTWARE ----------\n",
    "    for cat, items in buckets_sw.items():\n",
    "        path = sw_dir / f\"sw_{cat}.json\"\n",
    "        existing = _load_existing(path)\n",
    "        index    = _index_by_sku(existing)\n",
    "\n",
    "        to_save: List[Dict] = existing[:]\n",
    "        seen = set(s.get(\"cisco_product_id\") for s in existing)\n",
    "\n",
    "        for prod in tqdm(items, desc=f\"[SW] {cat}\", unit=\"sku\"):\n",
    "            sku = prod[\"cisco_product_id\"]\n",
    "            if sku in seen and not REFRESH_ENRICHMENT:\n",
    "                continue\n",
    "\n",
    "            if sku in index and REFRESH_ENRICHMENT:\n",
    "                merged = index[sku]\n",
    "                merged[\"commercial_name\"] = prod[\"commercial_name\"]\n",
    "                merged[\"pricing_model\"][\"base_price\"] = prod[\"pricing_model\"][\"base_price\"]\n",
    "                merged[\"pricing_model\"][\"elig_pct\"]   = prod[\"pricing_model\"][\"elig_pct\"]\n",
    "                prod = merged\n",
    "\n",
    "            if ENRICH_WITH_LLM:\n",
    "                _ = enrich_product_with_llm(prod, \"software\", cat)\n",
    "                time.sleep(RATE_LIMIT_SLEEP)\n",
    "\n",
    "            if sku in index:\n",
    "                for i, old in enumerate(to_save):\n",
    "                    if old.get(\"cisco_product_id\") == sku:\n",
    "                        to_save[i] = prod\n",
    "                        break\n",
    "            else:\n",
    "                to_save.append(prod)\n",
    "                index[sku] = prod\n",
    "                seen.add(sku)\n",
    "\n",
    "        path.write_text(json.dumps(to_save, indent=2), encoding=\"utf-8\")\n",
    "        files_written += 1\n",
    "\n",
    "    print(\" Done:\", {\n",
    "        \"hardware\": sum(len(json.loads((hw_dir/f).read_text(encoding='utf-8'))) for f in os.listdir(hw_dir) if f.endswith(\".json\")),\n",
    "        \"software\": sum(len(json.loads((sw_dir/f).read_text(encoding='utf-8'))) for f in os.listdir(sw_dir) if f.endswith(\".json\")),\n",
    "        \"files\": files_written,\n",
    "        \"out\": str(out_dir)\n",
    "    })\n",
    "\n",
    "# %%\n",
    "normalize_and_export_by_category(XLSX_PATH, OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420dd203-7d45-458d-8d3a-b1fb4d765413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5cc3b1-1709-4d25-a2c0-e865b39568d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd28f739-6701-4b91-840d-fc51e20b40bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# NORMALIZAO E ENRIQUECIMENTO POR CATEGORIA (NOTEBOOK-ONLY)\n",
    "# ============================================================\n",
    "\n",
    "import os, re, json, time, math\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- LLM (LangChain OpenAI) ---\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# =================== CONFIG ===================\n",
    "\n",
    "# Caminhos\n",
    "XLSX_PATH = \"data/raw/Cisco_Pricing.xlsx\"\n",
    "OUT_DIR   = Path(\"data/normalized\")\n",
    "\n",
    "# Execuo\n",
    "ENRICH_WITH_LLM      = True   # habilita enriquecimento por IA SKU-a-SKU\n",
    "REFRESH_ENRICHMENT   = True   # se j existe no JSON, re-enriquece e mescla\n",
    "RATE_LIMIT_SLEEP     = 0.6    # sleep entre chamadas LLM (ajuste se precisar)\n",
    "\n",
    "# Modo rpido para teste\n",
    "SAMPLE_MODE          = True    # liga modo amostra\n",
    "SAMPLE_PER_CATEGORY  = 5       # n de SKUs por categoria\n",
    "MAX_TOTAL_SKUS       = 40      # hard stop global (HW+SW)\n",
    "MAX_LLM_CALLS        = 25      # mx. de chamadas LLM no modo rpido\n",
    "\n",
    "# Filtros opcionais: processe s algumas categorias\n",
    "INCLUDE_ONLY_CATS_HW = None    # ex.: [\"switches\", \"access_points\"]\n",
    "INCLUDE_ONLY_CATS_SW = None    # ex.: [\"sw_support_license\", \"sw_wireless\"]\n",
    "\n",
    "# OpenAI\n",
    "OPENAI_MODEL = \"gpt-4o-mini\"\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")  # defina no ambiente\n",
    "if not OPENAI_API_KEY and ENRICH_WITH_LLM:\n",
    "    raise RuntimeError(\"Defina OPENAI_API_KEY no ambiente antes de rodar.\")\n",
    "\n",
    "# =================== HELPER: DETECO DE COLUNAS ===================\n",
    "\n",
    "def _find_col(df: pd.DataFrame, *cands) -> Optional[str]:\n",
    "    cols = [str(c).strip().lower() for c in df.columns]\n",
    "    for cand in cands:\n",
    "        for i, c in enumerate(cols):\n",
    "            if cand in c:\n",
    "                return df.columns[i]\n",
    "    return None\n",
    "\n",
    "def _norm_price(x) -> float:\n",
    "    s = str(x)\n",
    "    s = re.sub(r\"[^\\d,\\.]\", \"\", s)\n",
    "    # remove separador de milhar (.) quando h vrgula decimal\n",
    "    s = re.sub(r\"\\.(?=\\d{3},)\", \"\", s)\n",
    "    s = s.replace(\",\", \".\")\n",
    "    try:\n",
    "        return float(s)\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "# =================== CATEGORIAS & ESQUEMAS ===================\n",
    "\n",
    "# Mapeamento para slugs cannicos (hardware)\n",
    "def _canon_category_hw(raw: str) -> str:\n",
    "    s = raw.strip().lower()\n",
    "    # heursticas por palavra-chave\n",
    "    if re.search(r\"\\b(ap|access\\s*point|wireless)\\b\", s):\n",
    "        return \"access_points\"\n",
    "    if \"switch\" in s:\n",
    "        return \"switches\"\n",
    "    if \"router\" in s or \"isr\" in s or \"asr\" in s:\n",
    "        return \"routers\"\n",
    "    if \"firewall\" in s or \"asa\" in s or re.search(r\"\\bftd\\b\", s):\n",
    "        return \"firewalls\"\n",
    "    if \"controller\" in s or \"wlc\" in s:\n",
    "        return \"controllers\"\n",
    "    if \"sd-wan\" in s or \"sdwan\" in s or \"vmanage\" in s:\n",
    "        return \"sdwan\"\n",
    "    if \"sfp\" in s or \"qsfp\" in s or \"transceiver\" in s or \"optic\" in s:\n",
    "        return \"optics_transceivers\"\n",
    "    if \"camera\" in s or \"iot\" in s:\n",
    "        return \"cameras_iot\"\n",
    "    if \"psu\" in s or \"power supply\" in s or \"ups\" in s:\n",
    "        return \"power_psu_ups\"\n",
    "    if \"module\" in s or \"line card\" in s or \"linecard\" in s:\n",
    "        return \"modules_linecards\"\n",
    "    if \"ucs\" in s or \"server\" in s:\n",
    "        return \"servers\"\n",
    "    if \"storage\" in s:\n",
    "        return \"storage\"\n",
    "    if \"phone\" in s or \"telepresence\" in s or \"collaboration\" in s:\n",
    "        return \"collab_endpoints\"\n",
    "    # fallback: tenta derivar de nomes comuns (Meraki MS* => switches, MR* => AP)\n",
    "    if re.match(r\"^ms\\d\", s):  # Meraki Switch\n",
    "        return \"switches\"\n",
    "    if re.match(r\"^mr\\d\", s):  # Meraki AP\n",
    "        return \"access_points\"\n",
    "    if re.match(r\"^mx\\d\", s):  # Meraki Security/SD-WAN\n",
    "        return \"firewalls\"\n",
    "    return \"other_hw\"\n",
    "\n",
    "# Mapeamento para slugs cannicos (software)\n",
    "def _canon_category_sw(raw: str, sku: str, desc: str) -> str:\n",
    "    s = raw.strip().lower()\n",
    "    sd = f\"{sku} {desc}\".lower()\n",
    "    if \"license\" in s or \"support\" in s or \"entitlement\" in s:\n",
    "        return \"sw_support_license\"\n",
    "    if \"firewall\" in s or \"asa\" in s or \"firepower\" in s:\n",
    "        return \"sw_firewall\"\n",
    "    if \"security\" in s or \"securex\" in s or \"duo\" in s or \"umbrella\" in s:\n",
    "        return \"sw_security\"\n",
    "    if \"wireless\" in s or \"wlc\" in s or \"meraki\" in s:\n",
    "        # Meraki LIC- por padro licenciamento/gesto\n",
    "        if \"lic-\" in sd:\n",
    "            return \"sw_support_license\"\n",
    "        return \"sw_wireless\"\n",
    "    if \"sdwan\" in s or \"sd-wan\" in s:\n",
    "        return \"sw_routing_sdwan\"\n",
    "    if \"collab\" in s or \"webex\" in s:\n",
    "        return \"sw_collaboration\"\n",
    "    if \"datacenter\" in s or \"intersight\" in s or \"ucs\" in s:\n",
    "        return \"sw_datacenter\"\n",
    "    if \"observability\" in s or \"appdynamics\" in s or \"thousandeyes\" in s:\n",
    "        return \"sw_observability\"\n",
    "    # fallback por heurstica de SKU\n",
    "    if sku.upper().startswith(\"LIC-\"):\n",
    "        return \"sw_support_license\"\n",
    "    return \"sw_other\"\n",
    "\n",
    "# Campos por categoria (hardware)\n",
    "HARDWARE_ATTR_FIELDS: Dict[str, List[str]] = {\n",
    "    \"switches\": [\"port_count\",\"uplinks\",\"poe_budget_watts\",\"stacking\",\"layer\",\"throughput_gbps\",\"mounting\",\"redundancy\"],\n",
    "    \"access_points\": [\"wifi_standard\",\"throughput\",\"antenna\",\"indoor_outdoor\",\"mimo\",\"poe_class\",\"mesh_support\"],\n",
    "    \"routers\": [\"wan_ports\",\"lan_ports\",\"throughput_gbps\",\"vpn_throughput\",\"sdwan_ready\",\"redundant_psu\"],\n",
    "    \"firewalls\": [\"throughput_gbps\",\"ngfw\",\"ips\",\"vpn_peers\",\"ports\",\"ha_support\"],\n",
    "    \"controllers\": [\"ap_count_supported\",\"redundancy\",\"throughput_gbps\",\"model\"],\n",
    "    \"sdwan\": [\"role\",\"controllers\",\"overlay_type\",\"max_tunnels\",\"throughput_gbps\"],\n",
    "    \"optics_transceivers\": [\"form_factor\",\"speed_gbps\",\"wavelength_nm\",\"reach_m\",\"connector\"],\n",
    "    \"cameras_iot\": [\"resolution\",\"lens\",\"indoor_outdoor\",\"ir\",\"storage\"],\n",
    "    \"power_psu_ups\": [\"wattage\",\"input_voltage\",\"output_voltage\",\"form_factor\"],\n",
    "    \"modules_linecards\": [\"slot_type\",\"ports\",\"speed_gbps\",\"poe_support\"],\n",
    "    \"servers\": [\"cpu\",\"memory_gb\",\"storage\",\"form_factor\",\"nic\"],\n",
    "    \"storage\": [\"capacity_tb\",\"form_factor\",\"protocol\"],\n",
    "    \"collab_endpoints\": [\"type\",\"display\",\"codec\",\"microphones\"],\n",
    "    \"other_hw\": [\"notes\"]\n",
    "}\n",
    "\n",
    "# Campos por categoria (software)\n",
    "SOFTWARE_ATTR_FIELDS: Dict[str, List[str]] = {\n",
    "    \"sw_support_license\": [\"term\",\"edition\",\"device_type\",\"cloud_managed\",\"support_level\"],\n",
    "    \"sw_firewall\": [\"feature_set\",\"ips\",\"vpn\",\"firepower_version\",\"deployment_model\"],\n",
    "    \"sw_security\": [\"feature_set\",\"integrations\",\"cloud\",\"on_prem\"],\n",
    "    \"sw_wireless\": [\"controller_type\",\"ap_count\",\"ai_rf\",\"guest_access\"],\n",
    "    \"sw_routing_sdwan\": [\"feature_set\",\"controllers\",\"overlay\",\"cloud_gateway\"],\n",
    "    \"sw_collaboration\": [\"workloads\",\"capacity\",\"recording\",\"compliance\"],\n",
    "    \"sw_datacenter\": [\"hypervisor\",\"automation\",\"integrations\"],\n",
    "    \"sw_observability\": [\"sources\",\"metrics\",\"distributed_tracing\",\"synthetics\"],\n",
    "    \"sw_other\": [\"notes\"]\n",
    "}\n",
    "\n",
    "# =================== RECORD BUILDERS ===================\n",
    "\n",
    "def _hardware_record(sku: str, name: str, cat_slug: str, price: float, elig: float) -> Dict:\n",
    "    # cria dict com todos os campos base + atributos por categoria\n",
    "    attrs = {k: None for k in HARDWARE_ATTR_FIELDS.get(cat_slug, HARDWARE_ATTR_FIELDS[\"other_hw\"])}\n",
    "    return {\n",
    "        \"cisco_product_id\": sku,\n",
    "        \"commercial_name\": name,\n",
    "        \"product_type\": \"hardware\",\n",
    "        \"lifecycle\": {\"status\": \"unknown\", \"eos_announced\": None, \"last_support_date\": None},\n",
    "        \"technical_profile\": {\n",
    "            \"category\": cat_slug,\n",
    "            \"subcategory\": None,\n",
    "            \"hardware_attributes\": attrs\n",
    "        },\n",
    "        \"pricing_model\": {\n",
    "            \"type\": \"one_time\",\n",
    "            \"currency\": \"USD\",\n",
    "            \"base_price\": float(price),\n",
    "            \"elig_pct\": float(elig),\n",
    "            \"pricing_tiers\": []\n",
    "        },\n",
    "        \"dependencies\": {\"required_components\": [], \"compatible_with\": []},\n",
    "        \"regulatory\": {\"certifications\": []}\n",
    "    }\n",
    "\n",
    "def _software_record(sku: str, name: str, cat_slug: str, price: float, elig: float) -> Dict:\n",
    "    attrs = {k: None for k in SOFTWARE_ATTR_FIELDS.get(cat_slug, SOFTWARE_ATTR_FIELDS[\"sw_other\"])}\n",
    "    return {\n",
    "        \"cisco_product_id\": sku,\n",
    "        \"commercial_name\": name,\n",
    "        \"product_type\": \"software\",\n",
    "        \"lifecycle\": {\"status\": \"unknown\", \"eos_announced\": None, \"last_support_date\": None},\n",
    "        \"technical_profile\": {\n",
    "            \"category\": cat_slug,\n",
    "            \"subcategory\": None,\n",
    "            \"software_attributes\": attrs\n",
    "        },\n",
    "        \"pricing_model\": {\n",
    "            \"type\": \"one_time\",\n",
    "            \"currency\": \"USD\",\n",
    "            \"base_price\": float(price),\n",
    "            \"elig_pct\": float(elig),\n",
    "            \"pricing_tiers\": []\n",
    "        },\n",
    "        \"license\": {\n",
    "            \"term_months\": None,\n",
    "            \"seats_included\": None,\n",
    "            \"metering\": None,\n",
    "            \"sku_family\": None\n",
    "        },\n",
    "        \"compatibility\": {\n",
    "            \"requires_hardware\": [],\n",
    "            \"compatible_platforms\": [],\n",
    "            \"min_versions\": {}\n",
    "        }\n",
    "    }\n",
    "\n",
    "# =================== IO HELPERS ===================\n",
    "\n",
    "def _load_existing(path: Path) -> List[Dict]:\n",
    "    if path.exists():\n",
    "        try:\n",
    "            return json.loads(path.read_text(encoding=\"utf-8\"))\n",
    "        except Exception:\n",
    "            return []\n",
    "    return []\n",
    "\n",
    "def _index_by_sku(items: List[Dict]) -> Dict[str, Dict]:\n",
    "    idx = {}\n",
    "    for it in items:\n",
    "        sku = it.get(\"cisco_product_id\")\n",
    "        if sku:\n",
    "            idx[sku] = it\n",
    "    return idx\n",
    "\n",
    "# =================== ENRIQUECIMENTO VIA LLM ===================\n",
    "\n",
    "_llm = ChatOpenAI(model=OPENAI_MODEL, temperature=0.2) if ENRICH_WITH_LLM else None\n",
    "\n",
    "def enrich_product_with_llm(prod: Dict, ptype: str, cat_slug: str) -> Dict:\n",
    "    \"\"\"Preenche apenas os atributos da categoria. Desconhecido => null. Sem inventar.\"\"\"\n",
    "    if not ENRICH_WITH_LLM:\n",
    "        return prod\n",
    "\n",
    "    if ptype == \"hardware\":\n",
    "        keys = HARDWARE_ATTR_FIELDS.get(cat_slug, HARDWARE_ATTR_FIELDS[\"other_hw\"])\n",
    "        path = [\"technical_profile\", \"hardware_attributes\"]\n",
    "    else:\n",
    "        keys = SOFTWARE_ATTR_FIELDS.get(cat_slug, SOFTWARE_ATTR_FIELDS[\"sw_other\"])\n",
    "        path = [\"technical_profile\", \"software_attributes\"]\n",
    "\n",
    "    # Prompt: pedimos S o dicionrio de atributos, mais nada.\n",
    "    sys_msg = (\n",
    "        \"You are a careful data normalizer. \"\n",
    "        \"From the product name (and optional description), \"\n",
    "        \"infer ONLY the requested attributes for the category. \"\n",
    "        \"If unknown, return null. Respond strictly as a minified JSON object with those keys only.\"\n",
    "    )\n",
    "    user_msg = f\"\"\"\n",
    "Product:\n",
    "- SKU: {prod.get('cisco_product_id')}\n",
    "- Name: {prod.get('commercial_name')}\n",
    "- Category: {cat_slug}\n",
    "- Type: {ptype}\n",
    "\n",
    "Return JSON with keys exactly: {keys}\n",
    "If an attribute is unknown, set it to null.\n",
    "Numbers should be numeric (e.g., 740 not \"740\"), booleans true/false.\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        resp = _llm.invoke([{\"role\":\"system\",\"content\":sys_msg},\n",
    "                            {\"role\":\"user\",\"content\":user_msg}])\n",
    "        txt = resp.content.strip()\n",
    "        # Sanitiza: tenta isolar JSON\n",
    "        m = re.search(r\"\\{.*\\}\", txt, flags=re.S)\n",
    "        if m:\n",
    "            txt = m.group(0)\n",
    "        data = json.loads(txt)\n",
    "        # Merge no produto\n",
    "        target = prod\n",
    "        for key in path:\n",
    "            target = target[key]\n",
    "        # s sobrepe chaves declaradas\n",
    "        for k in keys:\n",
    "            if k in data:\n",
    "                target[k] = data[k]\n",
    "    except Exception as e:\n",
    "        # Falha no enriquecimento: segue com o registro base\n",
    "        pass\n",
    "\n",
    "    return prod\n",
    "\n",
    "# =================== PIPELINE ===================\n",
    "\n",
    "def normalize_and_export_by_category(xlsx_path: str, out_dir: Path):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    df = pd.read_excel(xlsx_path, engine=\"openpyxl\")\n",
    "\n",
    "    # Detecta colunas\n",
    "    col_type = _find_col(df, \"category-type\", \"category type\", \"type\")\n",
    "    col_cat  = _find_col(df, \"category\")\n",
    "    col_sku  = _find_col(df, \"sku\", \"part\", \"part number\")\n",
    "    col_desc = _find_col(df, \"desc\", \"description\", \"name\")\n",
    "    col_pri  = _find_col(df, \"pri\", \"price\", \"list price\")\n",
    "    col_elig = _find_col(df, \"elig\", \"eligibility\", \"elig_%\", \"eligibility %\")\n",
    "\n",
    "    if not all([col_type, col_cat, col_sku, col_desc, col_pri, col_elig]):\n",
    "        raise ValueError(\"No encontrei todas as colunas necessrias. Confira os nomes no Excel.\")\n",
    "\n",
    "    # Normaliza campos base\n",
    "    df[\"_type\"] = df[col_type].astype(str).str.strip().str.lower()\n",
    "    df[\"_cat\"]  = df[col_cat].astype(str).str.strip()\n",
    "    df[\"_sku\"]  = df[col_sku].astype(str).str.strip()\n",
    "    df[\"_desc\"] = df[col_desc].astype(str).str.strip()\n",
    "    df[\"_pri\"]  = df[col_pri].apply(_norm_price)\n",
    "    df[\"_elig\"] = (\n",
    "        df[col_elig].astype(str).str.strip().str.replace(\"%\",\"\", regex=False)\n",
    "        .str.replace(\",\", \".\", regex=False)\n",
    "    )\n",
    "    df[\"_elig\"] = pd.to_numeric(df[\"_elig\"], errors=\"coerce\").fillna(0.0) / 100.0\n",
    "\n",
    "    # Separa hardware/software\n",
    "    hw_rows = df[df[\"_type\"].str.contains(\"hard\", na=False)].copy()\n",
    "    sw_rows = df[df[\"_type\"].str.contains(\"soft\", na=False)].copy()\n",
    "\n",
    "    # Map categorias  listas\n",
    "    buckets_hw: Dict[str, List[Dict]] = {}\n",
    "    buckets_sw: Dict[str, List[Dict]] = {}\n",
    "\n",
    "    # Build candidatos hardware\n",
    "    for _, r in hw_rows.iterrows():\n",
    "        sku, name = r[\"_sku\"], r[\"_desc\"]\n",
    "        cat_slug = _canon_category_hw(r[\"_cat\"])\n",
    "        if INCLUDE_ONLY_CATS_HW and cat_slug not in INCLUDE_ONLY_CATS_HW:\n",
    "            continue\n",
    "        rec = _hardware_record(sku, name, cat_slug, float(r[\"_pri\"]), float(r[\"_elig\"]))\n",
    "        buckets_hw.setdefault(cat_slug, []).append(rec)\n",
    "\n",
    "    # Build candidatos software\n",
    "    for _, r in sw_rows.iterrows():\n",
    "        sku, name = r[\"_sku\"], r[\"_desc\"]\n",
    "        cat_slug = _canon_category_sw(r[\"_cat\"], sku, name)\n",
    "        if INCLUDE_ONLY_CATS_SW and cat_slug not in INCLUDE_ONLY_CATS_SW:\n",
    "            continue\n",
    "        rec = _software_record(sku, name, cat_slug, float(r[\"_pri\"]), float(r[\"_elig\"]))\n",
    "        buckets_sw.setdefault(cat_slug, []).append(rec)\n",
    "\n",
    "    # Amostragem por categoria\n",
    "    if SAMPLE_MODE:\n",
    "        for cat in list(buckets_hw.keys()):\n",
    "            buckets_hw[cat] = buckets_hw[cat][:SAMPLE_PER_CATEGORY]\n",
    "        for cat in list(buckets_sw.keys()):\n",
    "            buckets_sw[cat] = buckets_sw[cat][:SAMPLE_PER_CATEGORY]\n",
    "\n",
    "    # Pastas\n",
    "    hw_dir = out_dir / \"hardware\"\n",
    "    sw_dir = out_dir / \"software\"\n",
    "    hw_dir.mkdir(parents=True, exist_ok=True)\n",
    "    sw_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    files_written = 0\n",
    "    processed_skus = 0\n",
    "    llm_calls = 0\n",
    "\n",
    "    # ---------- HARDWARE ----------\n",
    "    for cat, items in buckets_hw.items():\n",
    "        if MAX_TOTAL_SKUS and processed_skus >= MAX_TOTAL_SKUS:\n",
    "            break\n",
    "        path = hw_dir / f\"hw_{cat}.json\"\n",
    "        existing = _load_existing(path)\n",
    "        index    = _index_by_sku(existing)\n",
    "\n",
    "        to_save: List[Dict] = existing[:]\n",
    "        seen = set(s.get(\"cisco_product_id\") for s in existing)\n",
    "\n",
    "        for prod in tqdm(items, desc=f\"[HW] {cat}\", unit=\"sku\"):\n",
    "            if MAX_TOTAL_SKUS and processed_skus >= MAX_TOTAL_SKUS:\n",
    "                break\n",
    "            sku = prod[\"cisco_product_id\"]\n",
    "\n",
    "            # merge/refresh\n",
    "            if sku in seen and not REFRESH_ENRICHMENT:\n",
    "                continue\n",
    "            if sku in index and REFRESH_ENRICHMENT:\n",
    "                merged = index[sku]\n",
    "                # atualiza campos base\n",
    "                merged[\"commercial_name\"] = prod[\"commercial_name\"]\n",
    "                merged[\"pricing_model\"][\"base_price\"] = prod[\"pricing_model\"][\"base_price\"]\n",
    "                merged[\"pricing_model\"][\"elig_pct\"]   = prod[\"pricing_model\"][\"elig_pct\"]\n",
    "                prod = merged\n",
    "\n",
    "            # enrich\n",
    "            if ENRICH_WITH_LLM and (not SAMPLE_MODE or llm_calls < MAX_LLM_CALLS):\n",
    "                prod = enrich_product_with_llm(prod, \"hardware\", cat)\n",
    "                llm_calls += 1\n",
    "                time.sleep(RATE_LIMIT_SLEEP)\n",
    "\n",
    "            # escreve\n",
    "            if sku in index:\n",
    "                for i, old in enumerate(to_save):\n",
    "                    if old.get(\"cisco_product_id\") == sku:\n",
    "                        to_save[i] = prod\n",
    "                        break\n",
    "            else:\n",
    "                to_save.append(prod)\n",
    "                index[sku] = prod\n",
    "                seen.add(sku)\n",
    "\n",
    "            processed_skus += 1\n",
    "\n",
    "        path.write_text(json.dumps(to_save, indent=2), encoding=\"utf-8\")\n",
    "        files_written += 1\n",
    "\n",
    "        if MAX_TOTAL_SKUS and processed_skus >= MAX_TOTAL_SKUS:\n",
    "            break\n",
    "\n",
    "    # ---------- SOFTWARE ----------\n",
    "    for cat, items in buckets_sw.items():\n",
    "        if MAX_TOTAL_SKUS and processed_skus >= MAX_TOTAL_SKUS:\n",
    "            break\n",
    "        path = sw_dir / f\"sw_{cat}.json\"\n",
    "        existing = _load_existing(path)\n",
    "        index    = _index_by_sku(existing)\n",
    "\n",
    "        to_save: List[Dict] = existing[:]\n",
    "        seen = set(s.get(\"cisco_product_id\") for s in existing)\n",
    "\n",
    "        for prod in tqdm(items, desc=f\"[SW] {cat}\", unit=\"sku\"):\n",
    "            if MAX_TOTAL_SKUS and processed_skus >= MAX_TOTAL_SKUS:\n",
    "                break\n",
    "\n",
    "            sku = prod[\"cisco_product_id\"]\n",
    "\n",
    "            if sku in seen and not REFRESH_ENRICHMENT:\n",
    "                continue\n",
    "            if sku in index and REFRESH_ENRICHMENT:\n",
    "                merged = index[sku]\n",
    "                merged[\"commercial_name\"] = prod[\"commercial_name\"]\n",
    "                merged[\"pricing_model\"][\"base_price\"] = prod[\"pricing_model\"][\"base_price\"]\n",
    "                merged[\"pricing_model\"][\"elig_pct\"]   = prod[\"pricing_model\"][\"elig_pct\"]\n",
    "                prod = merged\n",
    "\n",
    "            if ENRICH_WITH_LLM and (not SAMPLE_MODE or llm_calls < MAX_LLM_CALLS):\n",
    "                prod = enrich_product_with_llm(prod, \"software\", cat)\n",
    "                llm_calls += 1\n",
    "                time.sleep(RATE_LIMIT_SLEEP)\n",
    "\n",
    "            if sku in index:\n",
    "                for i, old in enumerate(to_save):\n",
    "                    if old.get(\"cisco_product_id\") == sku:\n",
    "                        to_save[i] = prod\n",
    "                        break\n",
    "            else:\n",
    "                to_save.append(prod)\n",
    "                index[sku] = prod\n",
    "                seen.add(sku)\n",
    "\n",
    "            processed_skus += 1\n",
    "\n",
    "        path.write_text(json.dumps(to_save, indent=2), encoding=\"utf-8\")\n",
    "        files_written += 1\n",
    "\n",
    "        if MAX_TOTAL_SKUS and processed_skus >= MAX_TOTAL_SKUS:\n",
    "            break\n",
    "\n",
    "    # resumo\n",
    "    def _count_jsons(dirp: Path):\n",
    "        n = 0\n",
    "        if not dirp.exists():\n",
    "            return 0\n",
    "        for f in os.listdir(dirp):\n",
    "            if f.endswith(\".json\"):\n",
    "                try:\n",
    "                    n += len(json.loads((dirp/f).read_text(encoding=\"utf-8\")))\n",
    "                except Exception:\n",
    "                    pass\n",
    "        return n\n",
    "\n",
    "    print(\" Done (fast mode)\" if SAMPLE_MODE else \" Done\", {\n",
    "        \"hardware\": _count_jsons(hw_dir),\n",
    "        \"software\": _count_jsons(sw_dir),\n",
    "        \"files\": files_written,\n",
    "        \"processed_skus\": processed_skus,\n",
    "        \"llm_calls\": llm_calls,\n",
    "        \"out\": str(out_dir)\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f99166ae-8645-43a7-ab00-6078ed25c42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HW] other_hw: 100%|| 5/5 [00:10<00:00,  2.07s/sku]\n",
      "[SW] sw_other: 100%|| 5/5 [00:09<00:00,  1.97s/sku]\n",
      "[SW] sw_support_license: 100%|| 5/5 [00:09<00:00,  1.85s/sku]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Done (fast mode) {'hardware': 10, 'software': 15, 'files': 3, 'processed_skus': 15, 'llm_calls': 15, 'out': 'data\\\\normalized'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "normalize_and_export_by_category(XLSX_PATH, OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b63057-b4fd-46df-b78b-596e5a9a73f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a90f44-90c9-4ea5-97b6-64ef380b786f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03704b57-ad3f-4209-9709-1dac60adf6a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 305\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSoftware:\u001b[39m\u001b[38;5;124m\"\u001b[39m, {k: \u001b[38;5;28mlen\u001b[39m(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m buckets_sw\u001b[38;5;241m.\u001b[39mitems()})\n\u001b[0;32m    304\u001b[0m \u001b[38;5;66;03m# --- EXECUO --------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m--> 305\u001b[0m process_excel_to_category_jsons(\n\u001b[0;32m    306\u001b[0m     XLSX_PATH,\n\u001b[0;32m    307\u001b[0m     sample_per_category\u001b[38;5;241m=\u001b[39mSAMPLE_PER_CATEGORY,\n\u001b[0;32m    308\u001b[0m     do_enrichment\u001b[38;5;241m=\u001b[39mDO_ENRICHMENT\n\u001b[0;32m    309\u001b[0m )\n",
      "Cell \u001b[1;32mIn[33], line 256\u001b[0m, in \u001b[0;36mprocess_excel_to_category_jsons\u001b[1;34m(xlsx_path, sample_per_category, do_enrichment)\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    255\u001b[0m     base \u001b[38;5;241m=\u001b[39m instantiate_from_template(template, sku, name, price, elig, subcat)\n\u001b[1;32m--> 256\u001b[0m     final \u001b[38;5;241m=\u001b[39m enrich_product_with_llm(base, template) \u001b[38;5;28;01mif\u001b[39;00m do_enrichment \u001b[38;5;28;01melse\u001b[39;00m base\n\u001b[0;32m    258\u001b[0m     buckets_hw\u001b[38;5;241m.\u001b[39msetdefault(mapped, [])\u001b[38;5;241m.\u001b[39mappend(final)\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# software\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# Escolhe categoria de software (se existir). Caso no, bucket genrico \"Software\"\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[33], line 181\u001b[0m, in \u001b[0;36menrich_product_with_llm\u001b[1;34m(product_obj, template_obj)\u001b[0m\n\u001b[0;32m    176\u001b[0m prompt \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemplate\u001b[39m\u001b[38;5;124m\"\u001b[39m: template_obj,\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproduct\u001b[39m\u001b[38;5;124m\"\u001b[39m: product_obj\n\u001b[0;32m    179\u001b[0m }\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     resp \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m    182\u001b[0m         model\u001b[38;5;241m=\u001b[39mOPENAI_MODEL,\n\u001b[0;32m    183\u001b[0m         temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[0;32m    184\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m    185\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: ENRICH_SYSTEM},\n\u001b[0;32m    186\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: json\u001b[38;5;241m.\u001b[39mdumps(prompt, ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)}\n\u001b[0;32m    187\u001b[0m         ],\n\u001b[0;32m    188\u001b[0m         response_format\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson_object\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m    189\u001b[0m     )\n\u001b[0;32m    190\u001b[0m     enriched \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(resp\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;66;03m# Se a LLM retornou s o objeto final (sem wrapper), ok.\u001b[39;00m\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;66;03m# Se ela retornou {\"product\": {...}}, trate:\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1087\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   1045\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1084\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1085\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m   1086\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m-> 1087\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m   1088\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1089\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m   1090\u001b[0m             {\n\u001b[0;32m   1091\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m   1092\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m   1093\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n\u001b[0;32m   1094\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m   1095\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m   1096\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m   1097\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m   1098\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m   1099\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[0;32m   1100\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m   1101\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m   1102\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n\u001b[0;32m   1103\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m   1104\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[0;32m   1105\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: prediction,\n\u001b[0;32m   1106\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m   1107\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_effort\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_effort,\n\u001b[0;32m   1108\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m   1109\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m   1110\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[0;32m   1111\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m   1112\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[0;32m   1113\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m   1114\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[0;32m   1115\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m   1116\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m   1117\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m   1118\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[0;32m   1119\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m   1120\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m   1121\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb_search_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: web_search_options,\n\u001b[0;32m   1122\u001b[0m             },\n\u001b[0;32m   1123\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsStreaming\n\u001b[0;32m   1124\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[0;32m   1125\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsNonStreaming,\n\u001b[0;32m   1126\u001b[0m         ),\n\u001b[0;32m   1127\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m   1128\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m   1129\u001b[0m         ),\n\u001b[0;32m   1130\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m   1131\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1132\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[0;32m   1133\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1256\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1243\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1244\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1251\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1252\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1253\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1254\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1255\u001b[0m     )\n\u001b[1;32m-> 1256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:979\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m    977\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 979\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    980\u001b[0m         request,\n\u001b[0;32m    981\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[0;32m    982\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    983\u001b[0m     )\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    985\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[0;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[0;32m    927\u001b[0m     request,\n\u001b[0;32m    928\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[0;32m    929\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    930\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m    931\u001b[0m )\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[0;32m    955\u001b[0m         request,\n\u001b[0;32m    956\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    957\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[0;32m    958\u001b[0m     )\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    989\u001b[0m     hook(request)\n\u001b[1;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1024\u001b[0m     )\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpx\\_transports\\default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    234\u001b[0m )\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    245\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mhandle_request(\n\u001b[0;32m    237\u001b[0m         pool_request\u001b[38;5;241m.\u001b[39mrequest\n\u001b[0;32m    238\u001b[0m     )\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[0;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    100\u001b[0m     (\n\u001b[0;32m    101\u001b[0m         http_version,\n\u001b[0;32m    102\u001b[0m         status,\n\u001b[0;32m    103\u001b[0m         reason_phrase,\n\u001b[0;32m    104\u001b[0m         headers,\n\u001b[0;32m    105\u001b[0m         trailing_data,\n\u001b[1;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    108\u001b[0m         http_version,\n\u001b[0;32m    109\u001b[0m         status,\n\u001b[0;32m    110\u001b[0m         reason_phrase,\n\u001b[0;32m    111\u001b[0m         headers,\n\u001b[0;32m    112\u001b[0m     )\n\u001b[0;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_event(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    219\u001b[0m     )\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_backends\\sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv(max_bytes)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ssl.py:1232\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1228\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1229\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1230\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1231\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(buflen)\n\u001b[0;32m   1233\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ssl.py:1105\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- CONFIG --------------------------------------------------------------\n",
    "import os, json, re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# OpenAI >=1.0\n",
    "from openai import OpenAI\n",
    "load_dotenv()\n",
    "\n",
    "# ARQUIVOS / PASTAS\n",
    "XLSX_PATH = Path(\"data/raw/Cisco_Pricing.xlsx\")   # ajuste se preciso\n",
    "SCHEMAS_HW_DIR = Path(\"schemas/hardware\")         # onde esto seus schemas de hardware\n",
    "SCHEMAS_SW_DIR = Path(\"schemas/software\")         # (opcional) schemas de software\n",
    "OUT_HW_DIR = Path(\"out/hardware\")\n",
    "OUT_SW_DIR = Path(\"out/software\")\n",
    "\n",
    "# TESTE RPIDO: limite por categoria (ex.: 5). Use None para completo.\n",
    "SAMPLE_PER_CATEGORY = 5\n",
    "\n",
    "# ENRIQUECIMENTO VIA LLM (True para enriquecer, False para s estruturar sem LLM)\n",
    "DO_ENRICHMENT = True\n",
    "OPENAI_MODEL = \"gpt-4o-mini\"   # pode trocar\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# --- HELPERS: leitura de schemas -----------------------------------------\n",
    "def load_schema_templates(dir_path: Path) -> dict:\n",
    "    \"\"\"\n",
    "    Carrega todos os .json como templates, indexando por 'category' em lowercase.\n",
    "    Exige que cada JSON tenha a chave 'category' no topo.\n",
    "    \"\"\"\n",
    "    templates = {}\n",
    "    if not dir_path.exists():\n",
    "        return templates\n",
    "    for f in dir_path.glob(\"*.json\"):\n",
    "        try:\n",
    "            data = json.loads(f.read_text(encoding=\"utf-8\"))\n",
    "            cat = (data.get(\"category\") or \"\").strip().lower()\n",
    "            if not cat:\n",
    "                print(f\"[WARN] Schema sem 'category': {f}\")\n",
    "                continue\n",
    "            templates[cat] = data\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Falha lendo schema {f}: {e}\")\n",
    "    return templates\n",
    "\n",
    "SCHEMAS_HW = load_schema_templates(SCHEMAS_HW_DIR)\n",
    "SCHEMAS_SW = load_schema_templates(SCHEMAS_SW_DIR)\n",
    "\n",
    "if not SCHEMAS_HW:\n",
    "    raise RuntimeError(\n",
    "        f\"Nenhum schema de hardware encontrado em {SCHEMAS_HW_DIR}. \"\n",
    "        \"Coloque seus arquivos schema_*.json l.\"\n",
    "    )\n",
    "\n",
    "# --- HELPERS: deteco de colunas -----------------------------------------\n",
    "def find_col(df: pd.DataFrame, substrings) -> str | None:\n",
    "    for col in df.columns:\n",
    "        lc = str(col).strip().lower()\n",
    "        for sub in substrings:\n",
    "            if sub in lc:\n",
    "                return col\n",
    "    return None\n",
    "\n",
    "# --- HELPERS: normalizao de campos do Excel -----------------------------\n",
    "def clean_price_series(series: pd.Series) -> pd.Series:\n",
    "    s = (series.astype(str)\n",
    "               .str.replace(r\"[^\\d\\.,]\", \"\", regex=True)\n",
    "               .str.replace(r\"\\.(?=\\d{3},)\", \"\", regex=True)  # 1.234,56 -> 1234,56\n",
    "               .str.replace(\",\", \".\", regex=False))\n",
    "    return pd.to_numeric(s, errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "def clean_pct_series(series: pd.Series) -> pd.Series:\n",
    "    s = (series.astype(str)\n",
    "               .str.replace(r\"[^\\d\\.,]\", \"\", regex=True)\n",
    "               .str.replace(\",\", \".\", regex=False))\n",
    "    return pd.to_numeric(s, errors=\"coerce\").fillna(0.0) / 100.0\n",
    "\n",
    "# --- CLASSIFICAO: hardware vs software & mapeamento de categoria --------\n",
    "SOFT_HINTS = re.compile(r\"\\b(lic|license|subscription|entitlement|support|software|dna|meraki lic)\\b\", re.I)\n",
    "\n",
    "def guess_product_type(desc: str, category_cell: str | None) -> str:\n",
    "    cat_str = (category_cell or \"\").lower()\n",
    "    desc_l = (desc or \"\").lower()\n",
    "    if \"software\" in cat_str or SOFT_HINTS.search(desc_l):\n",
    "        return \"software\"\n",
    "    return \"hardware\"\n",
    "\n",
    "# mapeamento do Excel -> categorias dos schemas (ajuste se precisar)\n",
    "# chaves em lowercase; valores = nome \"category\" exatamente como no schema\n",
    "HW_CATEGORY_MAP = {\n",
    "    \"switch\": \"Switches\",\n",
    "    \"switches\": \"Switches\",\n",
    "    \"router\": \"Routers\",\n",
    "    \"routers\": \"Routers\",\n",
    "    \"firewall\": \"Firewall\",\n",
    "    \"wireless\": \"Wireless\",\n",
    "    \"ap\": \"Wireless\",\n",
    "    \"antenna\": \"Antennas\",\n",
    "    \"antennas\": \"Antennas\",\n",
    "    \"cable\": \"Cabling\",\n",
    "    \"cabling\": \"Cabling\",\n",
    "    \"connector\": \"Connectors\",\n",
    "    \"connectors\": \"Connectors\",\n",
    "    \"meraki ms\": \"Switches\",\n",
    "    \"meraki mx\": \"Routers\",\n",
    "    \"asa\": \"Firewall\",\n",
    "}\n",
    "def map_hw_category_from_row(desc: str, category_cell: str | None) -> str | None:\n",
    "    text = f\"{category_cell or ''} {desc or ''}\".lower()\n",
    "    # match por palavra-chave\n",
    "    for k, v in HW_CATEGORY_MAP.items():\n",
    "        if k in text:\n",
    "            return v\n",
    "    # fallback: se no achar, tenta \"Switches\" se tiver \"port\"/\"poe\" no texto\n",
    "    if re.search(r\"\\bpoe\\b|\\bports?\\b\", text):\n",
    "        return \"Switches\"\n",
    "    return None\n",
    "\n",
    "def map_sw_category_from_row(desc: str, category_cell: str | None) -> str:\n",
    "    # voc pode criar schemas/software para: Management, Security, Switching, Wireless, Support etc.\n",
    "    # Aqui coloco um bucket genrico \"Software\" se no houver schemas SW especficos.\n",
    "    if SCHEMAS_SW:\n",
    "        # tentativa simples: usar \"Management\" se achar 'dna'/'meraki', seno 'Security' se 'fw/ips', etc.\n",
    "        text = f\"{category_cell or ''} {desc or ''}\".lower()\n",
    "        if any(x in text for x in [\"dna\", \"meraki\", \"dashboard\", \"cloud mgmt\"]):\n",
    "            target = \"Management\"\n",
    "        elif any(x in text for x in [\"firepower\", \"ips\", \"security\", \"amp\", \"umbrella\"]):\n",
    "            target = \"Security\"\n",
    "        elif any(x in text for x in [\"wireless\", \"ap\", \"wi-fi\"]):\n",
    "            target = \"Wireless\"\n",
    "        elif any(x in text for x in [\"switch\", \"ms2\", \"catalyst\"]):\n",
    "            target = \"Switching\"\n",
    "        else:\n",
    "            target = \"Software\"\n",
    "        # se no existir esse schema, cai no primeiro schema SW disponvel\n",
    "        cat_key = target.lower()\n",
    "        return next((schema[\"category\"] for k, schema in SCHEMAS_SW.items() if k == cat_key),\n",
    "                    list(SCHEMAS_SW.values())[0][\"category\"])\n",
    "    else:\n",
    "        return \"Software\"  # bucket genrico\n",
    "\n",
    "# --- HELPERS: instanciar um template e preencher com Excel ---------------\n",
    "def instantiate_from_template(template: dict, sku: str, name: str, price: float, elig_pct: float, subcategory: str | None):\n",
    "    obj = deepcopy(template)\n",
    "    # garantias bsicas\n",
    "    obj[\"cisco_product_id\"] = sku\n",
    "    obj[\"commercial_name\"] = name\n",
    "    obj[\"lifecycle\"] = obj.get(\"lifecycle\", {\"status\": \"active\", \"eos_announced\": None, \"last_support_date\": None})\n",
    "    obj[\"pricing_model\"] = obj.get(\"pricing_model\", {})\n",
    "    obj[\"pricing_model\"].setdefault(\"type\", \"one_time\")\n",
    "    obj[\"pricing_model\"].setdefault(\"currency\", \"USD\")\n",
    "    obj[\"pricing_model\"][\"base_price\"] = float(price or 0.0)\n",
    "    if \"elig_pct\" in obj[\"pricing_model\"]:\n",
    "        obj[\"pricing_model\"][\"elig_pct\"] = float(elig_pct or 0.0)\n",
    "    if subcategory is not None:\n",
    "        obj[\"subcategory\"] = subcategory or None\n",
    "    return obj\n",
    "\n",
    "# --- ENRIQUECIMENTO VIA LLM: produto por produto --------------------------\n",
    "ENRICH_SYSTEM = \"\"\"You are a strict JSON filler. \n",
    "You will receive a product JSON and a JSON schema template.\n",
    "- Keep all given keys as-is; DO NOT add keys that are not in the template.\n",
    "- Populate missing/null fields ONLY if deducible from product name/SKU/category semantics.\n",
    "- If unsure, keep the default/null.\n",
    "- Do not invent SKUs, specs, interfaces, or certifications.\n",
    "- Return only valid JSON matching the template keys.\n",
    "\"\"\"\n",
    "\n",
    "def enrich_product_with_llm(product_obj: dict, template_obj: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Envia 1 produto + template para a LLM e pede para devolver o produto com\n",
    "    os campos do template preenchidos quando possvel. Zero voo solo.\n",
    "    \"\"\"\n",
    "    prompt = {\n",
    "        \"template\": template_obj,\n",
    "        \"product\": product_obj\n",
    "    }\n",
    "    try:\n",
    "        resp = client.chat.completions.create(\n",
    "            model=OPENAI_MODEL,\n",
    "            temperature=0.0,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": ENRICH_SYSTEM},\n",
    "                {\"role\": \"user\", \"content\": json.dumps(prompt, ensure_ascii=False)}\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        enriched = json.loads(resp.choices[0].message.content)\n",
    "        # Se a LLM retornou s o objeto final (sem wrapper), ok.\n",
    "        # Se ela retornou {\"product\": {...}}, trate:\n",
    "        if \"product\" in enriched and isinstance(enriched[\"product\"], dict):\n",
    "            return enriched[\"product\"]\n",
    "        return enriched if isinstance(enriched, dict) else product_obj\n",
    "    except Exception as e:\n",
    "        print(f\"[ENRICH WARN] Falha ao enriquecer {product_obj.get('cisco_product_id')}: {e}\")\n",
    "        return product_obj\n",
    "\n",
    "# --- PIPELINE --------------------------------------------------------------\n",
    "def process_excel_to_category_jsons(\n",
    "    xlsx_path: Path,\n",
    "    sample_per_category: int | None = SAMPLE_PER_CATEGORY,\n",
    "    do_enrichment: bool = DO_ENRICHMENT\n",
    "):\n",
    "    if not xlsx_path.exists():\n",
    "        raise FileNotFoundError(f\"Arquivo no encontrado: {xlsx_path}\")\n",
    "\n",
    "    df = pd.read_excel(xlsx_path, engine=\"openpyxl\")\n",
    "\n",
    "    sku_col   = find_col(df, [\"sku\"])\n",
    "    desc_col  = find_col(df, [\"desc\", \"name\"])\n",
    "    price_col = find_col(df, [\"price\"])\n",
    "    elig_col  = find_col(df, [\"elig\"])\n",
    "    cat_col   = find_col(df, [\"category\"])\n",
    "    sub_col   = find_col(df, [\"sub_category\", \"subcategory\"])\n",
    "\n",
    "    missing = [n for n, c in [(\"SKU\", sku_col), (\"Desc\", desc_col), (\"Price\", price_col)] if c is None]\n",
    "    if missing:\n",
    "        raise RuntimeError(f\"Colunas obrigatrias ausentes: {missing}\")\n",
    "\n",
    "    # normalizao\n",
    "    df[\"__base_price\"] = clean_price_series(df[price_col])\n",
    "    df[\"__elig_pct\"]   = clean_pct_series(df[elig_col]) if elig_col else 0.0\n",
    "    df[\"__category\"]   = df[cat_col] if cat_col else None\n",
    "    df[\"__subcat\"]     = df[sub_col] if sub_col else None\n",
    "\n",
    "    # buffers por categoria\n",
    "    buckets_hw: dict[str, list] = {}\n",
    "    buckets_sw: dict[str, list] = {}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        sku  = str(row[sku_col]).strip()\n",
    "        name = str(row[desc_col]).strip()\n",
    "        price = float(row[\"__base_price\"])\n",
    "        elig  = float(row[\"__elig_pct\"])\n",
    "        cat_cell = (row[\"__category\"] if row[\"__category\"] is not None else \"\")\n",
    "        subcat   = (str(row[\"__subcat\"]).strip() if row[\"__subcat\"] is not None else None)\n",
    "\n",
    "        if not sku or not name:\n",
    "            continue\n",
    "\n",
    "        ptype = guess_product_type(name, cat_cell)\n",
    "\n",
    "        if ptype == \"hardware\":\n",
    "            mapped = map_hw_category_from_row(name, cat_cell)  # ex.: \"Switches\"\n",
    "            if not mapped:\n",
    "                # Se no conseguirmos mapear, pule ou bucketize como \"Unknown\"\n",
    "                mapped = \"Switches\"  # fallback educado\n",
    "            template = SCHEMAS_HW.get(mapped.lower())\n",
    "            if not template:\n",
    "                print(f\"[WARN] Sem template p/ '{mapped}'  SKU {sku} pulado\")\n",
    "                continue\n",
    "\n",
    "            base = instantiate_from_template(template, sku, name, price, elig, subcat)\n",
    "            final = enrich_product_with_llm(base, template) if do_enrichment else base\n",
    "\n",
    "            buckets_hw.setdefault(mapped, []).append(final)\n",
    "\n",
    "        else:  # software\n",
    "            # Escolhe categoria de software (se existir). Caso no, bucket genrico \"Software\"\n",
    "            mapped_sw = map_sw_category_from_row(name, cat_cell)\n",
    "            template_sw = SCHEMAS_SW.get(mapped_sw.lower())\n",
    "            if not template_sw:\n",
    "                # se no houver schemas de software, cria um template mnimo genrico compatvel\n",
    "                template_sw = {\n",
    "                    \"cisco_product_id\": \"\",\n",
    "                    \"commercial_name\": \"\",\n",
    "                    \"product_type\": \"software\",\n",
    "                    \"category\": \"Software\",\n",
    "                    \"subcategory\": None,\n",
    "                    \"lifecycle\": {\"status\": \"active\",\"eos_announced\": None,\"last_support_date\": None},\n",
    "                    \"pricing_model\": {\"type\": \"one_time\",\"currency\": \"USD\",\"base_price\": 0.0,\"elig_pct\": 0.01}\n",
    "                }\n",
    "\n",
    "            base = instantiate_from_template(template_sw, sku, name, price, elig, subcat)\n",
    "            final = enrich_product_with_llm(base, template_sw) if do_enrichment else base\n",
    "            buckets_sw.setdefault(template_sw[\"category\"], []).append(final)\n",
    "\n",
    "    # aplica SAMPLE_PER_CATEGORY\n",
    "    if sample_per_category is not None:\n",
    "        for k in list(buckets_hw.keys()):\n",
    "            buckets_hw[k] = buckets_hw[k][:sample_per_category]\n",
    "        for k in list(buckets_sw.keys()):\n",
    "            buckets_sw[k] = buckets_sw[k][:sample_per_category]\n",
    "\n",
    "    # garante diretrios\n",
    "    OUT_HW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    OUT_SW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # salva um arquivo por categoria\n",
    "    for cat, items in buckets_hw.items():\n",
    "        out_path = OUT_HW_DIR / f\"{cat.lower().replace(' ','_')}.json\"\n",
    "        out_path.write_text(json.dumps(items, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    for cat, items in buckets_sw.items():\n",
    "        out_path = OUT_SW_DIR / f\"{cat.lower().replace(' ','_')}.json\"\n",
    "        out_path.write_text(json.dumps(items, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    print(\" Finalizado.\")\n",
    "    print(\"Hardware:\", {k: len(v) for k, v in buckets_hw.items()})\n",
    "    print(\"Software:\", {k: len(v) for k, v in buckets_sw.items()})\n",
    "\n",
    "# --- EXECUO --------------------------------------------------------------\n",
    "process_excel_to_category_jsons(\n",
    "    XLSX_PATH,\n",
    "    sample_per_category=SAMPLE_PER_CATEGORY,\n",
    "    do_enrichment=DO_ENRICHMENT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c0b96411-0236-45d9-96d2-a68bb703169c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536d5bda-06ef-4b87-bd65-12421cbd365a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e689b69-ef9a-487d-9c8b-615326461af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01152f7a-0840-45e0-88dd-bf67bae182fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8066649c-c124-4206-855e-533f8467241c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "45d467a6-16d3-4e60-a30c-e2a83ce3ada4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in Excel: 4267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying rows: 100%|| 4267/4267 [00:00<00:00, 5309.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[HW] Wireless: 509 itens  out\\hardware\\hw_wireless.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich HW/Wireless:   0%|          | 2/509 [00:00<00:16, 31.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Limit reached (3) for HW/Wireless\n",
      "\n",
      "[HW] Switches: 1669 itens  out\\hardware\\hw_switches.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich HW/Switches:   0%|          | 2/1669 [00:00<00:47, 34.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Limit reached (3) for HW/Switches\n",
      "\n",
      "[HW] Routers: 614 itens  out\\hardware\\hw_routers.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich HW/Routers:   0%|          | 0/614 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Limit reached (3) for HW/Routers"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich HW/Routers:   0%|          | 2/614 [00:00<00:16, 38.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[HW] Firewall: 180 itens  out\\hardware\\hw_firewall.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich HW/Firewall:   1%|          | 2/180 [00:00<00:05, 34.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Limit reached (3) for HW/Firewall\n",
      "\n",
      "[HW] Connectors: 21 itens  out\\hardware\\hw_connectors.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Enrich HW/Connectors:  10%|         | 2/21 [00:00<00:01, 12.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Limit reached (3) for HW/Connectors\n",
      "\n",
      "[HW] Cabling: 3 itens  out\\hardware\\hw_cabling.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich HW/Cabling:  67%|   | 2/3 [00:00<00:00, 29.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Limit reached (3) for HW/Cabling\n",
      "\n",
      "[HW] Antennas: 8 itens  out\\hardware\\hw_antennas.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich HW/Antennas:  25%|       | 2/8 [00:00<00:00, 33.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Limit reached (3) for HW/Antennas\n",
      "\n",
      "[SW] Wireless: 545 itens  out\\software\\sw_wireless.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich SW/Wireless:   0%|          | 2/545 [00:00<00:15, 34.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Limit reached (3) for SW/Wireless\n",
      "\n",
      "[SW] Switches: 409 itens  out\\software\\sw_switches.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich SW/Switches:   0%|          | 2/409 [00:00<00:13, 29.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Limit reached (3) for SW/Switches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SW] Licenses: 9 itens  out\\software\\sw_licenses.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich SW/Licenses:  22%|       | 2/9 [00:00<00:00, 34.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Limit reached (3) for SW/Licenses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SW] Routers: 250 itens  out\\software\\sw_routers.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich SW/Routers:   1%|          | 2/250 [00:00<00:15, 16.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Limit reached (3) for SW/Routers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SW] Firewall: 50 itens  out\\software\\sw_firewall.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich SW/Firewall:   4%|         | 2/50 [00:00<00:03, 12.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Limit reached (3) for SW/Firewall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Summary ===\n",
      "{'hardware': 21, 'software': 15, 'files': 12}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hardware': 21, 'software': 15, 'files': 12}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Setup / Imports ==========================================================\n",
    "import os, json, time, copy, re\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# ---------- Switches de execuo ----------\n",
    "ENRICH_WITH_LLM = True          # True para preencher campos faltantes via LLM\n",
    "MAX_ITEMS_PER_CATEGORY = 3       # None = sem limite (use 3 para testar)\n",
    "LIMIT_CATEGORIES = None          # ex.: [\"Wireless\",\"Switches\"] para filtrar\n",
    "\n",
    "# ---------- Caminhos ----------\n",
    "XLSX_PATH       = Path(\"data/raw/Cisco_Pricing.xlsx\")\n",
    "SCHEMAS_HW_DIR  = Path(\"schemas/hardware\")   # ex.: schema_switches.json, schema_wireless.json ...\n",
    "SCHEMAS_SW_DIR  = Path(\"schemas/software\")   # opcional; se vazio, usa template genrico\n",
    "OUTPUT_DIR_HW   = Path(\"out/hardware\")\n",
    "OUTPUT_DIR_SW   = Path(\"out/software\")\n",
    "CACHE_PATH      = Path(\"out/enrichment_cache.json\")\n",
    "\n",
    "OUTPUT_DIR_HW.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_DIR_SW.mkdir(parents=True, exist_ok=True)\n",
    "CACHE_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === Cache util ===============================================================\n",
    "def _load_cache(path: Path) -> dict:\n",
    "    if path.exists():\n",
    "        try:\n",
    "            return json.loads(path.read_text(encoding=\"utf-8\"))\n",
    "        except Exception:\n",
    "            return {}\n",
    "    return {}\n",
    "\n",
    "def _save_cache(path: Path, data: dict):\n",
    "    tmp = path.with_suffix(\".tmp.json\")\n",
    "    tmp.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    tmp.replace(path)\n",
    "\n",
    "CACHE = _load_cache(CACHE_PATH)\n",
    "\n",
    "# === Carregamento dos schemas =================================================\n",
    "def load_schema_templates(dir_path: Path, expect_hw=True):\n",
    "    templates = {}\n",
    "    if dir_path.exists():\n",
    "        for fp in sorted(dir_path.glob(\"*.json\")):\n",
    "            try:\n",
    "                obj = json.loads(fp.read_text(encoding=\"utf-8\"))\n",
    "                cat = obj.get(\"category\")\n",
    "                if not cat:\n",
    "                    base = fp.stem.replace(\"schema_\", \"\")\n",
    "                    cat = base.replace(\"_\", \" \").title()\n",
    "                templates[cat] = obj\n",
    "            except Exception as e:\n",
    "                print(f\" Erro lendo {fp}: {e}\")\n",
    "    else:\n",
    "        if expect_hw:\n",
    "            print(f\" Diretrio de schemas no existe: {dir_path}\")\n",
    "    return templates\n",
    "\n",
    "SCHEMAS_HW = load_schema_templates(SCHEMAS_HW_DIR, expect_hw=True)\n",
    "SCHEMAS_SW = load_schema_templates(SCHEMAS_SW_DIR, expect_hw=False)\n",
    "\n",
    "if not SCHEMAS_HW:\n",
    "    raise RuntimeError(\n",
    "        f\"Nenhum schema de hardware encontrado em {SCHEMAS_HW_DIR}. \"\n",
    "        \"Coloque seus arquivos schema_*.json l (ex.: schema_switches.json).\"\n",
    "    )\n",
    "\n",
    "# === Template genrico p/ software ===========================================\n",
    "GENERIC_SW_SCHEMA = {\n",
    "    \"cisco_product_id\": \"\",\n",
    "    \"commercial_name\": \"\",\n",
    "    \"product_type\": \"software\",\n",
    "    \"category\": \"\",\n",
    "    \"subcategory\": \"\",\n",
    "    \"lifecycle\": {\"status\": \"active\", \"eos_announced\": None, \"last_support_date\": None},\n",
    "    \"license_model\": {\"type\": \"subscription\", \"term\": None, \"seats_or_nodes\": None, \"includes_support\": True},\n",
    "    \"entitlements\": {\"features\": [], \"tier\": None, \"usage_limits\": {}},\n",
    "    \"pricing_model\": {\"currency\": \"USD\", \"base_price\": 0.0, \"billing_cycle\": \"one_time\", \"pricing_tiers\": []},\n",
    "    \"dependencies\": {\"requires\": [], \"compatibility\": []},\n",
    "    \"regulatory\": {\"compliance\": []},\n",
    "    \"metadata\": {\"vendor_sku_aliases\": [], \"notes\": \"\"}\n",
    "}\n",
    "\n",
    "# === Normalizao das categorias =============================================\n",
    "HW_CATEGORY_MAP = {\n",
    "    \"switch\": \"Switches\", \"switches\": \"Switches\",\n",
    "    \"router\": \"Routers\", \"routers\": \"Routers\",\n",
    "    \"firewall\": \"Firewall\",\n",
    "    \"wireless\": \"Wireless\", \"access point\": \"Wireless\", \"ap\": \"Wireless\",\n",
    "    \"antenna\": \"Antennas\", \"antennas\": \"Antennas\",\n",
    "    \"cabling\": \"Cabling\",\n",
    "    \"connector\": \"Connectors\", \"connectors\": \"Connectors\",\n",
    "}\n",
    "SW_CATEGORY_MAP = {\n",
    "    # se vier \"Wireless\" para software, manteremos \"Wireless\" (ver fallback)\n",
    "    \"license\": \"Licenses\", \"licensing\": \"Licenses\",\n",
    "    \"subscription\": \"Subscriptions\",\n",
    "    \"support\": \"Support\",\n",
    "    \"cloud\": \"Cloud Services\", \"service\": \"Cloud Services\",\n",
    "}\n",
    "\n",
    "def normalize_hw_category(raw: str) -> str | None:\n",
    "    if not raw: return None\n",
    "    s = str(raw).strip().lower()\n",
    "    for key, cat in HW_CATEGORY_MAP.items():\n",
    "        if key in s:\n",
    "            return cat\n",
    "    # igual ao nome\n",
    "    if s in {v.lower() for v in HW_CATEGORY_MAP.values()}:\n",
    "        return s.title()\n",
    "    return None\n",
    "\n",
    "def normalize_sw_category(raw: str) -> str | None:\n",
    "    if not raw: return None\n",
    "    s = str(raw).strip().lower()\n",
    "    for key, cat in SW_CATEGORY_MAP.items():\n",
    "        if key in s:\n",
    "            return cat\n",
    "    # permitir categorias como \"Wireless\" tambm para software\n",
    "    if s in {v.lower() for v in HW_CATEGORY_MAP.values()}:\n",
    "        return s.title()\n",
    "    return None\n",
    "\n",
    "# === Deteco de colunas no Excel ============================================\n",
    "def detect_columns(df: pd.DataFrame) -> dict:\n",
    "    cols = {c: re.sub(r\"\\s+\", \"\", str(c).strip().lower()) for c in df.columns}\n",
    "    out = {\"sku\": None, \"desc\": None, \"price\": None, \"category\": None, \"category_type\": None, \"subcategory\": None}\n",
    "\n",
    "    for col, norm in cols.items():\n",
    "        if out[\"sku\"] is None and (norm == \"sku\" or \"partnumber\" in norm or norm == \"part\" or \"sku\" in norm):\n",
    "            out[\"sku\"] = col\n",
    "        elif out[\"desc\"] is None and (norm in {\"desc\",\"description\",\"name\"} or \"desc\" in norm or \"description\" in norm):\n",
    "            out[\"desc\"] = col\n",
    "        elif out[\"price\"] is None and (norm in {\"price\",\"pri\",\"list\"} or \"price\" in norm or norm == \"pri\"):\n",
    "            out[\"price\"] = col\n",
    "        elif out[\"category_type\"] is None and re.fullmatch(r\"category[-_]?type\", norm):\n",
    "            out[\"category_type\"] = col\n",
    "        elif out[\"category\"] is None and (norm == \"category\" or ((\"category\" in norm) and (\"type\" not in norm))):\n",
    "            out[\"category\"] = col\n",
    "        elif out[\"subcategory\"] is None and (\"subcategory\" in norm or \"sub-category\" in norm or norm == \"sub_category\"):\n",
    "            out[\"subcategory\"] = col\n",
    "\n",
    "    # sanity fallback\n",
    "    if out[\"category\"] is None and out[\"category_type\"] is not None:\n",
    "        # pelo menos garantimos que no confundiremos\n",
    "        pass\n",
    "\n",
    "    missing = [k for k, v in out.items() if v is None and k in (\"sku\",\"desc\",\"price\")]\n",
    "    if missing:\n",
    "        raise RuntimeError(f\"Excel sem colunas obrigatrias: {missing}. Detectado: {out}\")\n",
    "    return out\n",
    "\n",
    "def read_excel_rows(xlsx_path: Path) -> pd.DataFrame:\n",
    "    if not xlsx_path.exists():\n",
    "        raise FileNotFoundError(f\"Excel no encontrado: {xlsx_path}\")\n",
    "    df = pd.read_excel(xlsx_path, engine=\"openpyxl\")\n",
    "    cols = detect_columns(df)\n",
    "\n",
    "    # Limpa preo (vrgula decimal, separadores, etc.)\n",
    "    price_series = (\n",
    "        df[cols[\"price\"]]\n",
    "        .astype(str)\n",
    "        .str.replace(r\"[^\\d\\.,-]\", \"\", regex=True)\n",
    "        .str.replace(r\"\\.(?=\\d{3},)\", \"\", regex=True)  # remove separador de milhar antes de vrgula decimal\n",
    "        .str.replace(\",\", \".\", regex=False)\n",
    "    )\n",
    "    df[\"_price\"] = pd.to_numeric(price_series, errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "    df[\"_sku\"]   = df[cols[\"sku\"]].astype(str).str.strip()\n",
    "    df[\"_name\"]  = df[cols[\"desc\"]].astype(str).str.strip()\n",
    "    df[\"_cat\"]   = df[cols[\"category\"]].astype(str).str.strip() if cols[\"category\"] else \"\"\n",
    "    df[\"_cat_type\"] = df[cols[\"category_type\"]].astype(str).str.strip() if cols[\"category_type\"] else \"\"\n",
    "    df[\"_sub\"]   = df[cols[\"subcategory\"]].astype(str).str.strip() if cols[\"subcategory\"] else \"\"\n",
    "    return df\n",
    "\n",
    "# === LLM (enriquecimento opcional) ===========================================\n",
    "def _extract_json(text: str) -> dict:\n",
    "    \"\"\"Aceita resposta com/sem fences e retorna um dict JSON.\"\"\"\n",
    "    t = text.strip()\n",
    "    # remove codefence se vier\n",
    "    if t.startswith(\"```\"):\n",
    "        t = re.sub(r\"^```[a-zA-Z0-9]*\\s*\", \"\", t)\n",
    "        t = re.sub(r\"\\s*```$\", \"\", t)\n",
    "    s = t.find(\"{\"); e = t.rfind(\"}\")\n",
    "    if s != -1 and e != -1 and e > s:\n",
    "        t = t[s:e+1]\n",
    "    return json.loads(t)\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.9)\n",
    "\n",
    "ENRICH_PROMPT = ChatPromptTemplate.from_template(\n",
    "    \"you ara a Cisco expert\\n\"\n",
    "    \"You are a data normalizer. You receive a PARTIAL product JSON from Cisco catalog and a TARGET SCHEMA.\\n\"\n",
    "    \"Fill ONLY the missing fields, do not change existing values, do not invent extra keys.\\n\"\n",
    "    \"Keep structure and key names exactly as the schema. Use realistic, conservative values.\\n\"\n",
    "    \"If you don't know, keep null/empty.\\n\\n\"\n",
    "    \"<<<PARTIAL_JSON>>>\\n{partial}\\n<<<END_PARTIAL_JSON>>>\\n\\n\"\n",
    "    \"<<<TARGET_SCHEMA>>>\\n{schema}\\n<<<END_TARGET_SCHEMA>>>\\n\\n\"\n",
    "    \"Return ONLY a valid JSON object matching the target schema.\"\n",
    ")\n",
    "\n",
    "def enrich_with_llm(partial: dict, schema_obj: dict, cache_key: str) -> dict:\n",
    "    if not ENRICH_WITH_LLM:\n",
    "        return partial\n",
    "    if cache_key in CACHE:\n",
    "        return CACHE[cache_key]\n",
    "    chain = ENRICH_PROMPT | llm\n",
    "    tries = 0\n",
    "    while True:\n",
    "        tries += 1\n",
    "        try:\n",
    "            resp = chain.invoke({\n",
    "                \"partial\": json.dumps(partial, ensure_ascii=False, indent=2),\n",
    "                \"schema\":  json.dumps(schema_obj, ensure_ascii=False, indent=2),\n",
    "            })\n",
    "            enriched = _extract_json(resp.content)\n",
    "\n",
    "            out = copy.deepcopy(schema_obj)\n",
    "\n",
    "            def deep_merge(dst, src):\n",
    "                for k, v in src.items():\n",
    "                    if isinstance(v, dict) and isinstance(dst.get(k), dict):\n",
    "                        deep_merge(dst[k], v)\n",
    "                    else:\n",
    "                        dst[k] = v\n",
    "\n",
    "            deep_merge(out, partial)\n",
    "            deep_merge(out, enriched)\n",
    "\n",
    "            CACHE[cache_key] = out\n",
    "            if tries % 5 == 1:\n",
    "                _save_cache(CACHE_PATH, CACHE)\n",
    "            return out\n",
    "        except Exception as e:\n",
    "            if tries >= 3:\n",
    "                print(f\" LLM falhou para {cache_key}: {e}  usando partial.\")\n",
    "                return partial\n",
    "            time.sleep(1.2)\n",
    "\n",
    "# === Persistncia incremental por categoria ===================================\n",
    "def append_item_to_json(filepath: Path, item: dict):\n",
    "    if filepath.exists():\n",
    "        try:\n",
    "            arr = json.loads(filepath.read_text(encoding=\"utf-8\"))\n",
    "            if not isinstance(arr, list):\n",
    "                arr = []\n",
    "        except Exception:\n",
    "            arr = []\n",
    "    else:\n",
    "        arr = []\n",
    "    arr.append(item)\n",
    "    filepath.write_text(json.dumps(arr, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "# === Pipeline principal =======================================================\n",
    "def build_catalog_from_excel(\n",
    "    xlsx_path: Path = XLSX_PATH,\n",
    "    max_items_per_category: int | None = MAX_ITEMS_PER_CATEGORY,\n",
    "    limit_categories: list[str] | None = LIMIT_CATEGORIES,\n",
    "    verbose: bool = True\n",
    "):\n",
    "    df = read_excel_rows(xlsx_path)\n",
    "    if verbose:\n",
    "        print(f\"Rows in Excel: {len(df)}\")\n",
    "\n",
    "    buckets_hw = defaultdict(list)\n",
    "    buckets_sw = defaultdict(list)\n",
    "\n",
    "    records = df.to_dict(orient=\"records\")\n",
    "    for rec in tqdm(records, desc=\"Classifying rows\", disable=not verbose):\n",
    "        sku   = rec.get(\"_sku\", \"\").strip()\n",
    "        name  = rec.get(\"_name\", \"\").strip()\n",
    "        price = float(rec.get(\"_price\", 0.0) or 0.0)\n",
    "        raw_cat = rec.get(\"_cat\", \"\")\n",
    "        raw_type= rec.get(\"_cat_type\", \"\")\n",
    "        subcat  = rec.get(\"_sub\", \"\")\n",
    "\n",
    "        # 1) Decide Hardware/Software pelo Category-Type, se existir\n",
    "        pt = None\n",
    "        rt = raw_type.strip().lower()\n",
    "        if rt.startswith(\"hard\"):\n",
    "            pt = \"hardware\"\n",
    "        elif rt.startswith(\"soft\"):\n",
    "            pt = \"software\"\n",
    "\n",
    "        # 2) Normaliza categoria\n",
    "        hw_cat = normalize_hw_category(raw_cat)    # ex.: \"Wireless\"\n",
    "        sw_cat = normalize_sw_category(raw_cat)    # ex.: \"Wireless\" ou \"Licenses\"\n",
    "\n",
    "        # 3) Se no deu pra decidir tipo pelo Category-Type, decide por categoria\n",
    "        if not pt:\n",
    "            pt = \"hardware\" if hw_cat else (\"software\" if sw_cat else \"hardware\")\n",
    "\n",
    "        # 4) Categoria final\n",
    "        category = hw_cat if pt == \"hardware\" else (sw_cat or (raw_cat.strip().title() if raw_cat else \"Licenses\"))\n",
    "\n",
    "        # 5) (Opcional) fallback por texto do produto\n",
    "        if pt == \"hardware\" and not hw_cat:\n",
    "            txt = f\"{name} {sku}\".lower()\n",
    "            if \"switch\" in txt:             category = \"Switches\"\n",
    "            elif \"router\" in txt:           category = \"Routers\"\n",
    "            elif \"firewall\" in txt:         category = \"Firewall\"\n",
    "            elif \"access point\" in txt or \"ap \" in txt or txt.startswith(\"ap-\"): category = \"Wireless\"\n",
    "            elif \"antenna\" in txt:          category = \"Antennas\"\n",
    "            elif \"cable\" in txt:            category = \"Cabling\"\n",
    "            elif \"connector\" in txt:        category = \"Connectors\"\n",
    "\n",
    "        if limit_categories and category not in limit_categories:\n",
    "            continue\n",
    "\n",
    "        if pt == \"hardware\":\n",
    "            schema = SCHEMAS_HW.get(category)\n",
    "            if not schema:\n",
    "                if verbose:\n",
    "                    print(f\"  Sem schema p/ HW category='{category}', SKU={sku}  pulando\")\n",
    "                continue\n",
    "            base = copy.deepcopy(schema)\n",
    "            base[\"cisco_product_id\"] = sku\n",
    "            base[\"commercial_name\"] = name\n",
    "            base[\"product_type\"] = \"hardware\"\n",
    "            base.setdefault(\"pricing_model\", {})\n",
    "            base[\"pricing_model\"][\"currency\"] = base[\"pricing_model\"].get(\"currency\", \"USD\")\n",
    "            base[\"pricing_model\"][\"base_price\"] = price\n",
    "            base[\"technical_profile\"] = base.get(\"technical_profile\", {})\n",
    "            base[\"technical_profile\"][\"category\"] = category\n",
    "            base[\"technical_profile\"][\"subcategory\"] = subcat or \"\"\n",
    "            buckets_hw[category].append(base)\n",
    "\n",
    "        else:\n",
    "            schema = SCHEMAS_SW.get(category, GENERIC_SW_SCHEMA)\n",
    "            base = copy.deepcopy(schema)\n",
    "            base[\"cisco_product_id\"] = sku\n",
    "            base[\"commercial_name\"] = name\n",
    "            base[\"product_type\"] = \"software\"\n",
    "            base[\"category\"] = category\n",
    "            base[\"pricing_model\"] = base.get(\"pricing_model\", {})\n",
    "            base[\"pricing_model\"][\"currency\"] = base[\"pricing_model\"].get(\"currency\", \"USD\")\n",
    "            base[\"pricing_model\"][\"base_price\"] = price\n",
    "            if \"subcategory\" not in base:\n",
    "                base[\"subcategory\"] = subcat or \"\"\n",
    "            buckets_sw[category].append(base)\n",
    "\n",
    "    counts = {\"hardware\": 0, \"software\": 0, \"files\": 0}\n",
    "\n",
    "    # HARDWARE  1 arquivo por categoria\n",
    "    for category, items in buckets_hw.items():\n",
    "        out_file = OUTPUT_DIR_HW / f\"hw_{category.replace(' ', '_').lower()}.json\"\n",
    "        if verbose: print(f\"\\n[HW] {category}: {len(items)} itens  {out_file}\")\n",
    "        n = 0\n",
    "        for base in tqdm(items, desc=f\"Enrich HW/{category}\", disable=not verbose):\n",
    "            sku = base.get(\"cisco_product_id\", \"\")\n",
    "            schema = SCHEMAS_HW[category]\n",
    "            enriched = enrich_with_llm(base, schema, cache_key=f\"HW::{category}::{sku}\")\n",
    "            append_item_to_json(out_file, enriched)\n",
    "            counts[\"hardware\"] += 1\n",
    "            n += 1\n",
    "            if max_items_per_category and n >= max_items_per_category:\n",
    "                if verbose: print(f\"    Limit reached ({max_items_per_category}) for HW/{category}\")\n",
    "                break\n",
    "        counts[\"files\"] += 1\n",
    "\n",
    "    # SOFTWARE  1 arquivo por categoria\n",
    "    for category, items in buckets_sw.items():\n",
    "        out_file = OUTPUT_DIR_SW / f\"sw_{category.replace(' ', '_').lower()}.json\"\n",
    "        if verbose: print(f\"\\n[SW] {category}: {len(items)} itens  {out_file}\")\n",
    "        n = 0\n",
    "        for base in tqdm(items, desc=f\"Enrich SW/{category}\", disable=not verbose):\n",
    "            sku = base.get(\"cisco_product_id\", \"\")\n",
    "            schema = SCHEMAS_SW.get(category, GENERIC_SW_SCHEMA)\n",
    "            enriched = enrich_with_llm(base, schema, cache_key=f\"SW::{category}::{sku}\")\n",
    "            append_item_to_json(out_file, enriched)\n",
    "            counts[\"software\"] += 1\n",
    "            n += 1\n",
    "            if max_items_per_category and n >= max_items_per_category:\n",
    "                if verbose: print(f\"    Limit reached ({max_items_per_category}) for SW/{category}\")\n",
    "                break\n",
    "        counts[\"files\"] += 1\n",
    "\n",
    "    _save_cache(CACHE_PATH, CACHE)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n=== Summary ===\")\n",
    "        print(counts)\n",
    "    return counts\n",
    "\n",
    "# === EXECUO (teste rpido) ==================================================\n",
    "summary = build_catalog_from_excel(\n",
    "    xlsx_path=XLSX_PATH,\n",
    "    max_items_per_category=MAX_ITEMS_PER_CATEGORY,\n",
    "    limit_categories=LIMIT_CATEGORIES,   # ex.: [\"Wireless\",\"Switches\"]\n",
    "    verbose=True\n",
    ")\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77c607f-a7d8-4748-b18c-75de72d75a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4062d590-b8dd-422c-a38a-b6aa8ae2fee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbd32e5-7572-4c66-9140-7b7ce7a50926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3807f758-2538-4ff3-940d-9f532372cf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in Excel: 4267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying rows: 100%|| 4267/4267 [00:00<00:00, 14645.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[HW] Wireless: 509 itens  out\\hardware\\hw_wireless.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich HW/Wireless:   1%|          | 3/509 [00:10<28:53,  3.43s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 440\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m counts\n\u001b[0;32m    439\u001b[0m \u001b[38;5;66;03m# === EXECUO (teste rpido) ==================================================\u001b[39;00m\n\u001b[1;32m--> 440\u001b[0m summary \u001b[38;5;241m=\u001b[39m build_catalog_from_excel(\n\u001b[0;32m    441\u001b[0m     xlsx_path\u001b[38;5;241m=\u001b[39mXLSX_PATH,\n\u001b[0;32m    442\u001b[0m     max_items_per_category\u001b[38;5;241m=\u001b[39mMAX_ITEMS_PER_CATEGORY,\n\u001b[0;32m    443\u001b[0m     limit_categories\u001b[38;5;241m=\u001b[39mLIMIT_CATEGORIES,   \u001b[38;5;66;03m# ex.: [\"Wireless\",\"Switches\"]\u001b[39;00m\n\u001b[0;32m    444\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    445\u001b[0m )\n\u001b[0;32m    446\u001b[0m summary\n",
      "Cell \u001b[1;32mIn[66], line 406\u001b[0m, in \u001b[0;36mbuild_catalog_from_excel\u001b[1;34m(xlsx_path, max_items_per_category, limit_categories, verbose)\u001b[0m\n\u001b[0;32m    404\u001b[0m sku \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcisco_product_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    405\u001b[0m schema \u001b[38;5;241m=\u001b[39m SCHEMAS_HW[category]\n\u001b[1;32m--> 406\u001b[0m enriched \u001b[38;5;241m=\u001b[39m enrich_with_llm(base, schema, cache_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHW::\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m::\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msku\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    407\u001b[0m append_item_to_json(out_file, enriched)\n\u001b[0;32m    408\u001b[0m counts[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhardware\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[66], line 252\u001b[0m, in \u001b[0;36menrich_with_llm\u001b[1;34m(partial, schema_obj, cache_key)\u001b[0m\n\u001b[0;32m    250\u001b[0m tries \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 252\u001b[0m     resp \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39minvoke({\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartial\u001b[39m\u001b[38;5;124m\"\u001b[39m: json\u001b[38;5;241m.\u001b[39mdumps(partial, ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mschema\u001b[39m\u001b[38;5;124m\"\u001b[39m:  json\u001b[38;5;241m.\u001b[39mdumps(schema_obj, ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[0;32m    255\u001b[0m     })\n\u001b[0;32m    256\u001b[0m     enriched_json \u001b[38;5;241m=\u001b[39m _extract_json(resp\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;66;03m# Merge: schema baseline -> partial -> enriched\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3047\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3045\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3046\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3047\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config)\n\u001b[0;32m   3048\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3049\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:378\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    374\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    375\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    377\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 378\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    379\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    380\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    381\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    382\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    383\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    384\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    385\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    386\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    387\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    388\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:963\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    956\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    960\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    961\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    962\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:782\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    781\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 782\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    783\u001b[0m                 m,\n\u001b[0;32m    784\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    785\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    786\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    787\u001b[0m             )\n\u001b[0;32m    788\u001b[0m         )\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1028\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1026\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1028\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m   1029\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1030\u001b[0m     )\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1032\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1131\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1131\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpayload)\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1087\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   1045\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1084\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1085\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m   1086\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m-> 1087\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m   1088\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1089\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m   1090\u001b[0m             {\n\u001b[0;32m   1091\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m   1092\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m   1093\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n\u001b[0;32m   1094\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m   1095\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m   1096\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m   1097\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m   1098\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m   1099\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[0;32m   1100\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m   1101\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m   1102\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n\u001b[0;32m   1103\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m   1104\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[0;32m   1105\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: prediction,\n\u001b[0;32m   1106\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m   1107\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_effort\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_effort,\n\u001b[0;32m   1108\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m   1109\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m   1110\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[0;32m   1111\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m   1112\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[0;32m   1113\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m   1114\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[0;32m   1115\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m   1116\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m   1117\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m   1118\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[0;32m   1119\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m   1120\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m   1121\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb_search_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: web_search_options,\n\u001b[0;32m   1122\u001b[0m             },\n\u001b[0;32m   1123\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsStreaming\n\u001b[0;32m   1124\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[0;32m   1125\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsNonStreaming,\n\u001b[0;32m   1126\u001b[0m         ),\n\u001b[0;32m   1127\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m   1128\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m   1129\u001b[0m         ),\n\u001b[0;32m   1130\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m   1131\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1132\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[0;32m   1133\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1256\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1243\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1244\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1251\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1252\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1253\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1254\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1255\u001b[0m     )\n\u001b[1;32m-> 1256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:979\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m    977\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 979\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    980\u001b[0m         request,\n\u001b[0;32m    981\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[0;32m    982\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    983\u001b[0m     )\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    985\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[0;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[0;32m    927\u001b[0m     request,\n\u001b[0;32m    928\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[0;32m    929\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    930\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m    931\u001b[0m )\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[0;32m    955\u001b[0m         request,\n\u001b[0;32m    956\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    957\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[0;32m    958\u001b[0m     )\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    989\u001b[0m     hook(request)\n\u001b[1;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1024\u001b[0m     )\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpx\\_transports\\default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    234\u001b[0m )\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    245\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mhandle_request(\n\u001b[0;32m    237\u001b[0m         pool_request\u001b[38;5;241m.\u001b[39mrequest\n\u001b[0;32m    238\u001b[0m     )\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[0;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    100\u001b[0m     (\n\u001b[0;32m    101\u001b[0m         http_version,\n\u001b[0;32m    102\u001b[0m         status,\n\u001b[0;32m    103\u001b[0m         reason_phrase,\n\u001b[0;32m    104\u001b[0m         headers,\n\u001b[0;32m    105\u001b[0m         trailing_data,\n\u001b[1;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    108\u001b[0m         http_version,\n\u001b[0;32m    109\u001b[0m         status,\n\u001b[0;32m    110\u001b[0m         reason_phrase,\n\u001b[0;32m    111\u001b[0m         headers,\n\u001b[0;32m    112\u001b[0m     )\n\u001b[0;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_event(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    219\u001b[0m     )\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_backends\\sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv(max_bytes)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ssl.py:1232\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1228\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1229\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1230\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1231\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(buflen)\n\u001b[0;32m   1233\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ssl.py:1105\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# === Setup / Imports ==========================================================\n",
    "import os, json, time, copy, re\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# ---------- Switches de execuo ----------\n",
    "ENRICH_WITH_LLM = True          # True para preencher campos faltantes via LLM\n",
    "MAX_ITEMS_PER_CATEGORY = None       # None = sem limite (use 3 para testar)\n",
    "LIMIT_CATEGORIES = None          # ex.: [\"Wireless\",\"Switches\"] para filtrar\n",
    "\n",
    "# ---------- Caminhos ----------\n",
    "XLSX_PATH       = Path(\"data/raw/Cisco_Pricing.xlsx\")\n",
    "SCHEMAS_HW_DIR  = Path(\"schemas/hardware\")   # ex.: schema_switches.json, schema_wireless.json ...\n",
    "SCHEMAS_SW_DIR  = Path(\"schemas/software\")   # opcional; se vazio, usa template genrico\n",
    "OUTPUT_DIR_HW   = Path(\"out/hardware\")\n",
    "OUTPUT_DIR_SW   = Path(\"out/software\")\n",
    "CACHE_PATH      = Path(\"out/enrichment_cache.json\")\n",
    "\n",
    "OUTPUT_DIR_HW.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_DIR_SW.mkdir(parents=True, exist_ok=True)\n",
    "CACHE_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === Cache util ===============================================================\n",
    "def _load_cache(path: Path) -> dict:\n",
    "    if path.exists():\n",
    "        try:\n",
    "            return json.loads(path.read_text(encoding=\"utf-8\"))\n",
    "        except Exception:\n",
    "            return {}\n",
    "    return {}\n",
    "\n",
    "def _save_cache(path: Path, data: dict):\n",
    "    tmp = path.with_suffix(\".tmp.json\")\n",
    "    tmp.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    tmp.replace(path)\n",
    "\n",
    "CACHE = _load_cache(CACHE_PATH)\n",
    "\n",
    "# === Carregamento dos schemas =================================================\n",
    "def load_schema_templates(dir_path: Path, expect_hw=True):\n",
    "    templates = {}\n",
    "    if dir_path.exists():\n",
    "        for fp in sorted(dir_path.glob(\"*.json\")):\n",
    "            try:\n",
    "                obj = json.loads(fp.read_text(encoding=\"utf-8\"))\n",
    "                cat = obj.get(\"category\")\n",
    "                if not cat:\n",
    "                    base = fp.stem.replace(\"schema_\", \"\")\n",
    "                    cat = base.replace(\"_\", \" \").title()\n",
    "                templates[cat] = obj\n",
    "            except Exception as e:\n",
    "                print(f\" Erro lendo {fp}: {e}\")\n",
    "    else:\n",
    "        if expect_hw:\n",
    "            print(f\" Diretrio de schemas no existe: {dir_path}\")\n",
    "    return templates\n",
    "\n",
    "SCHEMAS_HW = load_schema_templates(SCHEMAS_HW_DIR, expect_hw=True)\n",
    "SCHEMAS_SW = load_schema_templates(SCHEMAS_SW_DIR, expect_hw=False)\n",
    "\n",
    "if not SCHEMAS_HW:\n",
    "    raise RuntimeError(\n",
    "        f\"Nenhum schema de hardware encontrado em {SCHEMAS_HW_DIR}. \"\n",
    "        \"Coloque seus arquivos schema_*.json l (ex.: schema_switches.json).\"\n",
    "    )\n",
    "\n",
    "# === Template genrico p/ software ===========================================\n",
    "GENERIC_SW_SCHEMA = {\n",
    "    \"cisco_product_id\": \"\",\n",
    "    \"commercial_name\": \"\",\n",
    "    \"product_type\": \"software\",\n",
    "    \"category\": \"\",\n",
    "    \"subcategory\": \"\",\n",
    "    \"lifecycle\": {\"status\": \"active\", \"eos_announced\": None, \"last_support_date\": None},\n",
    "    \"license_model\": {\"type\": \"subscription\", \"term\": None, \"seats_or_nodes\": None, \"includes_support\": True},\n",
    "    \"entitlements\": {\"features\": [], \"tier\": None, \"usage_limits\": {}},\n",
    "    \"pricing_model\": {\"currency\": \"USD\", \"base_price\": 0.0, \"billing_cycle\": \"one_time\", \"pricing_tiers\": []},\n",
    "    \"dependencies\": {\"requires\": [], \"compatibility\": []},\n",
    "    \"regulatory\": {\"compliance\": []},\n",
    "    \"metadata\": {\"vendor_sku_aliases\": [], \"notes\": \"\"}\n",
    "}\n",
    "\n",
    "# === Normalizao das categorias =============================================\n",
    "HW_CATEGORY_MAP = {\n",
    "    \"switch\": \"Switches\", \"switches\": \"Switches\",\n",
    "    \"router\": \"Routers\", \"routers\": \"Routers\",\n",
    "    \"firewall\": \"Firewall\",\n",
    "    \"wireless\": \"Wireless\", \"access point\": \"Wireless\", \"ap\": \"Wireless\",\n",
    "    \"antenna\": \"Antennas\", \"antennas\": \"Antennas\",\n",
    "    \"cabling\": \"Cabling\",\n",
    "    \"connector\": \"Connectors\", \"connectors\": \"Connectors\",\n",
    "}\n",
    "SW_CATEGORY_MAP = {\n",
    "    \"license\": \"Licenses\", \"licensing\": \"Licenses\",\n",
    "    \"subscription\": \"Subscriptions\",\n",
    "    \"support\": \"Support\",\n",
    "    \"cloud\": \"Cloud Services\", \"service\": \"Cloud Services\",\n",
    "}\n",
    "\n",
    "def normalize_hw_category(raw: str) -> str | None:\n",
    "    if not raw: return None\n",
    "    s = str(raw).strip().lower()\n",
    "    for key, cat in HW_CATEGORY_MAP.items():\n",
    "        if key in s:\n",
    "            return cat\n",
    "    if s in {v.lower() for v in HW_CATEGORY_MAP.values()}:\n",
    "        return s.title()\n",
    "    return None\n",
    "\n",
    "def normalize_sw_category(raw: str) -> str | None:\n",
    "    if not raw: return None\n",
    "    s = str(raw).strip().lower()\n",
    "    for key, cat in SW_CATEGORY_MAP.items():\n",
    "        if key in s:\n",
    "            return cat\n",
    "    if s in {v.lower() for v in HW_CATEGORY_MAP.values()}:\n",
    "        return s.title()\n",
    "    return None\n",
    "\n",
    "# === Deteco de colunas no Excel ============================================\n",
    "def detect_columns(df: pd.DataFrame) -> dict:\n",
    "    cols = {c: re.sub(r\"\\s+\", \"\", str(c).strip().lower()) for c in df.columns}\n",
    "    out = {\"sku\": None, \"desc\": None, \"price\": None, \"category\": None, \"category_type\": None, \"subcategory\": None}\n",
    "\n",
    "    for col, norm in cols.items():\n",
    "        if out[\"sku\"] is None and (norm == \"sku\" or \"partnumber\" in norm or norm == \"part\" or \"sku\" in norm):\n",
    "            out[\"sku\"] = col\n",
    "        elif out[\"desc\"] is None and (norm in {\"desc\",\"description\",\"name\"} or \"desc\" in norm or \"description\" in norm):\n",
    "            out[\"desc\"] = col\n",
    "        elif out[\"price\"] is None and (norm in {\"price\",\"pri\",\"list\"} or \"price\" in norm or norm == \"pri\"):\n",
    "            out[\"price\"] = col\n",
    "        elif out[\"category_type\"] is None and re.fullmatch(r\"category[-_]?type\", norm):\n",
    "            out[\"category_type\"] = col\n",
    "        elif out[\"category\"] is None and (norm == \"category\" or ((\"category\" in norm) and (\"type\" not in norm))):\n",
    "            out[\"category\"] = col\n",
    "        elif out[\"subcategory\"] is None and (\"subcategory\" in norm or \"sub-category\" in norm or norm == \"sub_category\"):\n",
    "            out[\"subcategory\"] = col\n",
    "\n",
    "    missing = [k for k, v in out.items() if v is None and k in (\"sku\",\"desc\",\"price\")]\n",
    "    if missing:\n",
    "        raise RuntimeError(f\"Excel sem colunas obrigatrias: {missing}. Detectado: {out}\")\n",
    "    return out\n",
    "\n",
    "def read_excel_rows(xlsx_path: Path) -> pd.DataFrame:\n",
    "    if not xlsx_path.exists():\n",
    "        raise FileNotFoundError(f\"Excel no encontrado: {xlsx_path}\")\n",
    "    df = pd.read_excel(xlsx_path, engine=\"openpyxl\")\n",
    "    cols = detect_columns(df)\n",
    "\n",
    "    # Limpa preo (vrgula decimal, separadores, etc.)\n",
    "    price_series = (\n",
    "        df[cols[\"price\"]]\n",
    "        .astype(str)\n",
    "        .str.replace(r\"[^\\d\\.,-]\", \"\", regex=True)\n",
    "        .str.replace(r\"\\.(?=\\d{3},)\", \"\", regex=True)  # remove separador de milhar antes de vrgula decimal\n",
    "        .str.replace(\",\", \".\", regex=False)\n",
    "    )\n",
    "    df[\"_price\"] = pd.to_numeric(price_series, errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "    df[\"_sku\"]   = df[cols[\"sku\"]].astype(str).str.strip()\n",
    "    df[\"_name\"]  = df[cols[\"desc\"]].astype(str).str.strip()\n",
    "    df[\"_cat\"]   = df[cols[\"category\"]].astype(str).str.strip() if cols[\"category\"] else \"\"\n",
    "    df[\"_cat_type\"] = df[cols[\"category_type\"]].astype(str).str.strip() if cols[\"category_type\"] else \"\"\n",
    "    df[\"_sub\"]   = df[cols[\"subcategory\"]].astype(str).str.strip() if cols[\"subcategory\"] else \"\"\n",
    "    return df\n",
    "\n",
    "# === LLM (enriquecimento opcional) ===========================================\n",
    "def _extract_json(text: str) -> dict:\n",
    "    \"\"\"Aceita resposta com/sem fences e retorna um dict JSON.\"\"\"\n",
    "    t = text.strip()\n",
    "    if t.startswith(\"```\"):\n",
    "        t = re.sub(r\"^```[a-zA-Z0-9]*\\s*\", \"\", t)\n",
    "        t = re.sub(r\"\\s*```$\", \"\", t)\n",
    "    s = t.find(\"{\"); e = t.rfind(\"}\")\n",
    "    if s != -1 and e != -1 and e > s:\n",
    "        t = t[s:e+1]\n",
    "    return json.loads(t)\n",
    "\n",
    "def _count_filled(obj) -> int:\n",
    "    c = 0\n",
    "    if isinstance(obj, dict):\n",
    "        for v in obj.values(): c += _count_filled(v)\n",
    "    elif isinstance(obj, list):\n",
    "        for v in obj: c += _count_filled(v)\n",
    "    else:\n",
    "        if obj not in (None, \"\", []): c += 1\n",
    "    return c\n",
    "\n",
    "def _diff_keys(before: dict, after: dict, prefix=\"\"):\n",
    "    changes = []\n",
    "    for k in after.keys():\n",
    "        b = before.get(k, None)\n",
    "        a = after.get(k, None)\n",
    "        path = f\"{prefix}.{k}\" if prefix else k\n",
    "        if isinstance(a, dict) and isinstance(b, dict):\n",
    "            changes += _diff_keys(b, a, prefix=path)\n",
    "        elif isinstance(a, list) and isinstance(b, list):\n",
    "            if len(a) != len(b): changes.append(path + \"[]\")\n",
    "        else:\n",
    "            if (b in (None, \"\", []) and a not in (None, \"\", [])) or (b != a):\n",
    "                changes.append(path)\n",
    "    return changes\n",
    "\n",
    "# Model config\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "MODEL_TEMP = 0.3\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=MODEL_TEMP)\n",
    "\n",
    "ENRICH_PROMPT = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a Cisco product data normalizer.\n",
    "\n",
    "You receive:\n",
    "- A PARTIAL product JSON (with SKU, name/description, raw category and base price).\n",
    "- A TARGET SCHEMA (with the exact keys/structure we must output).\n",
    "\n",
    "# GOAL\n",
    "Fill ALL missing or empty fields you can reasonably infer from the SKU, product name/description and category.\n",
    "Prefer realistic, conservative values (no marketing fluff). Keep units when applicable. If you don't know, leave null.\n",
    "\n",
    "# STRICT RULES\n",
    "- Output exactly the same key structure as TARGET SCHEMA (no extra/missing keys).\n",
    "- Do NOT modify existing non-empty values in the partial JSON  only fill blanks.\n",
    "- For hardware, prioritize filling `technical_profile.hardware_attributes` (ports, poe_* fields, uplinks, stacking, wifi_standard), `dependencies`, and `compatibility`.\n",
    "- For software, prioritize filling `license_model.term`, `billing_cycle`, `entitlements.features/tier`, and `dependencies`.\n",
    "- Keep currency as provided. Do not invent prices. Be concise and consistent.\n",
    "\n",
    "--- PARTIAL_JSON ---\n",
    "{partial}\n",
    "\n",
    "--- TARGET_SCHEMA ---\n",
    "{schema}\n",
    "\n",
    "Return ONLY a JSON object that matches the target schema (no explanations).\"\"\"\n",
    ")\n",
    "\n",
    "def enrich_with_llm(partial: dict, schema_obj: dict, cache_key: str) -> dict:\n",
    "    if not ENRICH_WITH_LLM:\n",
    "        return partial\n",
    "    if cache_key in CACHE:\n",
    "        return CACHE[cache_key]\n",
    "\n",
    "    chain = ENRICH_PROMPT | llm\n",
    "    tries = 0\n",
    "    while True:\n",
    "        tries += 1\n",
    "        try:\n",
    "            resp = chain.invoke({\n",
    "                \"partial\": json.dumps(partial, ensure_ascii=False, indent=2),\n",
    "                \"schema\":  json.dumps(schema_obj, ensure_ascii=False, indent=2),\n",
    "            })\n",
    "            enriched_json = _extract_json(resp.content)\n",
    "\n",
    "            # Merge: schema baseline -> partial -> enriched\n",
    "            out = copy.deepcopy(schema_obj)\n",
    "\n",
    "            def deep_merge(dst, src):\n",
    "                for k, v in src.items():\n",
    "                    if isinstance(v, dict) and isinstance(dst.get(k), dict):\n",
    "                        deep_merge(dst[k], v)\n",
    "                    else:\n",
    "                        dst[k] = v\n",
    "\n",
    "            before = copy.deepcopy(out)\n",
    "            deep_merge(out, partial)\n",
    "            deep_merge(out, enriched_json)\n",
    "\n",
    "            # Logs de enriquecimento\n",
    "            before_count = _count_filled(partial)\n",
    "            after_count  = _count_filled(out)\n",
    "            delta        = after_count - before_count\n",
    "            if delta <= 0:\n",
    "                print(f\"  {cache_key}: LLM retornou pouca coisa (delta={delta}).\")\n",
    "            else:\n",
    "                changed = _diff_keys(partial, out)\n",
    "                changed_preview = \", \".join(changed[:8]) + (\" ...\" if len(changed) > 8 else \"\")\n",
    "                print(f\" {cache_key}: +{delta} campos  {changed_preview}\")\n",
    "\n",
    "            CACHE[cache_key] = out\n",
    "            if (len(CACHE) % 10) == 0:\n",
    "                _save_cache(CACHE_PATH, CACHE)\n",
    "            return out\n",
    "\n",
    "        except Exception as e:\n",
    "            if tries >= 3:\n",
    "                print(f\" LLM falhou para {cache_key}: {e}  usando partial.\")\n",
    "                return partial\n",
    "            time.sleep(1.2)\n",
    "\n",
    "# === Persistncia incremental por categoria ===================================\n",
    "def append_item_to_json(filepath: Path, item: dict):\n",
    "    if filepath.exists():\n",
    "        try:\n",
    "            arr = json.loads(filepath.read_text(encoding=\"utf-8\"))\n",
    "            if not isinstance(arr, list):\n",
    "                arr = []\n",
    "        except Exception:\n",
    "            arr = []\n",
    "    else:\n",
    "        arr = []\n",
    "    arr.append(item)\n",
    "    filepath.write_text(json.dumps(arr, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "# === Pipeline principal =======================================================\n",
    "def build_catalog_from_excel(\n",
    "    xlsx_path: Path = XLSX_PATH,\n",
    "    max_items_per_category: int | None = MAX_ITEMS_PER_CATEGORY,\n",
    "    limit_categories: list[str] | None = LIMIT_CATEGORIES,\n",
    "    verbose: bool = True\n",
    "):\n",
    "    df = read_excel_rows(xlsx_path)\n",
    "    if verbose:\n",
    "        print(f\"Rows in Excel: {len(df)}\")\n",
    "\n",
    "    buckets_hw = defaultdict(list)\n",
    "    buckets_sw = defaultdict(list)\n",
    "\n",
    "    records = df.to_dict(orient=\"records\")\n",
    "    for rec in tqdm(records, desc=\"Classifying rows\", disable=not verbose):\n",
    "        sku   = rec.get(\"_sku\", \"\").strip()\n",
    "        name  = rec.get(\"_name\", \"\").strip()\n",
    "        price = float(rec.get(\"_price\", 0.0) or 0.0)\n",
    "        raw_cat = rec.get(\"_cat\", \"\")\n",
    "        raw_type= rec.get(\"_cat_type\", \"\")\n",
    "        subcat  = rec.get(\"_sub\", \"\")\n",
    "\n",
    "        # 1) Decide Hardware/Software pelo Category-Type, se existir\n",
    "        pt = None\n",
    "        rt = raw_type.strip().lower()\n",
    "        if rt.startswith(\"hard\"):\n",
    "            pt = \"hardware\"\n",
    "        elif rt.startswith(\"soft\"):\n",
    "            pt = \"software\"\n",
    "\n",
    "        # 2) Normaliza categoria\n",
    "        hw_cat = normalize_hw_category(raw_cat)    # ex.: \"Wireless\"\n",
    "        sw_cat = normalize_sw_category(raw_cat)    # ex.: \"Wireless\" ou \"Licenses\"\n",
    "\n",
    "        # 3) Se no deu pra decidir tipo pelo Category-Type, decide por categoria\n",
    "        if not pt:\n",
    "            pt = \"hardware\" if hw_cat else (\"software\" if sw_cat else \"hardware\")\n",
    "\n",
    "        # 4) Categoria final\n",
    "        category = hw_cat if pt == \"hardware\" else (sw_cat or (raw_cat.strip().title() if raw_cat else \"Licenses\"))\n",
    "\n",
    "        # 5) Fallback por texto do produto (hardware)\n",
    "        if pt == \"hardware\" and not hw_cat:\n",
    "            txt = f\"{name} {sku}\".lower()\n",
    "            if \"switch\" in txt:             category = \"Switches\"\n",
    "            elif \"router\" in txt:           category = \"Routers\"\n",
    "            elif \"firewall\" in txt:         category = \"Firewall\"\n",
    "            elif \"access point\" in txt or \"ap \" in txt or txt.startswith(\"ap-\"): category = \"Wireless\"\n",
    "            elif \"antenna\" in txt:          category = \"Antennas\"\n",
    "            elif \"cable\" in txt:            category = \"Cabling\"\n",
    "            elif \"connector\" in txt:        category = \"Connectors\"\n",
    "\n",
    "        if limit_categories and category not in limit_categories:\n",
    "            continue\n",
    "\n",
    "        if pt == \"hardware\":\n",
    "            schema = SCHEMAS_HW.get(category)\n",
    "            if not schema:\n",
    "                if verbose:\n",
    "                    print(f\"  Sem schema p/ HW category='{category}', SKU={sku}  pulando\")\n",
    "                continue\n",
    "            base = copy.deepcopy(schema)\n",
    "            base[\"cisco_product_id\"] = sku\n",
    "            base[\"commercial_name\"] = name\n",
    "            base[\"product_type\"] = \"hardware\"\n",
    "            base.setdefault(\"pricing_model\", {})\n",
    "            base[\"pricing_model\"][\"currency\"] = base[\"pricing_model\"].get(\"currency\", \"USD\")\n",
    "            base[\"pricing_model\"][\"base_price\"] = price\n",
    "            base[\"technical_profile\"] = base.get(\"technical_profile\", {})\n",
    "            base[\"technical_profile\"][\"category\"] = category\n",
    "            base[\"technical_profile\"][\"subcategory\"] = subcat or \"\"\n",
    "            buckets_hw[category].append(base)\n",
    "\n",
    "        else:\n",
    "            schema = SCHEMAS_SW.get(category, GENERIC_SW_SCHEMA)\n",
    "            base = copy.deepcopy(schema)\n",
    "            base[\"cisco_product_id\"] = sku\n",
    "            base[\"commercial_name\"] = name\n",
    "            base[\"product_type\"] = \"software\"\n",
    "            base[\"category\"] = category\n",
    "            base[\"pricing_model\"] = base.get(\"pricing_model\", {})\n",
    "            base[\"pricing_model\"][\"currency\"] = base[\"pricing_model\"].get(\"currency\", \"USD\")\n",
    "            base[\"pricing_model\"][\"base_price\"] = price\n",
    "            if \"subcategory\" not in base:\n",
    "                base[\"subcategory\"] = subcat or \"\"\n",
    "            buckets_sw[category].append(base)\n",
    "\n",
    "    counts = {\"hardware\": 0, \"software\": 0, \"files\": 0}\n",
    "\n",
    "    # HARDWARE  1 arquivo por categoria\n",
    "    for category, items in buckets_hw.items():\n",
    "        out_file = OUTPUT_DIR_HW / f\"hw_{category.replace(' ', '_').lower()}.json\"\n",
    "        if verbose: print(f\"\\n[HW] {category}: {len(items)} itens  {out_file}\")\n",
    "        n = 0\n",
    "        for base in tqdm(items, desc=f\"Enrich HW/{category}\", disable=not verbose):\n",
    "            sku = base.get(\"cisco_product_id\", \"\")\n",
    "            schema = SCHEMAS_HW[category]\n",
    "            enriched = enrich_with_llm(base, schema, cache_key=f\"HW::{category}::{sku}\")\n",
    "            append_item_to_json(out_file, enriched)\n",
    "            counts[\"hardware\"] += 1\n",
    "            n += 1\n",
    "            if max_items_per_category and n >= max_items_per_category:\n",
    "                if verbose: print(f\"    Limit reached ({max_items_per_category}) for HW/{category}\")\n",
    "                break\n",
    "        counts[\"files\"] += 1\n",
    "\n",
    "    # SOFTWARE  1 arquivo por categoria\n",
    "    for category, items in buckets_sw.items():\n",
    "        out_file = OUTPUT_DIR_SW / f\"sw_{category.replace(' ', '_').lower()}.json\"\n",
    "        if verbose: print(f\"\\n[SW] {category}: {len(items)} itens  {out_file}\")\n",
    "        n = 0\n",
    "        for base in tqdm(items, desc=f\"Enrich SW/{category}\", disable=not verbose):\n",
    "            sku = base.get(\"cisco_product_id\", \"\")\n",
    "            schema = SCHEMAS_SW.get(category, GENERIC_SW_SCHEMA)\n",
    "            enriched = enrich_with_llm(base, schema, cache_key=f\"SW::{category}::{sku}\")\n",
    "            append_item_to_json(out_file, enriched)\n",
    "            counts[\"software\"] += 1\n",
    "            n += 1\n",
    "            if max_items_per_category and n >= max_items_per_category:\n",
    "                if verbose: print(f\"    Limit reached ({max_items_per_category}) for SW/{category}\")\n",
    "                break\n",
    "        counts[\"files\"] += 1\n",
    "\n",
    "    _save_cache(CACHE_PATH, CACHE)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n=== Summary ===\")\n",
    "        print(counts)\n",
    "    return counts\n",
    "\n",
    "# === EXECUO (teste rpido) ==================================================\n",
    "summary = build_catalog_from_excel(\n",
    "    xlsx_path=XLSX_PATH,\n",
    "    max_items_per_category=MAX_ITEMS_PER_CATEGORY,\n",
    "    limit_categories=LIMIT_CATEGORIES,   # ex.: [\"Wireless\",\"Switches\"]\n",
    "    verbose=True\n",
    ")\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52e0780-2339-48e2-b486-cb889f87badd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08f751d-59c4-48dd-aca6-4fd33ec5cbfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b24062-475c-424f-bf0c-b7ab8eee18d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "72661b1a-b5de-4329-bbeb-d061f975ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= DEBUG CONFIG =================\n",
    "DEBUG_ENRICH = True\n",
    "DEBUG_DIR = Path(\"out/debug_raw\")\n",
    "DEBUG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# =============== UTILS ==========================\n",
    "def _extract_json(text: str) -> dict:\n",
    "    \"\"\"Aceita resposta com/sem fences e retorna um dict JSON.\"\"\"\n",
    "    t = text.strip()\n",
    "    # remove codefence se vier\n",
    "    if t.startswith(\"```\"):\n",
    "        t = re.sub(r\"^```[a-zA-Z0-9]*\\s*\", \"\", t)\n",
    "        t = re.sub(r\"\\s*```$\", \"\", t)\n",
    "    s = t.find(\"{\"); e = t.rfind(\"}\")\n",
    "    if s != -1 and e != -1 and e > s:\n",
    "        t = t[s:e+1]\n",
    "    return json.loads(t)\n",
    "\n",
    "def _count_filled(obj) -> int:\n",
    "    c = 0\n",
    "    if isinstance(obj, dict):\n",
    "        for v in obj.values(): c += _count_filled(v)\n",
    "    elif isinstance(obj, list):\n",
    "        for v in obj: c += _count_filled(v)\n",
    "    else:\n",
    "        if obj not in (None, \"\", []): c += 1\n",
    "    return c\n",
    "\n",
    "def _diff_keys(before: dict, after: dict, prefix=\"\"):\n",
    "    changes = []\n",
    "    for k in after.keys():\n",
    "        b = before.get(k, None)\n",
    "        a = after.get(k, None)\n",
    "        path = f\"{prefix}.{k}\" if prefix else k\n",
    "        if isinstance(a, dict) and isinstance(b, dict):\n",
    "            changes += _diff_keys(b, a, prefix=path)\n",
    "        elif isinstance(a, list) and isinstance(b, list):\n",
    "            if len(a) != len(b): changes.append(path + \"[]\")\n",
    "        else:\n",
    "            if (b in (None, \"\", []) and a not in (None, \"\", [])) or (b != a):\n",
    "                changes.append(path)\n",
    "    return changes\n",
    "\n",
    "def _validate_structure_against_schema(schema_obj: dict, data_obj: dict, prefix=\"\"):\n",
    "    \"\"\"Retorna listas (missing_keys, extra_keys) para auditoria rpida.\"\"\"\n",
    "    missing, extra = [], []\n",
    "    # chaves que existem no schema mas no no dado\n",
    "    for k in schema_obj.keys():\n",
    "        if k not in data_obj:\n",
    "            missing.append(f\"{prefix}{k}\")\n",
    "        else:\n",
    "            if isinstance(schema_obj[k], dict) and isinstance(data_obj[k], dict):\n",
    "                m, e = _validate_structure_against_schema(schema_obj[k], data_obj[k], prefix=f\"{prefix}{k}.\")\n",
    "                missing += m; extra += e\n",
    "            # se schema  dict e dado  lista ou primitivo, no foramos, s reportar diferena de tipo se quiser\n",
    "    # chaves extras no dado\n",
    "    for k in data_obj.keys():\n",
    "        if k not in schema_obj:\n",
    "            extra.append(f\"{prefix}{k}\")\n",
    "    return missing, extra\n",
    "# ===============================================\n",
    "\n",
    "# ======= LLM CONFIG (forar JSON) ==============\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "MODEL_TEMP = 0.3\n",
    "# Fora JSON puro\n",
    "llm_json = ChatOpenAI(model=MODEL_NAME, temperature=MODEL_TEMP,\n",
    "                      response_format={\"type\": \"json_object\"})\n",
    "\n",
    "ENRICH_PROMPT = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a Cisco product data normalizer.\n",
    "\n",
    "You receive:\n",
    "- A PARTIAL product JSON (with SKU, name/description, raw category and base price).\n",
    "- A TARGET SCHEMA (with the exact keys/structure we must output).\n",
    "\n",
    "# GOAL\n",
    "Fill ALL missing or empty fields you can reasonably infer from the SKU, product name/description and category.\n",
    "Prefer realistic, conservative values (no marketing fluff). Keep units when applicable. If you don't know, leave null.\n",
    "\n",
    "# STRICT RULES\n",
    "- Output exactly the same key structure as TARGET SCHEMA (no extra/missing keys).\n",
    "- Do NOT modify existing non-empty values in the partial JSON  only fill blanks.\n",
    "- For hardware, prioritize filling `technical_profile.hardware_attributes` (ports, poe_* fields, uplinks, stacking, wifi_standard), `dependencies`, and `compatibility`.\n",
    "- For software, prioritize filling `license_model.term`, `billing_cycle`, `entitlements.features/tier`, and `dependencies`.\n",
    "- Keep currency as provided. Do not invent prices. Be concise and consistent.\n",
    "\n",
    "--- PARTIAL_JSON ---\n",
    "{partial}\n",
    "\n",
    "--- TARGET_SCHEMA ---\n",
    "{schema}\n",
    "\n",
    "Return ONLY a JSON object that matches the target schema (no explanations).\"\"\"\n",
    ")\n",
    "\n",
    "def enrich_with_llm(partial: dict, schema_obj: dict, cache_key: str) -> dict:\n",
    "    \"\"\"Enriquece o 'partial' segundo 'schema_obj'.\n",
    "       Salva debug: prompt e resposta crus; valida estrutura; loga delta de campos.\"\"\"\n",
    "    if not ENRICH_WITH_LLM:\n",
    "        return partial\n",
    "    if cache_key in CACHE:\n",
    "        return CACHE[cache_key]\n",
    "\n",
    "    chain = ENRICH_PROMPT | llm_json\n",
    "    tries = 0\n",
    "    while True:\n",
    "        tries += 1\n",
    "        try:\n",
    "            # 1) chama LLM\n",
    "            input_vars = {\n",
    "                \"partial\": json.dumps(partial, ensure_ascii=False, indent=2),\n",
    "                \"schema\":  json.dumps(schema_obj, ensure_ascii=False, indent=2),\n",
    "            }\n",
    "            resp = chain.invoke(input_vars)\n",
    "            raw_text = resp.content\n",
    "\n",
    "            # 2) DEBUG: salva prompt + resposta crua\n",
    "            if DEBUG_ENRICH:\n",
    "                (DEBUG_DIR / f\"{cache_key.replace('::','__')}.prompt.json\").write_text(\n",
    "                    json.dumps(input_vars, ensure_ascii=False, indent=2), encoding=\"utf-8\"\n",
    "                )\n",
    "                (DEBUG_DIR / f\"{cache_key.replace('::','__')}.raw.txt\").write_text(\n",
    "                    raw_text, encoding=\"utf-8\"\n",
    "                )\n",
    "\n",
    "            # 3) extrai JSON\n",
    "            enriched_json = _extract_json(raw_text)\n",
    "\n",
    "            # 4) merge: schema -> partial -> enriched\n",
    "            out = copy.deepcopy(schema_obj)\n",
    "            def deep_merge(dst, src):\n",
    "                for k, v in src.items():\n",
    "                    if isinstance(v, dict) and isinstance(dst.get(k), dict):\n",
    "                        deep_merge(dst[k], v)\n",
    "                    else:\n",
    "                        # mantm o que veio em src (inclusive preenchendo vazios)\n",
    "                        dst[k] = v\n",
    "\n",
    "            before = copy.deepcopy(out)\n",
    "            deep_merge(out, partial)\n",
    "            deep_merge(out, enriched_json)\n",
    "\n",
    "            # 5) valida estrutura contra schema\n",
    "            missing, extra = _validate_structure_against_schema(schema_obj, out)\n",
    "            if DEBUG_ENRICH and (missing or extra):\n",
    "                print(f\"  {cache_key}: estrutura divergente  missing={len(missing)} extra={len(extra)}\")\n",
    "                (DEBUG_DIR / f\"{cache_key.replace('::','__')}.missing_keys.txt\").write_text(\n",
    "                    \"\\n\".join(missing), encoding=\"utf-8\"\n",
    "                )\n",
    "                (DEBUG_DIR / f\"{cache_key.replace('::','__')}.extra_keys.txt\").write_text(\n",
    "                    \"\\n\".join(extra), encoding=\"utf-8\"\n",
    "                )\n",
    "\n",
    "            # 6) log de campos preenchidos\n",
    "            before_count = _count_filled(partial)\n",
    "            after_count  = _count_filled(out)\n",
    "            delta        = after_count - before_count\n",
    "            if delta <= 0:\n",
    "                print(f\"  {cache_key}: LLM no acrescentou campos (delta={delta}). Veja {DEBUG_DIR} para prompt/sada.\")\n",
    "            else:\n",
    "                changed = _diff_keys(partial, out)\n",
    "                changed_preview = \", \".join(changed[:8]) + (\" ...\" if len(changed) > 8 else \"\")\n",
    "                print(f\" {cache_key}: +{delta} campos  {changed_preview}\")\n",
    "\n",
    "            # 7) cache + return\n",
    "            CACHE[cache_key] = out\n",
    "            if (len(CACHE) % 10) == 0:\n",
    "                _save_cache(CACHE_PATH, CACHE)\n",
    "            return out\n",
    "\n",
    "        except Exception as e:\n",
    "            # DEBUG: log de erro com a ltima resposta crua (se houver)\n",
    "            print(f\"  {cache_key}: falha ao parsear/mesclar  {e}\")\n",
    "            if tries >= 3:\n",
    "                print(f\"  {cache_key}: desistindo aps {tries} tentativas. Usando partial.\")\n",
    "                return partial\n",
    "            time.sleep(1.2)\n",
    "\n",
    "# ============ SMOKE TEST (rode antes do pipeline) ============================\n",
    "def smoke_test_enricher(sku: str, name: str, price: float, category: str, schema_bank: dict):\n",
    "    \"\"\"\n",
    "    Faz um teste isolado de enriquecimento com 1 produto.\n",
    "    - schema_bank: SCHEMAS_HW ou SCHEMAS_SW\n",
    "    \"\"\"\n",
    "    schema = schema_bank.get(category)\n",
    "    if not schema:\n",
    "        print(f\" Schema no encontrado para categoria '{category}'.\")\n",
    "        return\n",
    "    partial = copy.deepcopy(schema)\n",
    "    # preenche apenas o mnimo (como vem do Excel)\n",
    "    partial[\"cisco_product_id\"] = sku\n",
    "    partial[\"commercial_name\"]  = name\n",
    "    if \"product_type\" in partial:\n",
    "        # mantm como est no schema\n",
    "        pass\n",
    "    # preo\n",
    "    if \"pricing_model\" in partial:\n",
    "        partial[\"pricing_model\"][\"base_price\"] = price\n",
    "        partial[\"pricing_model\"][\"currency\"] = partial[\"pricing_model\"].get(\"currency\", \"USD\")\n",
    "\n",
    "    out = enrich_with_llm(partial, schema, cache_key=f\"SMOKE::{category}::{sku}\")\n",
    "    print(\"\\n--- RESULTADO (resumo) ---\")\n",
    "    print(json.dumps(out, ensure_ascii=False, indent=2)[:1200], \"...\\n\")\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4942d6de-e7f2-47b9-9e77-24d775a36075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SMOKE::Switches::MS225-48FP-HW: LLM no acrescentou campos (delta=0). Veja out\\debug_raw para prompt/sada.\n",
      "\n",
      "--- RESULTADO (resumo) ---\n",
      "{\n",
      "  \"cisco_product_id\": \"MS225-48FP-HW\",\n",
      "  \"commercial_name\": \"Meraki MS225-48FP L2 Stacking PoE Switch\",\n",
      "  \"product_type\": \"hardware\",\n",
      "  \"category\": \"Switches\",\n",
      "  \"subcategory\": null,\n",
      "  \"lifecycle\": {\n",
      "    \"status\": \"active\",\n",
      "    \"eos_announced\": null,\n",
      "    \"last_support_date\": null\n",
      "  },\n",
      "  \"pricing_model\": {\n",
      "    \"type\": \"one_time\",\n",
      "    \"currency\": \"USD\",\n",
      "    \"base_price\": 7770.0,\n",
      "    \"elig_pct\": 0.01,\n",
      "    \"pricing_tiers\": [\n",
      "      {\n",
      "        \"min_quantity\": 1,\n",
      "        \"price\": 0.0,\n",
      "        \"effective\": \"2025-01-01\",\n",
      "        \"discount_rules\": [\n",
      "          {\n",
      "            \"type\": \"volume\",\n",
      "            \"threshold\": 10,\n",
      "            \"discount_pct\": 0.15\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"dependencies\": {\n",
      "    \"required_components\": [],\n",
      "    \"compatible_with\": []\n",
      "  },\n",
      "  \"regulatory\": {\n",
      "    \"certifications\": [\n",
      "      \"FCC\",\n",
      "      \"CE\",\n",
      "      \"IC\"\n",
      "    ],\n",
      "    \"environment\": {\n",
      "      \"oper_temp_min_c\": -5,\n",
      "      \"oper_temp_max_c\": 45,\n",
      "      \"ip_rating\": null\n",
      "    }\n",
      "  },\n",
      "  \"attributes\": {\n",
      "    \"switch\": {\n",
      "      \"layer\": \"L2/L3\",\n",
      "      \"ports_total\": 48,\n",
      "      \"poe_ports\": 48,\n",
      "      \"poe_budget_w\": 740,\n",
      "      \"uplinks\": [\n",
      "        {\n",
      "          \"type\": \"SFP+\",\n",
      "          \"speed_gbps\": 10,\n",
      "          \" ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = smoke_test_enricher(\n",
    "    sku=\"MS225-48FP-HW\",\n",
    "    name=\"Meraki MS225-48FP L2 Stacking PoE Switch\",\n",
    "    price=7770.00,\n",
    "    category=\"Switches\",            # deve bater com o nome no schema_*.json\n",
    "    schema_bank=SCHEMAS_HW          # ou SCHEMAS_SW para software\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122aed35-8393-4ae7-a07e-8e87d04f8172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "db09cb7f-9738-454e-8d68-d86d4f676af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in Excel: 4267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying rows: 100%|| 4267/4267 [00:00<00:00, 21345.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[HW] Wireless: 509 itens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich HW/Wireless:   0%|          | 2/509 [00:00<00:09, 55.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Limit reached (3) for HW/Wireless\n",
      "\n",
      "[HW] Switches: 1563 itens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich HW/Switches:   0%|          | 2/1563 [00:00<00:50, 31.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Limit reached (3) for HW/Switches\n",
      "\n",
      "[HW] Routers: 604 itens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich HW/Routers:   0%|          | 2/604 [00:00<00:29, 20.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Limit reached (3) for HW/Routers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[HW] Firewall: 178 itens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich HW/Firewall:   1%|          | 2/178 [00:00<00:04, 43.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Limit reached (3) for HW/Firewall\n",
      "\n",
      "[HW] Connectors: 20 itens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich HW/Connectors:  10%|         | 2/20 [00:00<00:00, 51.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Limit reached (3) for HW/Connectors\n",
      "\n",
      "[HW] Cabling: 3 itens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich HW/Cabling:  67%|   | 2/3 [00:00<00:00, 74.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Limit reached (3) for HW/Cabling\n",
      "\n",
      "[HW] Antennas: 8 itens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich HW/Antennas:  25%|       | 2/8 [00:00<00:00, 101.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Limit reached (3) for HW/Antennas\n",
      "\n",
      "[SW] Wireless: 545 itens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich SW/Wireless:   0%|          | 2/545 [00:00<00:07, 77.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Limit reached (3) for SW/Wireless\n",
      "\n",
      "[SW] Switches: 515 itens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich SW/Switches:   0%|          | 2/515 [00:00<00:07, 68.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Limit reached (3) for SW/Switches\n",
      "\n",
      "[SW] Licenses: 9 itens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich SW/Licenses:  22%|       | 2/9 [00:00<00:00, 67.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Limit reached (3) for SW/Licenses\n",
      "\n",
      "[SW] Routers: 260 itens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich SW/Routers:   1%|          | 2/260 [00:00<00:03, 65.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Limit reached (3) for SW/Routers\n",
      "\n",
      "[SW] Firewall: 52 itens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich SW/Firewall:   4%|         | 2/52 [00:00<00:00, 63.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Limit reached (3) for SW/Firewall\n",
      "\n",
      "[SW] Connectors: 1 itens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich SW/Connectors: 100%|| 1/1 [00:00<00:00, 220.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Summary ===\n",
      "{'hardware': 21, 'software': 16, 'files': 13}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hardware': 21, 'software': 16, 'files': 13}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% ============================== Setup / Imports ==============================\n",
    "import os, json, time, copy, re\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# -------------------- Controles de execuo --------------------\n",
    "ENRICH_WITH_LLM = True          # True => preenche via LLM\n",
    "MAX_ITEMS_PER_CATEGORY = 3       # None = sem limite (use 3 p/ teste)\n",
    "LIMIT_CATEGORIES = None          # ex.: [\"Switches\",\"Wireless\"] para filtrar\n",
    "DEBUG_SMOKE = True               # salva prompt/resposta da LLM p/ auditoria\n",
    "TQDM_VERBOSE = True\n",
    "\n",
    "# -------------------- Caminhos --------------------\n",
    "XLSX_PATH       = Path(\"data/raw/Cisco_Pricing.xlsx\")\n",
    "SCHEMAS_HW_DIR  = Path(\"schemas/hardware\")\n",
    "SCHEMAS_SW_DIR  = Path(\"schemas/software\")\n",
    "OUTPUT_DIR_HW   = Path(\"out/hardware\")\n",
    "OUTPUT_DIR_SW   = Path(\"out/software\")\n",
    "CACHE_PATH      = Path(\"out/enrichment_cache.json\")\n",
    "DEBUG_DIR       = Path(\"out/debug_llm\")\n",
    "\n",
    "for p in [OUTPUT_DIR_HW, OUTPUT_DIR_SW, CACHE_PATH.parent, DEBUG_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# %% ============================== Cache utils =================================\n",
    "def _load_cache(path: Path) -> dict:\n",
    "    if path.exists():\n",
    "        try:\n",
    "            return json.loads(path.read_text(encoding=\"utf-8\"))\n",
    "        except Exception:\n",
    "            return {}\n",
    "    return {}\n",
    "\n",
    "def _save_cache(path: Path, data: dict):\n",
    "    tmp = path.with_suffix(\".tmp.json\")\n",
    "    tmp.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    tmp.replace(path)\n",
    "\n",
    "CACHE = _load_cache(CACHE_PATH)\n",
    "\n",
    "# %% ======================= Carregamento dos schemas ===========================\n",
    "def load_schema_templates(dir_path: Path, expect_hw=True):\n",
    "    \"\"\"\n",
    "    L todos os schema_*.json e devolve: { \"<Categoria>\": <dict do schema> }\n",
    "    Ex.: schema_switches.json -> categoria \"Switches\"\n",
    "    \"\"\"\n",
    "    templates = {}\n",
    "    if dir_path.exists():\n",
    "        for fp in sorted(dir_path.glob(\"*.json\")):\n",
    "            try:\n",
    "                obj = json.loads(fp.read_text(encoding=\"utf-8\"))\n",
    "                cat = obj.get(\"category\")\n",
    "                if not cat:\n",
    "                    base = fp.stem.replace(\"schema_\", \"\")\n",
    "                    cat = base.replace(\"_\", \" \").title()\n",
    "                templates[cat] = obj\n",
    "            except Exception as e:\n",
    "                print(f\" Erro lendo {fp}: {e}\")\n",
    "    else:\n",
    "        if expect_hw:\n",
    "            print(f\" Diretrio de schemas no existe: {dir_path}\")\n",
    "    return templates\n",
    "\n",
    "SCHEMAS_HW = load_schema_templates(SCHEMAS_HW_DIR, expect_hw=True)\n",
    "SCHEMAS_SW = load_schema_templates(SCHEMAS_SW_DIR, expect_hw=False)\n",
    "\n",
    "if not SCHEMAS_HW:\n",
    "    raise RuntimeError(\n",
    "        f\"Nenhum schema de hardware encontrado em {SCHEMAS_HW_DIR}. \"\n",
    "        \"Coloque seus arquivos schema_*.json l (ex.: schema_switches.json).\"\n",
    "    )\n",
    "\n",
    "# Fallback genrico se no houver schema de software especfico\n",
    "GENERIC_SW_SCHEMA = {\n",
    "    \"cisco_product_id\": \"\",\n",
    "    \"commercial_name\": \"\",\n",
    "    \"product_type\": \"software\",\n",
    "    \"category\": \"\",\n",
    "    \"subcategory\": \"\",\n",
    "    \"lifecycle\": {\"status\": \"active\", \"eos_announced\": None, \"last_support_date\": None},\n",
    "    \"license_model\": {\"type\": \"subscription\", \"term\": \"1Y\", \"seats_or_nodes\": 1, \"includes_support\": True},\n",
    "    \"entitlements\": {\"features\": [], \"tier\": \"Base\", \"usage_limits\": {}},\n",
    "    \"pricing_model\": {\"currency\": \"USD\", \"base_price\": 0.0, \"billing_cycle\": \"yearly\", \"pricing_tiers\": []},\n",
    "    \"dependencies\": {\"requires\": [], \"compatibility\": []},\n",
    "    \"regulatory\": {\"compliance\": []},\n",
    "    \"metadata\": {\"vendor_sku_aliases\": [], \"notes\": \"\"}\n",
    "}\n",
    "\n",
    "# %% ======================= Normalizao de categorias =========================\n",
    "HW_CATEGORY_MAP = {\n",
    "    \"switch\": \"Switches\", \"switches\": \"Switches\",\n",
    "    \"router\": \"Routers\", \"routers\": \"Routers\",\n",
    "    \"firewall\": \"Firewall\",\n",
    "    \"wireless\": \"Wireless\", \"access point\": \"Wireless\", \"ap \": \"Wireless\", \" ap-\": \"Wireless\",\n",
    "    \"antenna\": \"Antennas\", \"antennas\": \"Antennas\",\n",
    "    \"cabling\": \"Cabling\",\n",
    "    \"connector\": \"Connectors\", \"connectors\": \"Connectors\",\n",
    "}\n",
    "\n",
    "SW_CATEGORY_MAP = {\n",
    "    \"license\": \"Licenses\", \"licensing\": \"Licenses\",\n",
    "    \"subscription\": \"Subscriptions\",\n",
    "    \"support\": \"Support\",\n",
    "    \"cloud\": \"Cloud Services\", \"service\": \"Cloud Services\",\n",
    "    \"wireless\": \"Wireless\"  # permitir reuso de categoria\n",
    "}\n",
    "\n",
    "def normalize_hw_category(raw: str):\n",
    "    if not raw: return None\n",
    "    s = \" \" + str(raw).strip().lower() + \" \"\n",
    "    for key, cat in HW_CATEGORY_MAP.items():\n",
    "        if f\" {key} \" in s:\n",
    "            return cat\n",
    "    if str(raw).strip().title() in HW_CATEGORY_MAP.values():\n",
    "        return str(raw).strip().title()\n",
    "    return None\n",
    "\n",
    "def normalize_sw_category(raw: str):\n",
    "    if not raw: return None\n",
    "    s = \" \" + str(raw).strip().lower() + \" \"\n",
    "    for key, cat in SW_CATEGORY_MAP.items():\n",
    "        if f\" {key} \" in s:\n",
    "            return cat\n",
    "    if str(raw).strip().title() in HW_CATEGORY_MAP.values():\n",
    "        return str(raw).strip().title()\n",
    "    return None\n",
    "\n",
    "# ===== Heurstica para detectar licenas/software pelo SKU/Desc =====\n",
    "_LICENSE_TOKENS = [\n",
    "    r\"^l-\", r\"^lic-\", r\"-lic($|[^a-z0-9])\", r\"\\blicen[cs]e\\b\", r\"\\blic\\b\",\n",
    "    r\"\\bdna\\b\", r\"\\bnw-?[ae]\\b\", r\"network advantage\", r\"network essentials\",\n",
    "    r\"\\bsubscription\\b\", r\"\\bsupport\\b\", r\"\\bsnt\\b\", r\"\\bsmart\\s*net\\b\",\n",
    "    r\"\\bmeraki license\\b\", r\"\\bco-term\\b\", r\"\\basa\\s*lic\\b\", r\"\\bfirepower\\s*license\\b\",\n",
    "    r\"\\b1y\\b\", r\"\\b3y\\b\", r\"\\b5y\\b\", r\"\\b1yr\\b\", r\"\\b3yr\\b\", r\"\\b5yr\\b\",\n",
    "]\n",
    "\n",
    "def is_license_like(sku: str, name: str) -> bool:\n",
    "    txt = f\"{sku} {name}\".strip().lower()\n",
    "    for pat in _LICENSE_TOKENS:\n",
    "        if re.search(pat, txt):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# %% ============================ Excel parsing =================================\n",
    "def detect_columns(df: pd.DataFrame) -> dict:\n",
    "    # alvo: Category-Type, Category, SKU, Desc, price, Elig_%\n",
    "    out = {\"category_type\": None, \"category\": None, \"sku\": None, \"desc\": None, \"price\": None, \"elig\": None}\n",
    "    for col in df.columns:\n",
    "        norm = re.sub(r\"\\s+\", \"\", str(col).strip().lower())\n",
    "        if out[\"category_type\"] is None and norm in {\"category-type\", \"categorytype\"}:\n",
    "            out[\"category_type\"] = col\n",
    "        elif out[\"category\"] is None and norm == \"category\":\n",
    "            out[\"category\"] = col\n",
    "        elif out[\"sku\"] is None and norm in {\"sku\",\"partnumber\",\"part\",\"part#\",\"productid\",\"product_id\"}:\n",
    "            out[\"sku\"] = col\n",
    "        elif out[\"desc\"] is None and norm in {\"desc\",\"description\",\"name\",\"productname\",\"product_name\"}:\n",
    "            out[\"desc\"] = col\n",
    "        elif out[\"price\"] is None and norm in {\"price\",\"list\",\"listprice\",\"list_price\"}:\n",
    "            out[\"price\"] = col\n",
    "        elif out[\"elig\"] is None and norm in {\"elig_%\",\"elig\",\"eligibility\",\"eligpercent\",\"eligibility%\",\"elig_pct\"}:\n",
    "            out[\"elig\"] = col\n",
    "\n",
    "    missing = [k for k in (\"sku\",\"desc\",\"price\") if out[k] is None]\n",
    "    if missing:\n",
    "        raise RuntimeError(f\"Excel sem colunas obrigatrias: {missing}. Detectado: {out}\")\n",
    "    return out\n",
    "\n",
    "def read_excel_rows(xlsx_path: Path) -> pd.DataFrame:\n",
    "    if not xlsx_path.exists():\n",
    "        raise FileNotFoundError(f\"Excel no encontrado: {xlsx_path}\")\n",
    "    df = pd.read_excel(xlsx_path, engine=\"openpyxl\")\n",
    "    cols = detect_columns(df)\n",
    "\n",
    "    # limpar preo\n",
    "    price_series = (\n",
    "        df[cols[\"price\"]]\n",
    "        .astype(str)\n",
    "        .str.replace(r\"[^\\d\\.,-]\", \"\", regex=True)\n",
    "        .str.replace(r\"\\.(?=\\d{3},)\", \"\", regex=True)\n",
    "        .str.replace(\",\", \".\", regex=False)\n",
    "    )\n",
    "    df[\"_price\"] = pd.to_numeric(price_series, errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "    elig_series = None\n",
    "    if cols[\"elig\"] is not None:\n",
    "        elig_series = (\n",
    "            df[cols[\"elig\"]]\n",
    "            .astype(str)\n",
    "            .str.replace(r\"[^\\d\\.,-]\", \"\", regex=True)\n",
    "            .str.replace(\",\", \".\", regex=False)\n",
    "        )\n",
    "        df[\"_elig\"] = pd.to_numeric(elig_series, errors=\"coerce\").fillna(0.0)\n",
    "    else:\n",
    "        df[\"_elig\"] = 0.0\n",
    "\n",
    "    df[\"_sku\"]  = df[cols[\"sku\"]].astype(str).str.strip()\n",
    "    df[\"_name\"] = df[cols[\"desc\"]].astype(str).str.strip()\n",
    "    df[\"_cat\"]  = df[cols[\"category\"]].astype(str).str.strip() if cols[\"category\"] else \"\"\n",
    "    df[\"_cat_type\"] = df[cols[\"category_type\"]].astype(str).str.strip() if cols[\"category_type\"] else \"\"\n",
    "    return df\n",
    "\n",
    "# %% ======================= Helpers de merge/trava =============================\n",
    "def pick_environment(sku: str, name: str, category: str) -> dict:\n",
    "    \"\"\"\n",
    "    Heurstica simples para ambiente:\n",
    "    - Indoor enterprise (default): 0..45 C, IP30\n",
    "    - Fanless/compact: 0..50 C, IP30\n",
    "    - Outdoor (AP/switch outdoor): -20..55 C, IP67\n",
    "    - Industrial/Rugged (IE/IR/IW etc): -40..75 C, IP54 ou IP67\n",
    "    - Software/licena: sem ambiente (retornamos None para o caller tratar)\n",
    "    \"\"\"\n",
    "    txt = f\"{sku} {name}\".lower()\n",
    "    cat = (category or \"\").lower()\n",
    "\n",
    "    # Software (s pra segurana, mesmo que no seja chamado pra SW)\n",
    "    if cat in {\"licenses\", \"subscriptions\", \"support\", \"cloud services\"}:\n",
    "        return None\n",
    "\n",
    "    # Palavras-chave\n",
    "    is_outdoor = any(w in txt for w in [\"outdoor\", \"mr76\", \"mr86\", \"mr84\", \"ap-outdoor\"])\n",
    "    is_industrial = any(w in txt for w in [\"industrial\", \"rugged\", \"ie-\", \"ir\", \"iw\", \"cgr\", \"gr-\" , \"ic-\", \"ix-\"])\n",
    "    is_fanless = \"fanless\" in txt or \"compact\" in txt\n",
    "\n",
    "    # Wireless outdoor (Meraki/Cisco)\n",
    "    if is_outdoor or (\"wireless\" in cat and any(w in txt for w in [\"mr7\", \"mr8\"])):  # heurstica leve\n",
    "        return {\"oper_temp_min_c\": -20, \"oper_temp_max_c\": 55, \"ip_rating\": \"IP67\"}\n",
    "\n",
    "    # Industrial/rugged switches/routers (IE/IR/CGR)\n",
    "    if is_industrial:\n",
    "        # alguns IE/IR so IP54; se mencionar \"outdoor\"/\"ip67\", sobe\n",
    "        ip = \"IP67\" if \"ip67\" in txt or \"outdoor\" in txt else \"IP54\"\n",
    "        return {\"oper_temp_min_c\": -40, \"oper_temp_max_c\": 75, \"ip_rating\": ip}\n",
    "\n",
    "    # Indoor enterprise (default)\n",
    "    if is_fanless:\n",
    "        return {\"oper_temp_min_c\": 0, \"oper_temp_max_c\": 50, \"ip_rating\": \"IP30\"}\n",
    "\n",
    "    # Switch/AP enterprise normal\n",
    "    return {\"oper_temp_min_c\": 0, \"oper_temp_max_c\": 45, \"ip_rating\": \"IP30\"}\n",
    "\n",
    "\n",
    "\n",
    "def deep_get(obj, path_list, default=None):\n",
    "    cur = obj\n",
    "    for p in path_list:\n",
    "        if not isinstance(cur, dict) or p not in cur:\n",
    "            return default\n",
    "        cur = cur[p]\n",
    "    return cur\n",
    "\n",
    "def deep_set(obj, path_list, value):\n",
    "    cur = obj\n",
    "    for p in path_list[:-1]:\n",
    "        if p not in cur or not isinstance(cur[p], dict):\n",
    "            cur[p] = {}\n",
    "        cur = cur[p]\n",
    "    cur[path_list[-1]] = value\n",
    "\n",
    "def upsert_item_to_json(filepath: Path, item: dict, key=\"cisco_product_id\"):\n",
    "    arr = []\n",
    "    if filepath.exists():\n",
    "        try:\n",
    "            arr = json.loads(filepath.read_text(encoding=\"utf-8\"))\n",
    "            if not isinstance(arr, list):\n",
    "                arr = []\n",
    "        except Exception:\n",
    "            arr = []\n",
    "    sku = item.get(key)\n",
    "    arr = [x for x in arr if x.get(key) != sku]\n",
    "    arr.append(item)\n",
    "    filepath.write_text(json.dumps(arr, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "# Campos travados (do Excel)\n",
    "LOCK_PATHS = [\n",
    "    [\"cisco_product_id\"],\n",
    "    [\"commercial_name\"],\n",
    "    [\"product_type\"],\n",
    "    [\"pricing_model\", \"base_price\"],\n",
    "    [\"pricing_model\", \"elig_pct\"],\n",
    "    [\"technical_profile\", \"category\"],  # HW\n",
    "    [\"category\"],                      # SW\n",
    "]\n",
    "\n",
    "def apply_locks(enriched: dict, locked_from_excel: dict) -> dict:\n",
    "    out = copy.deepcopy(enriched)\n",
    "    for path in LOCK_PATHS:\n",
    "        val = deep_get(locked_from_excel, path, default=None)\n",
    "        if val is not None:\n",
    "            deep_set(out, path, val)\n",
    "    return out\n",
    "\n",
    "# %% ========================== LLM (enriquecimento) ===========================\n",
    "def _shape_from_schema(schema_obj):\n",
    "    \"\"\"\n",
    "    Gera a mesma estrutura de chaves do schema, mas zera TODOS os valores\n",
    "    para evitar que a LLM copie defaults do schema.\n",
    "    \"\"\"\n",
    "    if isinstance(schema_obj, dict):\n",
    "        out = {}\n",
    "        for k, v in schema_obj.items():\n",
    "            out[k] = _shape_from_schema(v)\n",
    "        return out\n",
    "    elif isinstance(schema_obj, list):\n",
    "        return [_shape_from_schema(schema_obj[0])] if schema_obj else []\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def _extract_json(text: str) -> dict:\n",
    "    t = text.strip()\n",
    "    if t.startswith(\"```\"):\n",
    "        t = re.sub(r\"^```[a-zA-Z0-9]*\\s*\", \"\", t)\n",
    "        t = re.sub(r\"\\s*```$\", \"\", t)\n",
    "    s = t.find(\"{\"); e = t.rfind(\"}\")\n",
    "    if s != -1 and e != -1 and e > s:\n",
    "        t = t[s:e+1]\n",
    "    return json.loads(t)\n",
    "\n",
    "def _has_nulls_or_empty(d):\n",
    "    if isinstance(d, dict):\n",
    "        for v in d.values():\n",
    "            if _has_nulls_or_empty(v):\n",
    "                return True\n",
    "        return False\n",
    "    if isinstance(d, list):\n",
    "        if len(d) == 0:\n",
    "            return True\n",
    "        return any(_has_nulls_or_empty(v) for v in d)\n",
    "    return d in (None, \"\", [])\n",
    "\n",
    "# ---- fallback programtico para eliminar nulos restantes (plausvel por categoria)\n",
    "def _fallback_fill_plausible(obj: dict, pt: str, category: str, sku: str, name: str) -> dict:\n",
    "    out = copy.deepcopy(obj)\n",
    "\n",
    "    def ensure(path, value):\n",
    "        cur = deep_get(out, path, None)\n",
    "        if cur in (None, \"\", []):\n",
    "            deep_set(out, path, value)\n",
    "\n",
    "    # ---- Defaults comuns\n",
    "    ensure([\"lifecycle\", \"status\"], \"active\")\n",
    "    ensure([\"lifecycle\", \"eos_announced\"], \"2030-12-31\")\n",
    "    ensure([\"lifecycle\", \"last_support_date\"], \"2035-12-31\")\n",
    "\n",
    "    ensure([\"pricing_model\", \"currency\"], \"USD\")\n",
    "    if pt == \"hardware\":\n",
    "        ensure([\"pricing_model\", \"type\"], \"one_time\")\n",
    "        # Subcategoria na RAIZ (se existir no schema) e em technical_profile\n",
    "        if \"subcategory\" in out and out[\"subcategory\"] in (None, \"\"):\n",
    "            out[\"subcategory\"] = \"access_switch\" if category == \"Switches\" else category.lower()\n",
    "        ensure(\n",
    "            [\"technical_profile\", \"subcategory\"],\n",
    "            out.get(\"subcategory\", \"access_switch\" if category == \"Switches\" else \"base\")\n",
    "        )\n",
    "    else:\n",
    "        ensure([\"pricing_model\", \"type\"], \"subscription\")\n",
    "        ensure([\"pricing_model\", \"billing_cycle\"], \"yearly\")\n",
    "        if \"subcategory\" in out and out[\"subcategory\"] in (None, \"\"):\n",
    "            out[\"subcategory\"] = \"feature_license\"\n",
    "\n",
    "    # Regulatory comuns\n",
    "    ensure([\"regulatory\", \"certifications\"], [\"FCC\", \"CE\", \"IC\"])\n",
    "    ensure([\"regulatory\", \"environment\", \"oper_temp_min_c\"], 0)\n",
    "    ensure([\"regulatory\", \"environment\", \"oper_temp_max_c\"], 50)\n",
    "    ensure([\"regulatory\", \"environment\", \"ip_rating\"], \"IP30\")\n",
    "\n",
    "    # ---- Especficos por categoria\n",
    "    txt = f\"{sku} {name}\".lower()\n",
    "\n",
    "    if pt == \"hardware\" and category == \"Firewall\":\n",
    "        ensure([\"attributes\", \"firewall\", \"fw_throughput_gbps\"], 1.0)\n",
    "        ensure([\"attributes\", \"firewall\", \"ngfw_throughput_gbps\"], 0.7)\n",
    "        ensure([\"attributes\", \"firewall\", \"ips_throughput_gbps\"], 0.6)\n",
    "        ensure([\"attributes\", \"firewall\", \"ipsec_vpn_gbps\"], 0.5)\n",
    "        ensure([\"attributes\", \"firewall\", \"max_sessions_m\"], 0.5)\n",
    "        ensure([\"attributes\", \"firewall\", \"interfaces\"], [{\"type\": \"GE\", \"qty\": 8}])\n",
    "        ensure([\"attributes\", \"firewall\", \"ha_supported\"], True)\n",
    "        ensure([\"attributes\", \"firewall\", \"utm_services\"], [\"IPS\", \"AV\", \"URL\"])\n",
    "\n",
    "    elif pt == \"hardware\" and category == \"Switches\":\n",
    "        ports = 48 if re.search(r\"\\b48\\b\", txt) else (24 if re.search(r\"\\b24\\b\", txt) else 24)\n",
    "        poe = 1 if (\"poe\" in txt or \"-p\" in sku.lower()) else 0\n",
    "        ensure([\"attributes\", \"switch\", \"layer\"], \"L2/L3\")\n",
    "        ensure([\"attributes\", \"switch\", \"ports_total\"], ports)\n",
    "        ensure([\"attributes\", \"switch\", \"poe_ports\"], ports if poe else 0)\n",
    "        ensure([\"attributes\", \"switch\", \"poe_budget_w\"], 740 if poe else 0)\n",
    "        ensure([\"attributes\", \"switch\", \"uplinks\"], [{\"type\": \"SFP+\", \"speed_gbps\": 10, \"qty\": 4}])\n",
    "        ensure([\"attributes\", \"switch\", \"stacking\", \"supported\"], True)\n",
    "        ensure([\"attributes\", \"switch\", \"stacking\", \"max_members\"], 8)\n",
    "        ensure([\"attributes\", \"switch\", \"stacking\", \"stack_bw_gbps\"], 80)\n",
    "        ensure([\"attributes\", \"switch\", \"switching_capacity_gbps\"], 216 if ports == 48 else 160)\n",
    "        ensure([\"attributes\", \"switch\", \"forwarding_mpps\"], 130 if ports == 48 else 95)\n",
    "        ensure([\"attributes\", \"switch\", \"latency_us\"], 3.2)\n",
    "        ensure([\"attributes\", \"switch\", \"features\"], [\"RSTP\", \"PVLAN\", \"ACLs\", \"QoS\"])\n",
    "\n",
    "    elif pt == \"hardware\" and category == \"Wireless\":\n",
    "        ensure([\"technical_profile\", \"subcategory\"], \"access_point\")\n",
    "        ensure([\"attributes\", \"wireless\", \"wifi_standard\"], \"802.11ax (Wi-Fi 6)\")\n",
    "        ensure([\"attributes\", \"wireless\", \"radios\"], [\"2.4 GHz\", \"5 GHz\"])\n",
    "        ensure([\"attributes\", \"wireless\", \"antenna_type\"], \"internal\")\n",
    "        ensure([\"attributes\", \"wireless\", \"throughput_mbps\"], 1200)\n",
    "        ensure([\"attributes\", \"wireless\", \"mounting\"], \"indoor\")\n",
    "        ensure([\"attributes\", \"wireless\", \"power_requirements\"], \"PoE+\")\n",
    "\n",
    "    elif pt == \"software\":\n",
    "        # Ajustes de licenas\n",
    "        if any(t in txt for t in [\"1y\", \"1yr\"]):\n",
    "            term = \"1Y\"\n",
    "        elif any(t in txt for t in [\"3y\", \"3yr\"]):\n",
    "            term = \"3Y\"\n",
    "        elif any(t in txt for t in [\"5y\", \"5yr\"]):\n",
    "            term = \"5Y\"\n",
    "        else:\n",
    "            term = \"1Y\"\n",
    "        ensure([\"license_model\", \"type\"], \"subscription\")\n",
    "        ensure([\"license_model\", \"term\"], term)\n",
    "        ensure([\"license_model\", \"seats_or_nodes\"], 1)\n",
    "        ensure([\"license_model\", \"includes_support\"], True)\n",
    "\n",
    "        if \"advantage\" in txt:\n",
    "            tier = \"Network Advantage\"\n",
    "            feats = [\"Advanced routing\", \"Segmentation\", \"Telemetry\"]\n",
    "        elif \"essentials\" in txt:\n",
    "            tier = \"Network Essentials\"\n",
    "            feats = [\"Layer 2/3 basic\", \"Access policies\", \"Basic monitoring\"]\n",
    "        elif \"dna\" in txt:\n",
    "            tier = \"Cisco DNA Advantage\"\n",
    "            feats = [\"SD-Access\", \"Automation\", \"Analytics\", \"Assurance\"]\n",
    "        else:\n",
    "            tier = \"Base\"\n",
    "            feats = [\"Basic feature set\"]\n",
    "        ensure([\"entitlements\", \"tier\"], tier)\n",
    "        ensure([\"entitlements\", \"features\"], feats)\n",
    "        ensure([\"pricing_model\", \"billing_cycle\"], \"yearly\")\n",
    "        ensure([\"regulatory\", \"compliance\"], [\"ISO/IEC 27001\", \"SOC 2\"])\n",
    "\n",
    "    # ---- Varredura final: nada pode ficar nulo/vazio\n",
    "    def fill_any_nulls(d):\n",
    "        if isinstance(d, dict):\n",
    "            for k, v in list(d.items()):\n",
    "                if v in (None, \"\", []):\n",
    "                    # defaults genricos\n",
    "                    if k.endswith(\"_date\"):\n",
    "                        d[k] = \"2030-12-31\"\n",
    "                    elif k.endswith(\"_gbps\") or k.endswith(\"_mbps\"):\n",
    "                        d[k] = 1.0\n",
    "                    elif k.endswith(\"_w\"):\n",
    "                        d[k] = 15\n",
    "                    elif k.startswith(\"max_\"):\n",
    "                        d[k] = 1\n",
    "                    elif isinstance(v, list):\n",
    "                        d[k] = [\"N/A\"]\n",
    "                    else:\n",
    "                        d[k] = \"N/A\"\n",
    "                else:\n",
    "                    fill_any_nulls(v)\n",
    "        elif isinstance(d, list):\n",
    "            if not d:\n",
    "                d.append(\"N/A\")\n",
    "            else:\n",
    "                for i, v in enumerate(list(d)):\n",
    "                    if v in (None, \"\", []):\n",
    "                        d[i] = \"N/A\"\n",
    "                    elif isinstance(v, (dict, list)):\n",
    "                        fill_any_nulls(v)\n",
    "\n",
    "    fill_any_nulls(out)\n",
    "    return out\n",
    "\n",
    "# LLM setup\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.9)\n",
    "\n",
    "ENRICH_PROMPT = ChatPromptTemplate.from_template(\n",
    "    \"You are a Cisco product data engineer and domain expert.\\n\"\n",
    "    \"Task: Given a PARTIAL product JSON (from Cisco price list) and a TARGET SHAPE (keys only, no values),\\n\"\n",
    "    \"produce a COMPLETE JSON that fills ALL fields with realistic, conservative values.\\n\"\n",
    "    \"Hard rules:\\n\"\n",
    "    \"1) Do NOT modify these fields from the PARTIAL JSON: SKU (cisco_product_id), commercial_name, product_type,\\n\"\n",
    "    \"   pricing_model.base_price, pricing_model.elig_pct, and category (hardware: technical_profile.category | software: root category).\\n\"\n",
    "    \"2) The TARGET SHAPE only shows the keys; IGNORE any numeric/string examples from schemas.\\n\"\n",
    "    \"3) Your output must NOT contain null, empty strings, or empty arrays. Always infer plausible values.\\n\"\n",
    "    \"4) Be coherent with Cisco families and the category. Use typical ranges/specs for that category.\\n\"\n",
    "    \"5) Keep the exact key names/structure of the TARGET SHAPE; add realistic lists (26 items) where applicable.\\n\"\n",
    "    \"6) Currency = USD unless specified; keep units consistent.\\n\"\n",
    "    \"Return ONLY a valid JSON object.\\n\\n\"\n",
    "    \"<<<PARTIAL_JSON>>>\\n{partial}\\n<<<END_PARTIAL_JSON>>>\\n\\n\"\n",
    "    \"<<<TARGET_SHAPE>>>\\n{shape}\\n<<<END_TARGET_SHAPE>>>\"\n",
    ")\n",
    "\n",
    "FIX_NULLS_PROMPT = ChatPromptTemplate.from_template(\n",
    "    \"You previously generated a product JSON but it still has null/empty fields.\\n\"\n",
    "    \"Replace ALL null, empty strings, or empty arrays with realistic, conservative Cisco-like values.\\n\"\n",
    "    \"Do not change: SKU, commercial_name, product_type, pricing_model.base_price, pricing_model.elig_pct, category.\\n\"\n",
    "    \"Return ONLY a valid JSON with the same structure.\\n\\n\"\n",
    "    \"<<<CURRENT_JSON>>>\\n{current}\\n<<<END_CURRENT_JSON>>>\"\n",
    ")\n",
    "\n",
    "def enrich_with_llm_fill_all(partial: dict, schema_obj: dict, cache_key: str, debug_tag: str | None = None) -> dict:\n",
    "    if not ENRICH_WITH_LLM:\n",
    "        return partial\n",
    "    if cache_key in CACHE:\n",
    "        return CACHE[cache_key]\n",
    "\n",
    "    target_shape = _shape_from_schema(schema_obj)\n",
    "\n",
    "    chainA = ENRICH_PROMPT | llm\n",
    "    tries = 0\n",
    "    while True:\n",
    "        tries += 1\n",
    "        try:\n",
    "            resp = chainA.invoke({\n",
    "                \"partial\": json.dumps(partial, ensure_ascii=False, indent=2),\n",
    "                \"shape\":   json.dumps(target_shape, ensure_ascii=False, indent=2),\n",
    "            })\n",
    "            first = _extract_json(resp.content)\n",
    "            first_locked = apply_locks(first, partial)\n",
    "\n",
    "            if DEBUG_SMOKE and debug_tag:\n",
    "                (DEBUG_DIR / f\"{debug_tag}.prompt.json\").write_text(\n",
    "                    json.dumps({\n",
    "                        \"partial\": json.dumps(partial, ensure_ascii=False, indent=2),\n",
    "                        \"shape\":   json.dumps(target_shape, ensure_ascii=False, indent=2)\n",
    "                    }, ensure_ascii=False, indent=2),\n",
    "                    encoding=\"utf-8\"\n",
    "                )\n",
    "                (DEBUG_DIR / f\"{debug_tag}.first.txt\").write_text(\n",
    "                    json.dumps(first_locked, ensure_ascii=False, indent=2),\n",
    "                    encoding=\"utf-8\"\n",
    "                )\n",
    "\n",
    "            final_obj = first_locked\n",
    "\n",
    "            # Segunda passada para remover nulos/vazios\n",
    "            if _has_nulls_or_empty(final_obj):\n",
    "                chainB = FIX_NULLS_PROMPT | llm\n",
    "                resp2 = chainB.invoke({\n",
    "                    \"current\": json.dumps(final_obj, ensure_ascii=False, indent=2)\n",
    "                })\n",
    "                second = _extract_json(resp2.content)\n",
    "                final_obj = apply_locks(second, partial)\n",
    "\n",
    "                if DEBUG_SMOKE and debug_tag:\n",
    "                    (DEBUG_DIR / f\"{debug_tag}.fix.txt\").write_text(\n",
    "                        json.dumps(final_obj, ensure_ascii=False, indent=2),\n",
    "                        encoding=\"utf-8\"\n",
    "                    )\n",
    "\n",
    "            # Terceira camada: fallback programtico (garantia hard de no-nulos)\n",
    "            if _has_nulls_or_empty(final_obj):\n",
    "                pt = partial.get(\"product_type\", \"hardware\")\n",
    "                category = partial.get(\"category\") or deep_get(partial, [\"technical_profile\", \"category\"], \"Unknown\")\n",
    "                final_obj = _fallback_fill_plausible(final_obj, pt, category, partial[\"cisco_product_id\"], partial[\"commercial_name\"])\n",
    "\n",
    "            CACHE[cache_key] = final_obj\n",
    "            if tries % 3 == 1:\n",
    "                _save_cache(CACHE_PATH, CACHE)\n",
    "            return final_obj\n",
    "\n",
    "        except Exception as e:\n",
    "            if tries >= 3:\n",
    "                print(f\" LLM falhou para {cache_key}: {e}  usando partial.\")\n",
    "                return partial\n",
    "            time.sleep(1.0)\n",
    "\n",
    "# %% ====================== Persistncia por categoria ==========================\n",
    "def save_item_by_category(item: dict, product_type: str, category: str):\n",
    "    if product_type == \"hardware\":\n",
    "        out_file = OUTPUT_DIR_HW / f\"hw_{category.replace(' ', '_').lower()}.json\"\n",
    "    else:\n",
    "        out_file = OUTPUT_DIR_SW / f\"sw_{category.replace(' ', '_').lower()}.json\"\n",
    "    upsert_item_to_json(out_file, item)\n",
    "\n",
    "# %% ============================= Pipeline ====================================\n",
    "def build_catalog_from_excel(\n",
    "    xlsx_path: Path = XLSX_PATH,\n",
    "    max_items_per_category: int | None = MAX_ITEMS_PER_CATEGORY,\n",
    "    limit_categories: list | None = LIMIT_CATEGORIES,\n",
    "    verbose: bool = True\n",
    "):\n",
    "    df = read_excel_rows(xlsx_path)\n",
    "    if verbose:\n",
    "        print(f\"Rows in Excel: {len(df)}\")\n",
    "\n",
    "    buckets_hw = defaultdict(list)\n",
    "    buckets_sw = defaultdict(list)\n",
    "\n",
    "    # classificar registros\n",
    "    records = df.to_dict(orient=\"records\")\n",
    "    for rec in tqdm(records, desc=\"Classifying rows\", disable=not TQDM_VERBOSE):\n",
    "        sku     = rec.get(\"_sku\", \"\").strip()\n",
    "        name    = rec.get(\"_name\", \"\").strip()\n",
    "        price   = float(rec.get(\"_price\", 0.0) or 0.0)\n",
    "        elig    = float(rec.get(\"_elig\", 0.0) or 0.0)\n",
    "        raw_cat = rec.get(\"_cat\", \"\")\n",
    "        raw_ct  = rec.get(\"_cat_type\", \"\")\n",
    "\n",
    "        # 1) Tipo via Category-Type\n",
    "        pt = None\n",
    "        if raw_ct:\n",
    "            s = raw_ct.strip().lower()\n",
    "            if s.startswith(\"hard\"): pt = \"hardware\"\n",
    "            elif s.startswith(\"soft\"): pt = \"software\"\n",
    "\n",
    "        # 2) Heurstica forte de licena/software pelo SKU/Desc\n",
    "        if is_license_like(sku, name):\n",
    "            pt = \"software\"\n",
    "\n",
    "        # 3) Normaliza categorias\n",
    "        hw_cat = normalize_hw_category(raw_cat)\n",
    "        sw_cat = normalize_sw_category(raw_cat)\n",
    "\n",
    "        # 4) Se ainda no deu para decidir por CT/heurstica, decide por categoria\n",
    "        if not pt:\n",
    "            pt = \"hardware\" if hw_cat else (\"software\" if sw_cat else \"hardware\")\n",
    "\n",
    "        # 5) Categoria final\n",
    "        category = hw_cat if pt == \"hardware\" else (sw_cat or \"Licenses\")\n",
    "\n",
    "        if limit_categories and category not in limit_categories:\n",
    "            continue\n",
    "\n",
    "        if pt == \"hardware\":\n",
    "            schema = SCHEMAS_HW.get(category)\n",
    "            if not schema:\n",
    "                if verbose:\n",
    "                    print(f\"  Sem schema p/ HW category='{category}', SKU={sku}  pulando\")\n",
    "                continue\n",
    "            partial = {\n",
    "                \"cisco_product_id\": sku,\n",
    "                \"commercial_name\":  name,\n",
    "                \"product_type\":     \"hardware\",\n",
    "                \"pricing_model\": {\"base_price\": price, \"elig_pct\": elig},\n",
    "                \"technical_profile\": {\"category\": category}\n",
    "            }\n",
    "            buckets_hw[category].append((partial, schema))\n",
    "        else:\n",
    "            schema = SCHEMAS_SW.get(category, GENERIC_SW_SCHEMA)\n",
    "            partial = {\n",
    "                \"cisco_product_id\": sku,\n",
    "                \"commercial_name\":  name,\n",
    "                \"product_type\":     \"software\",\n",
    "                \"category\":         category,\n",
    "                \"pricing_model\": {\"base_price\": price, \"elig_pct\": elig}\n",
    "            }\n",
    "            buckets_sw[category].append((partial, schema))\n",
    "\n",
    "    counts = {\"hardware\": 0, \"software\": 0, \"files\": 0}\n",
    "\n",
    "    # HARDWARE\n",
    "    for category, items in buckets_hw.items():\n",
    "        n = 0\n",
    "        if verbose: print(f\"\\n[HW] {category}: {len(items)} itens\")\n",
    "        for partial, schema in tqdm(items, desc=f\"Enrich HW/{category}\", disable=not TQDM_VERBOSE):\n",
    "            sku = partial.get(\"cisco_product_id\", \"\")\n",
    "            debug_tag = f\"HW__{category.replace(' ','_')}__{sku}\"\n",
    "            enriched = enrich_with_llm_fill_all(partial, schema, cache_key=f\"HW::{category}::{sku}\", debug_tag=debug_tag)\n",
    "            # Garantia hard final (se sobrou algo vazio)\n",
    "            if _has_nulls_or_empty(enriched):\n",
    "                enriched = _fallback_fill_plausible(enriched, \"hardware\", category, sku, partial[\"commercial_name\"])\n",
    "            save_item_by_category(enriched, \"hardware\", category)\n",
    "            counts[\"hardware\"] += 1\n",
    "            n += 1\n",
    "            if max_items_per_category and n >= max_items_per_category:\n",
    "                if verbose: print(f\"    Limit reached ({max_items_per_category}) for HW/{category}\")\n",
    "                break\n",
    "        counts[\"files\"] += 1\n",
    "\n",
    "    # SOFTWARE\n",
    "    for category, items in buckets_sw.items():\n",
    "        n = 0\n",
    "        if verbose: print(f\"\\n[SW] {category}: {len(items)} itens\")\n",
    "        for partial, schema in tqdm(items, desc=f\"Enrich SW/{category}\", disable=not TQDM_VERBOSE):\n",
    "            sku = partial.get(\"cisco_product_id\", \"\")\n",
    "            debug_tag = f\"SW__{category.replace(' ','_')}__{sku}\"\n",
    "            enriched = enrich_with_llm_fill_all(partial, schema, cache_key=f\"SW::{category}::{sku}\", debug_tag=debug_tag)\n",
    "            if _has_nulls_or_empty(enriched):\n",
    "                enriched = _fallback_fill_plausible(enriched, \"software\", category, sku, partial[\"commercial_name\"])\n",
    "            save_item_by_category(enriched, \"software\", category)\n",
    "            counts[\"software\"] += 1\n",
    "            n += 1\n",
    "            if max_items_per_category and n >= max_items_per_category:\n",
    "                if verbose: print(f\"    Limit reached ({max_items_per_category}) for SW/{category}\")\n",
    "                break\n",
    "        counts[\"files\"] += 1\n",
    "\n",
    "    _save_cache(CACHE_PATH, CACHE)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n=== Summary ===\")\n",
    "        print(counts)\n",
    "    return counts\n",
    "\n",
    "# %% ============================ Execuo (teste) =============================\n",
    "summary = build_catalog_from_excel(\n",
    "    xlsx_path=XLSX_PATH,\n",
    "    max_items_per_category=MAX_ITEMS_PER_CATEGORY,\n",
    "    limit_categories=LIMIT_CATEGORIES,   # ex.: [\"Switches\",\"Wireless\"]\n",
    "    verbose=True\n",
    ")\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c840ac19-85b2-4fa1-b11f-d080d643c8ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50c8301-6082-4861-9f77-2f6d47e979a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ccc09d3-5818-4622-be38-9bcf449445e8",
   "metadata": {},
   "source": [
    "## Most Recent Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cda27065-1d68-4a28-8139-ff619606284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instalaes necessrias\n",
    "#!pip install -q -U langchain-openai tavily-python langchain beautifulsoup4 chromadb pypdf unstructured\n",
    "\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_tools_agent, AgentExecutor\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- CONFIGURAO DAS CHAVES DE API ---\n",
    "#  Cole suas chaves aqui.\n",
    "OPENAI_API_KEY = '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'\n",
    "TAVILY_API_KEY = \"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\" # <-- SUA CHAVE DA TAVILY AQUI\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a947bf1-83e8-4424-a996-26b90699c66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data loaded: 16 products\n",
      " Recommendation data prepared\n",
      "\n",
      " [Orchestrator] Design a secure branchoffice solution for 50 users with WiFi6, firewall and PoE switches. Provide pricing.\n",
      "\n",
      " [Solution Designer]\n",
      " [ReviewerLLM]  skipped (placeholder)\n",
      " Technical Agent skipped (solution design already provides specs)\n",
      "\n",
      " [Pricing Agent]\n",
      "\n",
      " [Synthesizer]\n",
      " Solution Design\n",
      "Design a secure branch-office solution for 50 users with Wi-Fi 6, firewall, and PoE switches.\n",
      "\n",
      " Components:\n",
      "1. ASA 5516-X with FirePOWER Services (1)  Firewall\n",
      "2. Meraki MR53E Access Point (5)  Access Point\n",
      "3. Meraki Dual Band Omni Antennas (5)  Antenna\n",
      "\n",
      " Justification:\n",
      "The ASA5516-FPWR-K9 provides robust firewall capabilities with FirePOWER services, ensuring security for the branch office. The MR53E-HW access points support Wi-Fi 6, providing high-speed wireless connectivity for up to 50 users. The MA-ANT-20 omnidirectional antennas enhance the coverage and performance of the access points, ensuring reliable connectivity throughout the office.\n",
      "\n",
      " Technical Specifications:\n",
      "\n",
      " ASA 5516-X with FirePOWER Services (ASA5516-FPWR-K9)\n",
      "  - Category: security\n",
      "  - Subcategory: firewall\n",
      "  - Throughput: 4 Gbps\n",
      "  - Interfaces: 8x GE\n",
      "  - Vpn Throughput: 1 Gbps\n",
      "  - Threat Throughput: 500 Mbps\n",
      "  - Encryption: 3DES/AES\n",
      "\n",
      " Meraki MR53E Access Point (MR53E-HW)\n",
      "  - Category: wireless\n",
      "  - Subcategory: access_point\n",
      "  - Wifi Standard: 802.11ax\n",
      "  - Throughput: 2.5 Gbps\n",
      "  - Antenna Type: external\n",
      "  - Mounting: indoor\n",
      "  - Power Requirements: PoE+\n",
      "\n",
      " Meraki Dual Band Omni Antennas (MA-ANT-20)\n",
      "  - Category: antenna\n",
      "  - Subcategory: omni\n",
      "  - Frequency: 2.4/5 GHz\n",
      "  - Gain: 5 dBi\n",
      "  - Connector Type: RP-TNC\n",
      "\n",
      " Pricing:\n",
      "- ASA 5516-X with FirePOWER Services (1): USD 5995.00\n",
      "- Meraki MR53E Access Point (5): USD 8495.00\n",
      "- Meraki Dual Band Omni Antennas (5): USD 995.00\n",
      "\n",
      "TOTAL ESTIMATED: USD 15485.00\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# Cisco Sales Assistant  fluxo completo (julho/2025)\n",
    "# =============================================================\n",
    "\"\"\"\n",
    "Cria um agente LangGraph capaz de:\n",
    "   analisar a consulta do cliente\n",
    "   projetar uma soluo (Solution Designer)\n",
    "   buscar especificaes tcnicas\n",
    "   precificar os componentes\n",
    "   sintetizar tudo em uma resposta final\n",
    "\n",
    "Requisitos:\n",
    "  pip install langchain langgraph langchain-openai scikit-learn numpy\n",
    "\"\"\"\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 0. Imports\n",
    "# -------------------------------------------------------------\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict, TypedDict, Optional\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from langchain.tools import tool\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1. Carregar catlogo Cisco\n",
    "# -------------------------------------------------------------\n",
    "product_dict: Dict[str, Dict] = {}\n",
    "PRICELIST_PATH = \"data/raw/pricelist.json\"      # ajuste se necessrio\n",
    "\n",
    "try:\n",
    "    with open(PRICELIST_PATH, encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        products = data if isinstance(data, list) else data.get(\"products\", [])\n",
    "        for p in products:\n",
    "            pid = p.get(\"cisco_product_id\")\n",
    "            if pid:\n",
    "                product_dict[pid] = p\n",
    "    print(f\" Data loaded: {len(product_dict)} products\")\n",
    "except Exception as e:\n",
    "    print(f\" Error loading product data: {e}\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2. Preparar embeddings TFIDF para recomendaes\n",
    "# -------------------------------------------------------------\n",
    "def prepare_recommendation_data():\n",
    "    \"\"\"Gera matriz TFIDF a partir do catlogo para busca semntica.\"\"\"\n",
    "    texts: List[str] = []\n",
    "    for p in product_dict.values():\n",
    "        hw = p.get(\"technical_profile\", {}).get(\"hardware_attributes\", {})\n",
    "        txt = (\n",
    "            f\"{p.get('commercial_name', '')} {p.get('product_type', '')} \"\n",
    "            + \" \".join(f\"{k}={v}\" for k, v in hw.items())\n",
    "        ).strip()\n",
    "        texts.append(txt)\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "    matrix = vectorizer.fit_transform(texts) if texts else None\n",
    "    return vectorizer, matrix\n",
    "\n",
    "\n",
    "vectorizer, tfidf_matrix = prepare_recommendation_data()\n",
    "print(\" Recommendation data prepared\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3. Helper  lista enxuta de produtos (TOPK)\n",
    "# -------------------------------------------------------------\n",
    "def get_product_list_str(requirements: str, top_k: int = 50) -> str:\n",
    "    if tfidf_matrix is None:\n",
    "        return \"(catalog empty)\"\n",
    "    vec = vectorizer.transform([requirements])\n",
    "    sims = cosine_similarity(vec, tfidf_matrix).flatten()\n",
    "    idxs = sims.argsort()[::-1][:top_k]\n",
    "    prods = [list(product_dict.values())[i] for i in idxs]\n",
    "    return \"\\n\".join(\n",
    "        f\"- {p['cisco_product_id']}: {p['commercial_name']} \"\n",
    "        f\"({p['product_type']})\"\n",
    "        for p in prods\n",
    "    )\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4. Ferramentas (LangChain@tool)\n",
    "# -------------------------------------------------------------\n",
    "@tool\n",
    "def get_product_price(part_number: str) -> Dict:\n",
    "    \"\"\"Retrieve pricing information for a Cisco product.\"\"\"\n",
    "    prod = product_dict.get(part_number)\n",
    "    if not prod:\n",
    "        return {\"error\": f\"Product {part_number} not found\", \"part_number\": part_number}\n",
    "    pricing = prod.get(\"pricing_model\", {})\n",
    "    return {\n",
    "        \"price\": pricing.get(\"base_price\", 0.0),\n",
    "        \"currency\": pricing.get(\"currency\", \"USD\"),\n",
    "        \"description\": prod.get(\"commercial_name\", \"\"),\n",
    "        \"part_number\": part_number,\n",
    "        \"product_type\": prod.get(\"product_type\", \"\"),\n",
    "    }\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_technical_specs(part_number: str) -> Dict:\n",
    "    \"\"\"Retrieve hardware specifications for a Cisco product.\"\"\"\n",
    "    prod = product_dict.get(part_number)\n",
    "    if not prod:\n",
    "        return {\"error\": f\"Product {part_number} not found\", \"part_number\": part_number}\n",
    "    hw = prod.get(\"technical_profile\", {}).get(\"hardware_attributes\", {})\n",
    "    if not hw:\n",
    "        return {\"error\": f\"No technical specs for {part_number}\", \"part_number\": part_number}\n",
    "    return {\n",
    "        \"specifications\": hw,\n",
    "        \"description\": prod.get(\"commercial_name\", \"\"),\n",
    "        \"part_number\": part_number,\n",
    "        \"product_type\": prod.get(\"product_type\", \"\"),\n",
    "    }\n",
    "\n",
    "\n",
    "@tool\n",
    "def recommend_products(requirements: str, max_results: int = 3) -> List[Dict]:\n",
    "    \"\"\"Recommend Cisco products that best match the given requirements.\"\"\"\n",
    "    if tfidf_matrix is None:\n",
    "        return [{\"error\": \"Catalog not indexed\"}]\n",
    "    vec = vectorizer.transform([requirements])\n",
    "    sims = cosine_similarity(vec, tfidf_matrix).flatten()\n",
    "    idxs = sims.argsort()[::-1][:max_results]\n",
    "    base = list(product_dict.values())\n",
    "    return [\n",
    "        {\n",
    "            \"part_number\": base[i][\"cisco_product_id\"],\n",
    "            \"commercial_name\": base[i][\"commercial_name\"],\n",
    "            \"product_type\": base[i][\"product_type\"],\n",
    "            \"similarity_score\": float(sims[i]),\n",
    "        }\n",
    "        for i in idxs\n",
    "    ]\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 5. Pydanticmodels\n",
    "# -------------------------------------------------------------\n",
    "class SolutionComponent(BaseModel):\n",
    "    part_number: str = Field(description=\"Cisco product ID\")\n",
    "    quantity: int = Field(default=1, description=\"Quantity required\")\n",
    "    role: str = Field(description=\"Role in the solution\")\n",
    "\n",
    "\n",
    "class SolutionDesign(BaseModel):\n",
    "    summary: str\n",
    "    components: List[SolutionComponent]\n",
    "    justification: str\n",
    "\n",
    "\n",
    "class AgentRoutingDecision(BaseModel):\n",
    "    needs_design: bool = False\n",
    "    needs_technical: bool = False\n",
    "    needs_pricing: bool = False\n",
    "    query_parts: Dict[str, str] = Field(default_factory=dict)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 6. LLMeprompts\n",
    "# -------------------------------------------------------------\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "#  Orchestrator (corrigido)\n",
    "orchestrator_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a Cisco sales orchestration system.\n",
    "\n",
    "Analyse the user query and decide which specialised agents are needed:\n",
    "   Solution Designer    needs_design\n",
    "   Technical Agent      needs_technical\n",
    "   Pricing Agent        needs_pricing\n",
    "\n",
    "ALWAYS output a JSON object that matches the schema shown in\n",
    "{{format_instructions}}.\n",
    "\n",
    "User query: {{query}}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "orchestrator_agent = orchestrator_prompt | llm.with_structured_output(\n",
    "    AgentRoutingDecision\n",
    ")\n",
    "\n",
    "#  SolutionDesigner\n",
    "design_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a Cisco Solution Architect. Design a complete solution.\n",
    "\n",
    "Customer Requirements:\n",
    "{requirements}\n",
    "\n",
    "Available Cisco Products:\n",
    "{product_list}\n",
    "\n",
    "Return only part_numbers that appear above.\n",
    "Output as JSON in the schema provided.\"\"\"\n",
    ")\n",
    "\n",
    "llm_creative = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.4)  # s o designer\n",
    "\n",
    "design_agent = (\n",
    "    {\n",
    "        \"requirements\": lambda x: x[\"requirements\"],\n",
    "        \"product_list\": lambda x: get_product_list_str(x[\"requirements\"]),\n",
    "        \"format_instructions\": lambda x: x[\"format_instructions\"],\n",
    "    }\n",
    "    | design_prompt\n",
    "    | llm_creative.with_structured_output(SolutionDesign)\n",
    ")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 7. Statetype\n",
    "# -------------------------------------------------------------\n",
    "class AgentState(TypedDict):\n",
    "    user_query: str\n",
    "    orchestrator_decision: Optional[AgentRoutingDecision]\n",
    "    solution_design: Optional[SolutionDesign]\n",
    "    integrity_errors: List[str]\n",
    "    rule_errors: List[str]          #  NEW\n",
    "    technical_results: List[Dict]\n",
    "    pricing_results: List[Dict]\n",
    "    final_response: str\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 8. NOrchestrator\n",
    "# -------------------------------------------------------------\n",
    "def orchestrator_node(state: AgentState) -> AgentState:\n",
    "    print(f\"\\n [Orchestrator] {state['user_query']}\")\n",
    "\n",
    "    q = state[\"user_query\"]\n",
    "\n",
    "    # 1) tentativa normal com o LLM\n",
    "    try:\n",
    "        decision = orchestrator_agent.invoke(\n",
    "            {\n",
    "                \"query\": q,\n",
    "                \"format_instructions\": AgentRoutingDecision.schema(),\n",
    "            }\n",
    "        )\n",
    "    except Exception:\n",
    "        print(\" LLM parse fail  empty decision\")\n",
    "        decision = AgentRoutingDecision()\n",
    "\n",
    "    # 2) heurstica se vier tudo falso\n",
    "    if not any([decision.needs_design, decision.needs_technical, decision.needs_pricing]):\n",
    "        q_low = q.lower()\n",
    "        decision = AgentRoutingDecision(\n",
    "            needs_design=any(w in q_low for w in [\"design\", \"architecture\", \"solution\"]),\n",
    "            needs_technical=\"spec\" in q_low,\n",
    "            needs_pricing=any(w in q_low for w in [\"price\", \"cost\", \"quote\", \"pricing\"]),\n",
    "            query_parts={},\n",
    "        )\n",
    "\n",
    "    # 3) salva no estado e retorna\n",
    "    state[\"orchestrator_decision\"] = decision\n",
    "    return state\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 9. NSolutionDesigner\n",
    "# -------------------------------------------------------------\n",
    "def solution_design_node(state: AgentState) -> AgentState:\n",
    "    print(\"\\n [Solution Designer]\")\n",
    "    design = design_agent.invoke(\n",
    "        {\"requirements\": state[\"user_query\"], \"format_instructions\": SolutionDesign.schema()}\n",
    "    )\n",
    "    state[\"solution_design\"] = design\n",
    "    # fora que o agente de preo rode depois\n",
    "    state[\"orchestrator_decision\"].needs_pricing = True\n",
    "\n",
    "    # fora que o fluxo passe tambm pelo Technical Agent\n",
    "    state[\"orchestrator_decision\"].needs_technical = True\n",
    "\n",
    "    # specs de cada componente\n",
    "    state[\"technical_results\"] = []\n",
    "    for comp in design.components:\n",
    "        res = get_technical_specs(comp.part_number)\n",
    "        if \"error\" not in res:\n",
    "            res[\"quantity\"] = comp.quantity\n",
    "        state[\"technical_results\"].append(res)\n",
    "    return state\n",
    "\n",
    "def integrity_validator_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Camada0  verifica se cada SKU existe e qty 1.\"\"\"\n",
    "    design = state.get(\"solution_design\")\n",
    "    if design is None:\n",
    "        return state\n",
    "\n",
    "    errors, validated = [], []\n",
    "    for comp in design.components:\n",
    "        if comp.part_number not in product_dict:\n",
    "            errors.append(f\"SKU_NOT_FOUND: {comp.part_number}\")\n",
    "            continue\n",
    "        qty = max(1, int(comp.quantity))\n",
    "        if qty != comp.quantity:\n",
    "            errors.append(f\"QUANTITY_ADJUSTED: {comp.part_number}{qty}\")\n",
    "        validated.append(\n",
    "            SolutionComponent(\n",
    "                part_number=comp.part_number,\n",
    "                quantity=qty,\n",
    "                role=comp.role,\n",
    "            )\n",
    "        )\n",
    "    state[\"integrity_errors\"] = errors\n",
    "    design.components = validated            # substitui lista original\n",
    "    return state\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# ValidatorRules  (Camada1)\n",
    "# -------------------------------------------------------------\n",
    "def validator_rules_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Regras bsicas de compatibilidade / coerncia.\"\"\"\n",
    "    errors: List[str] = []\n",
    "    design = state.get(\"solution_design\")\n",
    "    if design is None:\n",
    "        state[\"rule_errors\"] = errors\n",
    "        return state\n",
    "\n",
    "    #  Regra 1: se a query menciona WiFi6, AP deve suportar ax\n",
    "    if \"wi-fi 6\" in state[\"user_query\"].lower():\n",
    "        for comp in design.components:\n",
    "            spec = next(\n",
    "                (t for t in state[\"technical_results\"] if t.get(\"part_number\") == comp.part_number),\n",
    "                None,\n",
    "            )\n",
    "            if spec and spec.get(\"specifications\", {}).get(\"wifi_standard\", \"\").lower() != \"802.11ax\":\n",
    "                errors.append(f\"WIFI6_AP_RULE fail: {comp.part_number}\")\n",
    "\n",
    "    #  Regra 2: componente marcado como PoE precisa ter info PoE\n",
    "    for comp in design.components:\n",
    "        if \"poe\" in comp.role.lower():\n",
    "            spec = next(\n",
    "                (t for t in state[\"technical_results\"] if t.get(\"part_number\") == comp.part_number),\n",
    "                None,\n",
    "            )\n",
    "            if spec and \"poe\" not in spec.get(\"specifications\", {}).get(\"power_requirements\", \"\").lower():\n",
    "                errors.append(f\"POE_SWITCH_RULE fail: {comp.part_number}\")\n",
    "\n",
    "    state[\"rule_errors\"] = errors\n",
    "    if errors:\n",
    "        print(\" Rule errors \", errors)\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 10. N  Technical Agent  (substitua TODO o bloco)\n",
    "# -------------------------------------------------------------\n",
    "### helper: extrai possveis Cisco partnumbers do texto\n",
    "PART_RE = re.compile(r\"[A-Z]{2,}\\d+[A-Z]*-[A-Za-z0-9]+(?:-[A-Za-z0-9]+)*\")\n",
    "\n",
    "def extract_part_numbers(text: str) -> List[str]:\n",
    "    return list({m.group(0) for m in PART_RE.finditer(text)})\n",
    "\n",
    "def technical_agent_node(state: AgentState) -> AgentState:\n",
    "    # pula se j h design\n",
    "    if state.get(\"solution_design\") is not None:\n",
    "        print(\" Technical Agent skipped (solution design already provides specs)\")\n",
    "        return state\n",
    "\n",
    "    query_part = state[\"orchestrator_decision\"].query_parts.get(\n",
    "        \"technical\", state[\"user_query\"]\n",
    "    )\n",
    "    ids = extract_part_numbers(query_part)\n",
    "\n",
    "    if ids:\n",
    "        print(f\"\\n [Technical Agent] Found explicit IDs: {ids}\")\n",
    "        state[\"technical_results\"] = [get_technical_specs(pid) for pid in ids]\n",
    "        return state\n",
    "\n",
    "    # fallback para recomendao sem IDs\n",
    "    if not state[\"orchestrator_decision\"].needs_technical:\n",
    "        print(\" Technical Agent skipped (flag false & no IDs)\")\n",
    "        return state\n",
    "\n",
    "    print(f\"\\n [Technical Agent] Generating recommendations for {query_part}\")\n",
    "    recs = recommend_products.invoke({\"requirements\": query_part, \"max_results\": 5})\n",
    "    state[\"technical_results\"] = []\n",
    "    for r in recs:\n",
    "        spec = get_technical_specs(r[\"part_number\"])\n",
    "        if \"error\" not in spec:\n",
    "            spec[\"recommendation_score\"] = r.get(\"similarity_score\", 0)\n",
    "        state[\"technical_results\"].append(spec)\n",
    "    return state\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 11. N  Pricing Agent\n",
    "# -------------------------------------------------------------\n",
    "def pricing_agent_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Gera lista de preos (com subtotal) para os SKUs relevantes.\"\"\"\n",
    "    if not state[\"orchestrator_decision\"].needs_pricing:\n",
    "        print(\" Pricing Agent skipped\")\n",
    "        return state\n",
    "\n",
    "    print(\"\\n [Pricing Agent]\")\n",
    "\n",
    "    # 1) Se houver SolutionDesign, precifica exatamente seus componentes\n",
    "    if isinstance(state.get(\"solution_design\"), SolutionDesign):\n",
    "        items = [\n",
    "            {\"part_number\": c.part_number, \"quantity\": c.quantity}\n",
    "            for c in state[\"solution_design\"].components\n",
    "        ]\n",
    "    else:\n",
    "        # 2) Tenta extrair IDs explicitamente mencionados na parte de preo da query\n",
    "        pricing_part = state[\"orchestrator_decision\"].query_parts.get(\n",
    "            \"pricing\", state[\"user_query\"]\n",
    "        )\n",
    "        ids = extract_part_numbers(pricing_part)\n",
    "        if ids:\n",
    "            items = [{\"part_number\": pid, \"quantity\": 1} for pid in ids]\n",
    "        else:\n",
    "            # 3) Fallback: usa IDs provenientes do Technical Agent\n",
    "            items = [\n",
    "                {\n",
    "                    \"part_number\": t.get(\"part_number\"),\n",
    "                    \"quantity\": t.get(\"quantity\", 1),\n",
    "                }\n",
    "                for t in state[\"technical_results\"]\n",
    "                if t.get(\"part_number\")\n",
    "            ]\n",
    "\n",
    "    # Deduplicar somando quantidades\n",
    "    dedup: Dict[str, int] = {}\n",
    "    for it in items:\n",
    "        dedup[it[\"part_number\"]] = dedup.get(it[\"part_number\"], 0) + it[\"quantity\"]\n",
    "\n",
    "    # Consultar preos e calcular subtotais\n",
    "    state[\"pricing_results\"] = []\n",
    "    for pn, qty in dedup.items():\n",
    "        price_info = get_product_price(pn)\n",
    "        price_info.update(\n",
    "            {\n",
    "                \"quantity\": qty,\n",
    "                \"subtotal\": price_info.get(\"price\", 0) * qty,\n",
    "            }\n",
    "        )\n",
    "        state[\"pricing_results\"].append(price_info)\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "###### Implementar futyuramente\n",
    "\n",
    "def rules_validator_node(state: AgentState) -> AgentState:\n",
    "    print(\" [ValidatorRules]  not implemented yet\")\n",
    "    return state\n",
    "\n",
    "def reviewer_node(state: AgentState) -> AgentState:\n",
    "    print(\" [ReviewerLLM]  skipped (placeholder)\")\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 12. N  Synthesizer  (verso refinada)\n",
    "# -------------------------------------------------------------\n",
    "def synthesize_node(state: AgentState) -> AgentState:\n",
    "    print(\"\\n [Synthesizer]\")\n",
    "    lines: List[str] = []\n",
    "\n",
    "    # \n",
    "    # 1) Solution Design (se houver)\n",
    "    # \n",
    "    if isinstance(state.get(\"solution_design\"), SolutionDesign):\n",
    "        d = state[\"solution_design\"]\n",
    "        lines.append(\" Solution Design\")\n",
    "        lines.append(d.summary)\n",
    "\n",
    "        lines.append(\"\\n Components:\")\n",
    "        for idx, comp in enumerate(d.components, 1):\n",
    "            desc = next(\n",
    "                (\n",
    "                    t.get(\"description\")\n",
    "                    for t in state[\"technical_results\"]\n",
    "                    if t.get(\"part_number\") == comp.part_number\n",
    "                ),\n",
    "                comp.part_number,\n",
    "            )\n",
    "            lines.append(f\"{idx}. {desc} ({comp.quantity})  {comp.role}\")\n",
    "\n",
    "        lines.append(\"\\n Justification:\\n\" + d.justification)\n",
    "\n",
    "    # \n",
    "    # 2) Technical Specifications  (sempre que houver)\n",
    "    # \n",
    "    if state[\"technical_results\"]:\n",
    "        lines.append(\"\\n Technical Specifications:\")\n",
    "        for t in state[\"technical_results\"]:\n",
    "            if \"error\" in t:\n",
    "                lines.append(f\"- {t.get('part_number')}: {t['error']}\")\n",
    "                continue\n",
    "            lines.append(f\"\\n {t['description']} ({t['part_number']})\")\n",
    "            for k, v in t.get(\"specifications\", {}).items():\n",
    "                lines.append(f\"  - {k.replace('_', ' ').title()}: {v}\")\n",
    "\n",
    "    # \n",
    "    # 3) Erros de integridade / regras\n",
    "    # \n",
    "    if state.get(\"integrity_errors\"):\n",
    "        lines.append(\"\\n Integrity issues:\")\n",
    "        for err in state[\"integrity_errors\"]:\n",
    "            lines.append(f\"- {err}\")\n",
    "\n",
    "    if state.get(\"rule_errors\"):\n",
    "        lines.append(\"\\n Rule issues:\")\n",
    "        for err in state[\"rule_errors\"]:\n",
    "            lines.append(f\"- {err}\")\n",
    "\n",
    "    # \n",
    "    # 4) Pricing\n",
    "    # \n",
    "    if state[\"pricing_results\"]:\n",
    "        total = 0.0\n",
    "        currency = \"USD\"\n",
    "        lines.append(\"\\n Pricing:\")\n",
    "        for p in state[\"pricing_results\"]:\n",
    "            if \"error\" in p:\n",
    "                lines.append(f\"- {p.get('part_number')}: {p['error']}\")\n",
    "                continue\n",
    "            currency = p[\"currency\"]\n",
    "            total += p[\"subtotal\"]\n",
    "            lines.append(\n",
    "                f\"- {p['description']} ({p['quantity']}): \"\n",
    "                f\"{currency} {p['subtotal']:.2f}\"\n",
    "            )\n",
    "        lines.append(f\"\\nTOTAL ESTIMATED: {currency} {total:.2f}\")\n",
    "\n",
    "    # \n",
    "    # 5) Caso nenhum dado relevante\n",
    "    # \n",
    "    if not lines:\n",
    "        lines.append(\" No relevant information found\")\n",
    "\n",
    "    state[\"final_response\"] = \"\\n\".join(lines)\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 13. Roteamento (todas as funes)\n",
    "# -------------------------------------------------------------\n",
    "def route_after_orch(state: AgentState) -> str:\n",
    "    \"\"\"Primeira deciso: vai para designer, tech, price ou direto ao synth.\"\"\"\n",
    "    dec = state[\"orchestrator_decision\"]\n",
    "    if dec.needs_design:\n",
    "        return \"designer\"\n",
    "    if dec.needs_technical:\n",
    "        return \"tech\"\n",
    "    if dec.needs_pricing:\n",
    "        return \"price\"\n",
    "    return \"synth\"\n",
    "\n",
    "\n",
    "def route_after_designer(_: AgentState) -> str:\n",
    "    \"\"\"Sempre passar pelo ValidatorIntegrity depois do designer.\"\"\"\n",
    "    return \"integrity\"\n",
    "\n",
    "\n",
    "def route_after_integrity(_: AgentState) -> str:\n",
    "    \"\"\"Aps Camada0, encaminha para as futuras regras.\"\"\"\n",
    "    return \"rules\"\n",
    "\n",
    "\n",
    "def route_after_rules(_: AgentState) -> str:\n",
    "    \"\"\"Placeholder  sempre manda para o reviewer (LLM stub).\"\"\"\n",
    "    return \"reviewer\"\n",
    "\n",
    "\n",
    "def route_after_reviewer(state: AgentState) -> str:\n",
    "    \"\"\"Decide se ainda precisa specs (tech) ou preo, seno sintetiza.\"\"\"\n",
    "    dec = state[\"orchestrator_decision\"]\n",
    "    if dec.needs_technical:\n",
    "        return \"tech\"\n",
    "    if dec.needs_pricing:\n",
    "        return \"price\"\n",
    "    return \"synth\"\n",
    "\n",
    "\n",
    "def route_after_tech(state: AgentState) -> str:\n",
    "    \"\"\"Se j precisamos de preo, vai ao pricing; seno, sintetiza.\"\"\"\n",
    "    return \"price\" if state[\"orchestrator_decision\"].needs_pricing else \"synth\"\n",
    "\n",
    "\n",
    "def route_after_price(_: AgentState) -> str:\n",
    "    \"\"\"Preo  a ltima etapa antes de sintetizar.\"\"\"\n",
    "    return \"synth\"\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 14. Construir o grafo\n",
    "# -------------------------------------------------------------\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# 1) Ns\n",
    "workflow.add_node(\"orch\", orchestrator_node)\n",
    "workflow.add_node(\"designer\", solution_design_node)           # Solution Designer\n",
    "workflow.add_node(\"integrity\", integrity_validator_node)\n",
    "workflow.add_node(\"rules\", validator_rules_node)       # stub\n",
    "workflow.add_node(\"reviewer\", reviewer_node)           # stub\n",
    "workflow.add_node(\"tech\", technical_agent_node)\n",
    "workflow.add_node(\"price\", pricing_agent_node)\n",
    "workflow.add_node(\"synth\", synthesize_node)\n",
    "\n",
    "\n",
    "# 2) Ponto de entrada\n",
    "workflow.set_entry_point(\"orch\")\n",
    "\n",
    "# 3) Condicionais\n",
    "workflow.add_conditional_edges(\"orch\", route_after_orch, {\n",
    "    \"designer\": \"designer\",\n",
    "    \"tech\": \"tech\",\n",
    "    \"price\": \"price\",\n",
    "    \"synth\": \"synth\",\n",
    "})\n",
    "\n",
    "workflow.add_conditional_edges(\"designer\", lambda _: \"integrity\", {\n",
    "    \"integrity\": \"integrity\",\n",
    "})\n",
    "\n",
    "workflow.add_conditional_edges(\"integrity\", lambda _: \"rules\", {\n",
    "    \"rules\": \"rules\",\n",
    "})\n",
    "\n",
    "workflow.add_conditional_edges(\"rules\", lambda _: \"reviewer\", {\n",
    "    \"reviewer\": \"reviewer\",\n",
    "})\n",
    "\n",
    "workflow.add_conditional_edges(\"reviewer\", route_after_reviewer, {\n",
    "    \"tech\": \"tech\",\n",
    "    \"price\": \"price\",\n",
    "    \"synth\": \"synth\",\n",
    "})\n",
    "\n",
    "workflow.add_conditional_edges(\"tech\", route_after_tech, {\n",
    "    \"price\": \"price\",\n",
    "    \"synth\": \"synth\",\n",
    "})\n",
    "\n",
    "workflow.add_conditional_edges(\"price\", route_after_price, {\n",
    "    \"synth\": \"synth\",\n",
    "})\n",
    "\n",
    "# 4) Encerramento\n",
    "workflow.add_edge(\"synth\", END)\n",
    "\n",
    "# 5) Compilar\n",
    "app = workflow.compile()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 15. Helper para executar\n",
    "# -------------------------------------------------------------\n",
    "def run_sales_quote(query: str) -> str:\n",
    "    init: AgentState = {\n",
    "        \"user_query\": query,\n",
    "        \"orchestrator_decision\": None,\n",
    "        \"solution_design\": None,\n",
    "        \"technical_results\": [],\n",
    "        \"pricing_results\": [],\n",
    "        \"integrity_errors\": [],\n",
    "        \"rule_errors\": [],\n",
    "        \"final_response\": \"\",\n",
    "    }\n",
    "    final_state = app.invoke(init)\n",
    "    return final_state[\"final_response\"]\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 16. Exemplo\n",
    "# -------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    q = (\n",
    "        \"Design a secure branchoffice solution for 50 users with WiFi6, \"\n",
    "        \"firewall and PoE switches. Provide pricing.\"\n",
    "    )\n",
    "    print(run_sales_quote(q))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab55926-052f-4bfe-9c10-a4efcd54c201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987e3d20-0db1-4b9b-a217-7e91e64bfe38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85b81858-ed4f-48e5-b9e5-d6ef6ab04496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [Orchestrator] whats the price for MR42E-HW\n",
      "\n",
      " [Pricing Agent]\n",
      "\n",
      " [Synthesizer]\n",
      "\n",
      " Pricing:\n",
      "- Meraki MR42E Access Point (1): USD 1099.00\n",
      "\n",
      "TOTAL ESTIMATED: USD 1099.00\n"
     ]
    }
   ],
   "source": [
    "print(run_sales_quote(\n",
    "    \"whats the price for MR42E-HW\"\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f6be0f-91ee-4a50-a326-c132ddcb7a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1a49fbbe-2171-478d-81ac-18c3c488931e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [Orchestrator] Design a secure branch-office solution for 50 users with WiFi 6, firewall and PoE switches. Provide pricing.\n",
      "\n",
      " [Solution Designer]\n",
      " [ValidatorRules]  not implemented yet\n",
      " [ReviewerLLM]  skipped (placeholder)\n",
      " Technical Agent skipped (solution design already provides specs)\n",
      "\n",
      " [Pricing Agent]\n",
      "\n",
      " [Synthesizer]\n",
      " Solution Design\n",
      "Design a secure branch-office solution for 50 users with Wi-Fi 6, firewall, and PoE switches.\n",
      "\n",
      " Components:\n",
      "1. ASA 5555-X Firewall (1)  Firewall\n",
      "2. Meraki MR53E Access Point (3)  Access Point for Wi-Fi 6 coverage\n",
      "3. ASA 5516-X with FirePOWER Services (1)  Firewall with FirePOWER Services\n",
      "\n",
      " Justification:\n",
      "The ASA5555-X is selected for its high performance and security features suitable for a branch office. The MR53E-HW access points provide Wi-Fi 6 capabilities for better performance and capacity for 50 users. The ASA5516-FPWR-K9 offers integrated FirePOWER services for enhanced security.\n",
      "\n",
      " Pricing:\n",
      "- ASA 5555-X Firewall (1): USD 28738.01\n",
      "- Meraki MR53E Access Point (3): USD 5097.00\n",
      "- ASA 5516-X with FirePOWER Services (1): USD 5995.00\n",
      "\n",
      "TOTAL ESTIMATED: USD 39830.01\n",
      "\n",
      " [Orchestrator] I need technical specs for ASA5516-FPWR-K9 and pricing for MR53E-HW\n",
      "\n",
      " [Technical Agent] Found explicit IDs: ['ASA5516-FPWR-K9', 'MR53E-HW']\n",
      "\n",
      " [Pricing Agent]\n",
      "\n",
      " [Synthesizer]\n",
      " Technical Specifications:\n",
      "\n",
      " ASA 5516-X with FirePOWER Services (ASA5516-FPWR-K9)\n",
      "  - Category: security\n",
      "  - Subcategory: firewall\n",
      "  - Throughput: 4 Gbps\n",
      "  - Interfaces: 8x GE\n",
      "  - Vpn Throughput: 1 Gbps\n",
      "  - Threat Throughput: 500 Mbps\n",
      "  - Encryption: 3DES/AES\n",
      "\n",
      " Meraki MR53E Access Point (MR53E-HW)\n",
      "  - Category: wireless\n",
      "  - Subcategory: access_point\n",
      "  - Wifi Standard: 802.11ax\n",
      "  - Throughput: 2.5 Gbps\n",
      "  - Antenna Type: external\n",
      "  - Mounting: indoor\n",
      "  - Power Requirements: PoE+\n",
      "\n",
      " Pricing:\n",
      "- ASA 5516-X with FirePOWER Services (1): USD 5995.00\n",
      "- Meraki MR53E Access Point (1): USD 1699.00\n",
      "\n",
      "TOTAL ESTIMATED: USD 7694.00\n"
     ]
    }
   ],
   "source": [
    "print(run_sales_quote(\n",
    "    \"Design a secure branch-office solution for 50 users with WiFi 6, firewall and PoE switches. Provide pricing.\"\n",
    "))\n",
    "\n",
    "print(run_sales_quote(\n",
    "    \"I need technical specs for ASA5516-FPWR-K9 and pricing for MR53E-HW\"\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291e610c-9800-43e8-8b71-b9b5218f1953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a57b7f27-fb2e-471a-9393-362e8c828015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [Orchestrator] I need technical specs for ASA5516-FPWR-K9 and pricing for MR53E-HW\n",
      "\n",
      " [Technical Agent] Found explicit IDs: ['ASA5516-FPWR-K9', 'MR53E-HW']\n",
      "\n",
      " [Pricing Agent]\n",
      "\n",
      " [Synthesizer]\n",
      "\n",
      " CLIENT RESPONSE 1:\n",
      "\n",
      " Pricing:\n",
      "- ASA 5516-X with FirePOWER Services (1): USD 5995.00\n",
      "- Meraki MR53E Access Point (1): USD 1699.00\n",
      "\n",
      "TOTAL ESTIMATED: USD 7694.00\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Solicitao tcnica + preo\n",
    "test_query_1 = \"I need technical specs for ASA5516-FPWR-K9 and pricing for MR53E-HW\"\n",
    "result_1 = run_sales_quote(test_query_1)\n",
    "print(\"\\n CLIENT RESPONSE 1:\")\n",
    "print(result_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6a42e3-14ab-4743-98ee-c293f52d1f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4c1a5e-45d8-4dbe-9136-d252c82610d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ffc46e-9211-47e8-b8d2-d9e364b1e736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab718d59-7619-4f75-87ef-7c365c259ceb",
   "metadata": {},
   "source": [
    "## Adaptao Completa para LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9090e31e-9c74-431e-b8fb-c617ed9541d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U llama-index llama-index-embeddings-openai beautifulsoup4 pypdf unstructured\n",
    "\n",
    "#!pip install -q -U llama-index==0.10.0 llama-index-embeddings-openai==0.1.0 beautifulsoup4==4.12.3 pypdf==4.2.0 unstructured==0.13.0 pillow==10.3.0 tenacity==8.2.3 protobuf==4.25.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbadad41-69a3-46ac-8624-4745595d941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- CONFIGURAO DAS CHAVES DE API ---\n",
    "#  Cole suas chaves aqui.\n",
    "OPENAI_API_KEY = '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'\n",
    "TAVILY_API_KEY = \"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\" # <-- SUA CHAVE DA TAVILY AQUI\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b40b446-9dbb-4ad5-b882-43fcda494f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.core import VectorStoreIndex, Settings\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ee9a8d0-de57-44dc-ab97-7ab1837d401e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file C:\\Users\\Giovani\\Desktop\\EMPRESAS\\02 DATA, CLOUD & BLOCKCHAIN\\DATA & AI\\11 - CONSULTORIAS\\BAIRESDEV\\PROJETOS\\CISCO\\cisco-quote-assistant\\data\\raw\\_product_catalog.csv with error: Error tokenizing data. C error: Expected 1 fields in line 11, saw 2\n",
      ". Skipping...\n",
      "Failed to load file C:\\Users\\Giovani\\Desktop\\EMPRESAS\\02 DATA, CLOUD & BLOCKCHAIN\\DATA & AI\\11 - CONSULTORIAS\\BAIRESDEV\\PROJETOS\\CISCO\\cisco-quote-assistant\\data\\raw\\Pricelist.csv with error: Error tokenizing data. C error: Expected 2 fields in line 12, saw 3\n",
      ". Skipping...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a4181723b24631bce6bdb17ac261bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2eb5ac67ce24fb2bb7fad982e1d930a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/982 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ndice criado com 6 documentos\n",
      "> Running step c5cd8ab7-5dfa-4ed3-b6a8-89527b824751. Step input: \n",
      "    Como especialista Cisco, analise estes requisitos e identifique:\n",
      "    - Tipo de soluo (rede, segurana, colaborao)\n",
      "    - Componentes crticos\n",
      "    - Restries de oramento\n",
      "    \n",
      "    Requisitos: Soluo de rede para escritrio com 50 usurios, requer Wi-Fi 6, switches PoE+ e firewall bsico. Oramento mximo: $15k.\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Giovani\\anaconda3\\Lib\\site-packages\\llama_index\\core\\agent\\react\\base.py:154: DeprecationWarning: Call to deprecated class ReActAgent. (ReActAgent has been rewritten and replaced by llama_index.core.agent.workflow.ReActAgent.\n",
      "\n",
      "This implementation will be removed in a v0.13.0 and the new implementation will be promoted to the `from llama_index.core.agent import ReActAgent` path.\n",
      "\n",
      "See the docs for more information: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
      "  return cls(\n",
      "C:\\Users\\Giovani\\anaconda3\\Lib\\site-packages\\deprecated\\classic.py:184: DeprecationWarning: Call to deprecated class AgentRunner. (AgentRunner has been deprecated and is not maintained.\n",
      "\n",
      "This implementation will be removed in a v0.13.0.\n",
      "\n",
      "See the docs for more information on updated agent usage: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
      "  return old_new1(cls, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: A partir dos requisitos fornecidos, posso identificar o tipo de soluo, os componentes crticos e as restries de oramento.\n",
      " \n",
      "- Tipo de soluo: Rede\n",
      "- Componentes crticos:\n",
      "  - Acesso Wi-Fi 6\n",
      "  - Switches PoE+\n",
      "  - Firewall bsico\n",
      "- Restries de oramento: $15k\n",
      "Answer: A soluo requerida  uma soluo de rede, com componentes crticos que incluem Wi-Fi 6, switches PoE+ e um firewall bsico, e o oramento mximo  de $15k.\n",
      "\u001b[0m> Running step c6be9b82-e464-47bc-a35e-d4edf71448f2. Step input: \n",
      "    Com base nesta anlise:\n",
      "    A soluo requerida  uma soluo de rede, com componentes crticos que incluem Wi-Fi 6, switches PoE+ e um firewall bsico, e o oramento mximo  de $15k.\n",
      "    \n",
      "    Gere TRS cenrios de cotao:\n",
      "    1. Custo-Otimizado: Foco em preo\n",
      "    2. Performance-Mxima: Melhores recursos\n",
      "    3. Balanceado: Equilbrio custo-benefcio\n",
      "    \n",
      "    Use esta estrutura:\n",
      "    [Cenrio X]\n",
      "    Descrio: ...\n",
      "    Componentes: \n",
      "      - Produto A (quantidade)\n",
      "      - Produto B (quantidade)\n",
      "    Trade-offs: ...\n",
      "    \n",
      "\u001b[1;3;38;5;200mThought: (Implicit) I can answer without any more tools!\n",
      "Answer: [Cenrio 1: Custo-Otimizado]  \n",
      "Descrio: Este cenrio foca em minimizar os custos, utilizando produtos que atendem aos requisitos bsicos sem recursos adicionais.  \n",
      "Componentes:  \n",
      "  - Access Point Wi-Fi 6 (5 unidades)  \n",
      "  - Switch PoE+ de 24 portas (2 unidades)  \n",
      "  - Firewall bsico (1 unidade)  \n",
      "Trade-offs: A soluo pode no oferecer a melhor performance em ambientes de alta densidade de usurios e pode ter limitaes em recursos de segurana avanados.\n",
      "\n",
      "[Cenrio 2: Performance-Mxima]  \n",
      "Descrio: Este cenrio prioriza a performance e os melhores recursos disponveis, garantindo uma rede robusta e segura.  \n",
      "Componentes:  \n",
      "  - Access Point Wi-Fi 6 de alta capacidade (5 unidades)  \n",
      "  - Switch PoE+ de 48 portas com gerenciamento avanado (2 unidades)  \n",
      "  - Firewall de prxima gerao (1 unidade)  \n",
      "Trade-offs: O custo total pode exceder o oramento de $15k, mas oferece a melhor performance e segurana.\n",
      "\n",
      "[Cenrio 3: Balanceado]  \n",
      "Descrio: Este cenrio busca um equilbrio entre custo e performance, utilizando produtos que oferecem um bom desempenho sem ultrapassar o oramento.  \n",
      "Componentes:  \n",
      "  - Access Point Wi-Fi 6 (5 unidades)  \n",
      "  - Switch PoE+ de 24 portas (2 unidades)  \n",
      "  - Firewall bsico com algumas funcionalidades adicionais (1 unidade)  \n",
      "Trade-offs: Embora no seja a opo mais barata, oferece um bom desempenho e segurana, mantendo-se dentro do oramento.\n",
      "\u001b[0m> Running step 680d16a5-c490-4a94-b230-93b90dd4eb07. Step input: \n",
      "    Para estes cenrios:\n",
      "    [Cenrio 1: Custo-Otimizado]  \n",
      "Descrio: Este cenrio foca em minimizar os custos, utilizando produtos que atendem aos requisitos bsicos sem recursos adicionais.  \n",
      "Componentes:  \n",
      "  - Access Point Wi-Fi 6 (5 unidades)  \n",
      "  - Switch PoE+ de 24 portas (2 unidades)  \n",
      "  - Firewall bsico (1 unidade)  \n",
      "Trade-offs: A soluo pode no oferecer a melhor performance em ambientes de alta densidade de usurios e pode ter limitaes em recursos de segurana avanados.\n",
      "\n",
      "[Cenrio 2: Performance-Mxima]  \n",
      "Descrio: Este cenrio prioriza a performance e os melhores recursos disponveis, garantindo uma rede robusta e segura.  \n",
      "Componentes:  \n",
      "  - Access Point Wi-Fi 6 de alta capacidade (5 unidades)  \n",
      "  - Switch PoE+ de 48 portas com gerenciamento avanado (2 unidades)  \n",
      "  - Firewall de prxima gerao (1 unidade)  \n",
      "Trade-offs: O custo total pode exceder o oramento de $15k, mas oferece a melhor performance e segurana.\n",
      "\n",
      "[Cenrio 3: Balanceado]  \n",
      "Descrio: Este cenrio busca um equilbrio entre custo e performance, utilizando produtos que oferecem um bom desempenho sem ultrapassar o oramento.  \n",
      "Componentes:  \n",
      "  - Access Point Wi-Fi 6 (5 unidades)  \n",
      "  - Switch PoE+ de 24 portas (2 unidades)  \n",
      "  - Firewall bsico com algumas funcionalidades adicionais (1 unidade)  \n",
      "Trade-offs: Embora no seja a opo mais barata, oferece um bom desempenho e segurana, mantendo-se dentro do oramento.\n",
      "    \n",
      "    Calcule:\n",
      "    - Preo total por cenrio\n",
      "    - Economia vs. MSRP\n",
      "    - 3 talking points por cenrio\n",
      "    \n",
      "\u001b[1;3;38;5;200mThought: (Implicit) I can answer without any more tools!\n",
      "Answer: Para calcular os preos totais por cenrio, a economia em relao ao MSRP e os pontos de discusso, primeiro precisamos estimar os preos dos componentes. Vou usar valores aproximados para cada componente:\n",
      "\n",
      "- Access Point Wi-Fi 6: $200 cada\n",
      "- Switch PoE+ de 24 portas: $800 cada\n",
      "- Switch PoE+ de 48 portas: $1,200 cada\n",
      "- Firewall bsico: $300 cada\n",
      "- Firewall de prxima gerao: $1,000 cada\n",
      "\n",
      "Agora, vamos calcular os preos totais e as economias.\n",
      "\n",
      "[Cenrio 1: Custo-Otimizado]  \n",
      "Preo total:  \n",
      "- Access Point Wi-Fi 6: 5 x $200 = $1,000  \n",
      "- Switch PoE+ de 24 portas: 2 x $800 = $1,600  \n",
      "- Firewall bsico: 1 x $300 = $300  \n",
      "Total: $1,000 + $1,600 + $300 = $2,900  \n",
      "\n",
      "Economia vs. MSRP:  \n",
      "Supondo que o MSRP total para uma soluo similar seja $4,000, a economia seria: $4,000 - $2,900 = $1,100  \n",
      "\n",
      "Talking Points:  \n",
      "1. Soluo de baixo custo, ideal para oramentos restritos.  \n",
      "2. Atende aos requisitos bsicos de conectividade e segurana.  \n",
      "3. Pode ser expandida no futuro conforme as necessidades aumentam.\n",
      "\n",
      "[Cenrio 2: Performance-Mxima]  \n",
      "Preo total:  \n",
      "- Access Point Wi-Fi 6 de alta capacidade: 5 x $300 = $1,500  \n",
      "- Switch PoE+ de 48 portas: 2 x $1,200 = $2,400  \n",
      "- Firewall de prxima gerao: 1 x $1,000 = $1,000  \n",
      "Total: $1,500 + $2,400 + $1,000 = $4,900  \n",
      "\n",
      "Economia vs. MSRP:  \n",
      "Supondo que o MSRP total para uma soluo similar seja $6,000, a economia seria: $6,000 - $4,900 = $1,100  \n",
      "\n",
      "Talking Points:  \n",
      "1. Oferece a melhor performance para ambientes de alta densidade.  \n",
      "2. Recursos avanados de segurana para proteger a rede.  \n",
      "3. Ideal para empresas que priorizam a confiabilidade e a velocidade.\n",
      "\n",
      "[Cenrio 3: Balanceado]  \n",
      "Preo total:  \n",
      "- Access Point Wi-Fi 6: 5 x $200 = $1,000  \n",
      "- Switch PoE+ de 24 portas: 2 x $800 = $1,600  \n",
      "- Firewall bsico com funcionalidades adicionais: 1 x $500 = $500  \n",
      "Total: $1,000 + $1,600 + $500 = $3,100  \n",
      "\n",
      "Economia vs. MSRP:  \n",
      "Supondo que o MSRP total para uma soluo similar seja $4,500, a economia seria: $4,500 - $3,100 = $1,400  \n",
      "\n",
      "Talking Points:  \n",
      "1. Equilbrio entre custo e performance, ideal para a maioria das empresas.  \n",
      "2. Oferece um bom nvel de segurana sem comprometer o oramento.  \n",
      "3. Flexvel para atender a diferentes necessidades de negcios.\n",
      "\u001b[0m## Anlise Tcnica\n",
      "A soluo requerida  uma soluo de rede, com componentes crticos que incluem Wi-Fi 6, switches PoE+ e um firewall bsico, e o oramento mximo  de $15k.\n",
      "\n",
      "## Cenrios\n",
      "[Cenrio 1: Custo-Otimizado]  \n",
      "Descrio: Este cenrio foca em minimizar os custos, utilizando produtos que atendem aos requisitos bsicos sem recursos adicionais.  \n",
      "Componentes:  \n",
      "  - Access Point Wi-Fi 6 (5 unidades)  \n",
      "  - Switch PoE+ de 24 portas (2 unidades)  \n",
      "  - Firewall bsico (1 unidade)  \n",
      "Trade-offs: A soluo pode no oferecer a melhor performance em ambientes de alta densidade de usurios e pode ter limitaes em recursos de segurana avanados.\n",
      "\n",
      "[Cenrio 2: Performance-Mxima]  \n",
      "Descrio: Este cenrio prioriza a performance e os melhores recursos disponveis, garantindo uma rede robusta e segura.  \n",
      "Componentes:  \n",
      "  - Access Point Wi-Fi 6 de alta capacidade (5 unidades)  \n",
      "  - Switch PoE+ de 48 portas com gerenciamento avanado (2 unidades)  \n",
      "  - Firewall de prxima gerao (1 unidade)  \n",
      "Trade-offs: O custo total pode exceder o oramento de $15k, mas oferece a melhor performance e segurana.\n",
      "\n",
      "[Cenrio 3: Balanceado]  \n",
      "Descrio: Este cenrio busca um equilbrio entre custo e performance, utilizando produtos que oferecem um bom desempenho sem ultrapassar o oramento.  \n",
      "Componentes:  \n",
      "  - Access Point Wi-Fi 6 (5 unidades)  \n",
      "  - Switch PoE+ de 24 portas (2 unidades)  \n",
      "  - Firewall bsico com algumas funcionalidades adicionais (1 unidade)  \n",
      "Trade-offs: Embora no seja a opo mais barata, oferece um bom desempenho e segurana, mantendo-se dentro do oramento.\n",
      "\n",
      "## Precificao\n",
      "Para calcular os preos totais por cenrio, a economia em relao ao MSRP e os pontos de discusso, primeiro precisamos estimar os preos dos componentes. Vou usar valores aproximados para cada componente:\n",
      "\n",
      "- Access Point Wi-Fi 6: $200 cada\n",
      "- Switch PoE+ de 24 portas: $800 cada\n",
      "- Switch PoE+ de 48 portas: $1,200 cada\n",
      "- Firewall bsico: $300 cada\n",
      "- Firewall de prxima gerao: $1,000 cada\n",
      "\n",
      "Agora, vamos calcular os preos totais e as economias.\n",
      "\n",
      "[Cenrio 1: Custo-Otimizado]  \n",
      "Preo total:  \n",
      "- Access Point Wi-Fi 6: 5 x $200 = $1,000  \n",
      "- Switch PoE+ de 24 portas: 2 x $800 = $1,600  \n",
      "- Firewall bsico: 1 x $300 = $300  \n",
      "Total: $1,000 + $1,600 + $300 = $2,900  \n",
      "\n",
      "Economia vs. MSRP:  \n",
      "Supondo que o MSRP total para uma soluo similar seja $4,000, a economia seria: $4,000 - $2,900 = $1,100  \n",
      "\n",
      "Talking Points:  \n",
      "1. Soluo de baixo custo, ideal para oramentos restritos.  \n",
      "2. Atende aos requisitos bsicos de conectividade e segurana.  \n",
      "3. Pode ser expandida no futuro conforme as necessidades aumentam.\n",
      "\n",
      "[Cenrio 2: Performance-Mxima]  \n",
      "Preo total:  \n",
      "- Access Point Wi-Fi 6 de alta capacidade: 5 x $300 = $1,500  \n",
      "- Switch PoE+ de 48 portas: 2 x $1,200 = $2,400  \n",
      "- Firewall de prxima gerao: 1 x $1,000 = $1,000  \n",
      "Total: $1,500 + $2,400 + $1,000 = $4,900  \n",
      "\n",
      "Economia vs. MSRP:  \n",
      "Supondo que o MSRP total para uma soluo similar seja $6,000, a economia seria: $6,000 - $4,900 = $1,100  \n",
      "\n",
      "Talking Points:  \n",
      "1. Oferece a melhor performance para ambientes de alta densidade.  \n",
      "2. Recursos avanados de segurana para proteger a rede.  \n",
      "3. Ideal para empresas que priorizam a confiabilidade e a velocidade.\n",
      "\n",
      "[Cenrio 3: Balanceado]  \n",
      "Preo total:  \n",
      "- Access Point Wi-Fi 6: 5 x $200 = $1,000  \n",
      "- Switch PoE+ de 24 portas: 2 x $800 = $1,600  \n",
      "- Firewall bsico com funcionalidades adicionais: 1 x $500 = $500  \n",
      "Total: $1,000 + $1,600 + $500 = $3,100  \n",
      "\n",
      "Economia vs. MSRP:  \n",
      "Supondo que o MSRP total para uma soluo similar seja $4,500, a economia seria: $4,500 - $3,100 = $1,400  \n",
      "\n",
      "Talking Points:  \n",
      "1. Equilbrio entre custo e performance, ideal para a maioria das empresas.  \n",
      "2. Oferece um bom nvel de segurana sem comprometer o oramento.  \n",
      "3. Flexvel para atender a diferentes necessidades de negcios.\n"
     ]
    }
   ],
   "source": [
    "# 1. Instalaes necessrias (remover LangChain, adicionar LlamaIndex)\n",
    "#!pip install -q -U llama-index llama-index-embeddings-openai beautifulsoup4 pypdf unstructured\n",
    "\n",
    "import os\n",
    "from llama_index.core import VectorStoreIndex, Settings\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- CONFIGURAO DAS CHAVES ---\n",
    "OPENAI_API_KEY = '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'  # Substituir\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "\n",
    "# =============================================================\n",
    "# Cisco Sales Assistant com LlamaIndex (Otimizado)\n",
    "# =============================================================\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 0. Configurao Global LlamaIndex\n",
    "# -------------------------------------------------------------\n",
    "#  Otimizado para performance Cisco\n",
    "Settings.embed_model = OpenAIEmbedding(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    dimensions=256  # 50% mais rpido que 1536-dim\n",
    ")\n",
    "Settings.llm = OpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "Settings.node_parser = SentenceSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=20,\n",
    "    separator=\"\\n\",\n",
    "    paragraph_separator=\"\\n\\n\"\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1. Carregar catlogo Cisco como ndice Hbrido\n",
    "# -------------------------------------------------------------\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.vector_stores import SimpleVectorStore\n",
    "\n",
    "# Carregar documentos (ajuste o caminho)\n",
    "documents = SimpleDirectoryReader(\"data/raw\").load_data()\n",
    "\n",
    "# Criar ndice com busca hbrida (keyword + vector)\n",
    "vector_store = SimpleVectorStore()  # FAISS-like local\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, \n",
    "    vector_store=vector_store,\n",
    "    show_progress=True\n",
    ")\n",
    "query_engine = index.as_query_engine(\n",
    "    similarity_top_k=5,\n",
    "    vector_store_query_mode=\"hybrid\"\n",
    ")\n",
    "print(f\" ndice criado com {len(documents)} documentos\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2. Ferramentas Adaptadas para LlamaIndex\n",
    "# -------------------------------------------------------------\n",
    "# --- Funo de Recomendao com RAG Hbrido ---\n",
    "def recommend_products(query: str, top_k: int = 3) -> list:\n",
    "    \"\"\"Recomenda produtos Cisco baseado em descries tcnicas.\"\"\"\n",
    "    results = query_engine.query(query)\n",
    "    return [\n",
    "        {\n",
    "            \"part_number\": node.metadata.get(\"cisco_product_id\", \"\"),\n",
    "            \"commercial_name\": node.metadata.get(\"commercial_name\", \"\"),\n",
    "            \"score\": node.score\n",
    "        }\n",
    "        for node in results.source_nodes[:top_k]\n",
    "    ]\n",
    "\n",
    "# --- Ferramenta de Preos (mantida) ---\n",
    "def get_product_price(part_number: str) -> dict:\n",
    "    \"\"\"Busca preo de produto por part number.\"\"\"\n",
    "    # Implementao direta (sem LangChain)\n",
    "    return {\"part_number\": part_number, \"price\": 299.99}  # Mock\n",
    "\n",
    "# --- Ferramentas como Objetos LlamaIndex ---\n",
    "recommend_tool = FunctionTool.from_defaults(fn=recommend_products)\n",
    "price_tool = FunctionTool.from_defaults(fn=get_product_price)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3. Agente ReAct com LlamaIndex\n",
    "# -------------------------------------------------------------\n",
    "#  Verso simplificada e mais rpida\n",
    "agent = ReActAgent.from_tools(\n",
    "    tools=[recommend_tool, price_tool],\n",
    "    llm=Settings.llm,\n",
    "    verbose=True,\n",
    "    max_iterations=6\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4. Fluxo de Cotao Otimizado\n",
    "# -------------------------------------------------------------\n",
    "def generate_cisco_quote(query: str) -> str:\n",
    "    \"\"\"Gera cotao completa com cenrios.\"\"\"\n",
    "    # Passo 1: Anlise de requisitos\n",
    "    analysis_prompt = f\"\"\"\n",
    "    Como especialista Cisco, analise estes requisitos e identifique:\n",
    "    - Tipo de soluo (rede, segurana, colaborao)\n",
    "    - Componentes crticos\n",
    "    - Restries de oramento\n",
    "    \n",
    "    Requisitos: {query}\n",
    "    \"\"\"\n",
    "    analysis = agent.chat(analysis_prompt).response\n",
    "    \n",
    "    # Passo 2: Gerao de cenrios\n",
    "    scenario_prompt = f\"\"\"\n",
    "    Com base nesta anlise:\n",
    "    {analysis}\n",
    "    \n",
    "    Gere TRS cenrios de cotao:\n",
    "    1. Custo-Otimizado: Foco em preo\n",
    "    2. Performance-Mxima: Melhores recursos\n",
    "    3. Balanceado: Equilbrio custo-benefcio\n",
    "    \n",
    "    Use esta estrutura:\n",
    "    [Cenrio X]\n",
    "    Descrio: ...\n",
    "    Componentes: \n",
    "      - Produto A (quantidade)\n",
    "      - Produto B (quantidade)\n",
    "    Trade-offs: ...\n",
    "    \"\"\"\n",
    "    scenarios = agent.chat(scenario_prompt).response\n",
    "    \n",
    "    # Passo 3: Precificao\n",
    "    pricing_prompt = f\"\"\"\n",
    "    Para estes cenrios:\n",
    "    {scenarios}\n",
    "    \n",
    "    Calcule:\n",
    "    - Preo total por cenrio\n",
    "    - Economia vs. MSRP\n",
    "    - 3 talking points por cenrio\n",
    "    \"\"\"\n",
    "    pricing = agent.chat(pricing_prompt).response\n",
    "    \n",
    "    return f\"## Anlise Tcnica\\n{analysis}\\n\\n## Cenrios\\n{scenarios}\\n\\n## Precificao\\n{pricing}\"\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 5. Exemplo de Execuo\n",
    "# -------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    query = (\n",
    "        \"Soluo de rede para escritrio com 50 usurios, \"\n",
    "        \"requer Wi-Fi 6, switches PoE+ e firewall bsico. \"\n",
    "        \"Oramento mximo: $15k.\"\n",
    "    )\n",
    "    print(generate_cisco_quote(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d862905b-473d-4de6-bc7d-ee953a9de701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c156f0-83ba-4730-b083-b58a44886b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c855a2d1-fb6c-4277-a77a-89fc7e67170d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# Cisco Sales Assistant  fluxo completo com validao Camada0\n",
    "# (Designer criativo, ValidatorIntegrity, stubs para futuras\n",
    "#  ValidatorRules e ReviewerLLM)\n",
    "# =============================================================\n",
    "\"\"\"\n",
    "Rodar este arquivo cria um agente LangGraph capaz de:\n",
    "   analisar a consulta do cliente\n",
    "   projetar uma soluo (Solution Designer) com leve criatividade\n",
    "   validar SKU/quantidade (Integrity)\n",
    "   (stubs) validar compatibilidade & revisar via LLM\n",
    "   buscar especificaes tcnicas\n",
    "   precificar os componentes\n",
    "   sintetizar tudo numa resposta final\n",
    "\n",
    "Requisitos:\n",
    "  pip install langchain langgraph langchain-openai scikit-learn numpy\n",
    "\"\"\"\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 0. Imports\n",
    "# -------------------------------------------------------------\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict, TypedDict, Optional\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from langchain.tools import tool\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1. Catlogo Cisco (ajuste caminho se necessrio)\n",
    "# -------------------------------------------------------------\n",
    "product_dict: Dict[str, Dict] = {}\n",
    "PRICELIST_PATH = \"data/raw/pricelist.json\"\n",
    "\n",
    "try:\n",
    "    with open(PRICELIST_PATH, encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        products = data if isinstance(data, list) else data.get(\"products\", [])\n",
    "        for p in products:\n",
    "            pid = p.get(\"cisco_product_id\")\n",
    "            if pid:\n",
    "                product_dict[pid] = p\n",
    "    print(f\" Data loaded: {len(product_dict)} products\")\n",
    "except Exception as e:\n",
    "    print(f\" Error loading product data: {e}\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2. Embeddings TFIDF\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "def prepare_recommendation_data():\n",
    "    texts: List[str] = []\n",
    "    for p in product_dict.values():\n",
    "        hw = p.get(\"technical_profile\", {}).get(\"hardware_attributes\", {})\n",
    "        txt = (\n",
    "            f\"{p.get('commercial_name', '')} {p.get('product_type', '')} \"\n",
    "            + \" \".join(f\"{k}={v}\" for k, v in hw.items())\n",
    "        ).strip()\n",
    "        texts.append(txt)\n",
    "    vec = TfidfVectorizer(stop_words=\"english\")\n",
    "    mat = vec.fit_transform(texts) if texts else None\n",
    "    return vec, mat\n",
    "\n",
    "vectorizer, tfidf_matrix = prepare_recommendation_data()\n",
    "print(\" Recommendation data prepared\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3. Helpers\n",
    "# -------------------------------------------------------------\n",
    "PART_RE = re.compile(r\"[A-Z]{2,}\\d+[A-Z]*-[A-Za-z0-9]+(?:-[A-Za-z0-9]+)*\")\n",
    "\n",
    "def extract_part_numbers(text: str) -> List[str]:\n",
    "    \"\"\"Return unique Ciscolooking part numbers in text.\"\"\"\n",
    "    return list({m.group(0) for m in PART_RE.finditer(text)})\n",
    "\n",
    "def get_product_list_str(requirements: str, top_k: int = 50) -> str:\n",
    "    if tfidf_matrix is None:\n",
    "        return \"(catalog empty)\"\n",
    "    vec = vectorizer.transform([requirements])\n",
    "    sims = cosine_similarity(vec, tfidf_matrix).flatten()\n",
    "    idxs = sims.argsort()[::-1][:top_k]\n",
    "    prods = [list(product_dict.values())[i] for i in idxs]\n",
    "    return \"\\n\".join(\n",
    "        f\"- {p['cisco_product_id']}: {p['commercial_name']} ({p['product_type']})\"\n",
    "        for p in prods\n",
    "    )\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4. LangChain tools\n",
    "# -------------------------------------------------------------\n",
    "@tool\n",
    "def get_product_price(part_number: str) -> Dict:\n",
    "    \"\"\"Retrieve pricing information for a Cisco product.\"\"\"\n",
    "    prod = product_dict.get(part_number)\n",
    "    if not prod:\n",
    "        return {\"error\": \"SKU_NOT_FOUND\", \"part_number\": part_number}\n",
    "    pricing = prod.get(\"pricing_model\", {})\n",
    "    return {\n",
    "        \"price\": pricing.get(\"base_price\", 0.0),\n",
    "        \"currency\": pricing.get(\"currency\", \"USD\"),\n",
    "        \"description\": prod.get(\"commercial_name\", \"\"),\n",
    "        \"part_number\": part_number,\n",
    "        \"product_type\": prod.get(\"product_type\", \"\"),\n",
    "    }\n",
    "\n",
    "@tool\n",
    "def get_technical_specs(part_number: str) -> Dict:\n",
    "    \"\"\"Retrieve hardware specs for a Cisco product.\"\"\"\n",
    "    prod = product_dict.get(part_number)\n",
    "    if not prod:\n",
    "        return {\"error\": \"SKU_NOT_FOUND\", \"part_number\": part_number}\n",
    "    hw = prod.get(\"technical_profile\", {}).get(\"hardware_attributes\", {})\n",
    "    if not hw:\n",
    "        return {\"error\": \"NO_SPECS\", \"part_number\": part_number}\n",
    "    return {\n",
    "        \"specifications\": hw,\n",
    "        \"description\": prod.get(\"commercial_name\", \"\"),\n",
    "        \"part_number\": part_number,\n",
    "        \"product_type\": prod.get(\"product_type\", \"\"),\n",
    "    }\n",
    "\n",
    "@tool\n",
    "def recommend_products(requirements: str, max_results: int = 3) -> List[Dict]:\n",
    "    \"\"\"Recommend products via TFIDF cosine similarity.\"\"\"\n",
    "    if tfidf_matrix is None:\n",
    "        return [{\"error\": \"CATALOG_NOT_INDEXED\"}]\n",
    "    vec = vectorizer.transform([requirements])\n",
    "    sims = cosine_similarity(vec, tfidf_matrix).flatten()\n",
    "    idxs = sims.argsort()[::-1][:max_results]\n",
    "    base = list(product_dict.values())\n",
    "    return [\n",
    "        {\n",
    "            \"part_number\": base[i][\"cisco_product_id\"],\n",
    "            \"commercial_name\": base[i][\"commercial_name\"],\n",
    "            \"product_type\": base[i][\"product_type\"],\n",
    "            \"similarity_score\": float(sims[i]),\n",
    "        }\n",
    "        for i in idxs\n",
    "    ]\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 5. Pydantic models\n",
    "# -------------------------------------------------------------\n",
    "class SolutionComponent(BaseModel):\n",
    "    part_number: str\n",
    "    quantity: int = Field(ge=1)\n",
    "    role: str\n",
    "\n",
    "class SolutionDesign(BaseModel):\n",
    "    summary: str\n",
    "    components: List[SolutionComponent]\n",
    "    justification: str\n",
    "\n",
    "class AgentRoutingDecision(BaseModel):\n",
    "    needs_design: bool = False\n",
    "    needs_technical: bool = False\n",
    "    needs_pricing: bool = False\n",
    "    query_parts: Dict[str, str] = Field(default_factory=dict)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 6. LLM & prompts\n",
    "# -------------------------------------------------------------\n",
    "llm_cold = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "llm_creative = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.4)  # designer\n",
    "\n",
    "orchestrator_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a Cisco sales orchestrator. Output JSON (AgentRoutingDecision) telling which agents to call.\n",
    "User query: {{query}}\n",
    "{{format_instructions}}\"\"\"\n",
    ")\n",
    "\n",
    "orchestrator_agent = orchestrator_prompt | llm_cold.with_structured_output(AgentRoutingDecision)\n",
    "\n",
    "design_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a Cisco Solution Architect. Combine ONLY the products listed below to build a solution. Keep summary 120tokens.\n",
    "Requirements:\n",
    "{requirements}\n",
    "\n",
    "Available Cisco Products:\n",
    "{product_list}\n",
    "\n",
    "Return JSON matching schema.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "design_agent = (\n",
    "    {\n",
    "        \"requirements\": lambda x: x[\"requirements\"],\n",
    "        \"product_list\": lambda x: get_product_list_str(x[\"requirements\"]),\n",
    "        \"format_instructions\": lambda x: x[\"format_instructions\"],\n",
    "    }\n",
    "    | design_prompt\n",
    "    | llm_creative.with_structured_output(SolutionDesign)\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 7. Graph state type\n",
    "# -------------------------------------------------------------\n",
    "class AgentState(TypedDict):\n",
    "    user_query: str\n",
    "    orchestrator_decision: Optional[AgentRoutingDecision]\n",
    "    solution_design: Optional[SolutionDesign]\n",
    "    integrity_errors: List[str]\n",
    "    technical_results: List[Dict]\n",
    "    pricing_results: List[Dict]\n",
    "    final_response: str\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 8. Nodes\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "def orchestrator_node(state: AgentState) -> AgentState:\n",
    "    print(f\"\\n [Orchestrator] {state['user_query']}\")\n",
    "    q = state[\"user_query\"]\n",
    "    try:\n",
    "        decision = orchestrator_agent.invoke({\n",
    "            \"query\": q,\n",
    "            \"format_instructions\": AgentRoutingDecision.schema(),\n",
    "        })\n",
    "    except Exception:\n",
    "        decision = AgentRoutingDecision()\n",
    "    if not any([decision.needs_design, decision.needs_technical, decision.needs_pricing]):\n",
    "        ql = q.lower()\n",
    "        decision = AgentRoutingDecision(\n",
    "            needs_design=any(w in ql for w in [\"design\", \"architecture\", \"solution\"]),\n",
    "            needs_technical=\"spec\" in ql,\n",
    "            needs_pricing=any(w in ql for w in [\"price\", \"cost\", \"quote\", \"pricing\"]),\n",
    "            query_parts={},\n",
    "        )\n",
    "    state[\"orchestrator_decision\"] = decision\n",
    "    return state\n",
    "\n",
    "\n",
    "def designer_node(state: AgentState) -> AgentState:\n",
    "    print(\"\\n [Solution Designer]\")\n",
    "    design = design_agent.invoke({\n",
    "        \"requirements\": state[\"user_query\"],\n",
    "        \"format_instructions\": SolutionDesign.schema(),\n",
    "    })\n",
    "    state[\"solution_design\"] = design\n",
    "    state[\"orchestrator_decision\"].needs_pricing = True  # fora pricing\n",
    "    return state\n",
    "\n",
    "\n",
    "def integrity_validator_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Camada 0  garante SKU vlido & qty 1\"\"\"\n",
    "    design = state.get(\"solution_design\")\n",
    "    if design is None:\n",
    "        return state\n",
    "\n",
    "    errors: List[str] = []\n",
    "    validated: List[SolutionComponent] = []\n",
    "    for comp in design.components:\n",
    "        if comp.part_number not in product_dict:\n",
    "            errors.append(f\"SKU_NOT_FOUND: {comp.part_number}\")\n",
    "            continue\n",
    "        qty = max(1, int(comp.quantity))\n",
    "        if qty != comp.quantity:\n",
    "            errors.append(f\"QUANTITY_ADJUSTED: {comp.part_number}  {qty}\")\n",
    "        validated.append(SolutionComponent(\n",
    "            part_number=comp.part_number,\n",
    "            quantity=qty,\n",
    "            role=comp.role,\n",
    "        ))\n",
    "    if errors:\n",
    "        print(\" Integrity errors \", errors)\n",
    "    state[\"integrity_errors\"] = errors\n",
    "    # substitui componentes por lista validada (mesmo se houver erros)\n",
    "    state[\"solution_design\"].components = validated\n",
    "    return state\n",
    "\n",
    "# --- Placeholder nodes ----------------------------------------------------\n",
    "\n",
    "def rules_validator_node(state: AgentState) -> AgentState:\n",
    "    print(\" [ValidatorRules]  not implemented yet\")\n",
    "    return state\n",
    "\n",
    "def reviewer_node(state: AgentState) -> AgentState:\n",
    "    print(\" [ReviewerLLM]  skipped (placeholder)\")\n",
    "    return state\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "def technical_agent_node(state: AgentState) -> AgentState:\n",
    "    # skip if we already have design (specs later)\n",
    "    if state.get(\"solution_design\") is not None:\n",
    "        return state\n",
    "\n",
    "    if not state[\"orchestrator_decision\"].needs_technical:\n",
    "        return state\n",
    "\n",
    "    query_part = state[\"orchestrator_decision\"].query_parts.get(\n",
    "        \"technical\", state[\"user_query\"])\n",
    "    ids = extract_part_numbers(query_part)\n",
    "    if ids:\n",
    "        state[\"technical_results\"] = [get_technical_specs(pid) for pid in ids]\n",
    "    else:\n",
    "        recs = recommend_products.invoke({\"requirements\": query_part, \"max_results\": 5})\n",
    "        state[\"technical_results\"] = [get_technical_specs(r[\"part_number\"]) for r in recs]\n",
    "    return state\n",
    "\n",
    "\n",
    "def pricing_agent_node(state: AgentState) -> AgentState:\n",
    "    if not state[\"orchestrator_decision\"].needs_pricing:\n",
    "        return state\n",
    "\n",
    "    # prefer componentes do design\n",
    "    if isinstance(state.get(\"solution_design\"), SolutionDesign):\n",
    "        items = [{\"pn\": c.part_number, \"qty\": c.quantity} for c in state[\"solution_design\"].components]\n",
    "    else:\n",
    "        ids = extract_part_numbers(state[\"user_query\"])\n",
    "        items = [{\"pn\": i, \"qty\": 1} for i in ids]\n",
    "\n",
    "    state[\"pricing_results\"] = []\n",
    "    for it in items:\n",
    "        info = get_product_price(it[\"pn\"])\n",
    "        info.update({\"quantity\": it[\"qty\"], \"subtotal\": info.get(\"price\", 0) * it[\"qty\"]})\n",
    "        state[\"pricing_results\"].append(info)\n",
    "    return state\n",
    "\n",
    "\n",
    "def synthesize_node(state: AgentState) -> AgentState:\n",
    "    lines: List[str] = []\n",
    "    if isinstance(state.get(\"solution_design\"), SolutionDesign):\n",
    "        d = state[\"solution_design\"]\n",
    "        lines.append(\" Solution Design\\n\" + d.summary)\n",
    "        lines.append(\"\\n Components:\")\n",
    "        for i, c in enumerate(d.components, 1):\n",
    "            lines.append(f\"{i}. {c.part_number} ({c.quantity})  {c.role}\")\n",
    "        if state.get(\"integrity_errors\"):\n",
    "            lines.append(\"\\n Integrity issues:\\n- \" + \"\\n- \".join(state[\"integrity_errors\"]))\n",
    "        lines.append(\"\\n Justification:\\n\" + d.justification)\n",
    "\n",
    "    if state[\"pricing_results\"]:\n",
    "        total = 0.0\n",
    "        currency = \"USD\"\n",
    "        lines.append(\"\\n Pricing:\")\n",
    "        for p in state[\"pricing_results\"]:\n",
    "            if \"error\" in p:\n",
    "                lines.append(f\"- {p.get('part_number')}: {p['error']}\")\n",
    "                continue\n",
    "            currency = p[\"currency\"]\n",
    "            total += p[\"subtotal\"]\n",
    "            lines.append(f\"- {p['description']} ({p['quantity']}): {currency} {p['subtotal']:.2f}\")\n",
    "        lines.append(f\"\\nTOTAL: {currency} {total:.2f}\")\n",
    "\n",
    "    if not lines:\n",
    "        lines.append(\"No relevant information found.\")\n",
    "    state[\"final_response\"] = \"\\n\".join(lines)\n",
    "    return state\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 9. Routing helpers\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "def route_after_orch(state: AgentState):\n",
    "    dec = state[\"orchestrator_decision\"]\n",
    "    if dec.needs_design:\n",
    "        return \"designer\"\n",
    "    if dec.needs_technical:\n",
    "        return \"tech\"\n",
    "    if dec.needs_pricing:\n",
    "        return \"price\"\n",
    "    return \"synth\"\n",
    "\n",
    "def route_after_designer(_):\n",
    "    return \"integrity\"\n",
    "\n",
    "def route_after_integrity(_):\n",
    "    return \"rules\"\n",
    "\n",
    "def route_after_rules(_):\n",
    "    return \"reviewer\"\n",
    "\n",
    "def route_after_reviewer(state: AgentState):\n",
    "    dec = state[\"orchestrator_decision\"]\n",
    "    if dec.needs_technical:\n",
    "        return \"tech\"\n",
    "    if dec.needs_pricing:\n",
    "        return \"price\"\n",
    "    return \"synth\"\n",
    "\n",
    "\n",
    "def route_after_tech(state: AgentState):\n",
    "    return \"price\" if state[\"orchestrator_decision\"].needs_pricing else \"synth\"\n",
    "\n",
    "def route_after_price(_):\n",
    "    return \"synth\"\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 10. Build graph\n",
    "# -------------------------------------------------------------\n",
    "workflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfff8297-6a06-42ad-8cc4-1e6cf6e900ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb568e5-eff7-4eda-9826-0d07482063ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b056aa2-5aef-44f9-8194-dd9ebb44a942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2d4efa-f508-4eb1-bae6-6ac6afce6a47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7a6c161-436c-4e3e-89e8-3508b77a896c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:services.ai_engine.app.core.tools:[product_search_tool] query='whats the price for MR42E-HW' k_faiss=5 k_bm25=5 k_tfidf=5\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Resultado da busca: [{'cisco_product_id': 'MR42-HW', 'commercial_name': 'Meraki MR42 Cloud Managed AP', 'description': '', 'technical_profile': {'category': 'Hardware', 'subcategory': ''}, 'pricing_model': {'base_price': 1099.0, 'currency': 'USD', 'elig_pct': 0.01}}, {'cisco_product_id': 'MR42E-HW', 'commercial_name': 'Meraki MR42E Cloud Managed Indoor AP with External Antennas', 'description': '', 'technical_profile': {'category': 'Hardware', 'subcategory': ''}, 'pricing_model': {'base_price': 1099.0, 'currency': 'USD', 'elig_pct': 0.01}}, {'cisco_product_id': 'MR52-HW', 'commercial_name': 'Meraki MR52 Cloud Managed AP', 'description': '', 'technical_profile': {'category': 'Hardware', 'subcategory': ''}, 'pricing_model': {'base_price': 1399.0, 'currency': 'USD', 'elig_pct': 0.01}}, {'cisco_product_id': 'MR74-HW', 'commercial_name': 'Meraki MR74 Cloud Managed AP', 'description': '', 'technical_profile': {'category': 'Hardware', 'subcategory': ''}, 'pricing_model': {'base_price': 1399.0, 'currency': 'USD', 'elig_pct': 0.01}}, {'cisco_product_id': 'MR33-HW', 'commercial_name': 'Meraki MR33 Cloud Managed AP', 'description': '', 'technical_profile': {'category': 'Hardware', 'subcategory': ''}, 'pricing_model': {'base_price': 649.0, 'currency': 'USD', 'elig_pct': 0.01}}, {'cisco_product_id': 'IR809-DINRAIL', 'commercial_name': 'Din Rail kit for the IR809', 'description': '', 'technical_profile': {'category': 'Hardware', 'subcategory': ''}, 'pricing_model': {'base_price': 75.0, 'currency': 'USD', 'elig_pct': 0.01}}, {'cisco_product_id': 'MEM180X-256D=', 'commercial_name': '256MB SODIMM DRAM for the Cisco 180X', 'description': '', 'technical_profile': {'category': 'Hardware', 'subcategory': ''}, 'pricing_model': {'base_price': 2300.0, 'currency': 'USD', 'elig_pct': 0.01}}, {'cisco_product_id': 'MEM181X-128D=', 'commercial_name': '128MB SODIMM DRAM for the Cisco 181X', 'description': '', 'technical_profile': {'category': 'Hardware', 'subcategory': ''}, 'pricing_model': {'base_price': 1150.0, 'currency': 'USD', 'elig_pct': 0.01}}, {'cisco_product_id': 'MX64-HW', 'commercial_name': 'Meraki MX64 Security Appliance', 'description': '', 'technical_profile': {'category': 'Hardware', 'subcategory': ''}, 'pricing_model': {'base_price': 595.0, 'currency': 'USD', 'elig_pct': 0.01}}, {'cisco_product_id': 'MX64W-HW', 'commercial_name': 'Meraki MX64W Security Appliance', 'description': '', 'technical_profile': {'category': 'Hardware', 'subcategory': ''}, 'pricing_model': {'base_price': 945.0, 'currency': 'USD', 'elig_pct': 0.01}}, {'cisco_product_id': 'MX65-HW', 'commercial_name': 'Meraki MX65 Cloud Managed Security Appliance', 'description': '', 'technical_profile': {'category': 'Hardware', 'subcategory': ''}, 'pricing_model': {'base_price': 945.0, 'currency': 'USD', 'elig_pct': 0.01}}, {'cisco_product_id': 'MX450-HW', 'commercial_name': 'Meraki MX450 Cloud Managed Security Appliance', 'description': '', 'technical_profile': {'category': 'Hardware', 'subcategory': ''}, 'pricing_model': {'base_price': 19995.0, 'currency': 'USD', 'elig_pct': 0.01}}]\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from services.ai_engine.app.core.tools import product_search_tool\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import openai\n",
    "\n",
    "# Configurao de logging para garantir que as mensagens apaream\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Defina a chave da API diretamente no cdigo\n",
    "#openai_api_key = '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'  # Substitua pela sua chave da OpenAI\n",
    "\n",
    "# Defina a chave da API diretamente\n",
    "#openai.api_key = openai_api_key  # Isso define a chave para todas as chamadas OpenAI\n",
    "\n",
    "# Configure o cliente OpenAIEmbeddings com a chave da API diretamente\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "# Teste rpido para realizar a busca\n",
    "try:\n",
    "    # Parmetros para a busca\n",
    "    query = \"whats the price for MR42E-HW\"\n",
    "    params = {\n",
    "        \"query\": query,\n",
    "        \"k_faiss\": 5,  # Nmero de resultados a serem retornados pela busca FAISS\n",
    "        \"k_bm25\": 5,   # Nmero de resultados a serem retornados pela busca BM25\n",
    "        \"k_tfidf\": 5   # Nmero de resultados a serem retornados pela busca TF-IDF\n",
    "    }\n",
    "\n",
    "    # Chama a funo de busca com os parmetros fornecidos\n",
    "    out = product_search_tool.invoke(params)\n",
    "\n",
    "    # Exibe a sada do teste\n",
    "    logging.info(\"Resultado da busca: %s\", out)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(\"Erro durante o teste: %s\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdab7ce-58f5-4cab-9134-5f550d1e00bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run_sales_quote(\n",
    "    \"whats the price for MR42E-HW\"\n",
    "))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
