{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78a41cde-9a88-41fa-a461-bf4093e2cdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyterlab in c:\\users\\giovani\\anaconda3\\lib\\site-packages (4.2.5)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\giovani\\anaconda3\\lib\\site-packages (0.3.0)\n",
      "Requirement already satisfied: langchain in c:\\users\\giovani\\anaconda3\\lib\\site-packages (0.3.14)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-1.0.15-cp39-abi3-win_amd64.whl.metadata (7.1 kB)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-5.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting unstructured\n",
      "  Downloading unstructured-0.18.5-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\giovani\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyterlab) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyterlab) (0.27.2)\n",
      "Requirement already satisfied: ipykernel>=6.5.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyterlab) (6.28.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyterlab) (3.1.4)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyterlab) (5.7.2)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyterlab) (2.2.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyterlab) (2.14.1)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyterlab) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyterlab) (0.2.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyterlab) (24.1)\n",
      "Requirement already satisfied: setuptools>=40.1.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyterlab) (75.1.0)\n",
      "Requirement already satisfied: tornado>=6.2.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyterlab) (6.4.1)\n",
      "Requirement already satisfied: traitlets in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyterlab) (5.14.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain-openai) (0.3.29)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain-openai) (1.61.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain-openai) (0.8.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain) (3.10.5)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain) (0.3.5)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.17 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain) (0.2.10)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain) (2.10.5)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Collecting langchain-core<0.4.0,>=0.3.29 (from langchain-openai)\n",
      "  Downloading langchain_core-0.3.68-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.26-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain-community) (2.6.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting pybase64>=1.4.1 (from chromadb)\n",
      "  Downloading pybase64-1.4.1-cp312-cp312-win_amd64.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from chromadb) (3.7.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from chromadb) (4.12.2)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.22.1-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.35.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from chromadb) (0.19.1)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from chromadb) (4.66.5)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from chromadb) (7.4.0)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from chromadb) (1.69.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.3.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from chromadb) (0.9.0)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.1.0-cp312-cp312-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from chromadb) (3.10.14)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from chromadb) (13.7.1)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from chromadb) (4.23.0)\n",
      "Requirement already satisfied: chardet in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from unstructured) (4.0.0)\n",
      "Requirement already satisfied: filetype in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from unstructured) (1.2.0)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: lxml in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from unstructured) (5.3.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from unstructured) (3.9.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from unstructured) (4.12.3)\n",
      "Collecting emoji (from unstructured)\n",
      "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Downloading python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langdetect (from unstructured)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     ------------------------------------- 981.5/981.5 kB 11.4 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting rapidfuzz (from unstructured)\n",
      "  Downloading rapidfuzz-3.13.0-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: backoff in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from unstructured) (2.2.1)\n",
      "Collecting unstructured-client (from unstructured)\n",
      "  Downloading unstructured_client-0.38.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: wrapt in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from unstructured) (1.14.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from unstructured) (5.9.0)\n",
      "Collecting python-oxmsg (from unstructured)\n",
      "  Downloading python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting html5lib (from unstructured)\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.0)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from httpx>=0.25.0->jupyterlab) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from httpx>=0.25.0->jupyterlab) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from httpx>=0.25.0->jupyterlab) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from httpx>=0.25.0->jupyterlab) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from httpx>=0.25.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab) (0.14.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab) (0.2.1)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab) (1.6.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab) (8.27.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab) (8.6.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab) (1.6.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab) (25.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jinja2>=3.0.3->jupyterlab) (2.1.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.10.6)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyter-core->jupyterlab) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyter-core->jupyterlab) (305.1)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (21.3.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.4.4)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.16.4)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (5.10.4)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.14.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (2.0.10)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.17.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.16.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (0.9.6)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.37.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting langsmith>=0.1.125 (from langchain-community)\n",
      "  Downloading langsmith-0.4.5-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-openai) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.6)\n",
      "Requirement already satisfied: sympy in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (7.0.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.35.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.35.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.35.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.35.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading protobuf-6.31.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting opentelemetry-semantic-conventions==0.56b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.15.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2023.12.25)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.28.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.4-cp312-cp312-win_amd64.whl.metadata (3.7 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.1.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-15.0.1-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from beautifulsoup4->unstructured) (2.5)\n",
      "Requirement already satisfied: webencodings in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from html5lib->unstructured) (0.5.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from nltk->unstructured) (1.4.2)\n",
      "Collecting olefile (from python-oxmsg->unstructured)\n",
      "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from unstructured-client->unstructured) (24.1.0)\n",
      "Requirement already satisfied: cryptography>=3.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from unstructured-client->unstructured) (43.0.0)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached protobuf-5.29.5-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: filelock in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (3.0.43)\n",
      "Requirement already satisfied: stack-data in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain-openai) (2.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.0)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.8.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.16.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.21)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.8.3)\n",
      "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab)\n",
      "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab)\n",
      "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab)\n",
      "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting webcolors>=24.6.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab)\n",
      "  Downloading webcolors-24.11.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.5)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n",
      "Requirement already satisfied: executing in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.2)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.2.3)\n",
      "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 18.1 MB/s eta 0:00:00\n",
      "Downloading langchain-0.3.26-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 24.2 MB/s eta 0:00:00\n",
      "Downloading chromadb-1.0.15-cp39-abi3-win_amd64.whl (19.5 MB)\n",
      "   ---------------------------------------- 0.0/19.5 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 8.1/19.5 MB 38.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 17.8/19.5 MB 43.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  19.4/19.5 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 19.5/19.5 MB 24.2 MB/s eta 0:00:00\n",
      "Downloading pypdf-5.8.0-py3-none-any.whl (309 kB)\n",
      "Downloading unstructured-0.18.5-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/1.8 MB 16.3 MB/s eta 0:00:00\n",
      "Downloading bcrypt-4.3.0-cp39-abi3-win_amd64.whl (152 kB)\n",
      "Downloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.9/1.9 MB 35.7 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.68-py3-none-any.whl (441 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading langsmith-0.4.5-py3-none-any.whl (367 kB)\n",
      "Downloading mmh3-5.1.0-cp312-cp312-win_amd64.whl (41 kB)\n",
      "Downloading onnxruntime-1.22.1-cp312-cp312-win_amd64.whl (12.7 MB)\n",
      "   ---------------------------------------- 0.0/12.7 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 6.6/12.7 MB 33.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.7 MB 34.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.7/12.7 MB 28.4 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_api-1.35.0-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.35.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.35.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.35.0-py3-none-any.whl (72 kB)\n",
      "Downloading opentelemetry_sdk-1.35.0-py3-none-any.whl (119 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl (201 kB)\n",
      "Downloading pybase64-1.4.1-cp312-cp312-win_amd64.whl (36 kB)\n",
      "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "   ---------------------------------------- 0.0/590.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 590.6/590.6 kB 10.6 MB/s eta 0:00:00\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
      "Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
      "Downloading rapidfuzz-3.13.0-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 28.8 MB/s eta 0:00:00\n",
      "Downloading unstructured_client-0.38.1-py3-none-any.whl (212 kB)\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 36.0 MB/s eta 0:00:00\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading httptools-0.6.4-cp312-cp312-win_amd64.whl (88 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Using cached protobuf-5.29.5-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading watchfiles-1.1.0-cp312-cp312-win_amd64.whl (292 kB)\n",
      "Downloading websockets-15.0.1-cp312-cp312-win_amd64.whl (176 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading webcolors-24.11.1-py3-none-any.whl (14 kB)\n",
      "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: pypika, langdetect\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53916 sha256=88986612cbfd8c4cfd5264d8db4e1ec1bed0ed31d67dbae47b1dae40d3f24dd1\n",
      "  Stored in directory: c:\\users\\giovani\\appdata\\local\\pip\\cache\\wheels\\d5\\3d\\69\\8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993251 sha256=1fcd098624e9bf9e517be4a404c9f84ed1928f1ce5b6934cb32e85715a57b9b2\n",
      "  Stored in directory: c:\\users\\giovani\\appdata\\local\\pip\\cache\\wheels\\c1\\67\\88\\e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
      "Successfully built pypika langdetect\n",
      "Installing collected packages: pypika, durationpy, websockets, webcolors, uri-template, typing-inspection, typing-inspect, rapidfuzz, python-magic, python-iso639, pyreadline3, pyproject_hooks, pypdf, pydantic-core, pybase64, protobuf, olefile, oauthlib, mmh3, marshmallow, langdetect, importlib-resources, httptools, html5lib, fqdn, emoji, bcrypt, watchfiles, requests-oauthlib, python-oxmsg, pydantic, opentelemetry-proto, opentelemetry-api, humanfriendly, dataclasses-json, build, unstructured-client, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, langsmith, kubernetes, isoduration, coloredlogs, unstructured, opentelemetry-sdk, onnxruntime, langchain-core, opentelemetry-exporter-otlp-proto-grpc, langchain-text-splitters, langchain, chromadb, langchain-community\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.27.2\n",
      "    Uninstalling pydantic_core-2.27.2:\n",
      "      Successfully uninstalled pydantic_core-2.27.2\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.6\n",
      "    Uninstalling protobuf-4.25.6:\n",
      "      Successfully uninstalled protobuf-4.25.6\n",
      "  Attempting uninstall: bcrypt\n",
      "    Found existing installation: bcrypt 3.2.0\n",
      "    Uninstalling bcrypt-3.2.0:\n",
      "      Successfully uninstalled bcrypt-3.2.0\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.10.5\n",
      "    Uninstalling pydantic-2.10.5:\n",
      "      Successfully uninstalled pydantic-2.10.5\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.2.10\n",
      "    Uninstalling langsmith-0.2.10:\n",
      "      Successfully uninstalled langsmith-0.2.10\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.29\n",
      "    Uninstalling langchain-core-0.3.29:\n",
      "      Successfully uninstalled langchain-core-0.3.29\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 0.3.5\n",
      "    Uninstalling langchain-text-splitters-0.3.5:\n",
      "      Successfully uninstalled langchain-text-splitters-0.3.5\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.3.14\n",
      "    Uninstalling langchain-0.3.14:\n",
      "      Successfully uninstalled langchain-0.3.14\n",
      "Successfully installed bcrypt-4.3.0 build-1.2.2.post1 chromadb-1.0.15 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.10 emoji-2.14.1 fqdn-1.5.1 html5lib-1.1 httptools-0.6.4 humanfriendly-10.0 importlib-resources-6.5.2 isoduration-20.11.0 kubernetes-33.1.0 langchain-0.3.26 langchain-community-0.3.27 langchain-core-0.3.68 langchain-text-splitters-0.3.8 langdetect-1.0.9 langsmith-0.4.5 marshmallow-3.26.1 mmh3-5.1.0 oauthlib-3.3.1 olefile-0.47 onnxruntime-1.22.1 opentelemetry-api-1.35.0 opentelemetry-exporter-otlp-proto-common-1.35.0 opentelemetry-exporter-otlp-proto-grpc-1.35.0 opentelemetry-proto-1.35.0 opentelemetry-sdk-1.35.0 opentelemetry-semantic-conventions-0.56b0 protobuf-5.29.5 pybase64-1.4.1 pydantic-2.11.7 pydantic-core-2.33.2 pypdf-5.8.0 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 python-iso639-2025.2.18 python-magic-0.4.27 python-oxmsg-0.0.2 rapidfuzz-3.13.0 requests-oauthlib-2.0.0 typing-inspect-0.9.0 typing-inspection-0.4.1 unstructured-0.18.5 unstructured-client-0.38.1 uri-template-1.3.0 watchfiles-1.1.0 webcolors-24.11.1 websockets-15.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Giovani\\anaconda3\\Lib\\site-packages\\~ydantic_core'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.37.1 requires pillow<11,>=7.1.0, but you have pillow 11.0.0 which is incompatible.\n",
      "tensorflow-intel 2.16.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.5 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install jupyterlab langchain-openai langchain langchain-community chromadb pypdf unstructured python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286b4d3e-01cf-4524-a9e2-5da7003766f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "\n",
    "# --- Configuration ---\n",
    "# This script will create a set of rich, interconnected dummy data\n",
    "# to populate the data/raw folder of the project structure.\n",
    "\n",
    "# Root directory for all raw data\n",
    "RAW_DATA_PATH = 'data/raw'\n",
    "\n",
    "# --- Data Definitions ---\n",
    "\n",
    "# 1. Product Catalog\n",
    "product_catalog_data = [\n",
    "    {'sku': 'C9300-24P', 'name': 'Catalyst 9300 24-port PoE+', 'category': 'Switch', 'description': 'Enterprise-grade stackable access switch, foundational for SD-Access.'},\n",
    "    {'sku': 'C9300-DNA-A-3Y', 'name': 'Cisco DNA Advantage, 3Y', 'category': 'Software License', 'description': '3-year DNA Advantage subscription for Catalyst 9300 series.'},\n",
    "    {'sku': 'FPR1120-ASA-K9', 'name': 'Firepower 1120 ASA', 'category': 'Firewall', 'description': 'NGFW for small to medium-sized businesses and branch offices.'},\n",
    "    {'sku': 'MER-MR46-HW', 'name': 'Meraki MR46', 'category': 'Access Point', 'description': 'Cloud-managed Wi-Fi 6 access point with 4x4:4 MIMO.'},\n",
    "    {'sku': 'LIC-MR-ENT-1Y', 'name': 'Meraki MR Enterprise License, 1Y', 'category': 'Cloud License', 'description': '1-year enterprise cloud management license for MR access points.'},\n",
    "    {'sku': 'CP-8841-K9', 'name': 'IP Phone 8841', 'category': 'Collaboration', 'description': '5-inch widescreen VGA display IP phone with 5 programmable line keys.'},\n",
    "    {'sku': 'GLC-TE', 'name': '1000BASE-T SFP Transceiver', 'category': 'Transceiver', 'description': 'SFP transceiver module for Category 5 copper wire.'}\n",
    "]\n",
    "\n",
    "# 2. Price List\n",
    "price_list_data = [\n",
    "    {'sku': 'C9300-24P', 'list_price_usd': 4500, 'partner_price_usd': 2700},\n",
    "    {'sku': 'C9300-DNA-A-3Y', 'list_price_usd': 1200, 'partner_price_usd': 720},\n",
    "    {'sku': 'FPR1120-ASA-K9', 'list_price_usd': 2800, 'partner_price_usd': 1680},\n",
    "    {'sku': 'MER-MR46-HW', 'list_price_usd': 950, 'partner_price_usd': 665},\n",
    "    {'sku': 'LIC-MR-ENT-1Y', 'list_price_usd': 150, 'partner_price_usd': 120},\n",
    "    {'sku': 'CP-8841-K9', 'list_price_usd': 320, 'partner_price_usd': 240},\n",
    "    {'sku': 'GLC-TE', 'list_price_usd': 100, 'partner_price_usd': 55}\n",
    "]\n",
    "\n",
    "# 3. Compatibility Rules\n",
    "compatibility_rules_data = {\n",
    "    \"C9300-24P\": {\n",
    "        \"requires\": [\"C9300-DNA-A-3Y\"],\n",
    "        \"supports\": [\"GLC-TE\"],\n",
    "        \"incompatible_with\": []\n",
    "    },\n",
    "    \"MER-MR46-HW\": {\n",
    "        \"requires\": [\"LIC-MR-ENT-1Y\"],\n",
    "        \"supports\": [],\n",
    "        \"incompatible_with\": [\"C9300-DNA-A-3Y\"]\n",
    "    },\n",
    "    \"FPR1120-ASA-K9\": {\n",
    "        \"requires\": [],\n",
    "        \"supports\": [\"GLC-TE\"],\n",
    "        \"incompatible_with\": []\n",
    "    }\n",
    "}\n",
    "\n",
    "# 4. Solution Guide for Healthcare\n",
    "healthcare_guide_content = \"\"\"\n",
    "# Solution Guide: Healthcare Clinic Network Refresh\n",
    "\n",
    "## Overview\n",
    "A healthcare clinic requires a highly reliable, secure, and HIPAA-compliant network infrastructure. Key requirements include secure Wi-Fi for staff and guests, robust firewalling to protect patient data (EHR), and reliable voice communication.\n",
    "\n",
    "## Recommended Components\n",
    "- **Switching:** The Catalyst 9300 series (e.g., C9300-24P) is recommended for the core network due to its advanced security features and stacking capabilities. A Cisco DNA Advantage license is mandatory for full functionality.\n",
    "- **Wireless:** For clinical areas, Meraki cloud-managed Wi-Fi 6 access points like the MR46 provide secure and easy-to-manage wireless connectivity. A separate guest SSID can be configured with traffic shaping rules.\n",
    "- **Security:** A next-generation firewall such as the Firepower 1000 series (e.g., FPR1120-ASA-K9) is essential for threat defense and intrusion prevention.\n",
    "- **Collaboration:** Cisco IP Phones from the 8800 series (e.g., CP-8841-K9) offer reliable voice and video communication suitable for reception and clinical staff.\n",
    "\"\"\"\n",
    "\n",
    "# 5. Enterprise Agreement for Healthcare\n",
    "healthcare_ea_data = {\n",
    "    \"agreement_name\": \"Healthcare Kickstart EA\",\n",
    "    \"target_segment\": \"Healthcare\",\n",
    "    \"minimum_user_count\": 50,\n",
    "    \"included_product_families\": [\"Catalyst 9300 Series\", \"Meraki MR Series\", \"Firepower 1000 Series\"],\n",
    "    \"default_discount_percentage\": {\n",
    "        \"hardware\": 45,\n",
    "        \"software\": 30\n",
    "    },\n",
    "    \"included_support_tier\": \"Solution Support\"\n",
    "}\n",
    "\n",
    "# 6. Historical Quotes for ML Training\n",
    "historical_quotes_data = [\n",
    "    {'quote_id': 'Q1-2023-001', 'customer_segment': 'Healthcare', 'total_list_price': 8500, 'final_discount_pct': 42, 'products_sku': 'C9300-24P;FPR1120-ASA-K9', 'won': 'Yes'},\n",
    "    {'quote_id': 'Q1-2023-002', 'customer_segment': 'Retail', 'total_list_price': 3500, 'final_discount_pct': 35, 'products_sku': 'MER-MR46-HW;LIC-MR-ENT-1Y', 'won': 'Yes'},\n",
    "    {'quote_id': 'Q1-2023-003', 'customer_segment': 'Healthcare', 'total_list_price': 9500, 'final_discount_pct': 50, 'products_sku': 'C9300-24P;FPR1120-ASA-K9', 'won': 'No'},\n",
    "    {'quote_id': 'Q2-2023-004', 'customer_segment': 'Finance', 'total_list_price': 15000, 'final_discount_pct': 40, 'products_sku': 'C9300-24P;C9300-DNA-A-3Y;CP-8841-K9', 'won': 'Yes'}\n",
    "]\n",
    "\n",
    "\n",
    "# --- File Writing Logic ---\n",
    "\n",
    "def create_files():\n",
    "    \"\"\"Creates the directories and files with the defined data.\"\"\"\n",
    "    print(f\"Creating dummy data in '{RAW_DATA_PATH}'...\")\n",
    "\n",
    "    # Define paths for all subdirectories\n",
    "    paths = {\n",
    "        \"guides\": os.path.join(RAW_DATA_PATH, 'solution_guides'),\n",
    "        \"eas\": os.path.join(RAW_DATA_PATH, 'enterprise_agreements'),\n",
    "        \"quotes\": os.path.join(RAW_DATA_PATH, 'historical_quotes')\n",
    "    }\n",
    "\n",
    "    # Create directories if they don't exist\n",
    "    for path in paths.values():\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    # 1. Write product_catalog.csv\n",
    "    with open(os.path.join(RAW_DATA_PATH, 'product_catalog.csv'), 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=product_catalog_data[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(product_catalog_data)\n",
    "    print(\" -> 'product_catalog.csv' created.\")\n",
    "    \n",
    "    # 2. Write price_list.csv\n",
    "    with open(os.path.join(RAW_DATA_PATH, 'price_list.csv'), 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=price_list_data[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(price_list_data)\n",
    "    print(\" -> 'price_list.csv' created.\")\n",
    "\n",
    "    # 3. Write compatibility_rules.json\n",
    "    with open(os.path.join(RAW_DATA_PATH, 'compatibility_rules.json'), 'w', encoding='utf-8') as f:\n",
    "        json.dump(compatibility_rules_data, f, indent=4)\n",
    "    print(\" -> 'compatibility_rules.json' created.\")\n",
    "\n",
    "    # 4. Write healthcare_solution.txt\n",
    "    with open(os.path.join(paths['guides'], 'healthcare_solution.txt'), 'w', encoding='utf-8') as f:\n",
    "        f.write(healthcare_guide_content)\n",
    "    print(\" -> 'healthcare_solution.txt' created.\")\n",
    "\n",
    "    # 5. Write healthcare_ea.json\n",
    "    with open(os.path.join(paths['eas'], 'healthcare_ea.json'), 'w', encoding='utf-8') as f:\n",
    "        json.dump(healthcare_ea_data, f, indent=4)\n",
    "    print(\" -> 'healthcare_ea.json' created.\")\n",
    "\n",
    "    # 6. Write historical_quotes.csv\n",
    "    with open(os.path.join(paths['quotes'], 'quotes_2023.csv'), 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=historical_quotes_data[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(historical_quotes_data)\n",
    "    print(\" -> 'quotes_2023.csv' created.\")\n",
    "    \n",
    "    print(\"\\nDummy data creation complete!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a63efeaa-6188-4a55-93f5-16606808f419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Carregando, dividindo e vetorizando os dados... ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "100%|██████████| 1/1 [00:09<00:00,  9.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos carregados: 8\n",
      "Documentos divididos em 10 chunks.\n",
      "Base de conhecimento criada e salva em 'data/processed/vector_store'.\n"
     ]
    }
   ],
   "source": [
    "# Define os caminhos relativos à raiz do projeto\n",
    "raw_data_path = 'data/raw'\n",
    "vector_store_path = 'data/processed/vector_store'\n",
    "\n",
    "print(\"--- Carregando, dividindo e vetorizando os dados... ---\")\n",
    "\n",
    "# 1. Carrega os documentos\n",
    "csv_loader = CSVLoader(file_path=f'{raw_data_path}/product_catalog.csv')\n",
    "text_loader = DirectoryLoader(path=f'{raw_data_path}/solution_guides/', glob=\"**/*.txt\", show_progress=True)\n",
    "all_docs = csv_loader.load() + text_loader.load()\n",
    "print(f\"Documentos carregados: {len(all_docs)}\")\n",
    "\n",
    "# 2. Divide os documentos\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "splits = text_splitter.split_documents(all_docs)\n",
    "print(f\"Documentos divididos em {len(splits)} chunks.\")\n",
    "\n",
    "# 3. Cria e persiste o Vector Store\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    "    persist_directory=vector_store_path  # Salva o DB no disco para uso futuro\n",
    ")\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "print(f\"Base de conhecimento criada e salva em '{vector_store_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2cb45a-396e-4129-a1bd-b1849ee77a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "919b5226-40fd-46f0-b272-950108e395e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Construindo a cadeia RAG e testando... ---\n",
      "\n",
      "--- Question ---\n",
      "What do you recommend for a small office that needs security and easy management?\n",
      "\n",
      "--- Generating AI Response ---\n",
      "For a small office that needs security and easy management, I recommend the following Cisco products:\n",
      "\n",
      "1. **Security:** The Firepower 1120 ASA (SKU: FPR1120-ASA-K9) is a next-generation firewall suitable for small to medium-sized businesses. It provides essential threat defense and intrusion prevention capabilities.\n",
      "\n",
      "2. **Wireless:** Consider using Meraki cloud-managed Wi-Fi 6 access points like the MR46. These access points offer secure and easy-to-manage wireless connectivity, which is ideal for small office environments.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Construindo a cadeia RAG e testando... ---\")\n",
    "\n",
    "# Define o LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.1)\n",
    "\n",
    "# Define o Prompt\n",
    "prompt_template = \"\"\"\n",
    "You are an expert Cisco product assistant. Your role is to help a salesperson create a quote.\n",
    "Use ONLY the context provided below to answer the question. Do not make up products or information.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Salesperson's Question:\n",
    "{question}\n",
    "\n",
    "Expert Answer:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# Constrói a cadeia RAG\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# ---- TESTE ----\n",
    "query = \"What do you recommend for a small office that needs security and easy management?\"\n",
    "print(f\"\\n--- Question ---\\n{query}\\n\")\n",
    "print(\"--- Generating AI Response ---\")\n",
    "\n",
    "# Invoca a cadeia\n",
    "response = rag_chain.invoke(query)\n",
    "\n",
    "# Imprime a resposta\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1129bd92-cb67-4c19-aa91-96bab2647829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91858f3d-9a9e-42b6-ac67-a15387217bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90443b44-2288-43c9-bafe-1fead085012c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26d12bc9-9023-42ae-979a-e87d762439a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chave da OpenAI carregada com sucesso.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import CSVLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Carrega as variáveis do arquivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Verifica se a chave foi carregada com sucesso\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\"Chave da OpenAI (OPENAI_API_KEY) não encontrada. Verifique seu arquivo .env na raiz do projeto.\")\n",
    "else:\n",
    "    print(\"Chave da OpenAI carregada com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7d1804-f492-4450-b981-4d7ea5fb9696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7829fa79-da3a-477c-b8f8-8af7a49dda99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 12:19:27,497 - INFO - Initializing CiscoRAGService...\n",
      "2025-07-13 12:19:27,498 - INFO - Loading documents from source...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initializing the full AI Service ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]2025-07-13 12:19:27,506 - WARNING - libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "100%|██████████| 1/1 [00:00<00:00, 78.52it/s]\n",
      "2025-07-13 12:19:27,518 - INFO - Loaded 8 documents.\n",
      "2025-07-13 12:19:27,518 - INFO - Splitting documents into chunks...\n",
      "2025-07-13 12:19:27,521 - INFO - Documents split into 10 chunks.\n",
      "2025-07-13 12:19:27,522 - INFO - Creating and persisting Vector Store...\n",
      "2025-07-13 12:19:29,244 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "2025-07-13 12:19:30,899 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-07-13 12:19:31,378 - INFO - Vector Store created at: data/processed/vector_store\n",
      "2025-07-13 12:19:32,458 - INFO - RAG Service initialized successfully.\n",
      "2025-07-13 12:19:32,458 - INFO - Received new query: What do you recommend for a small office that needs security and easy management?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Service Initialized ---\n",
      "\n",
      "--- Sending Query to the Service ---\n",
      "What do you recommend for a small office that needs security and easy management?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 12:19:32,987 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-07-13 12:19:36,783 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-13 12:19:36,802 - INFO - Response generated successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- AI Response ---\n",
      "For a small office that requires security and easy management, I recommend the following components:\n",
      "\n",
      "1. **Switching:** Use the **Catalyst 9300 series** (e.g., **C9300-24P**) for the core network. This switch offers advanced security features and stacking capabilities, which are beneficial for managing network traffic efficiently.\n",
      "\n",
      "2. **Wireless:** Implement **Meraki cloud-managed Wi-Fi 6 access points** like the **MR46**. These access points provide secure wireless connectivity and are easy to manage through the Meraki dashboard. Additionally, you can configure a separate guest SSID with traffic shaping rules to enhance network performance.\n",
      "\n",
      "3. **Security:** Deploy a **next-generation firewall** such as the **Firepower 1000 series** (e.g., **FPR1120-ASA-K9**). This firewall is essential for threat defense and intrusion prevention, ensuring that your office network remains secure.\n",
      "\n",
      "These recommendations focus on providing robust security while ensuring ease of management, making them ideal for a small office environment.\n"
     ]
    }
   ],
   "source": [
    "# Importa a classe usando o novo nome da pasta com underscore\n",
    "from services.ai_engine.app.core.rag_service import CiscoRAGService\n",
    "\n",
    "print(\"--- Initializing the full AI Service ---\")\n",
    "# Cria uma instância do nosso serviço.\n",
    "rag_service = CiscoRAGService()\n",
    "print(\"--- Service Initialized ---\")\n",
    "\n",
    "\n",
    "# Agora, vamos testar o serviço\n",
    "query = \"What do you recommend for a small office that needs security and easy management?\"\n",
    "print(f\"\\n--- Sending Query to the Service ---\\n{query}\\n\")\n",
    "\n",
    "# Usa o método da nossa classe para gerar a resposta\n",
    "response = rag_service.generate_response(query)\n",
    "\n",
    "print(\"--- AI Response ---\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea23d354-6664-4d6d-885d-51020acea4cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27560c9e-8b65-4099-a6d3-6a61b83c857c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5506c425-2cf2-4d2c-8352-a500b27f6464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 1: Instalar as bibliotecas necessárias\n",
    "# beautifulsoup4 é usado pelo WebBaseLoader para processar o HTML\n",
    "!pip install -q -U langchain-openai langchain chromadb beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb46a8ae-acd1-4a22-8989-f62b3619deb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Usando como base de conhecimento a URL: https://meraki.cisco.com/products/security-sd-wan/ ---\n",
      "1. Carregando conteúdo da web...\n",
      "2. Criando base de conhecimento em memória...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 13:39:39,384 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Construindo a cadeia de IA...\n",
      "4. Executando a consulta...\n",
      "\n",
      "--- Pergunta ---\n",
      "What are the main features of the Meraki MX security appliances according to this page?\n",
      "\n",
      "--- Gerando Resposta da IA ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 13:39:41,559 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-07-13 13:39:43,317 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# --- CONFIGURAÇÃO ---\n",
    "# ⚠️ Cole sua chave de API da OpenAI aqui\n",
    "OPENAI_API_KEY = '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'\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "\n",
    "# URL da página da Cisco que usaremos como base de conhecimento\n",
    "# Exemplo: página da família de firewalls Meraki MX\n",
    "url = \"https://meraki.cisco.com/products/security-sd-wan/\"\n",
    "print(f\"--- Usando como base de conhecimento a URL: {url} ---\")\n",
    "\n",
    "\n",
    "# --- INÍCIO DO PROCESSO RAG ---\n",
    "\n",
    "# 1. Carregar o conteúdo da página web\n",
    "print(\"1. Carregando conteúdo da web...\")\n",
    "loader = WebBaseLoader(url)\n",
    "docs = loader.load()\n",
    "\n",
    "# 2. Dividir o conteúdo em pedaços e criar a base vetorial em memória\n",
    "print(\"2. Criando base de conhecimento em memória...\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 3. Construir a cadeia de resposta\n",
    "print(\"3. Construindo a cadeia de IA...\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "prompt_template = \"\"\"You are a helpful assistant. Answer the user's question based ONLY on the following context.\n",
    "If the information is not in the context, say that you don't know.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | llm | StrOutputParser()\n",
    "\n",
    "# 4. Fazer a pergunta e obter a resposta\n",
    "print(\"4. Executando a consulta...\")\n",
    "query = \"What are the main features of the Meraki MX security appliances according to this page?\"\n",
    "\n",
    "print(f\"\\n--- Pergunta ---\\n{query}\")\n",
    "print(\"\\n--- Gerando Resposta da IA ---\")\n",
    "response = rag_chain.invoke(query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca14ad85-0fcc-47a0-84f8-84160bf3f70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Carregando conteúdo da web...\n",
      "\n",
      "--- INÍCIO DO CONTEÚDO BRUTO EXTRAÍDO (primeiros 2000 caracteres) ---\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Enterprise Network Security and SD-WAN | Cloud-Managed Solutions | Cisco Meraki\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Skip to primary navigation Skip to main content\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to content\n",
      "Skip to footer\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "United States (English)\n",
      "\n",
      "\n",
      "Australia (English)Brazil (Português)Canada (Français)China (简体字)France (Français)Germany (Deutsch)Japan (日本語)Korea (한국인)Latin America (Español)United Kingdom (English)United States (English)Contact usLog In\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Experiences\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Technologies\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Touchpoints\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Resources\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                        Get a Demo\n",
      "                    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Quick Links\n",
      "\n",
      "\n",
      "All\n",
      "Product\n",
      "Case\n",
      "Collateral\n",
      "Webinars\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Experiences\n",
      "From hybrid workforces to smarter workspaces, bring together technology and touchpoints to deliver exceptional experiences.\n",
      " LEARN MORE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Experiences\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Workforce\n",
      "\n",
      "\n",
      "\n",
      "Hybrid WorkforceEnable teams with superior performance no matter the environment. \n",
      "\n",
      "\n",
      "\n",
      "Remote WorkforceEnable your workforce with the tools for success.Workspace\n",
      "\n",
      "\n",
      "\n",
      "Safe EnvironmentsProtect and securely connect what matters most, regardless of location.\n",
      "\n",
      "\n",
      "\n",
      "Smart SpacesFrom contact tracing to footpath optimization, create the office of the future. \n",
      "\n",
      "\n",
      "Cloud-managed IT\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Technologies\n",
      "Deliver exceptional experiences to people, places, and things with best-in-class Meraki technologies.\n",
      " LEARN MORE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Technologies\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Platform\n",
      "\n",
      "\n",
      "\n",
      "PlatformThe cloud-first foundation for your entire network.\n",
      "\n",
      "\n",
      "\n",
      "Meraki DashboardMonitor, manage, and optimize your network.  \n",
      "\n",
      "\n",
      "\n",
      "SASEConverge networking and security stacks.Access Products\n",
      "\n",
      "\n",
      "\n",
      "Wireless\n",
      "\n",
      "\n",
      "\n",
      "Switching\n",
      "\n",
      "\n",
      "\n",
      "Mobile Device ManagementIoT Products\n",
      "\n",
      "\n",
      "\n",
      "Smart Cameras\n",
      "\n",
      "\n",
      "\n",
      "SensorsSecure SD-WAN Products\n",
      "\n",
      "\n",
      "\n",
      "Security and SD-WAN\n",
      "\n",
      "\n",
      "\n",
      "Assurance\n",
      "\n",
      "\n",
      "\n",
      "Hybrid Cloud\n",
      "\n",
      "\n",
      "\n",
      "Unified SASE\n",
      "\n",
      "\n",
      "\n",
      "Cellular Gateways\n",
      "\n",
      "\n",
      "View all products\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Touchpoints\n",
      "Think beyond endpoint devices to all the people, places, and things connecting with the web.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "To\n",
      "--- FIM DO CONTEÚDO BRUTO EXTRAÍDO ---\n",
      "\n",
      "2. Criando base de conhecimento em memória...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 13:42:08,744 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- CONTEXTO RECUPERADO PARA A PERGUNTA: 'What are the main features of the Meraki MX security appliances according to this page?' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 13:42:10,251 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- CHUNK RELEVANTE 1 ---\n",
      "\n",
      "Instant, always-on visibility for critical SaaS apps at scale.\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tProactive monitoring \t\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\t\t\t\tIdentify problems before users are impacted, whether apps are in use or not.\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tSmart root-cause analysis \t\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\t\t\t\tML-powered corrective recommendations, including confidence ratings across LAN, WAN, and app servers.\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\tTRY IT ON \t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Resource Hub\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Datasheet\n",
      "\n",
      "\n",
      "MX family datasheet\n",
      "\n",
      "Learn more about the multifunctional network security and SD-WAN building blocks of a SASE architecture.\n",
      "\n",
      "\n",
      "Learn more\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Webinar\n",
      "\n",
      "\n",
      "Introduction to Cisco Meraki Security and SD-WAN\n",
      "\n",
      "Hear about the security and SD-WAN features of Meraki MX appliances and get a deep-dive demo.\n",
      "\n",
      "\n",
      "Learn More \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "At-a-Glance\n",
      "\n",
      "\n",
      "Cisco SD-WAN powered by Meraki overview\n",
      "\n",
      "--- CHUNK RELEVANTE 2 ---\n",
      "\n",
      "Instant, always-on visibility for critical SaaS apps at scale.\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tProactive monitoring \t\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\t\t\t\tIdentify problems before users are impacted, whether apps are in use or not.\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tSmart root-cause analysis \t\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\t\t\t\tML-powered corrective recommendations, including confidence ratings across LAN, WAN, and app servers.\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\tTRY IT ON \t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Resource Hub\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Datasheet\n",
      "\n",
      "\n",
      "MX family datasheet\n",
      "\n",
      "Learn more about the multifunctional network security and SD-WAN building blocks of a SASE architecture.\n",
      "\n",
      "\n",
      "Learn more\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Webinar\n",
      "\n",
      "\n",
      "Introduction to Cisco Meraki Security and SD-WAN\n",
      "\n",
      "Hear about the security and SD-WAN features of Meraki MX appliances and get a deep-dive demo.\n",
      "\n",
      "\n",
      "Learn More \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "At-a-Glance\n",
      "\n",
      "\n",
      "Cisco SD-WAN powered by Meraki overview\n",
      "\n",
      "--- CHUNK RELEVANTE 3 ---\n",
      "\n",
      "Hear about the security and SD-WAN features of Meraki MX appliances and get a deep-dive demo.\n",
      "\n",
      "\n",
      "Learn More \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "At-a-Glance\n",
      "\n",
      "\n",
      "Cisco SD-WAN powered by Meraki overview\n",
      "\n",
      "Get SD-WAN defined along with key use cases and a view of how SD-WAN powered by Meraki works.\n",
      "\n",
      "\n",
      "Learn more\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Blog\n",
      "\n",
      "\n",
      "When to use on-premises or cloud security?\n",
      "\n",
      "Discover the best practices for building a cloud-enabled network security model.\n",
      "\n",
      "\n",
      "Learn more\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Nothing but the best for all your locations\n",
      "Choose a best-fit mix of secure Cisco Meraki and Catalyst SD-WAN, and streamline management with a single dashboard.\n",
      "\n",
      "\n",
      "Try it now\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Keeping 150+ locations secure and connected while reducing costs with SD-WAN.\n",
      "\n",
      "Cisco SD-WAN powered by Meraki provides branches with 20x more bandwidth and 4G backup\n",
      "20% savings on WAN after replacing costly MPLS with broadband and fiber\n",
      "\n",
      "Drove 40% cost savings across 42 financial services sites.\n",
      "Watch case study\n",
      "\n",
      "--- CHUNK RELEVANTE 4 ---\n",
      "\n",
      "NEXT CASE STUDY                                        \n",
      "Drove 40% cost savings across 42 financial services sites.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A complete tool kit to build a complete experience.\n",
      "Meraki security and SD-WAN appliances are uniquely designed to work with our teleworker and cellular gateways, wireless access points, switches, MDM, and IoT. Build experiences at scale with one platform.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Explore remote work\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Explore cellular gateways\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "EXPLORE HYBRID CLOUD\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Experience secure SD-WAN in three clicks.\n",
      "Mouse not included.\n",
      "\n",
      "Start Your Free Trial\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\tCOMPANY\n",
      "\t\t\t\t\t\t\t\n",
      "\n",
      "About Meraki\n",
      "\n",
      "\n",
      "Careers\n",
      "\n",
      "\n",
      "Privacy Statement\n",
      "\n",
      "\n",
      "Trust\n",
      "\n",
      "\n",
      "GDPR\n",
      "\n",
      "\n",
      "Terms of Use\n",
      "\n",
      "\n",
      "Cookies\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\tPARTNERS\n",
      "\t\t\t\t\t\t\t\n",
      "\n",
      "Meraki Partner Portal Login\n",
      "\n",
      "\n",
      "Cisco Partner Program\n",
      "\n",
      "\n",
      "Managed service providers\n",
      "\n",
      "\n",
      "Service provider\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\tGET STARTED\n",
      "\t\t\t\t\t\t\t\n",
      "\n",
      "Contact us\n",
      "\n",
      "\n",
      "Demo\n",
      "\n",
      "\n",
      "Start your trial\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\tRESOURCES\n",
      "\t\t\t\t\t\t\t\n",
      "\n",
      "Webinars\n",
      "--- FIM DO CONTEXTO RECUPERADO ---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "\n",
    "# --- INÍCIO DO PROCESSO DE DEPURAÇÃO ---\n",
    "\n",
    "# 1. Carregar o conteúdo da página web\n",
    "print(\"1. Carregando conteúdo da web...\")\n",
    "loader = WebBaseLoader(url)\n",
    "docs = loader.load()\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO DE DEPURAÇÃO 1: IMPRIMIR O CONTEÚDO BRUTO CARREGADO\n",
    "# Vamos ver o que o WebBaseLoader realmente \"viu\" na página.\n",
    "# ==============================================================================\n",
    "print(\"\\n--- INÍCIO DO CONTEÚDO BRUTO EXTRAÍDO (primeiros 2000 caracteres) ---\")\n",
    "if docs:\n",
    "    print(docs[0].page_content[:2000])\n",
    "else:\n",
    "    print(\"Nenhum conteúdo foi extraído da página.\")\n",
    "print(\"--- FIM DO CONTEÚDO BRUTO EXTRAÍDO ---\\n\")\n",
    "\n",
    "\n",
    "# 2. Dividir e criar a base vetorial\n",
    "print(\"2. Criando base de conhecimento em memória...\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 3. Fazer a pergunta e inspecionar o contexto recuperado\n",
    "query = \"What are the main features of the Meraki MX security appliances according to this page?\"\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO DE DEPURAÇÃO 2: VERIFICAR O CONTEXTO RECUPERADO ANTES DE ENVIAR AO LLM\n",
    "# Vamos ver exatamente quais pedaços de texto foram selecionados para responder à pergunta.\n",
    "# ==============================================================================\n",
    "print(f\"--- CONTEXTO RECUPERADO PARA A PERGUNTA: '{query}' ---\")\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"\\n--- CHUNK RELEVANTE {i+1} ---\\n\")\n",
    "    print(doc.page_content)\n",
    "print(\"--- FIM DO CONTEXTO RECUPERADO ---\")\n",
    "\n",
    "# 4. (Opcional) Você pode comentar o resto do código se quiser apenas depurar,\n",
    "# ou deixá-lo para ver se com algum ajuste o LLM agora responde.\n",
    "\n",
    "# print(\"\\n--- Gerando Resposta Final da IA ---\")\n",
    "# llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "# prompt_template = \"Answer the question based ONLY on the following context:\\n{context}\\nQuestion: {question}\\nAnswer:\"\n",
    "# prompt = PromptTemplate.from_template(prompt_template)\n",
    "# rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | llm | StrOutputParser()\n",
    "# response = rag_chain.invoke(query)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990ab2b8-e636-4097-9b71-2918dde5df28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ad7c9f-2abd-416f-912c-60ec5b3c59a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7a861b-e404-4e75-a32a-fa5217f8c7d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31d95ad0-5055-4ee7-ad33-f3e729c2f677",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U langchain-openai tavily-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f28731-cc5f-476c-8620-2f8d6006e0d1",
   "metadata": {},
   "source": [
    "## Editando meu agente de IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f986eb5-64e4-4abf-abaf-72684e1bdbbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "144f70f0-b59b-4e5e-a00d-b9e94f9f5ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Giovani\\AppData\\Local\\Temp\\ipykernel_8032\\1128514704.py:23: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  search_tool = TavilySearchResults(max_results=3)\n",
      "C:\\Users\\Giovani\\anaconda3\\Lib\\site-packages\\langsmith\\client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pergunta para o Agente ---\n",
      "What are the latest security advisories for Cisco Firepower 1000 series published in 2025?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 13:47:33,314 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'Cisco Firepower 1000 series security advisories 2025'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Cisco Adaptive Security Appliance Software, Firepower Threat ...', 'url': 'https://sec.cloudapps.cisco.com/security/center/content/CiscoSecurityAdvisory/cisco-sa-multiprod-ikev2-dos-gPctUqv2', 'content': 'advisory is available at the following link: advisory is part of the May 2025 release of the Cisco IOS and IOS XE Software Security Advisory Bundled Publication. For a complete list of the advisories and links to them, seeCisco Event Response: May 2025 Semiannual Cisco IOS and IOS XE Software Security Advisory Bundled Publication.Affected ProductsVulnerable ProductsThis vulnerability affects Cisco products if they are running a vulnerable release of Cisco ASA, FTD, IOS, or IOS XE Software and [...] This advisory is available at the following link:\\n\\nThis advisory is part of the May 2025 release of the Cisco IOS and IOS XE Software Security Advisory Bundled Publication. For a complete list of the advisories and links to them, see Cisco Event Response: May 2025 Semiannual Cisco IOS and IOS XE Software Security Advisory Bundled Publication.\\n\\nAffected Products\\n\\nVulnerable Products [...] NotificationsSubscribeRelated to This AdvisoryCisco Event Response: May 2025 Semiannual Cisco IOS and IOS XE Software Security Advisory Bundled Publication | Cisco Security AdvisoryCisco Adaptive Security Appliance Software, Firepower Threat Defense Software, IOS Software, and IOS XE Software IKEv2 Denial of Service VulnerabilityHighAdvisory ID:cisco-sa-multiprod-ikev2-dos-gPctUqv2First Published:2025 May 7 16:00 GMTVersion 1.0:FinalWorkarounds:No workarounds availableCisco Bug', 'score': 0.8145405}, {'title': 'Cisco security advisory (AV25-356)', 'url': 'https://www.cyber.gc.ca/en/alerts-advisories/cisco-security-advisory-av25-356', 'content': 'Cisco security advisory (AV25-356)\\n==================================\\n\\nSerial number:AV25-356\\n\\nDate:June 18, 2025\\n\\nOn June 18, 2025, Cisco published security advisories to address vulnerabilities in the following products: [...] The Cyber Centre encourages users and administrators to review the provided web links, perform the suggested mitigations and apply the necessary updates if available.\\n\\n   ClamAV UDF File Parsing Out-of-Bounds Read Information Disclosure Vulnerability\\n   Cisco Meraki MX and Z Series AnyConnect VPN with Client Certificate Authentication Denial of Service Vulnerability\\n   Cisco Security Advisories\\n\\nDate modified: 2025-06-18\\n\\nAbout this site\\n---------------\\n\\n### Government of Canada', 'score': 0.7763013}, {'title': 'Cisco Security Advisories', 'url': 'https://sec.cloudapps.cisco.com/security/center/publicationListing.x', 'content': '| Image 14Multiple Cisco Products Unauthenticated Remote Code Execution in Erlang/OTP SSH Server: April 2025Critical CVE-2025-32433  on an affected device.The vulnerability is due to a flaw in the handling of SSH messages Read More... | [...] | Image 17Cisco Integrated Management Controller Privilege Escalation VulnerabilityHigh CVE-2025-20261  for Cisco UCS B-Series, UCS C-Series, UCS S-Series, and UCS X-Series Servers could allow an authenticated, remote attacker to access internal services with elevated privileges.This Read More... | [...] | Image 9Cisco Identity Services Engine Unauthenticated Remote Code Execution VulnerabilitiesCritical CVE-2025-20281 CVE-2025-20282  and Cisco ISE Passive Identity Connector (ISE-PIC) could allow an unauthenticated, remote attacker to issue commands on the underlying operating system as the root user.For more information about these Read More... |', 'score': 0.6202772}]\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 13:47:39,485 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mHere are some of the latest security advisories for the Cisco Firepower 1000 series published in 2025:\n",
      "\n",
      "1. **Cisco Adaptive Security Appliance Software, Firepower Threat Defense Software, IOS Software, and IOS XE Software IKEv2 Denial of Service Vulnerability**\n",
      "   - **Advisory ID:** cisco-sa-multiprod-ikev2-dos-gPctUqv2\n",
      "   - **Published:** May 7, 2025\n",
      "   - **Description:** This advisory is part of the May 2025 release of the Cisco IOS and IOS XE Software Security Advisory Bundled Publication. It addresses a vulnerability affecting Cisco products running a vulnerable release of Cisco ASA, FTD, IOS, or IOS XE Software.\n",
      "   - **Link:** [Cisco Security Advisory](https://sec.cloudapps.cisco.com/security/center/content/CiscoSecurityAdvisory/cisco-sa-multiprod-ikev2-dos-gPctUqv2)\n",
      "\n",
      "2. **Cisco Security Advisory (AV25-356)**\n",
      "   - **Published:** June 18, 2025\n",
      "   - **Description:** This advisory addresses vulnerabilities in various Cisco products, including ClamAV UDF File Parsing Out-of-Bounds Read Information Disclosure Vulnerability and Cisco Meraki MX and Z Series AnyConnect VPN with Client Certificate Authentication Denial of Service Vulnerability.\n",
      "   - **Link:** [Cisco Security Advisory AV25-356](https://www.cyber.gc.ca/en/alerts-advisories/cisco-security-advisory-av25-356)\n",
      "\n",
      "For more detailed information, you can visit the Cisco Security Advisories page or the specific links provided.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "--- Resposta Final do Agente ---\n",
      "Here are some of the latest security advisories for the Cisco Firepower 1000 series published in 2025:\n",
      "\n",
      "1. **Cisco Adaptive Security Appliance Software, Firepower Threat Defense Software, IOS Software, and IOS XE Software IKEv2 Denial of Service Vulnerability**\n",
      "   - **Advisory ID:** cisco-sa-multiprod-ikev2-dos-gPctUqv2\n",
      "   - **Published:** May 7, 2025\n",
      "   - **Description:** This advisory is part of the May 2025 release of the Cisco IOS and IOS XE Software Security Advisory Bundled Publication. It addresses a vulnerability affecting Cisco products running a vulnerable release of Cisco ASA, FTD, IOS, or IOS XE Software.\n",
      "   - **Link:** [Cisco Security Advisory](https://sec.cloudapps.cisco.com/security/center/content/CiscoSecurityAdvisory/cisco-sa-multiprod-ikev2-dos-gPctUqv2)\n",
      "\n",
      "2. **Cisco Security Advisory (AV25-356)**\n",
      "   - **Published:** June 18, 2025\n",
      "   - **Description:** This advisory addresses vulnerabilities in various Cisco products, including ClamAV UDF File Parsing Out-of-Bounds Read Information Disclosure Vulnerability and Cisco Meraki MX and Z Series AnyConnect VPN with Client Certificate Authentication Denial of Service Vulnerability.\n",
      "   - **Link:** [Cisco Security Advisory AV25-356](https://www.cyber.gc.ca/en/alerts-advisories/cisco-security-advisory-av25-356)\n",
      "\n",
      "For more detailed information, you can visit the Cisco Security Advisories page or the specific links provided.\n"
     ]
    }
   ],
   "source": [
    "# 1. Instala as bibliotecas necessárias\n",
    "#!pip install -q -U langchain-openai tavily-python\n",
    "\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_tools_agent, AgentExecutor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- CONFIGURAÇÃO DAS CHAVES DE API ---\n",
    "# ⚠️ Cole suas chaves aqui. Use o gerenciador de segredos do Colab se preferir.\n",
    "OPENAI_API_KEY = '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'\n",
    "TAVILY_API_KEY = \"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\" # <-- SUA CHAVE DA TAVILY AQUI\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY\n",
    "\n",
    "\n",
    "# --- CONSTRUÇÃO DO AGENTE ---\n",
    "\n",
    "# 2. Defina as ferramentas que o agente pode usar\n",
    "# Neste caso, apenas a busca na web da Tavily. `max_results=3` limita a 3 resultados.\n",
    "search_tool = TavilySearchResults(max_results=3)\n",
    "tools = [search_tool]\n",
    "\n",
    "# 3. Crie o agente\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# Puxa um prompt pré-construído da comunidade LangChain, otimizado para agentes\n",
    "# Este prompt instrui o LLM sobre como pensar e usar as ferramentas\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "\n",
    "# Cria o agente, unindo o LLM, as ferramentas e o prompt\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "\n",
    "# Cria o \"Executor\", que é o que de fato roda o ciclo de pensamento do agente\n",
    "# verbose=True é MUITO importante para vermos o \"raciocínio\" do agente\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "# --- TESTE DO AGENTE ---\n",
    "query = \"What are the latest security advisories for Cisco Firepower 1000 series published in 2025?\"\n",
    "\n",
    "print(f\"--- Pergunta para o Agente ---\\n{query}\")\n",
    "\n",
    "# Invoca o agente e aguarda a resposta final\n",
    "response = agent_executor.invoke({\"input\": query})\n",
    "\n",
    "print(\"\\n--- Resposta Final do Agente ---\")\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79792347-39d5-4cc4-8fc0-f048ac98ed97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d448cc62-0118-498c-902a-2521cc72d961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4029a433-7ff0-48be-97b8-30eca1f59c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfce1c81-bf60-411d-97e2-75f9974c0da7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4df406d-421e-4859-b5bf-cf8c1c7ae872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eff00a-f4aa-4583-9c8a-b858c3dc7043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343219a7-7257-4cfe-a60c-fde064d26316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40d8e67-288b-44cd-90d3-6b9e3f845994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38ed038-3824-4782-a8cd-f4884dba41fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1036e5-1ae6-4872-9a51-6f7d342d5b26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "668b1ba5-866e-499a-b306-4b6a9fc3db39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instalações necessárias\n",
    "#!pip install -q -U langchain-openai tavily-python langchain beautifulsoup4 chromadb pypdf unstructured\n",
    "\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_tools_agent, AgentExecutor\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- CONFIGURAÇÃO DAS CHAVES DE API ---\n",
    "# ⚠️ Cole suas chaves aqui.\n",
    "OPENAI_API_KEY = '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'\n",
    "TAVILY_API_KEY = \"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\" # <-- SUA CHAVE DA TAVILY AQUI\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fea07ad3-91fa-4fdf-95f4-8e4f1a6a1e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Criando ferramenta de busca de arquivos locais... ---\n",
      "Ferramenta de busca de arquivos criada com sucesso.\n",
      "\n",
      "\n",
      "--- EXECUTANDO TESTE 1 (usando o arquivo local) ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `cisco_pricelist_search` with `{'query': 'C9200L-24P-4G-A'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCategory;Sub_Category;Part Number;Desc;price;Elig %: Hardware;Switches;C9200L-24PXG4X-EDU;Catalyst 9200L 24-p\n",
      "None: 8xmGig,16x1G,4x10G uplinks,K12;$6.740,00;100%\n",
      "\n",
      "Category;Sub_Category;Part Number;Desc;price;Elig %: Hardware;Switches;C9200L-24PXG2Y-EDU;Catalyst 9200L 24-p\n",
      "None: 8xmGig,16x1G,2x25G uplinks,K12;$7.290,00;100%\n",
      "\n",
      "Category;Sub_Category;Part Number;Desc;price;Elig %: Hardware;Switches;C9200L-48PXG4X-EDU;Catalyst 9200L 48-p\n",
      "None: 12xmGig,36x1G,4x10G uplinks,K12;$10.380,00;100%\n",
      "\n",
      "Category;Sub_Category;Part Number;Desc;price;Elig %: Hardware;Switches;C9200L-48PXG2Y-EDU;Catalyst 9200L 48-p\n",
      "None: 12xmGig,36x1G,2x25G uplinks,K12;$10.930,00;100%\u001b[0m\u001b[32;1m\u001b[1;3mI couldn't find the list price for the specific part number C9200L-24P-4G-A in the available data. If you have any other questions or need further assistance, feel free to ask!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "--- Resposta Final (do arquivo) ---\n",
      "I couldn't find the list price for the specific part number C9200L-24P-4G-A in the available data. If you have any other questions or need further assistance, feel free to ask!\n",
      "\n",
      "\n",
      "--- EXECUTANDO TESTE 2 (usando a busca na web) ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_search` with `{'query': 'Cisco quarterly earnings October 2023'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m[{'title': 'Investor Relations - CISCO REPORTS FIRST QUARTER EARNINGS', 'url': 'https://investor.cisco.com/news/news-details/2023/CISCO-REPORTS-FIRST-QUARTER-EARNINGS/default.aspx', 'content': 'Cisco today reported first quarter results for the period ended October 28, 2023. Cisco reported first quarter revenue of $14.7 billion, net income on a generally accepted accounting principles (GAAP) basis of $3.6 billion or $0.89 per share, and non-GAAP net income of $4.5 billion or $1.11 per share. [...] Three Months Ended\\nOctober 28, 2023\\nGross Margin Percentage:\\nAmericas 66.2%\\nEMEA 69.5%\\nAPJC 67.0%\\n\\nCISCO SYSTEMS, INC.\\nREVENUE FOR GROUPS OF SIMILAR PRODUCTS AND SERVICES\\n(In millions, except percentages)\\n\\nThree Months Ended\\nOctober 28, 2023\\nAmount Y/Y %\\nRevenue:\\nNetworking$ 8,822 10%\\nSecurity 1,010 4%\\nCollaboration 1,117 3%\\nObservability 190 21%\\nTotal Product 11,139 9%\\nServices 3,529 4%\\nTotal$ 14,668 8%\\n\\nAmounts may not sum and percentages may not recalculate due to rounding. [...] Net income per share:\\nBasic$ 0.90$ 0.65\\nDiluted$ 0.89$ 0.65\\nShares used in per-share calculation:\\nBasic 4,057 4,108\\nDiluted 4,087 4,116\\n\\nCISCO SYSTEMS, INC.\\nREVENUE BY SEGMENT\\n(In millions, except percentages)\\n\\nThree Months Ended\\nOctober 28, 2023\\nAmount Y/Y %\\nRevenue:\\nAmericas$ 9,022 14%\\nEMEA 3,664—%\\nAPJC 1,982(3)%\\nTotal$ 14,668 8%\\n\\nAmounts may not sum and percentages may not recalculate due to rounding.\\n\\nCISCO SYSTEMS, INC.\\nGROSS MARGIN PERCENTAGE BY SEGMENT\\n(In percentages)', 'score': 0.9485422}, {'title': 'Cisco Reports Fourth Quarter And Fiscal Year 2023 Earnings', 'url': 'https://newsroom.cisco.com/c/r/newsroom/en/us/a/y2023/m08/cisco-reports-fourth-quarter-and-fiscal-year-2023-earnings.html', 'content': 'Cisco has declared a quarterly dividend of $0.39 per common share to be paid on October 25, 2023, to all stockholders of record as of the close of business on October 4, 2023. Future dividends will be subject to Board approval.\\n\\nFinancial Summary\\n\\nAll comparative percentages are on a year-over-year basis unless otherwise noted.\\n\\nQ4 FY 2023 Highlights [...] | Current | $       13,908 |  | $       13,249 |  | $       12,784 |\\n| Noncurrent | 11,642 |  | 11,011 |  | 10,480 |\\n| Total | $       25,550 |  | $       24,260 |  | $       23,264 | [...] | Services |  | 3,553 |  | 4 % |  | 13,856 |  | 2 % |\\n| Total |  | $       15,203 |  | 16 % |  | $       56,998 |  | 11 % |', 'score': 0.92731744}, {'title': 'Investor Relations - CISCO REPORTS THIRD QUARTER EARNINGS', 'url': 'https://investor.cisco.com/news/news-details/2025/CISCO-REPORTS-THIRD-QUARTER-EARNINGS/default.aspx', 'content': 'per Share Amount Amount\\nFiscal 2025\\nApril 26, 2025$ 0.41$ 1,627 25$ 59.78$ 1,504$ 3,131\\nJanuary 25, 2025$ 0.40$ 1,593 21$ 58.58$ 1,236$ 2,829\\nOctober 26, 2024$ 0.40$ 1,592 40$ 49.56$ 2,003$ 3,595\\n\\nFiscal 2024\\nJuly 27, 2024$ 0.40$ 1,606 43$ 46.80$ 2,002$ 3,608\\nApril 27, 2024$ 0.40$ 1,615 26$ 49.22$ 1,256$ 2,871\\nJanuary 27, 2024$ 0.39$ 1,583 25$ 49.54$ 1,254$ 2,837\\nOctober 28, 2023$ 0.39$ 1,580 23$ 54.53$ 1,252$ 2,832\\n\\nCISCO SYSTEMS, INC.\\n\\nRECONCILIATIONS OF GAAP TO NON-GAAP MEASURES', 'score': 0.8479807}]\u001b[0m\u001b[32;1m\u001b[1;3mCisco recently reported its first quarter earnings for the period ending October 28, 2023. The company announced a revenue of $14.7 billion, with a net income of $3.6 billion on a GAAP basis, translating to $0.89 per share. On a non-GAAP basis, the net income was $4.5 billion or $1.11 per share.\n",
      "\n",
      "Here are some additional details from the report:\n",
      "\n",
      "- **Revenue by Product and Service:**\n",
      "  - Networking: $8.822 billion (10% increase year-over-year)\n",
      "  - Security: $1.010 billion (4% increase)\n",
      "  - Collaboration: $1.117 billion (3% increase)\n",
      "  - Observability: $190 million (21% increase)\n",
      "  - Total Product Revenue: $11.139 billion (9% increase)\n",
      "  - Services Revenue: $3.529 billion (4% increase)\n",
      "\n",
      "- **Revenue by Region:**\n",
      "  - Americas: $9.022 billion (14% increase)\n",
      "  - EMEA: $3.664 billion (no change)\n",
      "  - APJC: $1.982 billion (3% decrease)\n",
      "\n",
      "- **Gross Margin Percentage:**\n",
      "  - Americas: 66.2%\n",
      "  - EMEA: 69.5%\n",
      "  - APJC: 67.0%\n",
      "\n",
      "For more detailed information, you can view the full report on Cisco's [Investor Relations page](https://investor.cisco.com/news/news-details/2023/CISCO-REPORTS-FIRST-QUARTER-EARNINGS/default.aspx).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "--- Resposta Final (da web) ---\n",
      "Cisco recently reported its first quarter earnings for the period ending October 28, 2023. The company announced a revenue of $14.7 billion, with a net income of $3.6 billion on a GAAP basis, translating to $0.89 per share. On a non-GAAP basis, the net income was $4.5 billion or $1.11 per share.\n",
      "\n",
      "Here are some additional details from the report:\n",
      "\n",
      "- **Revenue by Product and Service:**\n",
      "  - Networking: $8.822 billion (10% increase year-over-year)\n",
      "  - Security: $1.010 billion (4% increase)\n",
      "  - Collaboration: $1.117 billion (3% increase)\n",
      "  - Observability: $190 million (21% increase)\n",
      "  - Total Product Revenue: $11.139 billion (9% increase)\n",
      "  - Services Revenue: $3.529 billion (4% increase)\n",
      "\n",
      "- **Revenue by Region:**\n",
      "  - Americas: $9.022 billion (14% increase)\n",
      "  - EMEA: $3.664 billion (no change)\n",
      "  - APJC: $1.982 billion (3% decrease)\n",
      "\n",
      "- **Gross Margin Percentage:**\n",
      "  - Americas: 66.2%\n",
      "  - EMEA: 69.5%\n",
      "  - APJC: 67.0%\n",
      "\n",
      "For more detailed information, you can view the full report on Cisco's [Investor Relations page](https://investor.cisco.com/news/news-details/2023/CISCO-REPORTS-FIRST-QUARTER-EARNINGS/default.aspx).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# --- PASSO A: CRIAR A FERRAMENTA DE BUSCA NOS SEUS ARQUIVOS ---\n",
    "\n",
    "print(\"--- Criando ferramenta de busca de arquivos locais... ---\")\n",
    "# Carrega os dados do seu arquivo CSV\n",
    "# Certifique-se de que o arquivo 'Pricelist.csv' está na pasta 'data/raw/'\n",
    "loader = CSVLoader(file_path='data/raw/Pricelist.csv')\n",
    "docs = loader.load()\n",
    "\n",
    "# Divide os documentos e cria o vector store\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Cria a ferramenta de busca de arquivos (RAG)\n",
    "# A 'description' é MUITO importante. É como o agente sabe quando usar esta ferramenta.\n",
    "file_search_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"cisco_pricelist_search\",\n",
    "    \"Use this tool when you need to find information about Cisco product part numbers, descriptions, or list prices from the NCDPI pricelist file.\"\n",
    ")\n",
    "print(\"Ferramenta de busca de arquivos criada com sucesso.\\n\")\n",
    "\n",
    "\n",
    "# --- PASSO B: DEFINIR A FERRAMENTA DE BUSCA NA WEB ---\n",
    "web_search_tool = TavilySearchResults(name=\"web_search\", max_results=3)\n",
    "\n",
    "\n",
    "# --- PASSO C: MONTAR O AGENTE COM AS DUAS FERRAMENTAS ---\n",
    "\n",
    "# Agora, a lista de ferramentas contém tanto a busca em arquivos quanto a busca na web\n",
    "tools = [file_search_tool, web_search_tool]\n",
    "\n",
    "# O restante da criação do agente é igual, mas agora ele é mais poderoso\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "# --- PASSO D: TESTAR O AGENTE HÍBRIDO ---\n",
    "\n",
    "# Teste 1: Uma pergunta que deve ser respondida pelo ARQUIVO CSV\n",
    "print(\"\\n--- EXECUTANDO TESTE 1 (usando o arquivo local) ---\")\n",
    "query_local = \"What is the list price for part number C9200L-24P-4G-A?\"\n",
    "response_local = agent_executor.invoke({\"input\": query_local})\n",
    "print(\"\\n--- Resposta Final (do arquivo) ---\")\n",
    "print(response_local['output'])\n",
    "\n",
    "# Teste 2: Uma pergunta que precisa da INTERNET\n",
    "print(\"\\n\\n--- EXECUTANDO TESTE 2 (usando a busca na web) ---\")\n",
    "query_web = \"What is the latest news about Cisco's quarterly earnings?\"\n",
    "response_web = agent_executor.invoke({\"input\": query_web})\n",
    "print(\"\\n--- Resposta Final (da web) ---\")\n",
    "print(response_web['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5a2ce7-76e2-4942-936a-382be56e1489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccdfa3b4-122a-4c1f-ae63-c7b13e8f85da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando o processo de indexação ---\n",
      "Documento CSV carregado com 4267 linhas.\n",
      "Documento dividido em 4267 chunks.\n",
      "Criando e salvando o banco de dados vetorial em: 'data/processed/cisco_pricelist_db'...\n",
      "\n",
      "--- Processo de Indexação Concluído! ---\n",
      "Sua base de conhecimento foi criada e salva no disco.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "print(\"--- Iniciando o processo de indexação ---\")\n",
    "\n",
    "# --- Carregar o documento ---\n",
    "# Certifique-se de que o seu arquivo está no caminho correto\n",
    "loader = CSVLoader(file_path='data/raw/Pricelist.csv') \n",
    "docs = loader.load()\n",
    "print(f\"Documento CSV carregado com {len(docs)} linhas.\")\n",
    "\n",
    "# --- Dividir em chunks ---\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "print(f\"Documento dividido em {len(splits)} chunks.\")\n",
    "\n",
    "# --- Criar e Salvar o Banco de Dados Vetorial ---\n",
    "# Define o local onde o banco de dados será salvo\n",
    "vector_db_path = 'data/processed/cisco_pricelist_db'\n",
    "\n",
    "print(f\"Criando e salvando o banco de dados vetorial em: '{vector_db_path}'...\")\n",
    "# Cria o vector store e usa 'persist_directory' para salvá-lo\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    persist_directory=vector_db_path\n",
    ")\n",
    "\n",
    "print(\"\\n--- Processo de Indexação Concluído! ---\")\n",
    "print(\"Sua base de conhecimento foi criada e salva no disco.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c0e0fe2-95c5-4c7a-b56f-1395185856f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Carregando a base de conhecimento do disco... ---\n",
      "Base de conhecimento carregada.\n",
      "\n",
      "--- Executando a pergunta: What is the price for part number C9200L-24P-4G-A? ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `cisco_product_and_price_search` with `{'query': 'C9200L-24P-4G-A'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCategory;Sub_Category;Part Number;Desc;price;Elig %: Hardware;Switches;C9200L-24PXG4X-EDU;Catalyst 9200L 24-p\n",
      "None: 8xmGig,16x1G,4x10G uplinks,K12;$6.740,00;100%\n",
      "\n",
      "Category;Sub_Category;Part Number;Desc;price;Elig %: Hardware;Switches;C9200L-24PXG2Y-EDU;Catalyst 9200L 24-p\n",
      "None: 8xmGig,16x1G,2x25G uplinks,K12;$7.290,00;100%\n",
      "\n",
      "Category;Sub_Category;Part Number;Desc;price;Elig %: Hardware;Switches;C9200L-48PXG4X-EDU;Catalyst 9200L 48-p\n",
      "None: 12xmGig,36x1G,4x10G uplinks,K12;$10.380,00;100%\n",
      "\n",
      "Category;Sub_Category;Part Number;Desc;price;Elig %: Hardware;Switches;C9200L-48PXG2Y-EDU;Catalyst 9200L 48-p\n",
      "None: 12xmGig,36x1G,2x25G uplinks,K12;$10.930,00;100%\u001b[0m\u001b[32;1m\u001b[1;3mI couldn't find the exact part number C9200L-24P-4G-A in the database. However, I found similar part numbers for the Catalyst 9200L series:\n",
      "\n",
      "1. **C9200L-24PXG4X-EDU**: $6,740.00\n",
      "2. **C9200L-24PXG2Y-EDU**: $7,290.00\n",
      "3. **C9200L-48PXG4X-EDU**: $10,380.00\n",
      "4. **C9200L-48PXG2Y-EDU**: $10,930.00\n",
      "\n",
      "If you need more specific information or a different part number, please let me know!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "--- Resposta Final do Agente ---\n",
      "I couldn't find the exact part number C9200L-24P-4G-A in the database. However, I found similar part numbers for the Catalyst 9200L series:\n",
      "\n",
      "1. **C9200L-24PXG4X-EDU**: $6,740.00\n",
      "2. **C9200L-24PXG2Y-EDU**: $7,290.00\n",
      "3. **C9200L-48PXG4X-EDU**: $10,380.00\n",
      "4. **C9200L-48PXG2Y-EDU**: $10,930.00\n",
      "\n",
      "If you need more specific information or a different part number, please let me know!\n"
     ]
    }
   ],
   "source": [
    "# --- PASSO A: CARREGAR O BANCO DE DADOS VETORIAL EXISTENTE ---\n",
    "print(\"--- Carregando a base de conhecimento do disco... ---\")\n",
    "vector_db_path = 'data/processed/cisco_pricelist_db'\n",
    "\n",
    "# Carrega o banco de dados vetorial que foi salvo no passo anterior\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=vector_db_path,\n",
    "    embedding_function=OpenAIEmbeddings()\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "print(\"Base de conhecimento carregada.\\n\")\n",
    "\n",
    "\n",
    "# --- PASSO B: CRIAR A FERRAMENTA DE BUSCA DE ARQUIVOS ---\n",
    "file_search_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"cisco_product_and_price_search\",\n",
    "    \"Use this tool when you need to find information about Cisco product part numbers, descriptions, or prices. It contains a detailed price.\"\n",
    ")\n",
    "\n",
    "\n",
    "# --- PASSO C: DEFINIR A FERRAMENTA DE BUSCA NA WEB E MONTAR O AGENTE ---\n",
    "web_search_tool = TavilySearchResults(name=\"web_search\", max_results=3)\n",
    "tools = [file_search_tool, web_search_tool]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "# --- PASSO D: TESTAR O AGENTE HÍBRIDO ---\n",
    "query = \"What is the price for part number C9200L-24P-4G-A?\"\n",
    "print(f\"--- Executando a pergunta: {query} ---\")\n",
    "\n",
    "response = agent_executor.invoke({\"input\": query})\n",
    "\n",
    "print(\"\\n--- Resposta Final do Agente ---\")\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14512d5-de55-4a8e-9437-c9f8f61b41ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1e789ffa-064c-4079-9b63-02dd5b1ead19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tentando carregar o arquivo Excel de: data/raw/Attachment_3_NCDPI_eRate_IFB_Pricelist.xlsx\n",
      "Arquivo Excel carregado com sucesso.\n",
      "Arquivo convertido com sucesso e salvo como: data/raw/Pricelist_corrigido.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Define os caminhos para os arquivos de entrada e saída\n",
    "# Certifique-se de que o nome do arquivo de entrada está correto\n",
    "input_excel_path = 'data/raw/Attachment_3_NCDPI_eRate_IFB_Pricelist.xlsx'\n",
    "output_csv_path = 'data/raw/Pricelist_corrigido.csv'\n",
    "\n",
    "print(f\"Tentando carregar o arquivo Excel de: {input_excel_path}\")\n",
    "\n",
    "try:\n",
    "    # Carrega o arquivo .xlsx para um DataFrame do Pandas\n",
    "    df = pd.read_excel(input_excel_path)\n",
    "    print(\"Arquivo Excel carregado com sucesso.\")\n",
    "\n",
    "    # Salva o DataFrame como um novo arquivo .csv\n",
    "    # A parte mais importante é o 'quoting=csv.QUOTE_ALL'\n",
    "    df.to_csv(\n",
    "        output_csv_path, \n",
    "        index=False,                  # Não salva o índice do DataFrame como uma coluna\n",
    "        encoding='utf-8',             # Define a codificação para evitar erros de caracteres\n",
    "        quoting=csv.QUOTE_ALL         # Força que todos os campos sejam envoltos por aspas duplas\n",
    "    )\n",
    "\n",
    "    print(f\"Arquivo convertido com sucesso e salvo como: {output_csv_path}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRO: Arquivo não encontrado em '{input_excel_path}'. Por favor, verifique se o arquivo está no local correto.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu um erro inesperado: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6152fb2-8c69-4fa1-8f0c-1ab737d4dc5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9ec15309-2f44-4948-87c5-c20808baec6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo Pricelist.csv carregado com sucesso no Pandas.\n"
     ]
    }
   ],
   "source": [
    "# 1. Instalações necessárias\n",
    "#!pip install -q -U langchain-openai tavily-python langchain pandas\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.agents import tool\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_tools_agent, AgentExecutor\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# --- CARREGAR OS DADOS COM PANDAS ---\n",
    "# Carrega o CSV em um DataFrame para acesso rápido e direto\n",
    "try:\n",
    "    pricelist_df = pd.read_csv('data/raw/Pricelist_corrigido.csv', engine='python', on_bad_lines='warn')\n",
    "    print(\"Arquivo Pricelist.csv carregado com sucesso no Pandas.\")\n",
    "    # Converte a coluna de Part Number para string para garantir correspondências exatas\n",
    "    pricelist_df['Part Number'] = pricelist_df['Part Number'].astype(str)\n",
    "except FileNotFoundError:\n",
    "    print(\"ERRO: O arquivo 'data/raw/Pricelist.csv' não foi encontrado.\")\n",
    "    pricelist_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "83e5e52e-e5bc-4f83-a2cc-a2a3f6f3abd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub_Category</th>\n",
       "      <th>Part Number</th>\n",
       "      <th>Desc</th>\n",
       "      <th>price</th>\n",
       "      <th>Elig %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>Hardware</td>\n",
       "      <td>Switches</td>\n",
       "      <td>C9200L-24P-4G-A</td>\n",
       "      <td>Catalyst 9200L 24-port PoE+, 4 x 1G, Network A...</td>\n",
       "      <td>2745.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category Sub_Category      Part Number  \\\n",
       "1597  Hardware     Switches  C9200L-24P-4G-A   \n",
       "\n",
       "                                                   Desc   price Elig %  \n",
       "1597  Catalyst 9200L 24-port PoE+, 4 x 1G, Network A...  2745.0      1  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pricelist_df[pricelist_df['Part Number']==\"C9200L-24P-4G-A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dc688a-246a-43ed-b2d2-5f495c3c8379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cb308617-e850-4ef7-af93-c1464a492ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Executando a pergunta: What is the list price for Part Number C9200L-24P-4G-A ? ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_product_price` with `{'part_number': 'C9200L-24P-4G-A'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mFound information for Part Number 'C9200L-24P-4G-A':\n",
      "- Description: N/A\n",
      "- List Price: $N/A\u001b[0m\u001b[32;1m\u001b[1;3mThe list price for Part Number C9200L-24P-4G-A is not available at this time, and the description is also not provided.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "--- Resposta Final do Agente ---\n",
      "The list price for Part Number C9200L-24P-4G-A is not available at this time, and the description is also not provided.\n"
     ]
    }
   ],
   "source": [
    "# --- PASSO A: CRIAR A FERRAMENTA DE BUSCA DIRETA ---\n",
    "\n",
    "@tool\n",
    "def search_product_price(part_number: str) -> str:\n",
    "    \"\"\"\n",
    "    Use this tool to find the exact list price and description for a specific Cisco Part Number.\n",
    "    The input must be the exact Part Number string.\n",
    "    \"\"\"\n",
    "    if pricelist_df is None:\n",
    "        return \"Error: Pricelist data is not available.\"\n",
    "    \n",
    "    # Busca exata (case-insensitive) no DataFrame\n",
    "    result = pricelist_df[pricelist_df['Part Number'].str.lower() == part_number.lower()]\n",
    "    \n",
    "    if result.empty:\n",
    "        return f\"Part Number '{part_number}' not found in the pricelist.\"\n",
    "    \n",
    "    # Formata a resposta\n",
    "    product_info = result.iloc[0]\n",
    "    return (\n",
    "        f\"Found information for Part Number '{part_number}':\\n\"\n",
    "        f\"- Description: {product_info.get('Description', 'N/A')}\\n\"\n",
    "        f\"- List Price: ${product_info.get('List Price', 'N/A')}\"\n",
    "    )\n",
    "\n",
    "\n",
    "# --- PASSO B: DEFINIR A FERRAMENTA DE BUSCA NA WEB E MONTAR O AGENTE ---\n",
    "\n",
    "web_search_tool = TavilySearchResults(name=\"web_search\", max_results=3)\n",
    "\n",
    "# Agora a lista de ferramentas contém nossa nova ferramenta de busca direta e a de busca na web\n",
    "tools = [search_product_price, web_search_tool]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "# --- PASSO C: TESTAR O AGENTE COM A NOVA FERRAMENTA ---\n",
    "\n",
    "# Pergunta que antes falhava, mas agora deve funcionar perfeitamente\n",
    "query = \"What is the list price for Part Number C9200L-24P-4G-A ?\"\n",
    "print(f\"--- Executando a pergunta: {query} ---\")\n",
    "\n",
    "response = agent_executor.invoke({\"input\": query})\n",
    "\n",
    "print(\"\\n--- Resposta Final do Agente ---\")\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fe8e17-8542-4ce4-a6f6-7098cfb29c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd61b58-fe5f-4fa6-8984-d13c17e25f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a831d81-c2cc-4ff9-961e-74a622959ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eda8635-399b-4110-93ef-20413a5ab1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2b1917-2920-4750-a59f-de269ebff913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7ac9972f-53ec-484a-b134-df9a2dd8208d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 16 products from data/raw/pricelist.json.\n",
      "Tool 'get_product_price_and_description' created and ready.\n"
     ]
    }
   ],
   "source": [
    "# --- Load the JSON data ---\n",
    "product_list = []\n",
    "try:\n",
    "    # Path to your JSON file\n",
    "    pricelist_path = 'data/raw/pricelist.json'\n",
    "    \n",
    "    with open(pricelist_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "        # --- CORREÇÃO AQUI ---\n",
    "        # Como o JSON já é uma lista, atribuímos diretamente.\n",
    "        if isinstance(data, list):\n",
    "            product_list = data\n",
    "        else:\n",
    "            # Caso o formato mude no futuro, ainda tentamos pegar a chave 'products'\n",
    "            product_list = data.get('products', [])\n",
    "            \n",
    "    print(f\"Successfully loaded {len(product_list)} products from {pricelist_path}.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: The file '{pricelist_path}' was not found.\")\n",
    "    product_list = []\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"ERROR: The file '{pricelist_path}' is not a valid JSON file.\")\n",
    "    product_list = []\n",
    "\n",
    "# --- Create the specialized Pricing Agent Tool ---\n",
    "@tool\n",
    "def get_product_price_and_description(part_number: str) -> str:\n",
    "    \"\"\"\n",
    "    Use this tool to find the exact list price, description, and manufacturer\n",
    "    for a specific Cisco Part Number from the JSON pricelist.\n",
    "    The input must be the exact Part Number string.\n",
    "    \"\"\"\n",
    "    if not product_list:\n",
    "        return \"Error: Product list data is not available.\"\n",
    "    \n",
    "    # Search for the product in the list of dictionaries (case-insensitive)\n",
    "    found_product = next((p for p in product_list if p.get('part_number', '').lower() == part_number.lower()), None)\n",
    "    \n",
    "    if not found_product:\n",
    "        return f\"Part Number '{part_number}' not found in the pricelist.\"\n",
    "    \n",
    "    # Format a clean response string from the found product dictionary\n",
    "    return (\n",
    "        f\"Info for '{found_product['part_number']}':\\n\"\n",
    "        f\"  Manufacturer: {found_product.get('manufacturer', 'N/A')}\\n\"\n",
    "        f\"  Description: {found_product.get('description', 'N/A')}\\n\"\n",
    "        f\"  List Price: ${found_product.get('list_price', 'N/A')}\"\n",
    "    )\n",
    "\n",
    "print(\"Tool 'get_product_price_and_description' created and ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3282edc1-e76c-4885-afc4-bb7f4d1eecfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technical Agent (SKU extractor) created correctly.\n"
     ]
    }
   ],
   "source": [
    "# Importa o ChatPromptTemplate que estava faltando\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# A definição do Pydantic (Skus) e do LLM (llm, structured_llm) continua a mesma\n",
    "class Skus(BaseModel):\n",
    "    \"\"\"A list of product SKUs extracted from the user's query.\"\"\"\n",
    "    sku_list: List[str] = Field(description=\"A list of part numbers mentioned in the query.\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "structured_llm = llm.with_structured_output(Skus)\n",
    "\n",
    "\n",
    "# --- CORREÇÃO AQUI ---\n",
    "# 1. Criamos um template de prompt para instruir o LLM sobre o que fazer com a query.\n",
    "technical_prompt = ChatPromptTemplate.from_template(\n",
    "    \"From the following user query, extract all and only the product cisco_product_id. If no part numbers are mentioned, return an empty list.\\n\\nUser Query: {query}\"\n",
    ")\n",
    "\n",
    "# 2. A cadeia agora inclui o prompt para formatar a entrada para o LLM.\n",
    "technical_agent_chain = (\n",
    "    # O primeiro passo ainda cria um dicionário com a query do usuário\n",
    "    {\"query\": lambda x: x} \n",
    "    # O segundo passo (novo) usa o prompt para formatar o dicionário em um texto de instrução\n",
    "    | technical_prompt\n",
    "    # O terceiro passo envia o prompt formatado para o LLM\n",
    "    | structured_llm\n",
    ")\n",
    "\n",
    "print(\"Technical Agent (SKU extractor) created correctly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7a7f8c50-c693-41a9-ad81-75ca00202f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_quote_flow(user_query: str):\n",
    "    \"\"\"\n",
    "    Orchestrates the two-agent flow to process a user query.\n",
    "    \"\"\"\n",
    "    print(\"--- STARTING QUOTE FLOW ---\")\n",
    "    \n",
    "    # 1. Call Technical Agent to identify SKUs\n",
    "    print(f\"\\n[Orchestrator] Sending to Technical Agent: '{user_query}'\")\n",
    "    skus_result = technical_agent_chain.invoke(user_query)\n",
    "    extracted_skus = skus_result.sku_list\n",
    "    \n",
    "    if not extracted_skus:\n",
    "        print(\"[Orchestrator] No SKUs identified. Ending flow.\")\n",
    "        return \"I could not identify any specific Part Numbers in your request.\"\n",
    "        \n",
    "    print(f\"[Orchestrator] Technical Agent identified SKUs: {extracted_skus}\")\n",
    "    \n",
    "    # 2. Call Pricing Agent (our tool) for each SKU\n",
    "    final_quote_details = []\n",
    "    print(\"\\n[Orchestrator] Querying Pricing Agent for each SKU...\")\n",
    "    for sku in extracted_skus:\n",
    "        print(f\"  - Looking up price for: {sku}\")\n",
    "        price_info = get_product_price_and_description.invoke(sku)\n",
    "        final_quote_details.append(price_info)\n",
    "        \n",
    "    # 3. Synthesize the final response\n",
    "    print(\"\\n--- FLOW COMPLETE. GENERATING FINAL RESPONSE ---\")\n",
    "    final_response = \"\\n\\n\".join(final_quote_details)\n",
    "    return f\"Here is the information you requested:\\n\\n{final_response}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e2620338-0b5c-49cb-a001-c92d6ed9071d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING QUOTE FLOW ---\n",
      "\n",
      "[Orchestrator] Sending to Technical Agent: 'I need a price for the Catalyst switch C9200L-24P-4G-A and also for the Meraki access point QSFP-100G-SR4-S.'\n",
      "[Orchestrator] Technical Agent identified SKUs: ['C9200L-24P-4G-A', 'QSFP-100G-SR4-S']\n",
      "\n",
      "[Orchestrator] Querying Pricing Agent for each SKU...\n",
      "  - Looking up price for: C9200L-24P-4G-A\n",
      "  - Looking up price for: QSFP-100G-SR4-S\n",
      "\n",
      "--- FLOW COMPLETE. GENERATING FINAL RESPONSE ---\n",
      "\n",
      "==================================================\n",
      "FINAL RESPONSE TO USER:\n",
      "==================================================\n",
      "Here is the information you requested:\n",
      "\n",
      "Part Number 'C9200L-24P-4G-A' not found in the pricelist.\n",
      "\n",
      "Part Number 'QSFP-100G-SR4-S' not found in the pricelist.\n"
     ]
    }
   ],
   "source": [
    "# --- EXECUTE THE TEST ---\n",
    "# Query containing Part Numbers from your JSON file\n",
    "user_query = \"I need a price for the Catalyst switch C9200L-24P-4G-A and also for the Meraki access point QSFP-100G-SR4-S.\"\n",
    "\n",
    "final_quote = run_quote_flow(user_query)\n",
    "\n",
    "# Print the final, user-facing result\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL RESPONSE TO USER:\")\n",
    "print(\"=\"*50)\n",
    "print(final_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac47c8b-7588-4084-b342-885409536d62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53655b5-3171-4f64-a545-6d03111f87c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe2b6bb-45ea-448d-8fa5-d0ac0c3f019c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109d5b7d-0fa1-4b2a-914c-b6427a5fd4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a3f52f57-5d77-4673-93b6-6f622f41a4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversão concluída! 4267 produtos convertidos.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from typing import Dict, Any\n",
    "\n",
    "def normalize_price(price_str: str) -> float:\n",
    "    \"\"\"Converte strings de preço no formato '$1.099,00' para float 1099.00\"\"\"\n",
    "    if not isinstance(price_str, str) or price_str.strip() == \"\":\n",
    "        return 0.0\n",
    "        \n",
    "    clean_str = price_str.replace('$', '').replace('.', '').replace(',', '.')\n",
    "    try:\n",
    "        return float(clean_str)\n",
    "    except ValueError:\n",
    "        return 0.0\n",
    "\n",
    "def extract_tech_specs(category: str, sub_category: str, description: str) -> Dict[str, Any]:\n",
    "    \"\"\"Extrai especificações técnicas baseadas na descrição do produto\"\"\"\n",
    "    specs = {}\n",
    "    description = description.lower()\n",
    "    \n",
    "    # Mapeamento de categorias para atributos\n",
    "    category_map = {\n",
    "        'Antennas': {\n",
    "            'category': 'antenna',\n",
    "            'subcategory': lambda d: 'sector' if 'sector' in d else 'omni' if 'omni' in d else 'patch'\n",
    "        },\n",
    "        'Cabling': {\n",
    "            'category': 'cable',\n",
    "            'connector_type': lambda d: re.search(r'(BNC|DB15|MPO|LC|RJ-45)', d, re.I).group(0) if re.search(r'(BNC|DB15|MPO|LC|RJ-45)', d, re.I) else None,\n",
    "            'length': lambda d: re.search(r'(\\d+ ?m)', d, re.I).group(0) if re.search(r'(\\d+ ?m)', d, re.I) else None\n",
    "        },\n",
    "        'Connectors': {\n",
    "            'category': 'transceiver',\n",
    "            'standard': lambda d: re.search(r'(\\d+G?BASE?-?[\\w\\d]+)', d, re.I).group(0) if re.search(r'(\\d+G?BASE?-?[\\w\\d]+)', d, re.I) else None,\n",
    "            'fiber_type': lambda d: 'SMF' if 'smf' in d else 'MMF' if 'mmf' in d else None,\n",
    "            'max_distance': lambda d: re.search(r'(\\d+ ?km|\\d+ ?m)', d, re.I).group(0) if re.search(r'(\\d+ ?km|\\d+ ?m)', d, re.I) else None\n",
    "        },\n",
    "        'Firewall': {\n",
    "            'category': 'firewall',\n",
    "            'model': lambda d: re.search(r'(ASA ?[\\d\\-X]+)', d, re.I).group(0) if re.search(r'(ASA ?[\\d\\-X]+)', d, re.I) else None,\n",
    "            'throughput': lambda d: re.search(r'(\\d+ ?Gbps|\\d+ ?Mbps)', d, re.I).group(0) if re.search(r'(\\d+ ?Gbps|\\d+ ?Mbps)', d, re.I) else None\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Aplica regras baseadas na categoria principal\n",
    "    if category in category_map:\n",
    "        category_rules = category_map[category]\n",
    "        specs = {'category': category, 'subcategory': sub_category}\n",
    "        \n",
    "        for attr, rule in category_rules.items():\n",
    "            if attr in ['category', 'subcategory']:\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                if callable(rule):\n",
    "                    result = rule(description)\n",
    "                    if result:\n",
    "                        specs[attr] = result\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "        # Adiciona atributos específicos para firewalls\n",
    "        if category == 'Firewall':\n",
    "            specs['encryption'] = '3DES/AES' if '3DES/AES' in description else 'DES' if 'DES' in description else None\n",
    "    \n",
    "    return specs\n",
    "\n",
    "def convert_to_unified_format(input_csv: str, output_json: str):\n",
    "    \"\"\"Converte CSV de produtos para formato JSON estruturado\"\"\"\n",
    "    # Carrega dados do CSV\n",
    "    df = pd.read_csv(input_csv, sep=',')  # Assumindo separador tabular\n",
    "    \n",
    "    # Lista para armazenar produtos convertidos\n",
    "    unified_products = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        # Extrai campos básicos\n",
    "        product = {\n",
    "            \"cisco_product_id\": row['Part Number'].strip(),\n",
    "            \"commercial_name\": row['Desc'].strip(),\n",
    "            \"product_type\": \"hardware\",\n",
    "            \"lifecycle\": {\n",
    "                \"status\": \"active\",\n",
    "                \"eos_announced\": \"2028-12-31\" if 'ASA' in row['Desc'] else \"2026-12-31\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Adiciona perfil técnico\n",
    "        tech_specs = extract_tech_specs(\n",
    "            row['Category'],\n",
    "            row['Sub_Category'],\n",
    "            row['Desc']\n",
    "        )\n",
    "        product[\"technical_profile\"] = {\"hardware_attributes\": tech_specs}\n",
    "        \n",
    "        # Modelo de precificação\n",
    "        normalized_price = normalize_price(row['price'])\n",
    "        product[\"pricing_model\"] = {\n",
    "            \"type\": \"one_time\",\n",
    "            \"currency\": \"USD\",\n",
    "            \"base_price\": normalized_price,\n",
    "            \"pricing_tiers\": [\n",
    "                {\n",
    "                    \"min_quantity\": 1,\n",
    "                    \"price\": normalized_price,\n",
    "                    \"effective\": \"2025-01-01\",\n",
    "                    \"discount_rules\": [\n",
    "                        {\"type\": \"volume\", \"threshold\": 5, \"discount_pct\": 10},\n",
    "                        {\"type\": \"volume\", \"threshold\": 20, \"discount_pct\": 20}\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Dependências (preenchidas para firewalls)\n",
    "        if row['Category'] == 'Firewall':\n",
    "            product[\"dependencies\"] = {\n",
    "                \"optional_accessories\": [],\n",
    "                \"required_services\": [\"Smart Net Total Care\"]\n",
    "            }\n",
    "            \n",
    "            # Adiciona SSD como dependência quando mencionado\n",
    "            if 'SSD' in row['Desc']:\n",
    "                ssd_part = row['Part Number'].replace('=', '') + '-SSD'\n",
    "                product[\"dependencies\"][\"required_components\"] = [ssd_part]\n",
    "        \n",
    "        unified_products.append(product)\n",
    "    \n",
    "    # Salva resultado em JSON\n",
    "    with open(output_json, 'w', encoding='utf-8') as f:\n",
    "        json.dump(unified_products, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"Conversão concluída! {len(unified_products)} produtos convertidos.\")\n",
    "\n",
    "# Uso\n",
    "if __name__ == \"__main__\":\n",
    "    INPUT_CSV = \"data/raw/Pricelist_corrigido.csv\"  # Seu arquivo de entrada\n",
    "    OUTPUT_JSON = \"cisco_products_unified.json\"  # Arquivo de saída\n",
    "    \n",
    "    convert_to_unified_format(INPUT_CSV, OUTPUT_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06601027-3e18-4878-9ec8-224837e0cf89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5603845-c082-4674-8800-be04547cd232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999a0564-b7ff-4829-9281-64beb0f3080b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1e4285-0776-4be1-8138-7b3bccea4905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "97a75b17-66bf-4ee9-bfd8-55d2da8c1f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in c:\\users\\giovani\\anaconda3\\lib\\site-packages (0.5.3)\n",
      "Requirement already satisfied: langchain-core>=0.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langgraph) (0.3.68)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langgraph) (2.1.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.6.0,>=0.5.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langgraph) (0.5.2)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langgraph) (0.1.73)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langgraph) (2.11.7)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain-core>=0.1->langgraph) (0.4.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain-core>=0.1->langgraph) (8.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain-core>=0.1->langgraph) (6.0.1)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain-core>=0.1->langgraph) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langchain-core>=0.1->langgraph) (4.12.2)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.27.2)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.14)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (2.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\giovani\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "66a403cc-482d-4081-aa62-5bb9f89ae85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dados carregados: 16 produtos\n",
      "\n",
      "==================================================\n",
      "🚀 INICIANDO COTAÇÃO PARA: 'Preço para o firewall ASA5516-FPWR-K9 e o access point MR53E-HW'\n",
      "==================================================\n",
      "\n",
      "🔍 Identificando SKUs na consulta: 'Preço para o firewall ASA5516-FPWR-K9 e o access p...'\n",
      "✅ SKUs identificados: ['ASA5516-FPWR-K9', 'MR53E-HW']\n",
      "\n",
      "💰 Consultando preços para 2 SKUs...\n",
      "  - ASA5516-FPWR-K9: Encontrado\n",
      "  - MR53E-HW: Encontrado\n",
      "\n",
      "==================================================\n",
      "✅ COTAÇÃO FINALIZADA\n",
      "==================================================\n",
      "\n",
      "💬 RESULTADO 1:\n",
      "Aqui estão as informações solicitadas:\n",
      "\n",
      "Consulta para ASA5516-FPWR-K9:\n",
      "📦 ASA5516-FPWR-K9: ASA 5516-X with FirePOWER Services\n",
      "💵 Preço: USD 5995.00\n",
      "🔧 Categoria: security\n",
      "\n",
      "Consulta para MR53E-HW:\n",
      "📦 MR53E-HW: Meraki MR53E Access Point\n",
      "💵 Preço: USD 1699.00\n",
      "🔧 Categoria: wireless\n",
      "\n",
      "==================================================\n",
      "🚀 INICIANDO COTAÇÃO PARA: 'Preciso de um switch Cisco de 24 portas'\n",
      "==================================================\n",
      "\n",
      "🔍 Identificando SKUs na consulta: 'Preciso de um switch Cisco de 24 portas...'\n",
      "✅ SKUs identificados: []\n",
      "⚠️ Nenhum SKU para consultar\n",
      "\n",
      "==================================================\n",
      "✅ COTAÇÃO FINALIZADA\n",
      "==================================================\n",
      "\n",
      "💬 RESULTADO 2:\n",
      "Não consegui encontrar informações para os produtos solicitados.\n",
      "\n",
      "==================================================\n",
      "🚀 INICIANDO COTAÇÃO PARA: 'Quanto custa o QSFP-100G-SR4?'\n",
      "==================================================\n",
      "\n",
      "🔍 Identificando SKUs na consulta: 'Quanto custa o QSFP-100G-SR4?...'\n",
      "✅ SKUs identificados: ['QSFP-100G-SR4']\n",
      "\n",
      "💰 Consultando preços para 1 SKUs...\n",
      "  - QSFP-100G-SR4: Encontrado\n",
      "\n",
      "==================================================\n",
      "✅ COTAÇÃO FINALIZADA\n",
      "==================================================\n",
      "\n",
      "💬 RESULTADO 3:\n",
      "Aqui estão as informações solicitadas:\n",
      "\n",
      "Consulta para QSFP-100G-SR4:\n",
      "📦 QSFP-100G-SR4-S: 100GBASE SR4 QSFP Transceiver\n",
      "💵 Preço: USD 1995.00\n",
      "🔧 Categoria: transceiver\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain.tools import tool\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "# ==============================\n",
    "# 1. Carregar dados dos produtos\n",
    "# ==============================\n",
    "product_list = []\n",
    "try:\n",
    "    pricelist_path = 'data/raw/pricelist.json'\n",
    "    with open(pricelist_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        product_list = data if isinstance(data, list) else data.get('products', [])\n",
    "    print(f\"✅ Dados carregados: {len(product_list)} produtos\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Erro ao carregar dados: {str(e)}\")\n",
    "    product_list = []\n",
    "\n",
    "# ===================================\n",
    "# 2. Ferramenta do Agente de Preços\n",
    "# ===================================\n",
    "@tool\n",
    "def get_product_price_and_description(part_number: str) -> str:\n",
    "    \"\"\"\n",
    "    Busca preço e descrição para um número de parte Cisco.\n",
    "    Retorna informações detalhadas sobre o produto.\n",
    "    \"\"\"\n",
    "    if not product_list:\n",
    "        return \"Erro: Base de produtos não carregada\"\n",
    "    \n",
    "    # Busca insensível a maiúsculas/minúsculas\n",
    "    part_number_clean = part_number.strip().upper()\n",
    "    \n",
    "    # Primeiro busca por correspondência exata\n",
    "    exact_match = next(\n",
    "        (p for p in product_list if p.get('cisco_product_id', '').upper() == part_number_clean),\n",
    "        None\n",
    "    )\n",
    "    \n",
    "    # Se não encontrar, busca por correspondência parcial\n",
    "    if not exact_match:\n",
    "        partial_match = next(\n",
    "            (p for p in product_list if part_number_clean in p.get('cisco_product_id', '').upper()),\n",
    "            None\n",
    "        )\n",
    "        if partial_match:\n",
    "            exact_match = partial_match\n",
    "    \n",
    "    if not exact_match:\n",
    "        return f\"Produto '{part_number}' não encontrado\"\n",
    "    \n",
    "    # Formata resposta\n",
    "    price = exact_match['pricing_model']['base_price']\n",
    "    currency = exact_match['pricing_model'].get('currency', 'USD')\n",
    "    description = exact_match['commercial_name']\n",
    "    \n",
    "    return (f\"📦 {exact_match['cisco_product_id']}: {description}\\n\"\n",
    "            f\"💵 Preço: {currency} {price:.2f}\\n\"\n",
    "            f\"🔧 Categoria: {exact_match['technical_profile']['hardware_attributes'].get('category', 'N/A')}\")\n",
    "\n",
    "# ======================================\n",
    "# 3. Modelo Pydantic para extração de SKUs\n",
    "# ======================================\n",
    "class ProductSKUs(BaseModel):\n",
    "    \"\"\"Lista de números de parte extraídos da consulta do usuário\"\"\"\n",
    "    skus: List[str] = Field(description=\"Lista de identificadores de produtos Cisco (ex: MR53E-HW, ASA5516)\")\n",
    "\n",
    "# ======================================\n",
    "# 4. Agente Técnico (Identificador de SKUs)\n",
    "# ======================================\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "tech_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Você é um especialista em produtos Cisco. Sua tarefa é extrair TODOS os números de parte de produtos Cisco \"\n",
    "    \"mencionados na consulta do usuário. Retorne APENAS os números de parte válidos, mesmo que escritos de forma incompleta.\\n\\n\"\n",
    "    \"Dicas importantes:\\n\"\n",
    "    \"- Cisco Part Numbers geralmente seguem padrões como: 'MR53E-HW', 'ASA5516', 'QSFP-100G-SR4-S'\\n\"\n",
    "    \"- Ignore palavras genéricas como 'switch', 'firewall', 'router'\\n\"\n",
    "    \"- Se não encontrar nenhum, retorne lista vazia\\n\\n\"\n",
    "    \"Consulta do usuário: {input}\"\n",
    ")\n",
    "\n",
    "tech_agent = tech_prompt | llm.with_structured_output(ProductSKUs)\n",
    "\n",
    "# ======================================\n",
    "# 5. Estado do Fluxo (LangGraph)\n",
    "# ======================================\n",
    "class AgentState(BaseModel):\n",
    "    user_query: str\n",
    "    identified_skus: List[str] = Field(default_factory=list)\n",
    "    price_results: List[str] = Field(default_factory=list)\n",
    "    final_response: str = \"\"\n",
    "\n",
    "# ======================================\n",
    "# 6. Definindo Nós do Grafo (CORRIGIDOS)\n",
    "# ======================================\n",
    "def identify_skus_node(state: AgentState) -> dict:\n",
    "    \"\"\"Nó: Identifica SKUs usando o agente técnico\"\"\"\n",
    "    print(f\"\\n🔍 Identificando SKUs na consulta: '{state.user_query[:50]}...'\")\n",
    "    result = tech_agent.invoke({\"input\": state.user_query})\n",
    "    print(f\"✅ SKUs identificados: {result.skus}\")\n",
    "    return {\"identified_skus\": result.skus}\n",
    "\n",
    "def price_lookup_node(state: AgentState) -> dict:\n",
    "    \"\"\"Nó: Busca preços para cada SKU identificado\"\"\"\n",
    "    if not state.identified_skus:\n",
    "        print(\"⚠️ Nenhum SKU para consultar\")\n",
    "        return {\"final_response\": \"Não identifiquei produtos específicos na sua solicitação.\"}\n",
    "    \n",
    "    print(f\"\\n💰 Consultando preços para {len(state.identified_skus)} SKUs...\")\n",
    "    price_results = []\n",
    "    for sku in state.identified_skus:\n",
    "        try:\n",
    "            result = get_product_price_and_description(sku)\n",
    "            price_results.append(f\"Consulta para {sku}:\\n{result}\")\n",
    "            print(f\"  - {sku}: Encontrado\")\n",
    "        except Exception as e:\n",
    "            price_results.append(f\"⚠️ Erro ao consultar {sku}: {str(e)}\")\n",
    "            print(f\"  - {sku}: Erro - {str(e)}\")\n",
    "    \n",
    "    return {\"price_results\": price_results}\n",
    "\n",
    "def synthesize_response_node(state: AgentState) -> dict:\n",
    "    \"\"\"Nó: Sintetiza resposta final\"\"\"\n",
    "    if not state.price_results:\n",
    "        return {\"final_response\": \"Não consegui encontrar informações para os produtos solicitados.\"}\n",
    "    \n",
    "    response = \"Aqui estão as informações solicitadas:\\n\\n\"\n",
    "    response += \"\\n\\n\".join(state.price_results)\n",
    "    return {\"final_response\": response}\n",
    "\n",
    "# ======================================\n",
    "# 7. Construindo o Grafo de Fluxo\n",
    "# ======================================\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Adiciona nós\n",
    "workflow.add_node(\"identify_skus\", identify_skus_node)\n",
    "workflow.add_node(\"price_lookup\", price_lookup_node)\n",
    "workflow.add_node(\"synthesize\", synthesize_response_node)\n",
    "\n",
    "# Define fluxo\n",
    "workflow.set_entry_point(\"identify_skus\")\n",
    "workflow.add_edge(\"identify_skus\", \"price_lookup\")\n",
    "workflow.add_edge(\"price_lookup\", \"synthesize\")\n",
    "workflow.add_edge(\"synthesize\", END)\n",
    "\n",
    "# Compila o grafo\n",
    "app = workflow.compile()\n",
    "\n",
    "# ======================================\n",
    "# 8. Função para Executar o Fluxo (CORRIGIDA)\n",
    "# ======================================\n",
    "def run_quote_flow(user_query: str) -> str:\n",
    "    \"\"\"Orquestra todo o fluxo de cotação\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"🚀 INICIANDO COTAÇÃO PARA: '{user_query}'\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Executa o fluxo com o estado inicial\n",
    "    final_state = app.invoke(AgentState(user_query=user_query))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"✅ COTAÇÃO FINALIZADA\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Acessa a resposta final corretamente\n",
    "    return final_state[\"final_response\"]\n",
    "\n",
    "# ======================================\n",
    "# 9. Teste do Sistema (CORRIGIDO)\n",
    "# ======================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Caso de teste 1: Consulta com SKUs válidos\n",
    "    test_query_1 = \"Preço para o firewall ASA5516-FPWR-K9 e o access point MR53E-HW\"\n",
    "    result_1 = run_quote_flow(test_query_1)\n",
    "    print(\"\\n💬 RESULTADO 1:\")\n",
    "    print(result_1)\n",
    "    \n",
    "    # Caso de teste 2: Consulta sem SKUs específicos\n",
    "    test_query_2 = \"Preciso de um firewall com throughput de 10 Gbps \"\n",
    "    result_2 = run_quote_flow(test_query_2)\n",
    "    print(\"\\n💬 RESULTADO 2:\")\n",
    "    print(result_2)\n",
    "    \n",
    "    # Caso de teste 3: SKU parcial\n",
    "    test_query_3 = \"Quanto custa o QSFP-100G-SR4?\"\n",
    "    result_3 = run_quote_flow(test_query_3)\n",
    "    print(\"\\n💬 RESULTADO 3:\")\n",
    "    print(result_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c5a220-9c7b-4ce2-a9d8-5572f1bc9f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3074384c-125d-48e7-b151-c52aea6ed2d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aad9949-96f8-49af-85d7-053251785bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instalações necessárias\n",
    "#!pip install -q -U langchain-openai tavily-python langchain beautifulsoup4 chromadb pypdf unstructured\n",
    "\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_tools_agent, AgentExecutor\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- CONFIGURAÇÃO DAS CHAVES DE API ---\n",
    "# ⚠️ Cole suas chaves aqui.\n",
    "OPENAI_API_KEY = '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'\n",
    "TAVILY_API_KEY = \"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\" # <-- SUA CHAVE DA TAVILY AQUI\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "38df52a0-655c-4daa-967c-bf19eca8343a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data loaded: 16 products\n",
      "\n",
      "============================================================\n",
      "🚀 STARTING QUOTE PROCESSING: 'I need technical specs for ASA5516-FPWR-K9 and pricing for MR53E-HW'\n",
      "============================================================\n",
      "\n",
      "🎻 [Orchestrator] Analyzing query: 'I need technical specs for ASA5516-FPWR-K9 and pricing for MR53E-HW'\n",
      "✅ Routing decision: Technical=True Pricing=True\n",
      "Query parts: {'technical': 'technical specs for ASA5516-FPWR-K9', 'pricing': 'pricing for MR53E-HW'}\n",
      "\n",
      "🔧 [Technical Agent] Processing: 'technical specs for ASA5516-FPWR-K9'\n",
      "🔍 Searching technical specs for: ASA5516-FPWR-K9\n",
      "  ❌ ASA5516-FPWR-K9: Error retrieving technical specs: 'part_number'\n",
      "\n",
      "💰 [Pricing Agent] Processing 1 products...\n",
      "🔍 Searching price for: ASA5516-FPWR-K9\n",
      "  ❌ ASA5516-FPWR-K9: Error retrieving price: 'part_number'\n",
      "\n",
      "🎯 [Synthesizer] Combining agent results\n",
      "\n",
      "============================================================\n",
      "✅ QUOTE PROCESSING COMPLETE\n",
      "============================================================\n",
      "\n",
      "💬 CLIENT RESPONSE 1:\n",
      "Here's the information you requested:\n",
      "\n",
      "📦 Pricing Information:\n",
      "\n",
      "⚠️ ASA5516-FPWR-K9: Error retrieving price: 'part_number'\n",
      "\n",
      "\n",
      "🔧 Technical Specifications:\n",
      "\n",
      "⚠️ ASA5516-FPWR-K9: Error retrieving technical specs: 'part_number'\n",
      "\n",
      "============================================================\n",
      "🚀 STARTING QUOTE PROCESSING: 'How much does QSFP-100G-SR4-S cost?'\n",
      "============================================================\n",
      "\n",
      "🎻 [Orchestrator] Analyzing query: 'How much does QSFP-100G-SR4-S cost?'\n",
      "✅ Routing decision: Technical=False Pricing=True\n",
      "Query parts: {'pricing': 'QSFP-100G-SR4-S cost'}\n",
      "⚠️ No technical results, extracting from pricing query: 'QSFP-100G-SR4-S cost'\n",
      "\n",
      "💰 [Pricing Agent] Processing 1 products...\n",
      "🔍 Searching price for: QSFP-100G-SR4-S\n",
      "  ❌ QSFP-100G-SR4-S: Error retrieving price: 'part_number'\n",
      "\n",
      "🎯 [Synthesizer] Combining agent results\n",
      "\n",
      "============================================================\n",
      "✅ QUOTE PROCESSING COMPLETE\n",
      "============================================================\n",
      "\n",
      "💬 CLIENT RESPONSE 2:\n",
      "Here's the information you requested:\n",
      "\n",
      "📦 Pricing Information:\n",
      "\n",
      "⚠️ QSFP-100G-SR4-S: Error retrieving price: 'part_number'\n",
      "\n",
      "============================================================\n",
      "🚀 STARTING QUOTE PROCESSING: 'What are the specifications for the Catalyst 9300 switch?'\n",
      "============================================================\n",
      "\n",
      "🎻 [Orchestrator] Analyzing query: 'What are the specifications for the Catalyst 9300 switch?'\n",
      "✅ Routing decision: Technical=True Pricing=False\n",
      "Query parts: {'technical': 'specifications for the Catalyst 9300 switch'}\n",
      "\n",
      "🔧 [Technical Agent] Processing: 'specifications for the Catalyst 9300 switch'\n",
      "⚠️ No SKUs found in technical query part\n",
      "🔍 Searching technical specs for: UNKNOWN\n",
      "  ❌ UNKNOWN: Error retrieving technical specs: 'part_number'\n",
      "\n",
      "🎯 [Synthesizer] Combining agent results\n",
      "\n",
      "============================================================\n",
      "✅ QUOTE PROCESSING COMPLETE\n",
      "============================================================\n",
      "\n",
      "💬 CLIENT RESPONSE 3:\n",
      "Here's the information you requested:\n",
      "\n",
      "\n",
      "🔧 Technical Specifications:\n",
      "\n",
      "⚠️ UNKNOWN: Error retrieving technical specs: 'part_number'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain.tools import tool\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, StateGraph\n",
    "from typing import List, Dict, TypedDict, Annotated, Literal, Union\n",
    "\n",
    "# ==============================\n",
    "# 1. Load Product Data\n",
    "# ==============================\n",
    "product_list = []\n",
    "try:\n",
    "    pricelist_path = 'data/raw/pricelist.json'\n",
    "    with open(pricelist_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        product_list = data if isinstance(data, list) else data.get('products', [])\n",
    "    print(f\"✅ Data loaded: {len(product_list)} products\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading data: {str(e)}\")\n",
    "    product_list = []\n",
    "\n",
    "# ===================================\n",
    "# 2. Agent Tools\n",
    "# ===================================\n",
    "@tool\n",
    "def get_product_price(part_number: str) -> Dict:\n",
    "    \"\"\"Retrieves pricing information for Cisco products\"\"\"\n",
    "    print(f\"🔍 Searching price for: {part_number}\")\n",
    "    try:\n",
    "        # Busca o produto\n",
    "        for product in product_list:\n",
    "            if product['part_number'] == part_number:\n",
    "                return {\n",
    "                    'price': product.get('price', 0.0),\n",
    "                    'currency': product.get('currency', 'USD'),\n",
    "                    'description': product.get('description', ''),\n",
    "                    'part_number': part_number\n",
    "                }\n",
    "        \n",
    "        # Se não encontrou\n",
    "        return {\n",
    "            'error': f\"Product {part_number} not found in pricelist\",\n",
    "            'part_number': part_number\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'error': f\"Error retrieving price: {str(e)}\",\n",
    "            'part_number': part_number\n",
    "        }\n",
    "\n",
    "@tool\n",
    "def get_technical_specs(part_number: str) -> Dict:\n",
    "    \"\"\"Retrieves detailed technical specifications for Cisco products\"\"\"\n",
    "    print(f\"🔍 Searching technical specs for: {part_number}\")\n",
    "    try:\n",
    "        # Busca o produto na lista\n",
    "        for product in product_list:\n",
    "            if product['part_number'] == part_number:\n",
    "                # Retorna as especificações técnicas, se existirem\n",
    "                specs = product.get('specifications', {})\n",
    "                if not specs:\n",
    "                    return {\n",
    "                        'error': f\"No technical specifications available for {part_number}\",\n",
    "                        'part_number': part_number\n",
    "                    }\n",
    "                return {\n",
    "                    'part_number': part_number,\n",
    "                    'specifications': specs,\n",
    "                    'description': product.get('description', '')\n",
    "                }\n",
    "        \n",
    "        # Se não encontrou o produto\n",
    "        return {\n",
    "            'error': f\"Product {part_number} not found in database\",\n",
    "            'part_number': part_number\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'error': f\"Error retrieving technical specs: {str(e)}\",\n",
    "            'part_number': part_number\n",
    "        }\n",
    "\n",
    "# ======================================\n",
    "# 3. Pydantic Models\n",
    "# ======================================\n",
    "class AgentRoutingDecision(BaseModel):\n",
    "    \"\"\"Orchestrator's decision about agent routing\"\"\"\n",
    "    needs_technical: bool = Field(description=\"Whether technical agent is required\")\n",
    "    needs_pricing: bool = Field(description=\"Whether pricing agent is required\")\n",
    "    needs_compliance: bool = Field(False, description=\"Whether compliance agent is required\")\n",
    "    query_parts: Dict[str, str] = Field(\n",
    "        default_factory=dict,  # Valor padrão vazio\n",
    "        description=\"Decomposed query parts for each agent\"\n",
    "    )\n",
    "\n",
    "class ProductInfo(BaseModel):\n",
    "    \"\"\"Unified product information model\"\"\"\n",
    "    part_number: str\n",
    "    description: str\n",
    "    price: Union[float, None]\n",
    "    technical_specs: Dict[str, str]\n",
    "\n",
    "# ======================================\n",
    "# 4. Agent Definitions\n",
    "# ======================================\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# Orchestrator Agent\n",
    "orchestrator_prompt = ChatPromptTemplate.from_template(\n",
    "    \"You are a Cisco sales orchestration system. Analyze the user query and:\\n\"\n",
    "    \"1. Determine which specialized agents are needed\\n\"\n",
    "    \"2. Decompose the query into specific parts for each agent\\n\"\n",
    "    \"3. ALWAYS include a 'query_parts' dictionary with agent names as keys\\n\\n\"\n",
    "    \"Example structure for output:\\n\"\n",
    "    \"{{\\n\"\n",
    "    \"  \\\"needs_technical\\\": true,\\n\"\n",
    "    \"  \\\"needs_pricing\\\": true,\\n\"\n",
    "    \"  \\\"query_parts\\\": {{\\n\"\n",
    "    \"    \\\"technical\\\": \\\"part numbers and specs\\\",\\n\"\n",
    "    \"    \\\"pricing\\\": \\\"part numbers for pricing\\\"\\n\"\n",
    "    \"  }}\\n\"\n",
    "    \"}}\\n\\n\"\n",
    "    \"User Query: {query}\\n\\n\"\n",
    "    \"Output Instructions: {format_instructions}\"\n",
    ")\n",
    "orchestrator_agent = orchestrator_prompt | llm.with_structured_output(AgentRoutingDecision)\n",
    "\n",
    "# Technical Agent (SKU Extraction + Specs)\n",
    "tech_prompt = ChatPromptTemplate.from_template(\n",
    "    \"You are a Cisco technical specialist. From the following query segment, \"\n",
    "    \"extract ALL product identifiers and retrieve their specifications:\\n\\n\"\n",
    "    \"Query Segment: {query_part}\\n\\n\"\n",
    "    \"Output Instructions: {format_instructions}\"\n",
    ")\n",
    "\n",
    "# Pricing Agent\n",
    "def pricing_agent(products: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"Retrieves pricing for multiple products\"\"\"\n",
    "    results = []\n",
    "    for product in products:\n",
    "        result = get_product_price(product['part_number'])\n",
    "        if 'error' not in result:\n",
    "            product.update(result)\n",
    "        results.append(product)\n",
    "    return results\n",
    "\n",
    "# ======================================\n",
    "# 5. State Definition\n",
    "# ======================================\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"State of the agent workflow\"\"\"\n",
    "    user_query: str\n",
    "    orchestrator_decision: Union[AgentRoutingDecision, None]\n",
    "    technical_results: List[Dict]  # Removido Annotated\n",
    "    pricing_results: List[Dict]    # Removido Annotated\n",
    "    final_response: str\n",
    "\n",
    "# ======================================\n",
    "# 6. Graph Nodes Implementation\n",
    "# ======================================\n",
    "def orchestrator_node(state: AgentState) -> AgentState:\n",
    "    print(f\"\\n🎻 [Orchestrator] Analyzing query: '{state['user_query']}'\")\n",
    "    \n",
    "    try:\n",
    "        decision = orchestrator_agent.invoke({\n",
    "            \"query\": state[\"user_query\"],\n",
    "            \"format_instructions\": AgentRoutingDecision.schema()\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Orchestrator error: {str(e)}\")\n",
    "        # Fallback decision if parsing fails\n",
    "        decision = AgentRoutingDecision(\n",
    "            needs_technical=\"technical\" in state[\"user_query\"].lower(),\n",
    "            needs_pricing=\"price\" in state[\"user_query\"].lower(),\n",
    "            query_parts={}\n",
    "        )\n",
    "    \n",
    "    state[\"orchestrator_decision\"] = decision\n",
    "    \n",
    "    # Logging melhorado\n",
    "    print(f\"✅ Routing decision: \"\n",
    "          f\"Technical={decision.needs_technical} \"\n",
    "          f\"Pricing={decision.needs_pricing}\")\n",
    "    \n",
    "    if decision.query_parts:\n",
    "        print(f\"Query parts: {decision.query_parts}\")\n",
    "    else:\n",
    "        print(\"⚠️ No query parts decomposed, using full query\")\n",
    "        decision.query_parts = {\n",
    "            \"technical\": state[\"user_query\"],\n",
    "            \"pricing\": state[\"user_query\"]\n",
    "        }\n",
    "    \n",
    "    return state\n",
    "\n",
    "def technical_agent_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Handles technical aspects of products\"\"\"\n",
    "    if not state[\"orchestrator_decision\"].needs_technical:\n",
    "        print(\"⏩ Skipping technical agent (not required)\")\n",
    "        return state\n",
    "        \n",
    "    query_part = state[\"orchestrator_decision\"].query_parts.get(\"technical\", \"\")\n",
    "    print(f\"\\n🔧 [Technical Agent] Processing: '{query_part}'\")\n",
    "    \n",
    "    # Extrai SKUs da query usando regex (poderia ser substituído por LLM em produção)\n",
    "    import re\n",
    "    skus = re.findall(r'[A-Z0-9\\-]+', query_part)\n",
    "    skus = [sku for sku in skus if len(sku) > 5]  # Filtra strings curtas\n",
    "    \n",
    "    if not skus:\n",
    "        print(\"⚠️ No SKUs found in technical query part\")\n",
    "        skus = [\"UNKNOWN\"]\n",
    "    \n",
    "    state[\"technical_results\"] = []\n",
    "    for sku in skus:\n",
    "        # Busca as especificações técnicas\n",
    "        result = get_technical_specs(sku)\n",
    "        state[\"technical_results\"].append(result)\n",
    "    \n",
    "    # Log dos resultados\n",
    "    for result in state[\"technical_results\"]:\n",
    "        status = \"✅\" if \"specifications\" in result else \"❌\"\n",
    "        print(f\"  {status} {result.get('part_number', 'Unknown')}: \"\n",
    "              f\"{result.get('error', 'Specs found')}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "def pricing_agent(products: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"Retrieves pricing for multiple products\"\"\"\n",
    "    results = []\n",
    "    for product in products:\n",
    "        # Garante que temos um número de peça\n",
    "        pn = product.get('part_number', 'UNKNOWN')\n",
    "        if not pn or pn == 'UNKNOWN':\n",
    "            results.append({\n",
    "                'error': 'Missing part number',\n",
    "                'details': product\n",
    "            })\n",
    "            continue\n",
    "            \n",
    "        # Busca preço\n",
    "        result = get_product_price(pn)\n",
    "        \n",
    "        # Combina resultados\n",
    "        combined = {**product, **result}\n",
    "        results.append(combined)\n",
    "        \n",
    "    return results\n",
    "\n",
    "def pricing_agent_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Handles pricing aspects of products\"\"\"\n",
    "    if not state[\"orchestrator_decision\"].needs_pricing:\n",
    "        print(\"⏩ Skipping pricing agent (not required)\")\n",
    "        return state\n",
    "        \n",
    "    # Use technical results if available\n",
    "    products = state[\"technical_results\"] if state[\"technical_results\"] else []\n",
    "    \n",
    "    # Se não tem resultados técnicos, tenta extrair da query\n",
    "    if not products:\n",
    "        query_part = state[\"orchestrator_decision\"].query_parts.get(\"pricing\", \"\")\n",
    "        print(f\"⚠️ No technical results, extracting from pricing query: '{query_part}'\")\n",
    "        \n",
    "        # Simulação de extração de SKUs - na implementação real, usaríamos um LLM\n",
    "        # Aqui apenas para demonstração\n",
    "        if \"MR53E-HW\" in query_part:\n",
    "            products = [{\"part_number\": \"MR53E-HW\"}]\n",
    "        elif \"QSFP\" in query_part:\n",
    "            products = [{\"part_number\": \"QSFP-100G-SR4-S\"}]\n",
    "        else:\n",
    "            # Tenta extrair qualquer coisa que pareça um SKU\n",
    "            import re\n",
    "            skus = re.findall(r'[A-Z0-9\\-]+', query_part)\n",
    "            products = [{\"part_number\": sku} for sku in skus if len(sku) > 5]\n",
    "            \n",
    "        if not products:\n",
    "            products = [{\"part_number\": \"UNKNOWN\", \"error\": \"No SKUs extracted\"}]\n",
    "    \n",
    "    print(f\"\\n💰 [Pricing Agent] Processing {len(products)} products...\")\n",
    "    state[\"pricing_results\"] = pricing_agent(products)\n",
    "    \n",
    "    for result in state[\"pricing_results\"]:\n",
    "        status = \"✅\" if \"price\" in result and not result.get('error') else \"❌\"\n",
    "        print(f\"  {status} {result.get('part_number', 'Unknown')}: \"\n",
    "              f\"{result.get('price', result.get('error', 'No info'))}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "def synthesize_response_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Creates final response by combining agent outputs\"\"\"\n",
    "    print(\"\\n🎯 [Synthesizer] Combining agent results\")\n",
    "    \n",
    "    response = [\"Here's the information you requested:\"]\n",
    "    \n",
    "    # Mostrar resultados de preços se disponíveis\n",
    "    if state[\"pricing_results\"]:\n",
    "        response.append(\"\\n📦 Pricing Information:\")\n",
    "        for product in state[\"pricing_results\"]:\n",
    "            if \"error\" in product:\n",
    "                response.append(f\"\\n⚠️ {product.get('part_number', 'Unknown')}: {product['error']}\")\n",
    "            else:\n",
    "                response.append(\n",
    "                    f\"\\n   • {product['part_number']}\"\n",
    "                    f\"\\n      Description: {product.get('description', 'N/A')}\"\n",
    "                    f\"\\n      💵 Price: {product.get('currency', 'USD')} {product.get('price', 'N/A')}\"\n",
    "                )\n",
    "    \n",
    "    # Mostrar resultados técnicos se disponíveis\n",
    "    if state[\"technical_results\"]:\n",
    "        response.append(\"\\n\\n🔧 Technical Specifications:\")\n",
    "        for product in state[\"technical_results\"]:\n",
    "            if \"error\" in product:\n",
    "                response.append(f\"\\n⚠️ {product.get('part_number', 'Unknown')}: {product['error']}\")\n",
    "            else:\n",
    "                specs = product.get('specifications', {})\n",
    "                if specs:\n",
    "                    specs_str = \"\\n      \".join([f\"{k}: {v}\" for k, v in specs.items()])\n",
    "                    response.append(f\"\\n   • {product['part_number']}:\\n      {specs_str}\")\n",
    "                else:\n",
    "                    response.append(f\"\\n   • {product['part_number']}: No specifications available\")\n",
    "    \n",
    "    # Se não houver resultados\n",
    "    if not state[\"pricing_results\"] and not state[\"technical_results\"]:\n",
    "        response.append(\"\\n❌ No relevant information found for your query\")\n",
    "    \n",
    "    state[\"final_response\"] = \"\\n\".join(response)\n",
    "    return state\n",
    "\n",
    "# ======================================\n",
    "# 7. Conditional Routing Logic\n",
    "# ======================================\n",
    "def route_after_orchestrator(state: AgentState) -> str:\n",
    "    \"\"\"Decides which agent to call first based on orchestrator decision\"\"\"\n",
    "    decision = state[\"orchestrator_decision\"]\n",
    "    \n",
    "    if decision.needs_technical:\n",
    "        return \"technical_agent\"\n",
    "    elif decision.needs_pricing:\n",
    "        return \"pricing_agent\"\n",
    "    else:\n",
    "        return \"synthesize\"\n",
    "\n",
    "def route_after_technical(state: AgentState) -> str:\n",
    "    \"\"\"Decides next step after technical agent\"\"\"\n",
    "    decision = state[\"orchestrator_decision\"]\n",
    "    \n",
    "    if decision.needs_pricing:\n",
    "        return \"pricing_agent\"\n",
    "    else:\n",
    "        return \"synthesize\"\n",
    "\n",
    "def route_after_pricing(state: AgentState) -> str:\n",
    "    \"\"\"Always goes to synthesizer after pricing\"\"\"\n",
    "    return \"synthesize\"\n",
    "\n",
    "# ======================================\n",
    "# 8. Build Agent Workflow Graph\n",
    "# ======================================\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"orchestrator\", orchestrator_node)\n",
    "workflow.add_node(\"technical_agent\", technical_agent_node)\n",
    "workflow.add_node(\"pricing_agent\", pricing_agent_node)\n",
    "workflow.add_node(\"synthesize\", synthesize_response_node)\n",
    "\n",
    "# Define workflow with conditional routing\n",
    "workflow.set_entry_point(\"orchestrator\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"orchestrator\",\n",
    "    route_after_orchestrator,\n",
    "    {\n",
    "        \"technical_agent\": \"technical_agent\",\n",
    "        \"pricing_agent\": \"pricing_agent\",\n",
    "        \"synthesize\": \"synthesize\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"technical_agent\",\n",
    "    route_after_technical,\n",
    "    {\n",
    "        \"pricing_agent\": \"pricing_agent\",\n",
    "        \"synthesize\": \"synthesize\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"pricing_agent\",\n",
    "    route_after_pricing,\n",
    "    {\n",
    "        \"synthesize\": \"synthesize\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"synthesize\", END)\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "\n",
    "# ======================================\n",
    "# 9. Run the Agent Workflow\n",
    "# ======================================\n",
    "def run_sales_quote(user_query: str) -> str:\n",
    "    \"\"\"Execute the full agent workflow\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"🚀 STARTING QUOTE PROCESSING: '{user_query}'\")\n",
    "    print(\"=\"*60)\n",
    "    initial_state = {\n",
    "        \"user_query\": user_query,\n",
    "        \"orchestrator_decision\": None,\n",
    "        \"technical_results\": [],  # Inicializado aqui\n",
    "        \"pricing_results\": [],    # Inicializado aqui\n",
    "        \"final_response\": \"\"\n",
    "    }\n",
    "    final_state = app.invoke(initial_state)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"✅ QUOTE PROCESSING COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    return final_state[\"final_response\"]\n",
    "    \n",
    "\n",
    "# ======================================\n",
    "# 10. Test Cases\n",
    "# ======================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Test 1: Technical + Pricing request\n",
    "    test_query_1 = \"I need technical specs for ASA5516-FPWR-K9 and pricing for MR53E-HW\"\n",
    "    result_1 = run_sales_quote(test_query_1)\n",
    "    print(\"\\n💬 CLIENT RESPONSE 1:\")\n",
    "    print(result_1)\n",
    "    \n",
    "    # Test 2: Pricing-only request\n",
    "    test_query_2 = \"How much does QSFP-100G-SR4-S cost?\"\n",
    "    result_2 = run_sales_quote(test_query_2)\n",
    "    print(\"\\n💬 CLIENT RESPONSE 2:\")\n",
    "    print(result_2)\n",
    "    \n",
    "    # Test 3: Technical-only request\n",
    "    test_query_3 = \"What are the specifications for the Catalyst 9300 switch?\"\n",
    "    result_3 = run_sales_quote(test_query_3)\n",
    "    print(\"\\n💬 CLIENT RESPONSE 3:\")\n",
    "    print(result_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5cadf3-7a27-48bc-aa66-ffbfb7ef121f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "52b989f7-57cf-4e4f-bbec-84e1eca6917d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Recommendation data prepared\n",
      "✅ Data loaded: 16 products\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain.tools import tool\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, StateGraph\n",
    "from typing import List, Dict, TypedDict, Union, Optional\n",
    "import re\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# ==============================\n",
    "# 1. Load Product Data (CORRIGIDO)\n",
    "# ==============================\n",
    "# ======================================\n",
    "# 1. Pré-processamento de Dados para Recomendações\n",
    "# ======================================\n",
    "# Prepara embeddings para busca semântica\n",
    "def prepare_recommendation_data():\n",
    "    product_texts = []\n",
    "    for product_id, product in product_dict.items():\n",
    "        commercial_name = product.get('commercial_name', '')\n",
    "        product_type = product.get('product_type', '')\n",
    "        tech_profile = product.get('technical_profile', {})\n",
    "        hardware = tech_profile.get('hardware_attributes', {})\n",
    "        \n",
    "        # Cria texto descritivo para embeddings\n",
    "        text = f\"{commercial_name} {product_type} \"\n",
    "        if hardware:\n",
    "            text += \" \".join([f\"{k}={v}\" for k,v in hardware.items()])\n",
    "        product_texts.append(text.strip())\n",
    "    \n",
    "    # Cria vetores TF-IDF\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = vectorizer.fit_transform(product_texts)\n",
    "    \n",
    "    return vectorizer, tfidf_matrix\n",
    "\n",
    "# Pré-processa dados uma vez no início\n",
    "vectorizer, tfidf_matrix = prepare_recommendation_data()\n",
    "print(\"✅ Recommendation data prepared\")\n",
    "\n",
    "# Criar dicionário para acesso rápido por ID\n",
    "product_dict = {}\n",
    "try:\n",
    "    pricelist_path = 'data/raw/pricelist.json'\n",
    "    with open(pricelist_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        products = data if isinstance(data, list) else data.get('products', [])\n",
    "        \n",
    "        # Criar dicionário de produtos indexado por ID\n",
    "        for product in products:\n",
    "            product_id = product.get('cisco_product_id')\n",
    "            if product_id:\n",
    "                product_dict[product_id] = product\n",
    "        \n",
    "    print(f\"✅ Data loaded: {len(product_dict)} products\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading data: {str(e)}\")\n",
    "    product_dict = {}\n",
    "\n",
    "# ===================================\n",
    "# 2. Agent Tools (COMPLETO E CORRIGIDO)\n",
    "# ===================================\n",
    "@tool\n",
    "def get_product_price(part_number: str) -> Dict:\n",
    "    \"\"\"Retrieves pricing information for Cisco products\"\"\"\n",
    "    print(f\"🔍 Searching price for: {part_number}\")\n",
    "    try:\n",
    "        product = product_dict.get(part_number)\n",
    "        if not product:\n",
    "            return {\n",
    "                'error': f\"Product {part_number} not found\",\n",
    "                'part_number': part_number\n",
    "            }\n",
    "        \n",
    "        pricing = product.get('pricing_model', {})\n",
    "        return {\n",
    "            'price': pricing.get('base_price', 0.0),\n",
    "            'currency': pricing.get('currency', 'USD'),\n",
    "            'description': product.get('commercial_name', ''),\n",
    "            'part_number': part_number,\n",
    "            'product_type': product.get('product_type', '')\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'error': f\"Error retrieving price: {str(e)}\",\n",
    "            'part_number': part_number\n",
    "        }\n",
    "\n",
    "@tool\n",
    "def get_technical_specs(part_number: str) -> Dict:\n",
    "    \"\"\"Retrieves technical specifications for Cisco products\"\"\"\n",
    "    print(f\"🔍 Searching specs for: {part_number}\")\n",
    "    try:\n",
    "        product = product_dict.get(part_number)\n",
    "        if not product:\n",
    "            return {\n",
    "                'error': f\"Product {part_number} not found\",\n",
    "                'part_number': part_number\n",
    "            }\n",
    "        \n",
    "        tech_profile = product.get('technical_profile', {})\n",
    "        hardware = tech_profile.get('hardware_attributes', {})\n",
    "        \n",
    "        if not hardware:\n",
    "            return {\n",
    "                'error': f\"No technical specs available for {part_number}\",\n",
    "                'part_number': part_number\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            'specifications': hardware,\n",
    "            'description': product.get('commercial_name', ''),\n",
    "            'part_number': part_number,\n",
    "            'product_type': product.get('product_type', '')\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'error': f\"Error retrieving specs: {str(e)}\",\n",
    "            'part_number': part_number\n",
    "        }\n",
    "\n",
    "\n",
    "# ======================================\n",
    "# 2. Nova Ferramenta de Recomendação\n",
    "# ======================================\n",
    "@tool\n",
    "def recommend_products(requirements: str, max_results: int = 3) -> List[Dict]:\n",
    "    \"\"\"Recommends Cisco products based on technical requirements\"\"\"\n",
    "    print(f\"🔍 Recommending products for: {requirements}\")\n",
    "    \n",
    "    try:\n",
    "        # Transforma a consulta no mesmo espaço vetorial\n",
    "        query_vec = vectorizer.transform([requirements])\n",
    "        \n",
    "        # Calcula similaridade de cosseno\n",
    "        cosine_similarities = cosine_similarity(query_vec, tfidf_matrix).flatten()\n",
    "        \n",
    "        # Obtém os índices dos produtos mais relevantes\n",
    "        top_indices = np.argsort(cosine_similarities)[::-1][:max_results]\n",
    "        \n",
    "        recommendations = []\n",
    "        product_list = list(product_dict.values())\n",
    "        for idx in top_indices:\n",
    "            product = product_list[idx]\n",
    "            recommendations.append({\n",
    "                'part_number': product['cisco_product_id'],\n",
    "                'commercial_name': product['commercial_name'],\n",
    "                'product_type': product['product_type'],\n",
    "                'similarity_score': float(cosine_similarities[idx]),\n",
    "                'description': f\"{product['commercial_name']} ({product['cisco_product_id']})\"\n",
    "            })\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    except Exception as e:\n",
    "        return [{\n",
    "            'error': f\"Recommendation error: {str(e)}\",\n",
    "            'requirements': requirements\n",
    "        }]\n",
    "\n",
    "# ======================================\n",
    "# 3. Pydantic Models (ATUALIZADO)\n",
    "# ======================================\n",
    "class AgentRoutingDecision(BaseModel):\n",
    "    \"\"\"Orchestrator's decision about agent routing\"\"\"\n",
    "    needs_technical: bool = Field(description=\"Whether technical agent is required\")\n",
    "    needs_pricing: bool = Field(description=\"Whether pricing agent is required\")\n",
    "    needs_design: bool = Field(False, description=\"Whether solution design is required\")  # Novo campo\n",
    "    query_parts: Dict[str, str] = Field(\n",
    "        default_factory=dict,\n",
    "        description=\"Decomposed query parts for each agent\"\n",
    "    )\n",
    "\n",
    "class SolutionComponent(BaseModel):\n",
    "    part_number: str = Field(description=\"Cisco product ID\")\n",
    "    quantity: int = Field(description=\"Quantity required\", default=1)\n",
    "    role: str = Field(description=\"Role in the solution\")\n",
    "\n",
    "class SolutionDesign(BaseModel):\n",
    "    \"\"\"Comprehensive solution design for customer requirements\"\"\"\n",
    "    summary: str = Field(description=\"High-level solution summary\")\n",
    "    components: List[SolutionComponent] = Field(description=\"List of required products\")\n",
    "    justification: str = Field(description=\"Technical and business justification\")\n",
    "\n",
    "# ======================================\n",
    "# 4. Agent Definitions (ATUALIZADO)\n",
    "# ======================================\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Orchestrator Agent\n",
    "orchestrator_prompt = ChatPromptTemplate.from_template(\n",
    "    \"You are a Cisco sales orchestration system. Analyze the user query and:\\n\"\n",
    "    \"1. Determine which specialized agents are needed\\n\"\n",
    "    \"2. Decompose the query into specific parts for each agent\\n\"\n",
    "    \"3. ALWAYS include a 'query_parts' dictionary with agent names as keys\\n\\n\"\n",
    "    \"Special handling for solution design requests:\\n\"\n",
    "    \"- If the user asks for a complete solution, architecture, or system design, set needs_design=True\\n\"\n",
    "    \"- Examples: 'design a solution for...', 'how to implement...', 'architecture for...'\\n\\n\"\n",
    "    \"Example structure for output:\\n\"\n",
    "    \"{{\\n\"\n",
    "    \"  \\\"needs_design\\\": true,\\n\"\n",
    "    \"  \\\"needs_technical\\\": false,\\n\"\n",
    "    \"  \\\"needs_pricing\\\": true,\\n\"\n",
    "    \"  \\\"query_parts\\\": {{\\n\"\n",
    "    \"    \\\"design\\\": \\\"secure cloud infrastructure for healthcare\\\"\\n\"\n",
    "    \"  }}\\n\"\n",
    "    \"}}\\n\\n\"\n",
    "    \"User Query: {query}\\n\\n\"\n",
    "    \"Output Instructions: {format_instructions}\"\n",
    ")\n",
    "orchestrator_agent = orchestrator_prompt | llm.with_structured_output(AgentRoutingDecision)\n",
    "\n",
    "# (nova instância, obrigatória depois de adicionar needs_design)\n",
    "orchestrator_agent = (\n",
    "    orchestrator_prompt\n",
    "    | llm.with_structured_output(AgentRoutingDecision)  # ← agora inclui needs_design\n",
    ")\n",
    "\n",
    "# Agente de Design de Solução\n",
    "design_prompt = ChatPromptTemplate.from_template(\n",
    "    \"You are a Cisco Solution Architect. Design a complete solution based on the customer requirements:\\n\\n\"\n",
    "    \"Customer Requirements: {requirements}\\n\\n\"\n",
    "    \"Available Cisco Products:\\n{product_list}\\n\\n\"\n",
    "    \"Output Instructions: {format_instructions}\"\n",
    ")\n",
    "\n",
    "# Gerar lista de produtos para contexto (resumida)\n",
    "def get_product_list_str():\n",
    "    return \"\\n\".join([f\"- {p['cisco_product_id']}: {p['commercial_name']} ({p['product_type']})\" \n",
    "                      for p in product_dict.values()])\n",
    "\n",
    "design_agent = (\n",
    "    {\n",
    "        \"requirements\": lambda x: x[\"requirements\"],\n",
    "        \"product_list\": RunnableLambda(get_product_list_str),\n",
    "        \"format_instructions\": lambda x: x[\"format_instructions\"]\n",
    "    }\n",
    "    | design_prompt\n",
    "    | llm.with_structured_output(SolutionDesign)\n",
    ")\n",
    "# ======================================\n",
    "# 5. State Definition (SIMPLIFICADO)\n",
    "# ======================================\n",
    "class AgentState(TypedDict):\n",
    "    user_query: str\n",
    "    orchestrator_decision: Optional[AgentRoutingDecision]\n",
    "    technical_results: List[Dict]\n",
    "    pricing_results: List[Dict]\n",
    "    solution_design: Optional[SolutionDesign]  # Novo campo\n",
    "    final_response: str\n",
    "\n",
    "# ======================================\n",
    "# 6. Graph Nodes Implementation (COMPLETO E CORRIGIDO)\n",
    "# ======================================\n",
    "def orchestrator_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Analyzes query and plans agent workflow\"\"\"\n",
    "    print(f\"\\n🎻 [Orchestrator] Analyzing query: '{state['user_query']}'\")\n",
    "    \n",
    "    try:\n",
    "        decision = orchestrator_agent.invoke({\n",
    "            \"query\": state[\"user_query\"],\n",
    "            \"format_instructions\": AgentRoutingDecision.schema()\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Orchestrator error: {str(e)}\")\n",
    "        # Fallback decision\n",
    "        decision = AgentRoutingDecision(\n",
    "            needs_technical=\"spec\" in state[\"user_query\"].lower(),\n",
    "            needs_pricing=\"price\" in state[\"user_query\"].lower() or \"cost\" in state[\"user_query\"].lower(),\n",
    "            query_parts={}\n",
    "        )\n",
    "    \n",
    "    state[\"orchestrator_decision\"] = decision\n",
    "    print(f\"✅ Routing decision: \"\n",
    "          f\"Technical={decision.needs_technical} \"\n",
    "          f\"Pricing={decision.needs_pricing}\")\n",
    "    \n",
    "    if decision.query_parts:\n",
    "        print(f\"Query parts: {decision.query_parts}\")\n",
    "    else:\n",
    "        print(\"⚠️ No query parts decomposed, using fallback\")\n",
    "        decision.query_parts = {\n",
    "            \"technical\": state[\"user_query\"],\n",
    "            \"pricing\": state[\"user_query\"]\n",
    "        }\n",
    "    \n",
    "    return state\n",
    "\n",
    "# ======================================\n",
    "# 3. Atualização do Agente Técnico\n",
    "# ======================================\n",
    "def technical_agent_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Handles technical aspects including recommendations\"\"\"\n",
    "    if not state[\"orchestrator_decision\"].needs_technical:\n",
    "        print(\"⏩ Skipping technical agent (not required)\")\n",
    "        return state\n",
    "        \n",
    "    query_part = state[\"orchestrator_decision\"].query_parts.get(\"technical\", \"\")\n",
    "    print(f\"\\n🔧 [Technical Agent] Processing: '{query_part}'\")\n",
    "    \n",
    "    # Verifica se é uma solicitação de recomendação\n",
    "    is_recommendation_request = any(word in query_part.lower() \n",
    "                                   for word in [\"recommend\", \"suggest\", \"what\", \"which\", \"choose\"])\n",
    "    \n",
    "    # Extrai produtos específicos se mencionados\n",
    "    found_ids = []\n",
    "    pattern = r'\\b([A-Z]{2,}\\d+[A-Z]?-\\w+-\\w+)\\b'\n",
    "    found_ids = re.findall(pattern, query_part)\n",
    "    \n",
    "    # Se for solicitação de recomendação ou não encontrou produtos específicos\n",
    "    if is_recommendation_request or not found_ids:\n",
    "        print(\"🔎 Detected recommendation request\")\n",
    "        recommendations = recommend_products.invoke({\"requirements\": query_part, \"max_results\": 5})\n",
    "        \n",
    "        if recommendations:\n",
    "            state[\"technical_results\"] = []\n",
    "            for rec in recommendations:\n",
    "                if 'error' not in rec:\n",
    "                    # Obtém especificações completas para os recomendados\n",
    "                    specs = get_technical_specs(rec['part_number'])\n",
    "                    if 'error' not in specs:\n",
    "                        specs['recommendation_score'] = rec.get('similarity_score', 0)\n",
    "                        state[\"technical_results\"].append(specs)\n",
    "            \n",
    "            print(f\"✅ Generated {len(state['technical_results'])} recommendations\")\n",
    "        else:\n",
    "            state[\"technical_results\"] = [{\n",
    "                'error': 'No products match your requirements',\n",
    "                'query': query_part\n",
    "            }]\n",
    "    else:\n",
    "        # Busca produtos específicos mencionados\n",
    "        state[\"technical_results\"] = []\n",
    "        for product_id in set(found_ids):\n",
    "            result = get_technical_specs(product_id)\n",
    "            state[\"technical_results\"].append(result)\n",
    "        \n",
    "        print(f\"✅ Found {len(found_ids)} specific products\")\n",
    "    \n",
    "    # Log dos resultados\n",
    "    for result in state[\"technical_results\"]:\n",
    "        if 'error' in result:\n",
    "            print(f\"  ❌ {result.get('part_number', 'Unknown')}: {result['error']}\")\n",
    "        else:\n",
    "            score = result.get('recommendation_score', '')\n",
    "            score_str = f\" [Score: {score:.2f}]\" if score else \"\"\n",
    "            print(f\"  ✅ {result.get('part_number', 'Unknown')}: Specs found{score_str}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "\n",
    "def pricing_agent_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Handles pricing aspects of products\"\"\"\n",
    "    if not state[\"orchestrator_decision\"].needs_pricing:\n",
    "        print(\"⏩ Skipping pricing agent (not required)\")\n",
    "        return state\n",
    "        \n",
    "    # Usar resultados técnicos se disponíveis\n",
    "    products = []\n",
    "    if state[\"technical_results\"]:\n",
    "        products = [{\n",
    "            'part_number': item.get('part_number', '')\n",
    "        } for item in state[\"technical_results\"]]\n",
    "    \n",
    "    # Se não tem resultados técnicos, extrair da query de preços\n",
    "    if not products:\n",
    "        query_part = state[\"orchestrator_decision\"].query_parts.get(\"pricing\", \"\")\n",
    "        print(f\"⚠️ No technical results, extracting from pricing query: '{query_part}'\")\n",
    "        \n",
    "        # Extrair todos os IDs de produto conhecidos\n",
    "        known_ids = list(product_dict.keys())\n",
    "        \n",
    "        # Encontrar IDs mencionados na query\n",
    "        for product_id in known_ids:\n",
    "            if product_id in query_part:\n",
    "                products.append({'part_number': product_id})\n",
    "        \n",
    "        # Se não encontrou, tentar padrões Cisco\n",
    "        if not products:\n",
    "            pattern = r'\\b([A-Z]{2,}\\d+[A-Z]?-\\w+-\\w+)\\b'\n",
    "            found_ids = re.findall(pattern, query_part)\n",
    "            products = [{'part_number': pid} for pid in found_ids]\n",
    "    \n",
    "    if not products:\n",
    "        print(\"⚠️ No products identified for pricing\")\n",
    "        products = [{'part_number': 'UNKNOWN'}]\n",
    "    \n",
    "    print(f\"\\n💰 [Pricing Agent] Processing {len(products)} products...\")\n",
    "    state[\"pricing_results\"] = []\n",
    "    \n",
    "    for product in products:\n",
    "        pn = product.get('part_number', 'UNKNOWN')\n",
    "        result = get_product_price(pn)\n",
    "        state[\"pricing_results\"].append(result)\n",
    "    \n",
    "    # Log dos resultados\n",
    "    for result in state[\"pricing_results\"]:\n",
    "        status = \"✅\" if \"price\" in result and not result.get('error') else \"❌\"\n",
    "        print(f\"  {status} {result.get('part_number', 'Unknown')}: \"\n",
    "              f\"{result.get('price', result.get('error', 'No info'))}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "def synthesize_response_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Creates final response with solution designs\"\"\"\n",
    "    print(\"\\n🎯 [Synthesizer] Combining agent results\")\n",
    "    \n",
    "    response = []\n",
    "    \n",
    "    # Tratar designs de solução\n",
    "    if state.get(\"solution_design\"):\n",
    "        design = state[\"solution_design\"]\n",
    "        response.append(\"🚀 Solution Design:\")\n",
    "        response.append(f\"\\n{design.summary}\")\n",
    "        \n",
    "        response.append(\"\\n\\n🔧 Solution Components:\")\n",
    "        for i, comp in enumerate(design.components, 1):\n",
    "            # Buscar informações técnicas deste componente\n",
    "            tech_info = next((t for t in state[\"technical_results\"] \n",
    "                            if t.get('part_number') == comp.part_number), {})\n",
    "            \n",
    "            desc = tech_info.get('description', comp.part_number)\n",
    "            response.append(f\"\\n{i}. {desc} ({comp.quantity}x) - {comp.role}\")\n",
    "            \n",
    "            # Adicionar especificações se disponíveis\n",
    "            specs = tech_info.get('specifications', {})\n",
    "            if specs:\n",
    "                for key, value in specs.items():\n",
    "                    response.append(f\"   - {key.replace('_', ' ').title()}: {value}\")\n",
    "        \n",
    "        response.append(f\"\\n\\n✅ Justification:\\n{design.justification}\")\n",
    "        \n",
    "        # Adicionar preços se disponíveis\n",
    "        if state[\"pricing_results\"]:\n",
    "            total = 0\n",
    "            response.append(\"\\n\\n💵 Pricing Breakdown:\")\n",
    "            for product in state[\"pricing_results\"]:\n",
    "                if \"error\" not in product:\n",
    "                    qty = next((c.quantity for c in design.components \n",
    "                               if c.part_number == product['part_number']), 1)\n",
    "                    price = product.get('price', 0) * qty\n",
    "                    total += price\n",
    "                    response.append(\n",
    "                        f\"\\n- {product['description']} ({product['part_number']}) \"\n",
    "                        f\"{qty}x: {product['currency']} {price:.2f}\"\n",
    "                    )\n",
    "            response.append(f\"\\n\\n💎 TOTAL ESTIMATED COST: {product['currency']} {total:.2f}\")\n",
    "    \n",
    "    # Restante da lógica anterior (para consultas não relacionadas a design)\n",
    "    else:\n",
    "        # ... (manter lógica anterior para consultas técnicas e de preço)\n",
    "        pass\n",
    "    \n",
    "    # Sem resultados\n",
    "    if not response:\n",
    "        response.append(\"❌ No relevant information found for your query\")\n",
    "    \n",
    "    state[\"final_response\"] = \"\\n\".join(response)\n",
    "    return state\n",
    "\n",
    "\n",
    "def solution_design_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Designs comprehensive solutions based on requirements\"\"\"\n",
    "    print(f\"\\n🎨 [Solution Architect] Designing solution for: {state['user_query']}\")\n",
    "    \n",
    "    try:\n",
    "        design = design_agent.invoke({\n",
    "            \"requirements\": state[\"user_query\"],\n",
    "            \"format_instructions\": SolutionDesign.schema()\n",
    "        })\n",
    "        state[\"solution_design\"] = design\n",
    "        print(f\"✅ Solution design created with {len(design.components)} components\")\n",
    "        \n",
    "        # Extrai componentes para processamento técnico e de preços\n",
    "        components = [{\"part_number\": c.part_number, \"quantity\": c.quantity} for c in design.components]\n",
    "        state[\"technical_results\"] = []\n",
    "        for comp in components:\n",
    "            # Busca especificações técnicas para cada componente\n",
    "            result = get_technical_specs(comp['part_number'])\n",
    "            if 'error' not in result:\n",
    "                result['quantity'] = comp['quantity']\n",
    "            state[\"technical_results\"].append(result)\n",
    "        \n",
    "        print(f\"✅ Technical specs retrieved for {len(components)} components\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        state[\"solution_design\"] = {\n",
    "            \"error\": f\"Solution design failed: {str(e)}\"\n",
    "        }\n",
    "        print(f\"❌ Solution design error: {str(e)}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "# ======================================\n",
    "# 7. Conditional Routing Logic (MANTIDO)\n",
    "# ======================================\n",
    "def route_after_orchestrator(state: AgentState) -> str:\n",
    "    decision = state[\"orchestrator_decision\"]\n",
    "    \n",
    "    if decision.needs_design:\n",
    "        return \"solution_designer\"\n",
    "    elif decision.needs_technical:\n",
    "        return \"technical_agent\"\n",
    "    elif decision.needs_pricing:\n",
    "        return \"pricing_agent\"\n",
    "    else:\n",
    "        return \"synthesize\"\n",
    "\n",
    "def route_after_designer(state: AgentState) -> str:\n",
    "    \"\"\"After solution design, always go to technical agent first\"\"\"\n",
    "    return \"technical_agent\"\n",
    "\n",
    "def route_after_technical(state: AgentState) -> str:\n",
    "    decision = state[\"orchestrator_decision\"]\n",
    "    if decision.needs_pricing:\n",
    "        return \"pricing_agent\"\n",
    "    else:\n",
    "        return \"synthesize\"\n",
    "\n",
    "def route_after_pricing(state: AgentState) -> str:\n",
    "    return \"synthesize\"\n",
    "\n",
    "# ======================================\n",
    "# 8. Build Agent Workflow Graph (MANTIDO)\n",
    "# ======================================\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Adicionar nós (incluindo o novo designer de soluções)\n",
    "workflow.add_node(\"orchestrator\", orchestrator_node)\n",
    "workflow.add_node(\"solution_designer\", solution_design_node)  # Novo nó\n",
    "workflow.add_node(\"technical_agent\", technical_agent_node)\n",
    "workflow.add_node(\"pricing_agent\", pricing_agent_node)\n",
    "workflow.add_node(\"synthesize\", synthesize_response_node)\n",
    "\n",
    "\n",
    "workflow.set_entry_point(\"orchestrator\")\n",
    "\n",
    "# Roteamento do orquestrador\n",
    "workflow.add_conditional_edges(\n",
    "    \"orchestrator\",\n",
    "    route_after_orchestrator,\n",
    "    {\n",
    "        \"solution_designer\": \"solution_designer\",\n",
    "        \"technical_agent\": \"technical_agent\",\n",
    "        \"pricing_agent\": \"pricing_agent\",\n",
    "        \"synthesize\": \"synthesize\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Roteamento do designer de soluções\n",
    "workflow.add_conditional_edges(\n",
    "    \"solution_designer\",\n",
    "    route_after_designer,\n",
    "    {\n",
    "        \"technical_agent\": \"technical_agent\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Roteamento do agente técnico\n",
    "workflow.add_conditional_edges(\n",
    "    \"technical_agent\",\n",
    "    route_after_technical,\n",
    "    {\n",
    "        \"pricing_agent\": \"pricing_agent\",\n",
    "        \"synthesize\": \"synthesize\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Roteamento do agente de preços\n",
    "workflow.add_conditional_edges(\n",
    "    \"pricing_agent\",\n",
    "    route_after_pricing,\n",
    "    {\n",
    "        \"synthesize\": \"synthesize\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"synthesize\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "# ======================================\n",
    "# 9. Run the Agent Workflow (ATUALIZADO)\n",
    "# ======================================\n",
    "def run_sales_quote(user_query: str) -> str:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"🚀 STARTING QUOTE PROCESSING: '{user_query}'\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    initial_state = {\n",
    "        \"user_query\": user_query,\n",
    "        \"orchestrator_decision\": None,\n",
    "        \"technical_results\": [],\n",
    "        \"pricing_results\": [],\n",
    "        \"final_response\": \"\"\n",
    "    }\n",
    "    \n",
    "    final_state = app.invoke(initial_state)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"✅ QUOTE PROCESSING COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return final_state[\"final_response\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43801131-eb92-4a20-aaf2-0da35c69bec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b28eeb-c56c-4790-b36d-0152b875ce4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# 10. Test Cases (ATUALIZADO)\n",
    "# ======================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Test 1: Solicitação técnica + preço\n",
    "    test_query_1 = \"I need technical specs for ASA5516-FPWR-K9 and pricing for MR53E-HW\"\n",
    "    result_1 = run_sales_quote(test_query_1)\n",
    "    print(\"\\n💬 CLIENT RESPONSE 1:\")\n",
    "    print(result_1)\n",
    "    \n",
    "    # Test 2: Solicitação de preço com nome comercial\n",
    "    test_query_2 = \"How much does QSFP-100G-SR4-S cost?\"\n",
    "    result_2 = run_sales_quote(test_query_2)\n",
    "    print(\"\\n💬 CLIENT RESPONSE 2:\")\n",
    "    print(result_2)\n",
    "    \n",
    "    # Test 3: Solicitação técnica com nome comercial\n",
    "    test_query_3 = \"What are the specifications for the Catalyst 9300 switch?\"\n",
    "    result_3 = run_sales_quote(test_query_3)\n",
    "    print(\"\\n💬 CLIENT RESPONSE 3:\")\n",
    "    print(result_3)\n",
    "    \n",
    "    # Test 4: Produto não encontrado\n",
    "    test_query_4 = \"Price for NONEXISTENT-PRODUCT-123\"\n",
    "    result_4 = run_sales_quote(test_query_4)\n",
    "    print(\"\\n💬 CLIENT RESPONSE 4:\")\n",
    "    print(result_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1178bd78-43df-456e-ab12-64d077a5ccbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "4bdf6650-b554-42a1-99cc-1a4a11af2059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "🚀 STARTING QUOTE PROCESSING: 'How can I create a quote for a healthcare client with 200 users who needs cloud security and hybrid infrastructure?'\n",
      "============================================================\n",
      "\n",
      "🎻 [Orchestrator] Analyzing query: 'How can I create a quote for a healthcare client with 200 users who needs cloud security and hybrid infrastructure?'\n",
      "✅ Routing decision: Technical=True Pricing=True\n",
      "Query parts: {'technical': 'cloud security and hybrid infrastructure', 'pricing': 'quote for a healthcare client with 200 users'}\n",
      "\n",
      "🔧 [Technical Agent] Processing: 'cloud security and hybrid infrastructure'\n",
      "🔎 Detected recommendation request\n",
      "🔍 Recommending products for: cloud security and hybrid infrastructure\n",
      "🔍 Searching specs for: ASA5555-X\n",
      "🔍 Searching specs for: ASA5525-X\n",
      "🔍 Searching specs for: ASA5516-FPWR-K9\n",
      "🔍 Searching specs for: QSFP-100G-SR4-S\n",
      "🔍 Searching specs for: QSFP-100G-LR4-S\n",
      "✅ Generated 5 recommendations\n",
      "  ✅ ASA5555-X: Specs found [Score: 0.21]\n",
      "  ✅ ASA5525-X: Specs found [Score: 0.20]\n",
      "  ✅ ASA5516-FPWR-K9: Specs found [Score: 0.20]\n",
      "  ✅ QSFP-100G-SR4-S: Specs found\n",
      "  ✅ QSFP-100G-LR4-S: Specs found\n",
      "\n",
      "💰 [Pricing Agent] Processing 5 products...\n",
      "🔍 Searching price for: ASA5555-X\n",
      "🔍 Searching price for: ASA5525-X\n",
      "🔍 Searching price for: ASA5516-FPWR-K9\n",
      "🔍 Searching price for: QSFP-100G-SR4-S\n",
      "🔍 Searching price for: QSFP-100G-LR4-S\n",
      "  ✅ ASA5555-X: 28738.01\n",
      "  ✅ ASA5525-X: 10225.02\n",
      "  ✅ ASA5516-FPWR-K9: 5995.0\n",
      "  ✅ QSFP-100G-SR4-S: 1995.0\n",
      "  ✅ QSFP-100G-LR4-S: 29995.0\n",
      "\n",
      "🎯 [Synthesizer] Combining agent results\n",
      "\n",
      "============================================================\n",
      "✅ QUOTE PROCESSING COMPLETE\n",
      "============================================================\n",
      "❌ No relevant information found for your query\n"
     ]
    }
   ],
   "source": [
    "# Teste de design de solução\n",
    "test_query = \"How can I create a quote for a healthcare client with 200 users who needs cloud security and hybrid infrastructure?\"\n",
    "result = run_sales_quote(test_query)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ac97b3-2642-4918-aac4-1875f714d0f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "514dd37a-7bf4-46ab-82b6-fc3c808130ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "🚀 STARTING QUOTE PROCESSING: 'I need technical specs for ASA5516-FPWR-K9 and pricing for MR53E-HW'\n",
      "============================================================\n",
      "\n",
      "🎻 [Orchestrator] Analyzing query: 'I need technical specs for ASA5516-FPWR-K9 and pricing for MR53E-HW'\n",
      "✅ Routing decision: Technical=True Pricing=True\n",
      "Query parts: {'technical': 'technical specs for ASA5516-FPWR-K9', 'pricing': 'pricing for MR53E-HW'}\n",
      "\n",
      "🔧 [Technical Agent] Processing: 'technical specs for ASA5516-FPWR-K9'\n",
      "🔍 Searching specs for: ASA5516-FPWR-K9\n",
      "✅ Found 1 specific products\n",
      "  ✅ ASA5516-FPWR-K9: Specs found\n",
      "\n",
      "💰 [Pricing Agent] Processing 1 products...\n",
      "🔍 Searching price for: ASA5516-FPWR-K9\n",
      "  ✅ ASA5516-FPWR-K9: 5995.0\n",
      "\n",
      "🎯 [Synthesizer] Combining agent results\n",
      "\n",
      "============================================================\n",
      "✅ QUOTE PROCESSING COMPLETE\n",
      "============================================================\n",
      "\n",
      "💬 CLIENT RESPONSE 1:\n",
      "\n",
      "🔧 Technical Specifications:\n",
      "\n",
      "• ASA 5516-X with FirePOWER Services (ASA5516-FPWR-K9)\n",
      "  - Category: security\n",
      "  - Subcategory: firewall\n",
      "  - Throughput: 4 Gbps\n",
      "  - Interfaces: 8x GE\n",
      "  - Vpn Throughput: 1 Gbps\n",
      "  - Threat Throughput: 500 Mbps\n",
      "  - Encryption: 3DES/AES\n",
      "\n",
      "\n",
      "📊 Pricing Information:\n",
      "\n",
      "• ASA 5516-X with FirePOWER Services (ASA5516-FPWR-K9)\n",
      "  💵 Price: USD 5995.0\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Solicitação técnica + preço\n",
    "test_query_1 = \"I need technical specs for ASA5516-FPWR-K9 and pricing for MR53E-HW\"\n",
    "result_1 = run_sales_quote(test_query_1)\n",
    "print(\"\\n💬 CLIENT RESPONSE 1:\")\n",
    "print(result_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5920ee-2c5c-4091-826c-88a8e93a4399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64628d4a-827c-4e80-9eba-22e17ee1870a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "bb8bc4ab-1ef0-458c-bb9f-e672a27af70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "🚀 STARTING QUOTE PROCESSING: 'I need some firewall with throughput of only 4 Gbps and a price igual to 5995.00, what do  you recommend?'\n",
      "============================================================\n",
      "\n",
      "🎻 [Orchestrator] Analyzing query: 'I need some firewall with throughput of only 4 Gbps and a price igual to 5995.00, what do  you recommend?'\n",
      "✅ Routing decision: Technical=True Pricing=True\n",
      "Query parts: {'technical': 'firewall recommendations with throughput of 4 Gbps', 'pricing': 'price equal to 5995.00'}\n",
      "\n",
      "🔧 [Technical Agent] Processing: 'firewall recommendations with throughput of 4 Gbps'\n",
      "🔎 Detected recommendation request\n",
      "🔍 Recommending products for: firewall recommendations with throughput of 4 Gbps\n",
      "🔍 Searching specs for: ASA5555-X\n",
      "🔍 Searching specs for: ASA5525-X\n",
      "🔍 Searching specs for: ASA5516-FPWR-K9\n",
      "🔍 Searching specs for: MR53E-HW\n",
      "🔍 Searching specs for: MR42E-HW\n",
      "✅ Generated 5 recommendations\n",
      "  ✅ ASA5555-X: Specs found [Score: 0.64]\n",
      "  ✅ ASA5525-X: Specs found [Score: 0.62]\n",
      "  ✅ ASA5516-FPWR-K9: Specs found [Score: 0.40]\n",
      "  ✅ MR53E-HW: Specs found [Score: 0.20]\n",
      "  ✅ MR42E-HW: Specs found [Score: 0.19]\n",
      "\n",
      "💰 [Pricing Agent] Processing 5 products...\n",
      "🔍 Searching price for: ASA5555-X\n",
      "🔍 Searching price for: ASA5525-X\n",
      "🔍 Searching price for: ASA5516-FPWR-K9\n",
      "🔍 Searching price for: MR53E-HW\n",
      "🔍 Searching price for: MR42E-HW\n",
      "  ✅ ASA5555-X: 28738.01\n",
      "  ✅ ASA5525-X: 10225.02\n",
      "  ✅ ASA5516-FPWR-K9: 5995.0\n",
      "  ✅ MR53E-HW: 1699.0\n",
      "  ✅ MR42E-HW: 1099.0\n",
      "\n",
      "🎯 [Synthesizer] Combining agent results\n",
      "\n",
      "============================================================\n",
      "✅ QUOTE PROCESSING COMPLETE\n",
      "============================================================\n",
      "\n",
      "💬 CLIENT RESPONSE 2:\n",
      "🔍 Based on your requirements, I recommend these products:\n",
      "\n",
      "🏆 #1: ASA 5555-X Firewall (Match: 63.9%)\n",
      "   Key Specifications:\n",
      "   - Category: security\n",
      "   - Subcategory: firewall\n",
      "   - Throughput: 20 Gbps\n",
      "   - Interfaces: 8x GE + expansion\n",
      "   - Vpn Throughput: 5 Gbps\n",
      "   - Threat Throughput: 4 Gbps\n",
      "\n",
      "🏆 #2: ASA 5525-X Firewall (Match: 62.3%)\n",
      "   Key Specifications:\n",
      "   - Category: security\n",
      "   - Subcategory: firewall\n",
      "   - Throughput: 10 Gbps\n",
      "   - Interfaces: 8x GE + 1x Mgmt\n",
      "   - Vpn Throughput: 2 Gbps\n",
      "   - Threat Throughput: 1.5 Gbps\n",
      "\n",
      "🏆 #3: ASA 5516-X with FirePOWER Services (Match: 39.8%)\n",
      "   Key Specifications:\n",
      "   - Category: security\n",
      "   - Subcategory: firewall\n",
      "   - Throughput: 4 Gbps\n",
      "   - Interfaces: 8x GE\n",
      "   - Vpn Throughput: 1 Gbps\n",
      "   - Threat Throughput: 500 Mbps\n",
      "   - Encryption: 3DES/AES\n",
      "\n",
      "🏆 #4: Meraki MR53E Access Point (Match: 19.9%)\n",
      "   Key Specifications:\n",
      "   - Category: wireless\n",
      "   - Subcategory: access_point\n",
      "   - Wifi Standard: 802.11ax\n",
      "   - Throughput: 2.5 Gbps\n",
      "   - Antenna Type: external\n",
      "   - Mounting: indoor\n",
      "   - Power Requirements: PoE+\n",
      "\n",
      "🏆 #5: Meraki MR42E Access Point (Match: 19.2%)\n",
      "   Key Specifications:\n",
      "   - Category: wireless\n",
      "   - Subcategory: access_point\n",
      "   - Wifi Standard: 802.11ac Wave 2\n",
      "   - Throughput: 1.7 Gbps\n",
      "   - Antenna Type: external\n",
      "   - Mounting: indoor\n",
      "   - Power Requirements: PoE+\n",
      "\n",
      "\n",
      "📊 Pricing Information:\n",
      "\n",
      "• ASA 5555-X Firewall (ASA5555-X)\n",
      "  💵 Price: USD 28738.01\n",
      "\n",
      "• ASA 5525-X Firewall (ASA5525-X)\n",
      "  💵 Price: USD 10225.02\n",
      "\n",
      "• ASA 5516-X with FirePOWER Services (ASA5516-FPWR-K9)\n",
      "  💵 Price: USD 5995.0\n",
      "\n",
      "• Meraki MR53E Access Point (MR53E-HW)\n",
      "  💵 Price: USD 1699.0\n",
      "\n",
      "• Meraki MR42E Access Point (MR42E-HW)\n",
      "  💵 Price: USD 1099.0\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Solicitação de preço com nome comercial\n",
    "test_query_2 = \"I need some firewall with throughput of only 4 Gbps and a price igual to 5995.00, what do  you recommend?\"\n",
    "result_2 = run_sales_quote(test_query_2)\n",
    "print(\"\\n💬 CLIENT RESPONSE 2:\")\n",
    "print(result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c2599e-3e59-4a34-b78d-4d7edebd0a12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c73b9a7-ca7f-4177-8285-ad583dae464c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500f2e20-b2bf-4a7a-bae8-7a3ea040e552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3ab2a2-6599-4be4-8db5-b6b708f1fded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05e4a6e-c49f-4dff-b9c3-40d66ebc6627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65795d1-5401-4b4a-bc5f-7a1946df5c48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f59fca-96e5-4831-a1a9-c82c37eaa239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "926f5f4e-4e08-476e-911a-fe75a13bd008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data loaded: 16 products\n",
      "✅ Recommendation data prepared\n",
      "\n",
      "🎻 [Orchestrator] «Design a secure branch‑office solution for 50 users with Wi‑Fi 6, firewall and PoE switches. Provide pricing.»\n",
      "\n",
      "🎨 [Solution Designer]\n",
      "⏩ Technical Agent skipped (solution design already provides specs)\n",
      "\n",
      "💰 [Pricing Agent]\n",
      "\n",
      "🎯 [Synthesizer]\n",
      "🚀 Solution Design\n",
      "Design a secure branch-office solution for 50 users with Wi-Fi 6, firewall, and PoE switches.\n",
      "\n",
      "🔧 Components:\n",
      "1. ASA 5516-X with FirePOWER Services (1×) – Firewall with FirePOWER Services\n",
      "2. Meraki MR53E Access Point (3×) – Wi-Fi 6 Access Points for coverage and capacity\n",
      "3. ASA 5555-X Firewall (1×) – Additional Firewall for redundancy and security\n",
      "\n",
      "✅ Justification:\n",
      "The ASA5516-FPWR-K9 provides robust firewall capabilities with FirePOWER services, suitable for securing the branch office. The MR53E-HW access points support Wi-Fi 6, ensuring high performance and capacity for 50 users. The additional ASA5555-X firewall offers redundancy and enhanced security features.\n",
      "\n",
      "💵 Pricing:\n",
      "- ASA 5516-X with FirePOWER Services (1×): USD 5995.00\n",
      "- Meraki MR53E Access Point (3×): USD 5097.00\n",
      "- ASA 5555-X Firewall (1×): USD 28738.01\n",
      "\n",
      "TOTAL ESTIMATED: USD 39830.01\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# Cisco Sales Assistant – fluxo completo (julho/2025)\n",
    "# =============================================================\n",
    "\"\"\"\n",
    "Cria um agente LangGraph capaz de:\n",
    "  • analisar a consulta do cliente\n",
    "  • projetar uma solução (Solution Designer)\n",
    "  • buscar especificações técnicas\n",
    "  • precificar os componentes\n",
    "  • sintetizar tudo em uma resposta final\n",
    "\n",
    "Requisitos:\n",
    "  pip install langchain langgraph langchain-openai scikit-learn numpy\n",
    "\"\"\"\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 0. Imports\n",
    "# -------------------------------------------------------------\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict, TypedDict, Optional\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from langchain.tools import tool\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1. Carregar catálogo Cisco\n",
    "# -------------------------------------------------------------\n",
    "product_dict: Dict[str, Dict] = {}\n",
    "PRICELIST_PATH = \"data/raw/pricelist.json\"      # ajuste se necessário\n",
    "\n",
    "try:\n",
    "    with open(PRICELIST_PATH, encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        products = data if isinstance(data, list) else data.get(\"products\", [])\n",
    "        for p in products:\n",
    "            pid = p.get(\"cisco_product_id\")\n",
    "            if pid:\n",
    "                product_dict[pid] = p\n",
    "    print(f\"✅ Data loaded: {len(product_dict)} products\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading product data: {e}\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2. Preparar embeddings TF‑IDF para recomendações\n",
    "# -------------------------------------------------------------\n",
    "def prepare_recommendation_data():\n",
    "    \"\"\"Gera matriz TF‑IDF a partir do catálogo para busca semântica.\"\"\"\n",
    "    texts: List[str] = []\n",
    "    for p in product_dict.values():\n",
    "        hw = p.get(\"technical_profile\", {}).get(\"hardware_attributes\", {})\n",
    "        txt = (\n",
    "            f\"{p.get('commercial_name', '')} {p.get('product_type', '')} \"\n",
    "            + \" \".join(f\"{k}={v}\" for k, v in hw.items())\n",
    "        ).strip()\n",
    "        texts.append(txt)\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "    matrix = vectorizer.fit_transform(texts) if texts else None\n",
    "    return vectorizer, matrix\n",
    "\n",
    "\n",
    "vectorizer, tfidf_matrix = prepare_recommendation_data()\n",
    "print(\"✅ Recommendation data prepared\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3. Helper – lista enxuta de produtos (TOP‑K)\n",
    "# -------------------------------------------------------------\n",
    "def get_product_list_str(requirements: str, top_k: int = 50) -> str:\n",
    "    if tfidf_matrix is None:\n",
    "        return \"(catalog empty)\"\n",
    "    vec = vectorizer.transform([requirements])\n",
    "    sims = cosine_similarity(vec, tfidf_matrix).flatten()\n",
    "    idxs = sims.argsort()[::-1][:top_k]\n",
    "    prods = [list(product_dict.values())[i] for i in idxs]\n",
    "    return \"\\n\".join(\n",
    "        f\"- {p['cisco_product_id']}: {p['commercial_name']} \"\n",
    "        f\"({p['product_type']})\"\n",
    "        for p in prods\n",
    "    )\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4. Ferramentas (LangChain @tool)\n",
    "# -------------------------------------------------------------\n",
    "@tool\n",
    "def get_product_price(part_number: str) -> Dict:\n",
    "    \"\"\"Retrieve pricing information for a Cisco product.\"\"\"\n",
    "    prod = product_dict.get(part_number)\n",
    "    if not prod:\n",
    "        return {\"error\": f\"Product {part_number} not found\", \"part_number\": part_number}\n",
    "    pricing = prod.get(\"pricing_model\", {})\n",
    "    return {\n",
    "        \"price\": pricing.get(\"base_price\", 0.0),\n",
    "        \"currency\": pricing.get(\"currency\", \"USD\"),\n",
    "        \"description\": prod.get(\"commercial_name\", \"\"),\n",
    "        \"part_number\": part_number,\n",
    "        \"product_type\": prod.get(\"product_type\", \"\"),\n",
    "    }\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_technical_specs(part_number: str) -> Dict:\n",
    "    \"\"\"Retrieve hardware specifications for a Cisco product.\"\"\"\n",
    "    prod = product_dict.get(part_number)\n",
    "    if not prod:\n",
    "        return {\"error\": f\"Product {part_number} not found\", \"part_number\": part_number}\n",
    "    hw = prod.get(\"technical_profile\", {}).get(\"hardware_attributes\", {})\n",
    "    if not hw:\n",
    "        return {\"error\": f\"No technical specs for {part_number}\", \"part_number\": part_number}\n",
    "    return {\n",
    "        \"specifications\": hw,\n",
    "        \"description\": prod.get(\"commercial_name\", \"\"),\n",
    "        \"part_number\": part_number,\n",
    "        \"product_type\": prod.get(\"product_type\", \"\"),\n",
    "    }\n",
    "\n",
    "\n",
    "@tool\n",
    "def recommend_products(requirements: str, max_results: int = 3) -> List[Dict]:\n",
    "    \"\"\"Recommend Cisco products that best match the given requirements.\"\"\"\n",
    "    if tfidf_matrix is None:\n",
    "        return [{\"error\": \"Catalog not indexed\"}]\n",
    "    vec = vectorizer.transform([requirements])\n",
    "    sims = cosine_similarity(vec, tfidf_matrix).flatten()\n",
    "    idxs = sims.argsort()[::-1][:max_results]\n",
    "    base = list(product_dict.values())\n",
    "    return [\n",
    "        {\n",
    "            \"part_number\": base[i][\"cisco_product_id\"],\n",
    "            \"commercial_name\": base[i][\"commercial_name\"],\n",
    "            \"product_type\": base[i][\"product_type\"],\n",
    "            \"similarity_score\": float(sims[i]),\n",
    "        }\n",
    "        for i in idxs\n",
    "    ]\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 5. Pydantic models\n",
    "# -------------------------------------------------------------\n",
    "class SolutionComponent(BaseModel):\n",
    "    part_number: str = Field(description=\"Cisco product ID\")\n",
    "    quantity: int = Field(default=1, description=\"Quantity required\")\n",
    "    role: str = Field(description=\"Role in the solution\")\n",
    "\n",
    "\n",
    "class SolutionDesign(BaseModel):\n",
    "    summary: str\n",
    "    components: List[SolutionComponent]\n",
    "    justification: str\n",
    "\n",
    "\n",
    "class AgentRoutingDecision(BaseModel):\n",
    "    needs_design: bool = False\n",
    "    needs_technical: bool = False\n",
    "    needs_pricing: bool = False\n",
    "    query_parts: Dict[str, str] = Field(default_factory=dict)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 6. LLM e prompts\n",
    "# -------------------------------------------------------------\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# — Orchestrator (corrigido)\n",
    "orchestrator_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a Cisco sales orchestration system.\n",
    "\n",
    "Analyse the user query and decide which specialised agents are needed:\n",
    "  • Solution Designer   → needs_design\n",
    "  • Technical Agent     → needs_technical\n",
    "  • Pricing Agent       → needs_pricing\n",
    "\n",
    "ALWAYS output a JSON object that matches the schema shown in\n",
    "{{format_instructions}}.\n",
    "\n",
    "User query: {{query}}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "orchestrator_agent = orchestrator_prompt | llm.with_structured_output(\n",
    "    AgentRoutingDecision\n",
    ")\n",
    "\n",
    "# — Solution Designer\n",
    "design_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a Cisco Solution Architect. Design a complete solution.\n",
    "\n",
    "Customer Requirements:\n",
    "{requirements}\n",
    "\n",
    "Available Cisco Products:\n",
    "{product_list}\n",
    "\n",
    "Return only part_numbers that appear above.\n",
    "Output as JSON in the schema provided.\"\"\"\n",
    ")\n",
    "design_agent = (\n",
    "    {\n",
    "        \"requirements\": lambda x: x[\"requirements\"],\n",
    "        \"product_list\": lambda x: get_product_list_str(x[\"requirements\"]),\n",
    "        \"format_instructions\": lambda x: x[\"format_instructions\"],\n",
    "    }\n",
    "    | design_prompt\n",
    "    | llm.with_structured_output(SolutionDesign)\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 7. State type\n",
    "# -------------------------------------------------------------\n",
    "class AgentState(TypedDict):\n",
    "    user_query: str\n",
    "    orchestrator_decision: Optional[AgentRoutingDecision]\n",
    "    solution_design: Optional[SolutionDesign]\n",
    "    technical_results: List[Dict]\n",
    "    pricing_results: List[Dict]\n",
    "    final_response: str\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 8. Nó — Orchestrator\n",
    "# -------------------------------------------------------------\n",
    "def orchestrator_node(state: AgentState) -> AgentState:\n",
    "    print(f\"\\n🎻 [Orchestrator] «{state['user_query']}»\")\n",
    "\n",
    "    q = state[\"user_query\"]\n",
    "\n",
    "    # 1) tentativa normal com o LLM\n",
    "    try:\n",
    "        decision = orchestrator_agent.invoke(\n",
    "            {\n",
    "                \"query\": q,\n",
    "                \"format_instructions\": AgentRoutingDecision.schema(),\n",
    "            }\n",
    "        )\n",
    "    except Exception:\n",
    "        print(\"⚠️ LLM parse fail → empty decision\")\n",
    "        decision = AgentRoutingDecision()\n",
    "\n",
    "    # 2) heurística se vier tudo falso\n",
    "    if not any([decision.needs_design, decision.needs_technical, decision.needs_pricing]):\n",
    "        q_low = q.lower()\n",
    "        decision = AgentRoutingDecision(\n",
    "            needs_design=any(w in q_low for w in [\"design\", \"architecture\", \"solution\"]),\n",
    "            needs_technical=\"spec\" in q_low,\n",
    "            needs_pricing=any(w in q_low for w in [\"price\", \"cost\", \"quote\", \"pricing\"]),\n",
    "            query_parts={},\n",
    "        )\n",
    "\n",
    "    # 3) salva no estado e retorna\n",
    "    state[\"orchestrator_decision\"] = decision\n",
    "    return state\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 9. Nó — Solution Designer\n",
    "# -------------------------------------------------------------\n",
    "def solution_design_node(state: AgentState) -> AgentState:\n",
    "    print(\"\\n🎨 [Solution Designer]\")\n",
    "    design = design_agent.invoke(\n",
    "        {\"requirements\": state[\"user_query\"], \"format_instructions\": SolutionDesign.schema()}\n",
    "    )\n",
    "    state[\"solution_design\"] = design\n",
    "    # força que o agente de preço rode depois\n",
    "    state[\"orchestrator_decision\"].needs_pricing = True\n",
    "\n",
    "    # specs de cada componente\n",
    "    state[\"technical_results\"] = []\n",
    "    for comp in design.components:\n",
    "        res = get_technical_specs(comp.part_number)\n",
    "        if \"error\" not in res:\n",
    "            res[\"quantity\"] = comp.quantity\n",
    "        state[\"technical_results\"].append(res)\n",
    "    return state\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 10. Nó — Technical Agent  (substitua TODO o bloco)\n",
    "# -------------------------------------------------------------\n",
    "### helper: extrai possíveis Cisco part‑numbers do texto\n",
    "PART_RE = re.compile(r\"[A-Z]{2,}\\d+[A-Z]*-[A-Za-z0-9]+(?:-[A-Za-z0-9]+)*\")\n",
    "\n",
    "def extract_part_numbers(text: str) -> List[str]:\n",
    "    return list({m.group(0) for m in PART_RE.finditer(text)})\n",
    "\n",
    "def technical_agent_node(state: AgentState) -> AgentState:\n",
    "    # pula se já há design\n",
    "    if state.get(\"solution_design\") is not None:\n",
    "        print(\"⏩ Technical Agent skipped (solution design already provides specs)\")\n",
    "        return state\n",
    "\n",
    "    query_part = state[\"orchestrator_decision\"].query_parts.get(\n",
    "        \"technical\", state[\"user_query\"]\n",
    "    )\n",
    "    ids = extract_part_numbers(query_part)\n",
    "\n",
    "    if ids:\n",
    "        print(f\"\\n🔧 [Technical Agent] Found explicit IDs: {ids}\")\n",
    "        state[\"technical_results\"] = [get_technical_specs(pid) for pid in ids]\n",
    "        return state\n",
    "\n",
    "    # fallback para recomendação sem IDs\n",
    "    if not state[\"orchestrator_decision\"].needs_technical:\n",
    "        print(\"⏩ Technical Agent skipped (flag false & no IDs)\")\n",
    "        return state\n",
    "\n",
    "    print(f\"\\n🔧 [Technical Agent] Generating recommendations for «{query_part}»\")\n",
    "    recs = recommend_products.invoke({\"requirements\": query_part, \"max_results\": 5})\n",
    "    state[\"technical_results\"] = []\n",
    "    for r in recs:\n",
    "        spec = get_technical_specs(r[\"part_number\"])\n",
    "        if \"error\" not in spec:\n",
    "            spec[\"recommendation_score\"] = r.get(\"similarity_score\", 0)\n",
    "        state[\"technical_results\"].append(spec)\n",
    "    return state\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 11. Nó — Pricing Agent  (substitua TODO o bloco)\n",
    "# -------------------------------------------------------------\n",
    "def pricing_agent_node(state: AgentState) -> AgentState:\n",
    "    if not state[\"orchestrator_decision\"].needs_pricing:\n",
    "        print(\"⏩ Pricing Agent skipped\")\n",
    "        return state\n",
    "\n",
    "    print(\"\\n💰 [Pricing Agent]\")\n",
    "\n",
    "    # 1) Se houver design → componentes do design\n",
    "    if isinstance(state.get(\"solution_design\"), SolutionDesign):\n",
    "        items = [\n",
    "            {\"part_number\": c.part_number, \"quantity\": c.quantity}\n",
    "            for c in state[\"solution_design\"].components\n",
    "        ]\n",
    "    else:\n",
    "        # 2) Extrai IDs mencionados na parte de preço da query\n",
    "        pricing_part = state[\"orchestrator_decision\"].query_parts.get(\"pricing\", state[\"user_query\"])\n",
    "        ids = extract_part_numbers(pricing_part)\n",
    "        if ids:\n",
    "            items = [{\"part_number\": pid, \"quantity\": 1} for pid in ids]\n",
    "        else:\n",
    "            # 3) fallback: usa IDs de technical_results\n",
    "            items = [\n",
    "                {\"part_number\": t.get(\"part_number\"), \"quantity\": t.get(\"quantity\", 1)}\n",
    "                for t in state[\"technical_results\"] if t.get(\"part_number\")\n",
    "            ]\n",
    "\n",
    "    # deduplicar\n",
    "    dedup: Dict[str, int] = {}\n",
    "    for it in items:\n",
    "        dedup[it[\"part_number\"]] = dedup.get(it[\"part_number\"], 0) + it[\"quantity\"]\n",
    "\n",
    "    state[\"pricing_results\"] = []\n",
    "    for pn, qty in dedup.items():\n",
    "        price_info = get_product_price(pn)\n",
    "        price_info.update(\n",
    "            {\n",
    "                \"quantity\": qty,\n",
    "                \"subtotal\": price_info.get(\"price\", 0) * qty,\n",
    "            }\n",
    "        )\n",
    "        state[\"pricing_results\"].append(price_info)\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 12. Nó — Synthesizer\n",
    "# -------------------------------------------------------------\n",
    "def synthesize_node(state: AgentState) -> AgentState:\n",
    "    print(\"\\n🎯 [Synthesizer]\")\n",
    "    lines: List[str] = []\n",
    "\n",
    "    # caso haja Solution Design\n",
    "    if isinstance(state.get(\"solution_design\"), SolutionDesign):\n",
    "        d = state[\"solution_design\"]\n",
    "        lines.append(\"🚀 Solution Design\\n\" + d.summary)\n",
    "        lines.append(\"\\n🔧 Components:\")\n",
    "        for i, c in enumerate(d.components, 1):\n",
    "            desc = next(\n",
    "                (\n",
    "                    t.get(\"description\")\n",
    "                    for t in state[\"technical_results\"]\n",
    "                    if t.get(\"part_number\") == c.part_number\n",
    "                ),\n",
    "                c.part_number,\n",
    "            )\n",
    "            lines.append(f\"{i}. {desc} ({c.quantity}×) – {c.role}\")\n",
    "        lines.append(\"\\n✅ Justification:\\n\" + d.justification)\n",
    "\n",
    "    # preços\n",
    "    if state[\"pricing_results\"]:\n",
    "        total = 0.0\n",
    "        currency = \"USD\"\n",
    "        lines.append(\"\\n💵 Pricing:\")\n",
    "        for p in state[\"pricing_results\"]:\n",
    "            if \"error\" in p:\n",
    "                lines.append(f\"- {p.get('part_number')}: {p['error']}\")\n",
    "                continue\n",
    "            currency = p[\"currency\"]\n",
    "            total += p[\"subtotal\"]\n",
    "            lines.append(\n",
    "                f\"- {p['description']} ({p['quantity']}×): \"\n",
    "                f\"{currency} {p['subtotal']:.2f}\"\n",
    "            )\n",
    "        lines.append(f\"\\nTOTAL ESTIMATED: {currency} {total:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "    if not lines:\n",
    "        lines.append(\"❌ No relevant information found\")\n",
    "\n",
    "    state[\"final_response\"] = \"\\n\".join(lines)\n",
    "    return state\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 13. Roteamento\n",
    "# -------------------------------------------------------------\n",
    "def route_after_orch(state: AgentState) -> str:\n",
    "    dec = state[\"orchestrator_decision\"]\n",
    "    if dec.needs_design:\n",
    "        return \"designer\"\n",
    "    if dec.needs_technical:\n",
    "        return \"tech\"\n",
    "    if dec.needs_pricing:\n",
    "        return \"price\"\n",
    "    return \"synth\"\n",
    "\n",
    "\n",
    "def route_after_designer(_):  # sempre vai para specs\n",
    "    return \"tech\"\n",
    "\n",
    "\n",
    "def route_after_tech(state: AgentState) -> str:\n",
    "    return \"price\" if state[\"orchestrator_decision\"].needs_pricing else \"synth\"\n",
    "\n",
    "\n",
    "def route_after_price(_):\n",
    "    return \"synth\"\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 14. Construir o grafo\n",
    "# -------------------------------------------------------------\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"orch\", orchestrator_node)\n",
    "workflow.add_node(\"designer\", solution_design_node)\n",
    "workflow.add_node(\"tech\", technical_agent_node)\n",
    "workflow.add_node(\"price\", pricing_agent_node)\n",
    "workflow.add_node(\"synth\", synthesize_node)\n",
    "\n",
    "workflow.set_entry_point(\"orch\")\n",
    "workflow.add_conditional_edges(\"orch\", route_after_orch, {\n",
    "    \"designer\": \"designer\",\n",
    "    \"tech\": \"tech\",\n",
    "    \"price\": \"price\",\n",
    "    \"synth\": \"synth\",\n",
    "})\n",
    "workflow.add_conditional_edges(\"designer\", route_after_designer, {\"tech\": \"tech\"})\n",
    "workflow.add_conditional_edges(\"tech\", route_after_tech, {\"price\": \"price\", \"synth\": \"synth\"})\n",
    "workflow.add_conditional_edges(\"price\", route_after_price, {\"synth\": \"synth\"})\n",
    "workflow.add_edge(\"synth\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 15. Helper para executar\n",
    "# -------------------------------------------------------------\n",
    "def run_sales_quote(query: str) -> str:\n",
    "    init: AgentState = {\n",
    "        \"user_query\": query,\n",
    "        \"orchestrator_decision\": None,\n",
    "        \"solution_design\": None,\n",
    "        \"technical_results\": [],\n",
    "        \"pricing_results\": [],\n",
    "        \"final_response\": \"\",\n",
    "    }\n",
    "    final_state = app.invoke(init)\n",
    "    return final_state[\"final_response\"]\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 16. Exemplo\n",
    "# -------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    q = (\n",
    "        \"Design a secure branch‑office solution for 50 users with Wi‑Fi 6, \"\n",
    "        \"firewall and PoE switches. Provide pricing.\"\n",
    "    )\n",
    "    print(run_sales_quote(q))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b18ee1d-d16d-4660-a22a-e0f413a3bf86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cd2657-f877-48a3-b598-09f1ca273737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5508823-c487-4785-b615-dc49a65072d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "235f53dd-7415-4513-836a-acb7d9448cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to read the file: data/raw/pricelist.json\n",
      "✅ Success! File has been re-saved with correct UTF-8 encoding at: data/raw/pricelist_corrected.json\n",
      "\n",
      "Please update your 'tools.py' and 'scripts/ingest_data.py' files to use this new filename.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the path to your problematic JSON file\n",
    "# NOTE: The file name might be different on your end. Please double-check.\n",
    "problem_file_path = 'data/raw/pricelist.json' \n",
    "corrected_file_path = 'data/raw/pricelist_corrected.json' # We'll save it as a new file\n",
    "\n",
    "try:\n",
    "    print(f\"Attempting to read the file: {problem_file_path}\")\n",
    "    \n",
    "    # Read the file using 'latin-1' encoding, which is a common fallback\n",
    "    with open(problem_file_path, 'r', encoding='latin-1') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # Write the content back out using the standard 'utf-8' encoding\n",
    "    with open(corrected_file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "        \n",
    "    print(f\"✅ Success! File has been re-saved with correct UTF-8 encoding at: {corrected_file_path}\")\n",
    "    print(\"\\nPlease update your 'tools.py' and 'scripts/ingest_data.py' files to use this new filename.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ ERROR: Could not find the file at '{problem_file_path}'. Please check the path and filename.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "327c8de0-721e-4390-95a1-a90aab0b5e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- lendo data\\processed\\vector_store\\docstore.json ---\n",
      "OK: é JSON UTF-8 válido\n",
      "\n",
      "--- lendo data\\processed\\vector_store\\index_store.json ---\n",
      "OK: é JSON UTF-8 válido\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "paths = [\n",
    "    Path(\"data/processed/vector_store/docstore.json\"),\n",
    "    Path(\"data/processed/vector_store/index_store.json\"),\n",
    "]\n",
    "\n",
    "for p in paths:\n",
    "    print(f\"\\n--- lendo {p} ---\")\n",
    "    if not p.exists():\n",
    "        print(\"não existe\")\n",
    "        continue\n",
    "    try:\n",
    "        with open(p, encoding=\"utf-8\") as f:\n",
    "            _ = json.load(f)\n",
    "        print(\"OK: é JSON UTF-8 válido\")\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(\"Erro de decodificação UTF-8:\", e)\n",
    "        try:\n",
    "            with open(p, encoding=\"latin-1\") as f:\n",
    "                sample = f.read(500)\n",
    "            print(\"Conteúdo inicial (latin-1):\", repr(sample))\n",
    "        except Exception as e2:\n",
    "            print(\"Não conseguiu ler nem em latin-1:\", e2)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Arquivo é texto mas não é JSON válido:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6cdc928-109c-4fbc-ba48-4673c01f3d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo já é UTF-8 válido.\n",
      "Arquivo limpo salvo em data\\raw\\pricelist_cleaned.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "RAW = Path(\"data/raw/pricelist.json\")\n",
    "CLEAN = Path(\"data/raw/pricelist_cleaned.json\")\n",
    "\n",
    "def clean_input_json():\n",
    "    # 1. Leia em binário e decodifique com replacement para mostrar/neutralizar bytes inválidos\n",
    "    raw_bytes = RAW.read_bytes()\n",
    "    try:\n",
    "        text = raw_bytes.decode(\"utf-8\")\n",
    "        print(\"Arquivo já é UTF-8 válido.\")\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"Decoding error: {e}; repondo bytes inválidos com replacement.\")\n",
    "        text = raw_bytes.decode(\"utf-8\", errors=\"replace\")  # substitui os inválidos por �\n",
    "\n",
    "    # 2. Tente carregar como JSON (isso também valida estrutura)\n",
    "    try:\n",
    "        data = json.loads(text)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Erro de JSON: {e}. Pode haver problemas estruturais além do encoding.\")\n",
    "        raise\n",
    "\n",
    "    # 3. Reescreve de forma “limpa” com UTF-8 sem BOM, indentado (opcional)\n",
    "    with CLEAN.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"Arquivo limpo salvo em {CLEAN}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    clean_input_json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5fcc800-896c-4aba-ad49-37ef5977990f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'product' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m unicodedata\u001b[38;5;241m.\u001b[39mnormalize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNFKC\u001b[39m\u001b[38;5;124m\"\u001b[39m, s)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# ao montar text_content:\u001b[39;00m\n\u001b[0;32m      9\u001b[0m text_content \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProduct: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnormalize_text(product\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommercial_name\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (SKU: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnormalize_text(product\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcisco_product_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDescription: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnormalize_text(product\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCategory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnormalize_text(product\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtechnical_profile\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m{})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     13\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'product' is not defined"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    return unicodedata.normalize(\"NFKC\", s)\n",
    "\n",
    "# ao montar text_content:\n",
    "text_content = (\n",
    "    f\"Product: {normalize_text(product.get('commercial_name', ''))} (SKU: {normalize_text(product.get('cisco_product_id', ''))})\\n\"\n",
    "    f\"Description: {normalize_text(product.get('description', ''))}\\n\"\n",
    "    f\"Category: {normalize_text(product.get('technical_profile', {}).get('category', ''))}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80ce7151-ca71-49a5-ac29-395af3095d7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'products' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# dentro do loop de criação dos documentos:\u001b[39;00m\n\u001b[0;32m      9\u001b[0m documents \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m product \u001b[38;5;129;01min\u001b[39;00m products:\n\u001b[0;32m     11\u001b[0m     text_content \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProduct: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnormalize_text(product\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommercial_name\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(SKU: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnormalize_text(product\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcisco_product_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDescription: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnormalize_text(product\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCategory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnormalize_text(product\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtechnical_profile\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m{})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     16\u001b[0m     )\n\u001b[0;32m     17\u001b[0m     doc \u001b[38;5;241m=\u001b[39m Document(\n\u001b[0;32m     18\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext_content,\n\u001b[0;32m     19\u001b[0m         metadata\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m         }\n\u001b[0;32m     24\u001b[0m     )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'products' is not defined"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    return unicodedata.normalize(\"NFKC\", s)\n",
    "\n",
    "# dentro do loop de criação dos documentos:\n",
    "documents = []\n",
    "for product in products:\n",
    "    text_content = (\n",
    "        f\"Product: {normalize_text(product.get('commercial_name', ''))} \"\n",
    "        f\"(SKU: {normalize_text(product.get('cisco_product_id', ''))})\\n\"\n",
    "        f\"Description: {normalize_text(product.get('description', ''))}\\n\"\n",
    "        f\"Category: {normalize_text(product.get('technical_profile', {}).get('category', ''))}\"\n",
    "    )\n",
    "    doc = Document(\n",
    "        text=text_content,\n",
    "        metadata={\n",
    "            \"sku\": normalize_text(product.get('cisco_product_id', '')),\n",
    "            \"name\": normalize_text(product.get('commercial_name', '')),\n",
    "            \"full_data_json\": json.dumps(product)  # esse pode ficar cru se quiser\n",
    "        }\n",
    "    )\n",
    "    documents.append(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2815e2f7-c12e-4ad7-ad45-a6c2980ea8d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61e15911-0b08-44a6-9915-abeb2aa72b19",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (1827490101.py, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[13], line 26\u001b[1;36m\u001b[0m\n\u001b[1;33m    return\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import unicodedata\n",
    "from pathlib import Path\n",
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    return unicodedata.normalize(\"NFKC\", s)\n",
    "\n",
    "# --- 2. Load & clean data (em memória, sem renomear o arquivo) ---\n",
    "try:\n",
    "    raw_path = Path(\"data/raw/pricelist.json\")\n",
    "    raw_bytes = raw_path.read_bytes()\n",
    "    try:\n",
    "        text = raw_bytes.decode(\"utf-8\")\n",
    "    except UnicodeDecodeError:\n",
    "        # substitui caracteres inválidos para não quebrar o JSON\n",
    "        text = raw_bytes.decode(\"utf-8\", errors=\"replace\")\n",
    "        logging.warning(\"Encontrados bytes inválidos no JSON de input; corrigidos com replacement.\")\n",
    "\n",
    "    data = json.loads(text)\n",
    "    products = data if isinstance(data, list) else data.get(\"products\", [])\n",
    "    logging.info(f\"Successfully loaded {len(products)} products from {raw_path}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Failed to load or parse data/raw/pricelist.json: {e}\")\n",
    "    return\n",
    "\n",
    "# --- 3. Create LlamaIndex Document Objects com normalização ---\n",
    "documents = []\n",
    "for product in products:\n",
    "    commercial_name = normalize_text(product.get(\"commercial_name\", \"\"))\n",
    "    sku = normalize_text(product.get(\"cisco_product_id\", \"\"))\n",
    "    description = normalize_text(product.get(\"description\", \"\"))\n",
    "    category = normalize_text(product.get(\"technical_profile\", {}).get(\"category\", \"\"))\n",
    "\n",
    "    text_content = (\n",
    "        f\"Product: {commercial_name} (SKU: {sku})\\n\"\n",
    "        f\"Description: {description}\\n\"\n",
    "        f\"Category: {category}\"\n",
    "    )\n",
    "    doc = Document(\n",
    "        text=text_content,\n",
    "        metadata={\n",
    "            \"sku\": sku,\n",
    "            \"name\": commercial_name,\n",
    "            \"full_data_json\": json.dumps(product, ensure_ascii=False)\n",
    "        }\n",
    "    )\n",
    "    documents.append(doc)\n",
    "logging.info(f\"Created {len(documents)} LlamaIndex Document objects.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0aec6cdd-9b35-4e7f-bf49-be0fa2e0f6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo corrigido salvo como pricelist_fixed.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def fix_json_errors(data):\n",
    "    for product in data:\n",
    "        # Correção para QSFP-100G-SR4-S\n",
    "        if product.get(\"cisco_product_id\") == \"QSFP-100G-SR4-S\":\n",
    "            # Corrigir preço inconsistente\n",
    "            if \"pricing_model\" in product:\n",
    "                base_price = product[\"pricing_model\"][\"base_price\"]\n",
    "                for tier in product[\"pricing_model\"].get(\"pricing_tiers\", []):\n",
    "                    tier[\"price\"] = base_price\n",
    "            \n",
    "            # Remover dependências incorretas\n",
    "            if \"dependencies\" in product:\n",
    "                del product[\"dependencies\"]\n",
    "        \n",
    "        # Correção para ASA5555-X\n",
    "        elif product.get(\"cisco_product_id\") == \"ASA5555-X\":\n",
    "            if \"pricing_model\" in product:\n",
    "                for tier in product[\"pricing_model\"].get(\"pricing_tiers\", []):\n",
    "                    for rule in tier.get(\"discount_rules\", []):\n",
    "                        if rule.get(\"type\") == \"enterprise\":\n",
    "                            rule[\"type\"] = \"partner\"\n",
    "                            rule[\"level\"] = \"enterprise\"\n",
    "\n",
    "# Carregar o arquivo original\n",
    "with open(\"data/raw/pricelist_cleaned.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Aplicar correções\n",
    "fix_json_errors(data)\n",
    "\n",
    "# Salvar arquivo corrigido\n",
    "with open(\"data/raw/pricelist_fixed.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Arquivo corrigido salvo como pricelist_fixed.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f729251-2c37-4f78-860b-67d1dfefd787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f20198-ce2b-4b7b-b721-074e2884d006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7f3ebd-2b3d-44ab-a705-2c45e98b73a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f08ade87-28d0-43e5-ae69-3a94957513bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hardware': 0, 'software': 0, 'files': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Notebook cell: Normalizador v2 com enriquecimento por SKU ---\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json, re\n",
    "from datetime import date\n",
    "from typing import Optional, Dict, List, Any\n",
    "\n",
    "# ================= CONFIG =================\n",
    "XLSX_PATH   = Path(\"data/raw/Cisco_Pricing.xlsx\")\n",
    "OUT_BASE    = Path(\"data/normalized\")\n",
    "CURRENCY    = \"USD\"\n",
    "\n",
    "ENRICH_WITH_LLM = True      # >>> troque para True se quiser enriquecer\n",
    "OPENAI_MODEL    = \"gpt-4o-mini\"\n",
    "\n",
    "# ================= OpenAI (opcional) =================\n",
    "client = None\n",
    "if ENRICH_WITH_LLM:\n",
    "    from openai import OpenAI\n",
    "    client = OpenAI()\n",
    "\n",
    "# ================= Helpers =================\n",
    "def find_col(df: pd.DataFrame, substrs: list[str]) -> Optional[str]:\n",
    "    for col in df.columns:\n",
    "        lc = str(col).strip().lower()\n",
    "        if any(s in lc for s in substrs):\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "def clean_price(val: Any) -> float:\n",
    "    s = str(val)\n",
    "    s = re.sub(r\"[^\\d,\\.]\", \"\", s)\n",
    "    s = re.sub(r\"\\.(?=\\d{3},)\", \"\", s)  # 1.234,56 -> 1234,56\n",
    "    s = s.replace(\",\", \".\")\n",
    "    try:\n",
    "        return round(float(s), 2)\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def clean_pct(val: Any) -> float:\n",
    "    s = re.sub(r\"[^\\d,\\.]\", \"\", str(val)).replace(\",\", \".\")\n",
    "    try:\n",
    "        return float(s)/100.0\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def term_months_from_text(text: str) -> Optional[int]:\n",
    "    if not text: return None\n",
    "    t = text.upper()\n",
    "    m = re.search(r\"(\\d+)\\s*Y(R|EARS?)?\", t) or re.search(r\"(\\d+)\\s*YR\", t)\n",
    "    if m: return int(m.group(1)) * 12\n",
    "    m = re.search(r\"(\\d+)\\s*MONTH\", t)\n",
    "    if m: return int(m.group(1))\n",
    "    m = re.search(r\"-(\\d+)YR\\b\", t)\n",
    "    if m: return int(m.group(1)) * 12\n",
    "    return None\n",
    "\n",
    "def load_json_list(path: Path) -> List[dict]:\n",
    "    if path.exists():\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            try:\n",
    "                return json.load(f)\n",
    "            except Exception:\n",
    "                return []\n",
    "    return []\n",
    "\n",
    "def save_json_list(path: Path, data: List[dict]):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# ================= Categorias & Blueprints =================\n",
    "# Campos esperados por categoria (hardware/software).\n",
    "HW_ATTR_BLUEPRINT = {\n",
    "    \"switches\":   [\"port_count\",\"poe_budget_w\",\"uplinks\",\"uplink_speed\",\"layer\",\"stacking\",\"throughput_gbps\"],\n",
    "    \"routers\":    [\"wan_ports\",\"lan_ports\",\"throughput_gbps\",\"sdwan_support\",\"vpn_tps\",\"modules_supported\"],\n",
    "    \"wireless\":   [\"wifi_standard\",\"spatial_streams\",\"mimo\",\"antenna_type\",\"indoor_outdoor\",\"ip_rating\",\"poe_class\"],\n",
    "    \"firewall\":   [\"fw_throughput_gbps\",\"ips_gbps\",\"max_sessions\",\"interfaces\",\"ha_supported\",\"vpn_peers\"],\n",
    "    \"antennas\":   [\"bands\",\"gain_dbi\",\"connector_type\",\"polarization\",\"beamwidth\",\"ip_rating\"],\n",
    "    \"cabling\":    [\"type\",\"length_m\",\"connector_a\",\"connector_b\",\"shielding\"],\n",
    "    \"connectors\": [\"type\",\"gender\",\"impedance_ohm\",\"application\"],\n",
    "}\n",
    "\n",
    "SW_ATTR_BLUEPRINT = {\n",
    "    \"wireless\":           {\"features\": [], \"bundles\": []},\n",
    "    \"switches\":           {\"features\": [], \"bundles\": []},\n",
    "    \"routers\":            {\"features\": [], \"bundles\": []},\n",
    "    \"firewall\":           {\"features\": [], \"bundles\": []},\n",
    "    \"sw_support_license\": {\"support_level\": None, \"sla_hrs\": None, \"on_site\": None}\n",
    "}\n",
    "\n",
    "# Mapeamento de categoria da planilha -> slug final\n",
    "CANON = {\n",
    "    \"hardware\": {\n",
    "        \"antennas\": \"antennas\",\n",
    "        \"cabling\": \"cabling\",\n",
    "        \"connectors\": \"connectors\",\n",
    "        \"firewall\": \"firewall\",\n",
    "        \"routers\": \"routers\",\n",
    "        \"switches\": \"switches\",\n",
    "        \"wireless\": \"wireless\",\n",
    "    },\n",
    "    \"software\": {\n",
    "        \"firewall\": \"firewall\",\n",
    "        \"routers\": \"routers\",\n",
    "        \"sw support license\": \"sw_support_license\",\n",
    "        \"switches\": \"switches\",\n",
    "        \"wireless\": \"wireless\",\n",
    "    }\n",
    "}\n",
    "\n",
    "def canon_hw(raw: str) -> str:\n",
    "    k = raw.strip().lower()\n",
    "    return CANON[\"hardware\"].get(k, re.sub(r\"[^a-z0-9]+\",\"_\", k))\n",
    "\n",
    "def canon_sw(raw: str) -> str:\n",
    "    k = raw.strip().lower()\n",
    "    return CANON[\"software\"].get(k, re.sub(r\"[^a-z0-9]+\",\"_\", k))\n",
    "\n",
    "# ================= Templates de registro =================\n",
    "def base_product(sku: str, name: str, ptype: str) -> Dict:\n",
    "    return {\n",
    "        \"cisco_product_id\": sku,\n",
    "        \"commercial_name\": name,\n",
    "        \"product_type\": ptype,\n",
    "        \"lifecycle\": {\"status\": \"active\", \"eos_announced\": None, \"last_support_date\": None},\n",
    "        \"regulatory\": {\"certifications\": []}\n",
    "    }\n",
    "\n",
    "def hardware_record(sku: str, name: str, category: str, price: float, elig_frac: float) -> Dict:\n",
    "    return {\n",
    "        **base_product(sku, name, \"hardware\"),\n",
    "        \"technical_profile\": {\n",
    "            \"category\": category,\n",
    "            \"subcategory\": \"\",\n",
    "            \"hardware_attributes\": {k: None for k in HW_ATTR_BLUEPRINT.get(category, [])}\n",
    "        },\n",
    "        \"pricing_model\": {\n",
    "            \"type\": \"one_time\",\n",
    "            \"currency\": CURRENCY,\n",
    "            \"base_price\": price,\n",
    "            \"elig_pct\": elig_frac,\n",
    "            \"pricing_tiers\": [{\n",
    "                \"min_quantity\": 1,\n",
    "                \"price\": price,\n",
    "                \"effective\": str(date.today()),\n",
    "                \"discount_rules\": []\n",
    "            }]\n",
    "        },\n",
    "        \"dependencies\": {\"required_components\": [], \"compatible_with\": []}\n",
    "    }\n",
    "\n",
    "def software_record(sku: str, name: str, category: str, price: float, elig_frac: float, desc: str) -> Dict:\n",
    "    term = term_months_from_text(sku) or term_months_from_text(name) or term_months_from_text(desc) or 12\n",
    "    needs_hw = bool(re.search(r\"(meraki|lic-)\", f\"{sku} {name} {desc}\", re.I))\n",
    "    profile = {\"category\": category, \"license_model\": \"term\", \"term_months\": int(term), \"seat_unit\": \"device\", \"requires_hardware\": needs_hw}\n",
    "\n",
    "    # preenche os campos per-category\n",
    "    if category in SW_ATTR_BLUEPRINT:\n",
    "        blueprint = SW_ATTR_BLUEPRINT[category]\n",
    "        profile.update(blueprint)\n",
    "\n",
    "    return {\n",
    "        **base_product(sku, name, \"software\"),\n",
    "        \"software_profile\": profile,\n",
    "        \"entitlement\": {\"smart_account_required\": needs_hw, \"partner_tier_pricing\": {}},\n",
    "        \"pricing_model\": {\n",
    "            \"type\": \"subscription\",\n",
    "            \"currency\": CURRENCY,\n",
    "            \"list_price\": price,\n",
    "            \"elig_pct\": elig_frac,\n",
    "            \"billing\": \"prepaid\",\n",
    "            \"term_months\": int(term),\n",
    "            \"pricing_tiers\": [{\n",
    "                \"min_quantity\": 1,\n",
    "                \"price\": price,\n",
    "                \"term_months\": int(term),\n",
    "                \"effective\": str(date.today()),\n",
    "                \"discount_rules\": []\n",
    "            }]\n",
    "        }\n",
    "    }\n",
    "\n",
    "# ================= Enriquecimento 1-a-1 (opcional) =================\n",
    "def llm_enrich_attributes(product: Dict) -> Dict:\n",
    "    \"\"\"Enriquece APENAS os campos previstos no blueprint, 1 SKU por vez.\"\"\"\n",
    "    if not (ENRICH_WITH_LLM and client):\n",
    "        return product\n",
    "\n",
    "    if product[\"product_type\"] == \"hardware\":\n",
    "        cat = product[\"technical_profile\"][\"category\"]\n",
    "        allowed = HW_ATTR_BLUEPRINT.get(cat, [])\n",
    "        if not allowed:\n",
    "            return product\n",
    "\n",
    "        schema_hint = {k: \"<value>\" for k in allowed}\n",
    "        prompt = f\"\"\"\n",
    "Return JSON ONLY. Fill the keys in \"hardware_attributes\" using the allowed keys below.\n",
    "Do not invent SKU/price. If unknown, keep null. No extra keys.\n",
    "\n",
    "SKU: {product['cisco_product_id']}\n",
    "Name: {product['commercial_name']}\n",
    "Category: {cat}\n",
    "\n",
    "Allowed keys: {allowed}\n",
    "\n",
    "Respond exactly as:\n",
    "{{\n",
    "  \"hardware_attributes\": {json.dumps(schema_hint)}\n",
    "}}\n",
    "\"\"\".strip()\n",
    "        try:\n",
    "            resp = client.chat.completions.create(\n",
    "                model=OPENAI_MODEL,\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "                messages=[{\"role\":\"user\",\"content\": prompt}],\n",
    "                temperature=0.1\n",
    "            )\n",
    "            data = json.loads(resp.choices[0].message.content)\n",
    "            attrs = data.get(\"hardware_attributes\", {})\n",
    "            # filtra apenas keys permitidas\n",
    "            filtered = {k: attrs.get(k, None) for k in allowed}\n",
    "            product[\"technical_profile\"][\"hardware_attributes\"].update(filtered)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    else:  # software\n",
    "        cat = product[\"software_profile\"][\"category\"]\n",
    "        # duas modalidades: features/bundles OU suporte\n",
    "        if cat == \"sw_support_license\":\n",
    "            allowed = list(SW_ATTR_BLUEPRINT[\"sw_support_license\"].keys())\n",
    "            schema_hint = {k: \"<value>\" for k in allowed}\n",
    "            prompt = f\"\"\"\n",
    "Return JSON ONLY. Fill the keys in \"support\" using the allowed keys below.\n",
    "If unknown, keep null. No extra keys.\n",
    "\n",
    "SKU: {product['cisco_product_id']}\n",
    "Name: {product['commercial_name']}\n",
    "Category: {cat}\n",
    "\n",
    "Allowed keys: {allowed}\n",
    "\n",
    "Respond exactly as:\n",
    "{{\n",
    "  \"support\": {json.dumps(schema_hint)}\n",
    "}}\n",
    "\"\"\".strip()\n",
    "            try:\n",
    "                resp = client.chat.completions.create(\n",
    "                    model=OPENAI_MODEL,\n",
    "                    response_format={\"type\": \"json_object\"},\n",
    "                    messages=[{\"role\":\"user\",\"content\": prompt}],\n",
    "                    temperature=0.1\n",
    "                )\n",
    "                data = json.loads(resp.choices[0].message.content)\n",
    "                s = data.get(\"support\", {})\n",
    "                product[\"software_profile\"][\"support_level\"] = s.get(\"support_level\")\n",
    "                product[\"software_profile\"][\"sla_hrs\"] = s.get(\"sla_hrs\")\n",
    "                product[\"software_profile\"][\"on_site\"] = s.get(\"on_site\")\n",
    "            except Exception:\n",
    "                pass\n",
    "        else:\n",
    "            prompt = f\"\"\"\n",
    "Return JSON ONLY. Provide \"features\" (list of short feature names) and optional \"bundles\" (e.g., DNA Essentials/Advantage, MR Enterprise).\n",
    "If unknown, return empty arrays.\n",
    "\n",
    "SKU: {product['cisco_product_id']}\n",
    "Name: {product['commercial_name']}\n",
    "Category: {cat}\n",
    "\n",
    "Respond exactly as:\n",
    "{{\n",
    "  \"features\": [],\n",
    "  \"bundles\": []\n",
    "}}\n",
    "\"\"\".strip()\n",
    "            try:\n",
    "                resp = client.chat.completions.create(\n",
    "                    model=OPENAI_MODEL,\n",
    "                    response_format={\"type\": \"json_object\"},\n",
    "                    messages=[{\"role\":\"user\",\"content\": prompt}],\n",
    "                    temperature=0.1\n",
    "                )\n",
    "                data = json.loads(resp.choices[0].message.content)\n",
    "                if isinstance(data.get(\"features\"), list):\n",
    "                    product[\"software_profile\"][\"features\"] = data[\"features\"]\n",
    "                if isinstance(data.get(\"bundles\"), list):\n",
    "                    product[\"software_profile\"][\"bundles\"] = data[\"bundles\"]\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    return product\n",
    "\n",
    "# ================= Pipeline principal =================\n",
    "def normalize_catalog_per_item(xlsx_path: Path, out_dir: Path) -> Dict[str, int]:\n",
    "    df = pd.read_excel(xlsx_path, engine=\"openpyxl\")\n",
    "\n",
    "    c_type = find_col(df, [\"category-type\", \"category type\"])\n",
    "    c_cat  = find_col(df, [\"category\"])\n",
    "    c_sku  = find_col(df, [\"sku\", \"part\"])\n",
    "    c_desc = find_col(df, [\"desc\", \"description\", \"name\"])\n",
    "    c_price= find_col(df, [\"pri\",\"price\",\"list\"])\n",
    "    c_elig = find_col(df, [\"elig\"])\n",
    "\n",
    "    missing = [n for n,c in [(\"Category-Type\",c_type),(\"Category\",c_cat),(\"SKU\",c_sku),(\"Desc\",c_desc),(\"Price\",c_price),(\"Elig_%\",c_elig)] if c is None]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Colunas ausentes: {missing}\")\n",
    "\n",
    "    df[\"_type\"]   = df[c_type].astype(str).str.strip().str.lower()\n",
    "    df[\"_catraw\"] = df[c_cat].astype(str).str.strip()\n",
    "    df[\"_sku\"]    = df[c_sku].astype(str).str.strip()\n",
    "    df[\"_name\"]   = df[c_desc].astype(str).str.strip()\n",
    "    df[\"_price\"]  = df[c_price].apply(clean_price)\n",
    "    df[\"_eligf\"]  = df[c_elig].apply(clean_pct)\n",
    "\n",
    "    (out_dir/\"hardware\").mkdir(parents=True, exist_ok=True)\n",
    "    (out_dir/\"software\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    counts = {\"hardware\":0, \"software\":0, \"files\":0}\n",
    "\n",
    "    # --- HARDWARE: processa 1 a 1 e grava por categoria ---\n",
    "    hw = df[df[\"_type\"]==\"hardware\"]\n",
    "    for raw_cat, chunk in hw.groupby(\"_catraw\"):\n",
    "        cat = canon_hw(raw_cat)\n",
    "        out_file = out_dir/\"hardware\"/f\"hw_{cat}.json\"\n",
    "        existing = load_json_list(out_file)\n",
    "        seen = {p.get(\"cisco_product_id\") for p in existing}\n",
    "\n",
    "        for _, r in chunk.iterrows():\n",
    "            sku = r[\"_sku\"]\n",
    "            if sku in seen: \n",
    "                continue\n",
    "            prod = hardware_record(sku, r[\"_name\"], cat, r[\"_price\"], r[\"_eligf\"])\n",
    "            prod = llm_enrich_attributes(prod)  # 1 chamada por SKU (se habilitado)\n",
    "            existing.append(prod)\n",
    "            counts[\"hardware\"] += 1\n",
    "\n",
    "        save_json_list(out_file, existing)\n",
    "        counts[\"files\"] += 1\n",
    "\n",
    "    # --- SOFTWARE: idem ---\n",
    "    sw = df[df[\"_type\"]==\"software\"]\n",
    "    for raw_cat, chunk in sw.groupby(\"_catraw\"):\n",
    "        cat = canon_sw(raw_cat)\n",
    "        out_file = out_dir/\"software\"/f\"sw_{cat}.json\"\n",
    "        existing = load_json_list(out_file)\n",
    "        seen = {p.get(\"cisco_product_id\") for p in existing}\n",
    "\n",
    "        for _, r in chunk.iterrows():\n",
    "            sku = r[\"_sku\"]\n",
    "            if sku in seen:\n",
    "                continue\n",
    "            prod = software_record(sku, r[\"_name\"], cat, r[\"_price\"], r[\"_eligf\"], r[\"_name\"])\n",
    "            prod = llm_enrich_attributes(prod)  # 1 chamada por SKU (se habilitado)\n",
    "            existing.append(prod)\n",
    "            counts[\"software\"] += 1\n",
    "\n",
    "        save_json_list(out_file, existing)\n",
    "        counts[\"files\"] += 1\n",
    "\n",
    "    return counts\n",
    "\n",
    "# ================= Run =================\n",
    "OUT_BASE.mkdir(parents=True, exist_ok=True)\n",
    "stats = normalize_catalog_per_item(XLSX_PATH, OUT_BASE)\n",
    "stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75262e3a-8421-4e7b-b79f-72ede065b324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Columns detected: {'type': 'Category-Type', 'category': 'Category-Type', 'sku': 'SKU', 'desc': 'Desc', 'price': 'price', 'elig': 'Elig_%'}\n",
      "→ Type counts: {'hardware': 3004, 'software': 1263}\n",
      "→ Sample categories: {'hardware': 3004, 'software': 1263}\n",
      "✅ Done: {'hardware': 3004, 'software': 1263, 'files': 2}\n",
      "→ Output folders: data\\normalized\\hardware and data\\normalized\\software\n"
     ]
    }
   ],
   "source": [
    "import os, json, re, math\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# ====== CONFIG ======\n",
    "XLSX_PATH = \"data/raw/Cisco_Pricing.xlsx\"   # ajuste se necessário\n",
    "OUT_DIR   = Path(\"data/normalized\")\n",
    "ENRICH_WITH_LLM = True                     # mantenha False por enquanto\n",
    "\n",
    "# Mapeamento canônico de categorias (o que vimos nas telas)\n",
    "CANON_HW = {\n",
    "    \"antennas\": \"antennas\",\n",
    "    \"antenna\": \"antennas\",\n",
    "    \"cabling\": \"cabling\",\n",
    "    \"connectors\": \"connectors\",\n",
    "    \"firewall\": \"firewall\",\n",
    "    \"firewalls\": \"firewall\",\n",
    "    \"routers\": \"routers\",\n",
    "    \"router\": \"routers\",\n",
    "    \"switches\": \"switches\",\n",
    "    \"switch\": \"switches\",\n",
    "    \"wireless\": \"wireless\",\n",
    "}\n",
    "\n",
    "CANON_SW = {\n",
    "    \"wireless\": \"wireless\",\n",
    "    \"switches\": \"switches\",\n",
    "    \"routers\": \"routers\",\n",
    "    \"firewall\": \"firewall\",\n",
    "    \"firewalls\": \"firewall\",\n",
    "    \"sw support license\": \"sw_support_license\",\n",
    "    \"support license\": \"sw_support_license\",\n",
    "}\n",
    "\n",
    "# Blueprints MUITO resumidos (use os completos que combinamos se quiser)\n",
    "HW_ATTR_BLUEPRINT = {\n",
    "    \"switches\":    {\"port_count\": None, \"poe_budget_w\": None, \"layer\": None},\n",
    "    \"routers\":     {\"wan_ports\": None},\n",
    "    \"firewall\":    {\"throughput_gbps\": None},\n",
    "    \"wireless\":    {\"wifi_standard\": None, \"antenna_type\": None},\n",
    "    \"antennas\":    {\"connector_type\": None, \"gain_dbi\": None},\n",
    "    \"cabling\":     {\"cable_type\": None, \"length_m\": None},\n",
    "    \"connectors\":  {\"connector_type\": None},\n",
    "}\n",
    "SW_ATTR_BLUEPRINT = {\n",
    "    \"wireless\":           {\"features\": [], \"term_months\": None},\n",
    "    \"switches\":           {\"features\": [], \"term_months\": None},\n",
    "    \"routers\":            {\"features\": [], \"term_months\": None},\n",
    "    \"firewall\":           {\"features\": [], \"term_months\": None},\n",
    "    \"sw_support_license\": {\"support_level\": None, \"sla_hrs\": None, \"on_site\": None, \"term_months\": None},\n",
    "}\n",
    "\n",
    "def _find_col(df, *candidates):\n",
    "    cols = {str(c).strip().lower(): c for c in df.columns}\n",
    "    for want in candidates:\n",
    "        for k, orig in cols.items():\n",
    "            if want in k:\n",
    "                return orig\n",
    "    return None\n",
    "\n",
    "def _norm_text(x):\n",
    "    return str(x).strip()\n",
    "\n",
    "def _norm_price(x):\n",
    "    if pd.isna(x):\n",
    "        return 0.0\n",
    "    s = str(x)\n",
    "    s = re.sub(r\"[^\\d,\\.]\", \"\", s)\n",
    "    # trata formatos comuns: 1.234,56 → 1234.56 ; 1234,56 → 1234.56\n",
    "    if s.count(\",\") == 1 and s.count(\".\") >= 1 and s.rfind(\",\") > s.rfind(\".\"):\n",
    "        s = s.replace(\".\", \"\").replace(\",\", \".\")\n",
    "    elif s.count(\",\") == 1 and s.count(\".\") == 0:\n",
    "        s = s.replace(\",\", \".\")\n",
    "    try:\n",
    "        return float(s)\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def _canon_category(raw, typ):\n",
    "    base = _norm_text(raw).lower()\n",
    "    if typ == \"hardware\":\n",
    "        for k in CANON_HW:\n",
    "            if k in base:\n",
    "                return CANON_HW[k]\n",
    "    else:\n",
    "        for k in CANON_SW:\n",
    "            if k in base:\n",
    "                return CANON_SW[k]\n",
    "    # fallback: slug simples\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"_\", base) or \"uncategorized\"\n",
    "\n",
    "def _hardware_record(row, sku, name, cat_slug, price, elig):\n",
    "    rec = {\n",
    "        \"cisco_product_id\": sku,\n",
    "        \"commercial_name\": name,\n",
    "        \"product_type\": \"hardware\",\n",
    "        \"lifecycle\": {\"status\": \"unknown\"},\n",
    "        \"technical_profile\": {\n",
    "            \"hardware_attributes\": {}\n",
    "        },\n",
    "        \"pricing_model\": {\n",
    "            \"type\": \"one_time\",\n",
    "            \"currency\": \"USD\",\n",
    "            \"base_price\": price,\n",
    "            \"elig_pct\": elig\n",
    "        }\n",
    "    }\n",
    "    # aplica blueprint da categoria se existir\n",
    "    attrs = HW_ATTR_BLUEPRINT.get(cat_slug)\n",
    "    if attrs:\n",
    "        rec[\"technical_profile\"][\"hardware_attributes\"].update(attrs)\n",
    "    return rec\n",
    "\n",
    "def _software_record(row, sku, name, cat_slug, price, elig):\n",
    "    rec = {\n",
    "        \"cisco_product_id\": sku,\n",
    "        \"commercial_name\": name,\n",
    "        \"product_type\": \"software\",\n",
    "        \"software_profile\": {\n",
    "            \"edition\": None,\n",
    "            \"license_type\": \"subscription\",\n",
    "            \"term_months\": 12,\n",
    "            \"features\": [],\n",
    "            \"bundles\": []\n",
    "        },\n",
    "        \"pricing_model\": {\n",
    "            \"type\": \"term_subscription\",\n",
    "            \"currency\": \"USD\",\n",
    "            \"base_price\": price,\n",
    "            \"elig_pct\": elig\n",
    "        }\n",
    "    }\n",
    "    bp = SW_ATTR_BLUEPRINT.get(cat_slug)\n",
    "    if bp:\n",
    "        rec[\"software_profile\"].update({k: v for k, v in bp.items() if k not in rec[\"software_profile\"]})\n",
    "    return rec\n",
    "\n",
    "def normalize_and_export(xlsx_path, out_dir):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    df = pd.read_excel(xlsx_path, engine=\"openpyxl\")\n",
    "    # descoberta robusta de colunas\n",
    "    col_type = _find_col(df, \"category-type\", \"category type\")\n",
    "    col_cat  = _find_col(df, \"category\")\n",
    "    col_sku  = _find_col(df, \"sku\", \"part\", \"part number\")\n",
    "    col_desc = _find_col(df, \"desc\", \"description\", \"name\")\n",
    "    col_pri  = _find_col(df, \"pri\", \"price\", \"list price\")\n",
    "    col_elig = _find_col(df, \"elig\", \"eligibility\")\n",
    "\n",
    "    print(\"→ Columns detected:\", {\n",
    "        \"type\": col_type, \"category\": col_cat, \"sku\": col_sku, \"desc\": col_desc, \"price\": col_pri, \"elig\": col_elig\n",
    "    })\n",
    "    if not all([col_type, col_cat, col_sku, col_desc, col_pri, col_elig]):\n",
    "        raise ValueError(\"Não encontrei todas as colunas necessárias. Confira os nomes no Excel.\")\n",
    "\n",
    "    # normalizações básicas\n",
    "    df[\"_type\"] = df[col_type].astype(str).str.strip().str.lower()\n",
    "    df[\"_cat\"]  = df[col_cat].astype(str).str.strip()\n",
    "    df[\"_sku\"]  = df[col_sku].astype(str).str.strip()\n",
    "    df[\"_desc\"] = df[col_desc].astype(str).str.strip()\n",
    "    df[\"_pri\"]  = df[col_pri].apply(_norm_price)\n",
    "    df[\"_elig\"] = df[col_elig].astype(str).str.strip().str.replace(\"%\",\"\", regex=False)\n",
    "    df[\"_elig\"] = pd.to_numeric(df[\"_elig\"].str.replace(\",\", \".\", regex=False), errors=\"coerce\").fillna(0)/100.0\n",
    "\n",
    "    # diagnóstico de valores\n",
    "    print(\"→ Type counts:\", df[\"_type\"].value_counts().to_dict())\n",
    "    print(\"→ Sample categories:\", df[\"_cat\"].dropna().astype(str).str.strip().str.lower().value_counts().head(15).to_dict())\n",
    "\n",
    "    # coletores por categoria\n",
    "    buckets_hw = {}\n",
    "    buckets_sw = {}\n",
    "\n",
    "    hw_rows = df[df[\"_type\"].str.contains(\"hard\")]\n",
    "    sw_rows = df[df[\"_type\"].str.contains(\"soft\")]\n",
    "\n",
    "    for _, r in hw_rows.iterrows():\n",
    "        cat_slug = _canon_category(r[\"_cat\"], \"hardware\")\n",
    "        rec = _hardware_record(r, r[\"_sku\"], r[\"_desc\"], cat_slug, r[\"_pri\"], r[\"_elig\"])\n",
    "        buckets_hw.setdefault(cat_slug, []).append(rec)\n",
    "\n",
    "    for _, r in sw_rows.iterrows():\n",
    "        cat_slug = _canon_category(r[\"_cat\"], \"software\")\n",
    "        rec = _software_record(r, r[\"_sku\"], r[\"_desc\"], cat_slug, r[\"_pri\"], r[\"_elig\"])\n",
    "        buckets_sw.setdefault(cat_slug, []).append(rec)\n",
    "\n",
    "    # salvar\n",
    "    hw_dir = out_dir / \"hardware\"\n",
    "    sw_dir = out_dir / \"software\"\n",
    "    hw_dir.mkdir(parents=True, exist_ok=True)\n",
    "    sw_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    files = 0\n",
    "    for cat, items in buckets_hw.items():\n",
    "        p = hw_dir / f\"hw_{cat}.json\"\n",
    "        p.write_text(json.dumps(items, indent=2))\n",
    "        files += 1\n",
    "    for cat, items in buckets_sw.items():\n",
    "        p = sw_dir / f\"sw_{cat}.json\"\n",
    "        p.write_text(json.dumps(items, indent=2))\n",
    "        files += 1\n",
    "\n",
    "    print(\"✅ Done:\", {\"hardware\": sum(len(v) for v in buckets_hw.values()),\n",
    "                       \"software\": sum(len(v) for v in buckets_sw.values()),\n",
    "                       \"files\": files})\n",
    "    print(\"→ Output folders:\", hw_dir, \"and\", sw_dir)\n",
    "\n",
    "normalize_and_export(XLSX_PATH, OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8093bff3-7e43-4b5f-82f8-0710c4a571a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4495a97f-2e05-4d9a-9860-259c30c42941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Columns detected: {'type': 'Category-Type', 'category': 'Category-Type', 'sku': 'SKU', 'desc': 'Desc', 'price': 'price', 'elig': 'Elig_%'}\n",
      "→ Type counts: {'hardware': 3004, 'software': 1263}\n",
      "→ Sample categories: {'hardware': 3004, 'software': 1263}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HW] hardware:  18%|█▊        | 539/3004 [04:30<20:38,  1.99sku/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 544\u001b[0m\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Done:\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\n\u001b[0;32m    537\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhardware\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mlen\u001b[39m(json\u001b[38;5;241m.\u001b[39mloads((hw_dir\u001b[38;5;241m/\u001b[39mf)\u001b[38;5;241m.\u001b[39mread_text(encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m))) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(hw_dir) \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[0;32m    538\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftware\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mlen\u001b[39m(json\u001b[38;5;241m.\u001b[39mloads((sw_dir\u001b[38;5;241m/\u001b[39mf)\u001b[38;5;241m.\u001b[39mread_text(encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m))) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(sw_dir) \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[0;32m    539\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles\u001b[39m\u001b[38;5;124m\"\u001b[39m: files_written,\n\u001b[0;32m    540\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(out_dir)\n\u001b[0;32m    541\u001b[0m     })\n\u001b[0;32m    543\u001b[0m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[1;32m--> 544\u001b[0m normalize_and_export_by_category(XLSX_PATH, OUT_DIR)\n",
      "Cell \u001b[1;32mIn[14], line 481\u001b[0m, in \u001b[0;36mnormalize_and_export_by_category\u001b[1;34m(xlsx_path, out_dir)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ENRICH_WITH_LLM:\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;66;03m# preenche somente os campos null do blueprint\u001b[39;00m\n\u001b[0;32m    480\u001b[0m     _ \u001b[38;5;241m=\u001b[39m enrich_product_with_llm(prod, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhardware\u001b[39m\u001b[38;5;124m\"\u001b[39m, cat)\n\u001b[1;32m--> 481\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(RATE_LIMIT_SLEEP)\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# se já existia, update lista; se não, append\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sku \u001b[38;5;129;01min\u001b[39;00m index:\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;66;03m# atualiza no array existente\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# Normalizador + Enriquecimento (por categoria / por SKU)\n",
    "# Lê Cisco_Pricing.xlsx, cria JSONs por categoria (hardware/software),\n",
    "# e opcionalmente enriquece campos faltantes com a LLM (um produto por vez).\n",
    "\n",
    "# %%\n",
    "import os, json, re, time, math\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# OpenAI v1\n",
    "try:\n",
    "    from openai import OpenAI\n",
    "    _openai_available = True\n",
    "except Exception:\n",
    "    _openai_available = False\n",
    "\n",
    "# =================== CONFIG ===================\n",
    "XLSX_PATH = \"data/raw/Cisco_Pricing.xlsx\"    # <<< ajuste se necessário\n",
    "OUT_DIR   = Path(\"data/normalized\")\n",
    "\n",
    "# Toggle de enriquecimento\n",
    "ENRICH_WITH_LLM   = True     # <<< defina para True quando quiser enriquecer\n",
    "REFRESH_ENRICHMENT= True    # True = reprocessa/enriquece mesmo se já existir no JSON\n",
    "OPENAI_MODEL      = \"gpt-4o-mini\"\n",
    "OPENAI_API_KEY    = os.getenv(\"OPENAI_API_KEY\")  # pode setar aqui string literal se preferir\n",
    "RATE_LIMIT_SLEEP  = 0.5      # seconds entre chamadas, ajuste conforme necessário\n",
    "\n",
    "# =================== MAPEAMENTOS ===================\n",
    "# Canonicalização das categorias (use os nomes do seu Excel)\n",
    "CANON_HW = {\n",
    "    \"antennas\": \"antennas\", \"antenna\": \"antennas\",\n",
    "    \"cabling\": \"cabling\",\n",
    "    \"connectors\": \"connectors\", \"connector\": \"connectors\",\n",
    "    \"firewall\": \"firewall\", \"firewalls\": \"firewall\",\n",
    "    \"routers\": \"routers\", \"router\": \"routers\",\n",
    "    \"switches\": \"switches\", \"switch\": \"switches\",\n",
    "    \"wireless\": \"wireless\", \"access point\": \"wireless\", \"access points\": \"wireless\",\n",
    "}\n",
    "CANON_SW = {\n",
    "    \"wireless\": \"wireless\",\n",
    "    \"switches\": \"switches\",\n",
    "    \"routers\": \"routers\",\n",
    "    \"firewall\": \"firewall\", \"firewalls\": \"firewall\",\n",
    "    \"sw support license\": \"sw_support_license\", \"support license\": \"sw_support_license\",\n",
    "}\n",
    "\n",
    "# Blueprints de atributos por categoria (pode estender quando quiser)\n",
    "HW_ATTR_BLUEPRINT: Dict[str, Dict[str, Any]] = {\n",
    "    \"switches\": {\n",
    "        \"category\": \"switch\",\n",
    "        \"subcategory\": None,\n",
    "        \"port_count\": None,\n",
    "        \"poe_budget_w\": None,\n",
    "        \"layer\": None,                  # L2/L3\n",
    "        \"uplink\": None,                 # ex: \"2x10G SFP+\"\n",
    "        \"stacking\": None,               # True/False/None\n",
    "        \"mounting\": None,               # rack/desktop\n",
    "        \"throughput_gbps\": None,\n",
    "        \"power_requirements\": None,\n",
    "    },\n",
    "    \"routers\": {\n",
    "        \"category\": \"router\",\n",
    "        \"wan_ports\": None,\n",
    "        \"sdwan_capable\": None,\n",
    "        \"vpn_throughput_mbps\": None,\n",
    "        \"throughput_gbps\": None,\n",
    "        \"power_requirements\": None,\n",
    "    },\n",
    "    \"firewall\": {\n",
    "        \"category\": \"firewall\",\n",
    "        \"throughput_gbps\": None,\n",
    "        \"ngfw_features\": [],\n",
    "        \"vpn_throughput_mbps\": None,\n",
    "        \"ha_supported\": None,\n",
    "        \"power_requirements\": None,\n",
    "    },\n",
    "    \"wireless\": {\n",
    "        \"category\": \"wireless\",\n",
    "        \"subcategory\": \"access_point\",\n",
    "        \"wifi_standard\": None,          # ex: 802.11ac/ax\n",
    "        \"throughput\": None,             # ex: \"1.7 Gbps\"\n",
    "        \"antenna_type\": None,           # internal/external\n",
    "        \"mounting\": None,               # indoor/outdoor\n",
    "        \"power_requirements\": None,     # PoE/PoE+\n",
    "        \"mu_mimo\": None,                # True/False/None\n",
    "    },\n",
    "    \"antennas\": {\n",
    "        \"category\": \"antenna\",\n",
    "        \"connector_type\": None,\n",
    "        \"gain_dbi\": None,\n",
    "        \"polarity\": None,               # single/dual\n",
    "        \"mounting\": None,\n",
    "        \"band\": None,                   # 2.4/5/6 GHz\n",
    "    },\n",
    "    \"cabling\": {\n",
    "        \"category\": \"cable\",\n",
    "        \"cable_type\": None,             # cat5e/cat6/sfp+/dac/etc\n",
    "        \"length_m\": None,\n",
    "        \"connector_a\": None,\n",
    "        \"connector_b\": None,\n",
    "        \"shielding\": None,              # UTP/STP\n",
    "    },\n",
    "    \"connectors\": {\n",
    "        \"category\": \"connector\",\n",
    "        \"connector_type\": None,         # rj45/sfp/sfp+/qsfp\n",
    "        \"gender\": None,\n",
    "        \"plating\": None,\n",
    "    }\n",
    "}\n",
    "\n",
    "SW_ATTR_BLUEPRINT: Dict[str, Dict[str, Any]] = {\n",
    "    # subscriptions \"funcionais\"\n",
    "    \"wireless\": {\n",
    "        \"edition\": None,\n",
    "        \"license_type\": \"subscription\",\n",
    "        \"term_months\": None,\n",
    "        \"features\": [],\n",
    "        \"bundles\": [],\n",
    "        \"per_device_or_site\": None      # per_device/per_site/unknown\n",
    "    },\n",
    "    \"switches\": {\n",
    "        \"edition\": None,\n",
    "        \"license_type\": \"subscription\",\n",
    "        \"term_months\": None,\n",
    "        \"features\": [],\n",
    "        \"bundles\": [],\n",
    "        \"per_device_or_site\": None\n",
    "    },\n",
    "    \"routers\": {\n",
    "        \"edition\": None,\n",
    "        \"license_type\": \"subscription\",\n",
    "        \"term_months\": None,\n",
    "        \"features\": [],\n",
    "        \"bundles\": [],\n",
    "        \"per_device_or_site\": None\n",
    "    },\n",
    "    \"firewall\": {\n",
    "        \"edition\": None,\n",
    "        \"license_type\": \"subscription\",\n",
    "        \"term_months\": None,\n",
    "        \"features\": [],\n",
    "        \"bundles\": [],\n",
    "        \"per_device_or_site\": None\n",
    "    },\n",
    "    # licenças de suporte\n",
    "    \"sw_support_license\": {\n",
    "        \"support_level\": None,          # base/enterprise/24x7 etc\n",
    "        \"sla_hrs\": None,                # 8x5/24x7\n",
    "        \"on_site\": None,                # True/False/None\n",
    "        \"term_months\": None\n",
    "    }\n",
    "}\n",
    "\n",
    "# =================== HELPERS ===================\n",
    "def _find_col(df: pd.DataFrame, *candidates) -> str | None:\n",
    "    cols = {str(c).strip().lower(): c for c in df.columns}\n",
    "    for want in candidates:\n",
    "        for k, orig in cols.items():\n",
    "            if want in k:\n",
    "                return orig\n",
    "    return None\n",
    "\n",
    "def _slugify(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"_\", str(s).strip().lower()).strip(\"_\") or \"uncategorized\"\n",
    "\n",
    "def _norm_price(x) -> float:\n",
    "    if pd.isna(x): return 0.0\n",
    "    s = str(x)\n",
    "    s = re.sub(r\"[^\\d,\\.]\", \"\", s)\n",
    "    if s.count(\",\") == 1 and s.count(\".\") >= 1 and s.rfind(\",\") > s.rfind(\".\"):\n",
    "        s = s.replace(\".\", \"\").replace(\",\", \".\")\n",
    "    elif s.count(\",\") == 1 and s.count(\".\") == 0:\n",
    "        s = s.replace(\",\", \".\")\n",
    "    try:\n",
    "        return float(s)\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def _canon_category(raw: str, typ: str) -> str:\n",
    "    base = str(raw or \"\").strip().lower()\n",
    "    mapping = CANON_HW if typ == \"hardware\" else CANON_SW\n",
    "    for k in mapping:\n",
    "        if k in base:\n",
    "            return mapping[k]\n",
    "    return _slugify(base)\n",
    "\n",
    "def _hardware_record(sku: str, name: str, cat_slug: str, price: float, elig: float) -> Dict:\n",
    "    rec = {\n",
    "        \"cisco_product_id\": sku,\n",
    "        \"commercial_name\": name,\n",
    "        \"product_type\": \"hardware\",\n",
    "        \"lifecycle\": {\"status\": \"unknown\"},\n",
    "        \"technical_profile\": {\n",
    "            \"hardware_attributes\": {}\n",
    "        },\n",
    "        \"pricing_model\": {\n",
    "            \"type\": \"one_time\",\n",
    "            \"currency\": \"USD\",\n",
    "            \"base_price\": price,\n",
    "            \"elig_pct\": float(elig)\n",
    "        }\n",
    "    }\n",
    "    attrs = HW_ATTR_BLUEPRINT.get(cat_slug)\n",
    "    if attrs:\n",
    "        rec[\"technical_profile\"][\"hardware_attributes\"].update(attrs)\n",
    "    return rec\n",
    "\n",
    "def _software_record(sku: str, name: str, cat_slug: str, price: float, elig: float) -> Dict:\n",
    "    # subs vs suporte\n",
    "    if cat_slug == \"sw_support_license\":\n",
    "        profile = {\n",
    "            \"support_level\": None,\n",
    "            \"sla_hrs\": None,\n",
    "            \"on_site\": None,\n",
    "            \"term_months\": None\n",
    "        }\n",
    "        pricing = {\n",
    "            \"type\": \"term_subscription\",\n",
    "            \"currency\": \"USD\",\n",
    "            \"base_price\": price,\n",
    "            \"elig_pct\": float(elig)\n",
    "        }\n",
    "        rec = {\n",
    "            \"cisco_product_id\": sku,\n",
    "            \"commercial_name\": name,\n",
    "            \"product_type\": \"software\",\n",
    "            \"software_profile\": profile,\n",
    "            \"pricing_model\": pricing\n",
    "        }\n",
    "    else:\n",
    "        profile = {\n",
    "            \"edition\": None,\n",
    "            \"license_type\": \"subscription\",\n",
    "            \"term_months\": 12,\n",
    "            \"features\": [],\n",
    "            \"bundles\": [],\n",
    "            \"per_device_or_site\": None\n",
    "        }\n",
    "        # merge com blueprint\n",
    "        bp = SW_ATTR_BLUEPRINT.get(cat_slug)\n",
    "        if bp:\n",
    "            for k, v in bp.items():\n",
    "                profile.setdefault(k, v)\n",
    "        rec = {\n",
    "            \"cisco_product_id\": sku,\n",
    "            \"commercial_name\": name,\n",
    "            \"product_type\": \"software\",\n",
    "            \"software_profile\": profile,\n",
    "            \"pricing_model\": {\n",
    "                \"type\": \"term_subscription\",\n",
    "                \"currency\": \"USD\",\n",
    "                \"base_price\": price,\n",
    "                \"elig_pct\": float(elig)\n",
    "            }\n",
    "        }\n",
    "    return rec\n",
    "\n",
    "def _load_existing(path: Path) -> List[Dict]:\n",
    "    if path.exists():\n",
    "        try:\n",
    "            return json.loads(path.read_text(encoding=\"utf-8\"))\n",
    "        except Exception:\n",
    "            return []\n",
    "    return []\n",
    "\n",
    "def _index_by_sku(items: List[Dict]) -> Dict[str, Dict]:\n",
    "    out = {}\n",
    "    for it in items:\n",
    "        sku = str(it.get(\"cisco_product_id\") or \"\").strip()\n",
    "        if sku:\n",
    "            out[sku] = it\n",
    "    return out\n",
    "\n",
    "# =================== LLM ENRICHMENT ===================\n",
    "def _llm_client():\n",
    "    if not _openai_available:\n",
    "        raise RuntimeError(\"Pacote 'openai' não encontrado. Instale com: pip install openai\")\n",
    "    key = OPENAI_API_KEY or os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not key:\n",
    "        raise RuntimeError(\"OPENAI_API_KEY não definido.\")\n",
    "    client = OpenAI(api_key=key)\n",
    "    return client\n",
    "\n",
    "def _llm_prompt_for_enrichment(product: Dict, product_type: str, cat_slug: str) -> str:\n",
    "    # Seleciona quais campos podem ser preenchidos\n",
    "    if product_type == \"hardware\":\n",
    "        allowed = list((HW_ATTR_BLUEPRINT.get(cat_slug) or {}).keys())\n",
    "        path = \"technical_profile.hardware_attributes\"\n",
    "    else:\n",
    "        if cat_slug == \"sw_support_license\":\n",
    "            allowed = list(SW_ATTR_BLUEPRINT[\"sw_support_license\"].keys())\n",
    "            path = \"software_profile\"\n",
    "        else:\n",
    "            allowed = list((SW_ATTR_BLUEPRINT.get(cat_slug) or {}).keys())\n",
    "            # software funcional tem software_profile como raiz\n",
    "            path = \"software_profile\"\n",
    "\n",
    "    skeleton = {\n",
    "        \"fill_path\": path,\n",
    "        \"allowed_fields\": allowed,\n",
    "        \"only_fill_nulls\": True,\n",
    "        \"return_unknown_as_null\": True\n",
    "    }\n",
    "\n",
    "    name = product.get(\"commercial_name\", \"\")\n",
    "    sku  = product.get(\"cisco_product_id\", \"\")\n",
    "    return (\n",
    "        \"You are a data normalizer for Cisco product catalog.\\n\"\n",
    "        \"STRICT RULES:\\n\"\n",
    "        \" - Fill ONLY the fields listed in 'allowed_fields' below.\\n\"\n",
    "        \" - Fill ONLY when you are reasonably certain from the product name/SKU semantics.\\n\"\n",
    "        \" - If unsure, set the value to null (do NOT guess).\\n\"\n",
    "        \" - Return a single valid JSON object with only the keys to update (no prose).\\n\\n\"\n",
    "        f\"PRODUCT_NAME: {name}\\n\"\n",
    "        f\"SKU: {sku}\\n\\n\"\n",
    "        f\"FILL_INSTRUCTIONS_JSON:\\n{json.dumps(skeleton, indent=2)}\\n\"\n",
    "        \"Output JSON example:\\n\"\n",
    "        \"{ \\\"<field1>\\\": <value or null>, \\\"<field2>\\\": <value or null> }\\n\"\n",
    "    )\n",
    "\n",
    "def enrich_product_with_llm(product: Dict, product_type: str, cat_slug: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Chama a LLM para preencher APENAS os campos null do blueprint da categoria.\n",
    "    Retorna um dicionário com as chaves atualizadas (ou {} se nada a fazer).\n",
    "    \"\"\"\n",
    "    # Detecta se há algo para preencher\n",
    "    if product_type == \"hardware\":\n",
    "        path = (\"technical_profile\", \"hardware_attributes\")\n",
    "        bp   = HW_ATTR_BLUEPRINT.get(cat_slug) or {}\n",
    "    else:\n",
    "        if cat_slug == \"sw_support_license\":\n",
    "            path = (\"software_profile\",)\n",
    "            bp   = SW_ATTR_BLUEPRINT[\"sw_support_license\"]\n",
    "        else:\n",
    "            path = (\"software_profile\",)\n",
    "            bp   = SW_ATTR_BLUEPRINT.get(cat_slug) or {}\n",
    "\n",
    "    # verifica nulls\n",
    "    node = product\n",
    "    for p in path:\n",
    "        node = node.get(p, {})\n",
    "    needs = False\n",
    "    for k in bp.keys():\n",
    "        if node.get(k, None) in (None, [], \"\"):\n",
    "            needs = True\n",
    "            break\n",
    "    if not needs:\n",
    "        return {}\n",
    "\n",
    "    client = _llm_client()\n",
    "    prompt = _llm_prompt_for_enrichment(product, product_type, cat_slug)\n",
    "\n",
    "    try:\n",
    "        resp = client.chat.completions.create(\n",
    "            model=OPENAI_MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a strict JSON filler that never hallucinates.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            temperature=0.0,\n",
    "        )\n",
    "        raw = resp.choices[0].message.content.strip()\n",
    "        data = json.loads(raw)\n",
    "        # filtra apenas campos permitidos\n",
    "        allowed = set((HW_ATTR_BLUEPRINT if product_type==\"hardware\" else SW_ATTR_BLUEPRINT.get(cat_slug, {})).keys()) \\\n",
    "                  if product_type==\"hardware\" else \\\n",
    "                  (set(SW_ATTR_BLUEPRINT[\"sw_support_license\"].keys()) if cat_slug==\"sw_support_license\"\n",
    "                   else set(SW_ATTR_BLUEPRINT.get(cat_slug, {}).keys()))\n",
    "        cleaned = {k: v for k, v in data.items() if k in allowed}\n",
    "        # aplica no produto\n",
    "        target = product\n",
    "        for p in path:\n",
    "            if p not in target:\n",
    "                target[p] = {}\n",
    "            target = target[p]\n",
    "        for k, v in cleaned.items():\n",
    "            if target.get(k) in (None, [], \"\"):\n",
    "                target[k] = v\n",
    "        return cleaned\n",
    "    except Exception as e:\n",
    "        # Falha de parsing ou de chamada -> não enriquece\n",
    "        # Você pode logar se quiser\n",
    "        return {}\n",
    "\n",
    "# =================== PIPELINE ===================\n",
    "def normalize_and_export_by_category(xlsx_path: str, out_dir: Path):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    df = pd.read_excel(xlsx_path, engine=\"openpyxl\")\n",
    "\n",
    "    # Detecta colunas\n",
    "    col_type = _find_col(df, \"category-type\", \"category type\", \"type\")\n",
    "    col_cat  = _find_col(df, \"category\")\n",
    "    col_sku  = _find_col(df, \"sku\", \"part\", \"part number\")\n",
    "    col_desc = _find_col(df, \"desc\", \"description\", \"name\")\n",
    "    col_pri  = _find_col(df, \"pri\", \"price\", \"list price\")\n",
    "    col_elig = _find_col(df, \"elig\", \"eligibility\", \"elig_%\", \"eligibility %\")\n",
    "\n",
    "    print(\"→ Columns detected:\", {\n",
    "        \"type\": col_type, \"category\": col_cat, \"sku\": col_sku, \"desc\": col_desc, \"price\": col_pri, \"elig\": col_elig\n",
    "    })\n",
    "    if not all([col_type, col_cat, col_sku, col_desc, col_pri, col_elig]):\n",
    "        raise ValueError(\"Não encontrei todas as colunas necessárias. Confira os nomes no Excel.\")\n",
    "\n",
    "    # Normaliza campos base\n",
    "    df[\"_type\"] = df[col_type].astype(str).str.strip().str.lower()\n",
    "    df[\"_cat\"]  = df[col_cat].astype(str).str.strip()\n",
    "    df[\"_sku\"]  = df[col_sku].astype(str).str.strip()\n",
    "    df[\"_desc\"] = df[col_desc].astype(str).str.strip()\n",
    "    df[\"_pri\"]  = df[col_pri].apply(_norm_price)\n",
    "    df[\"_elig\"] = (\n",
    "        df[col_elig].astype(str).str.strip().str.replace(\"%\",\"\", regex=False)\n",
    "        .str.replace(\",\", \".\", regex=False)\n",
    "    )\n",
    "    df[\"_elig\"] = pd.to_numeric(df[\"_elig\"], errors=\"coerce\").fillna(0.0) / 100.0\n",
    "\n",
    "    print(\"→ Type counts:\", df[\"_type\"].value_counts().to_dict())\n",
    "    print(\"→ Sample categories:\", df[\"_cat\"].str.lower().value_counts().head(15).to_dict())\n",
    "\n",
    "    # Buckets por categoria\n",
    "    buckets_hw: Dict[str, List[Dict]] = {}\n",
    "    buckets_sw: Dict[str, List[Dict]] = {}\n",
    "\n",
    "    # Separa\n",
    "    hw_rows = df[df[\"_type\"].str.contains(\"hard\", na=False)]\n",
    "    sw_rows = df[df[\"_type\"].str.contains(\"soft\", na=False)]\n",
    "\n",
    "    # Monta registros iniciais\n",
    "    for _, r in hw_rows.iterrows():\n",
    "        sku, name = r[\"_sku\"], r[\"_desc\"]\n",
    "        cat_slug = _canon_category(r[\"_cat\"], \"hardware\")\n",
    "        rec = _hardware_record(sku, name, cat_slug, float(r[\"_pri\"]), float(r[\"_elig\"]))\n",
    "        buckets_hw.setdefault(cat_slug, []).append(rec)\n",
    "\n",
    "    for _, r in sw_rows.iterrows():\n",
    "        sku, name = r[\"_sku\"], r[\"_desc\"]\n",
    "        cat_slug = _canon_category(r[\"_cat\"], \"software\")\n",
    "        rec = _software_record(sku, name, cat_slug, float(r[\"_pri\"]), float(r[\"_elig\"]))\n",
    "        buckets_sw.setdefault(cat_slug, []).append(rec)\n",
    "\n",
    "    # Salva por categoria (merge com existentes + enriquecimento)\n",
    "    hw_dir = out_dir / \"hardware\"\n",
    "    sw_dir = out_dir / \"software\"\n",
    "    hw_dir.mkdir(parents=True, exist_ok=True)\n",
    "    sw_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    files_written = 0\n",
    "\n",
    "    # ---------- HARDWARE ----------\n",
    "    for cat, items in buckets_hw.items():\n",
    "        path = hw_dir / f\"hw_{cat}.json\"\n",
    "        existing = _load_existing(path)\n",
    "        index    = _index_by_sku(existing)\n",
    "\n",
    "        # Merge + enrich\n",
    "        to_save: List[Dict] = existing[:]  # start with existing\n",
    "        seen = set(s.get(\"cisco_product_id\") for s in existing)\n",
    "\n",
    "        for prod in tqdm(items, desc=f\"[HW] {cat}\", unit=\"sku\"):\n",
    "            sku = prod[\"cisco_product_id\"]\n",
    "            if sku in seen and not REFRESH_ENRICHMENT:\n",
    "                # já existe → mantém\n",
    "                continue\n",
    "\n",
    "            # Se já existia e vamos refresh, substitui\n",
    "            if sku in index and REFRESH_ENRICHMENT:\n",
    "                # mantém campos já preenchidos\n",
    "                merged = index[sku]\n",
    "                # sobrepõe preço/desc se mudou\n",
    "                merged[\"commercial_name\"] = prod[\"commercial_name\"]\n",
    "                merged[\"pricing_model\"][\"base_price\"] = prod[\"pricing_model\"][\"base_price\"]\n",
    "                merged[\"pricing_model\"][\"elig_pct\"]   = prod[\"pricing_model\"][\"elig_pct\"]\n",
    "                prod = merged\n",
    "\n",
    "            if ENRICH_WITH_LLM:\n",
    "                # preenche somente os campos null do blueprint\n",
    "                _ = enrich_product_with_llm(prod, \"hardware\", cat)\n",
    "                time.sleep(RATE_LIMIT_SLEEP)\n",
    "\n",
    "            # se já existia, update lista; se não, append\n",
    "            if sku in index:\n",
    "                # atualiza no array existente\n",
    "                for i, old in enumerate(to_save):\n",
    "                    if old.get(\"cisco_product_id\") == sku:\n",
    "                        to_save[i] = prod\n",
    "                        break\n",
    "            else:\n",
    "                to_save.append(prod)\n",
    "                index[sku] = prod\n",
    "                seen.add(sku)\n",
    "\n",
    "        path.write_text(json.dumps(to_save, indent=2), encoding=\"utf-8\")\n",
    "        files_written += 1\n",
    "\n",
    "    # ---------- SOFTWARE ----------\n",
    "    for cat, items in buckets_sw.items():\n",
    "        path = sw_dir / f\"sw_{cat}.json\"\n",
    "        existing = _load_existing(path)\n",
    "        index    = _index_by_sku(existing)\n",
    "\n",
    "        to_save: List[Dict] = existing[:]\n",
    "        seen = set(s.get(\"cisco_product_id\") for s in existing)\n",
    "\n",
    "        for prod in tqdm(items, desc=f\"[SW] {cat}\", unit=\"sku\"):\n",
    "            sku = prod[\"cisco_product_id\"]\n",
    "            if sku in seen and not REFRESH_ENRICHMENT:\n",
    "                continue\n",
    "\n",
    "            if sku in index and REFRESH_ENRICHMENT:\n",
    "                merged = index[sku]\n",
    "                merged[\"commercial_name\"] = prod[\"commercial_name\"]\n",
    "                merged[\"pricing_model\"][\"base_price\"] = prod[\"pricing_model\"][\"base_price\"]\n",
    "                merged[\"pricing_model\"][\"elig_pct\"]   = prod[\"pricing_model\"][\"elig_pct\"]\n",
    "                prod = merged\n",
    "\n",
    "            if ENRICH_WITH_LLM:\n",
    "                _ = enrich_product_with_llm(prod, \"software\", cat)\n",
    "                time.sleep(RATE_LIMIT_SLEEP)\n",
    "\n",
    "            if sku in index:\n",
    "                for i, old in enumerate(to_save):\n",
    "                    if old.get(\"cisco_product_id\") == sku:\n",
    "                        to_save[i] = prod\n",
    "                        break\n",
    "            else:\n",
    "                to_save.append(prod)\n",
    "                index[sku] = prod\n",
    "                seen.add(sku)\n",
    "\n",
    "        path.write_text(json.dumps(to_save, indent=2), encoding=\"utf-8\")\n",
    "        files_written += 1\n",
    "\n",
    "    print(\"✅ Done:\", {\n",
    "        \"hardware\": sum(len(json.loads((hw_dir/f).read_text(encoding='utf-8'))) for f in os.listdir(hw_dir) if f.endswith(\".json\")),\n",
    "        \"software\": sum(len(json.loads((sw_dir/f).read_text(encoding='utf-8'))) for f in os.listdir(sw_dir) if f.endswith(\".json\")),\n",
    "        \"files\": files_written,\n",
    "        \"out\": str(out_dir)\n",
    "    })\n",
    "\n",
    "# %%\n",
    "normalize_and_export_by_category(XLSX_PATH, OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420dd203-7d45-458d-8d3a-b1fb4d765413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5cc3b1-1709-4d25-a2c0-e865b39568d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd28f739-6701-4b91-840d-fc51e20b40bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# NORMALIZAÇÃO E ENRIQUECIMENTO POR CATEGORIA (NOTEBOOK-ONLY)\n",
    "# ============================================================\n",
    "\n",
    "import os, re, json, time, math\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- LLM (LangChain OpenAI) ---\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# =================== CONFIG ===================\n",
    "\n",
    "# Caminhos\n",
    "XLSX_PATH = \"data/raw/Cisco_Pricing.xlsx\"\n",
    "OUT_DIR   = Path(\"data/normalized\")\n",
    "\n",
    "# Execução\n",
    "ENRICH_WITH_LLM      = True   # habilita enriquecimento por IA SKU-a-SKU\n",
    "REFRESH_ENRICHMENT   = True   # se já existe no JSON, re-enriquece e mescla\n",
    "RATE_LIMIT_SLEEP     = 0.6    # sleep entre chamadas LLM (ajuste se precisar)\n",
    "\n",
    "# Modo rápido para teste\n",
    "SAMPLE_MODE          = True    # liga modo amostra\n",
    "SAMPLE_PER_CATEGORY  = 5       # nº de SKUs por categoria\n",
    "MAX_TOTAL_SKUS       = 40      # hard stop global (HW+SW)\n",
    "MAX_LLM_CALLS        = 25      # máx. de chamadas LLM no modo rápido\n",
    "\n",
    "# Filtros opcionais: processe só algumas categorias\n",
    "INCLUDE_ONLY_CATS_HW = None    # ex.: [\"switches\", \"access_points\"]\n",
    "INCLUDE_ONLY_CATS_SW = None    # ex.: [\"sw_support_license\", \"sw_wireless\"]\n",
    "\n",
    "# OpenAI\n",
    "OPENAI_MODEL = \"gpt-4o-mini\"\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")  # defina no ambiente\n",
    "if not OPENAI_API_KEY and ENRICH_WITH_LLM:\n",
    "    raise RuntimeError(\"Defina OPENAI_API_KEY no ambiente antes de rodar.\")\n",
    "\n",
    "# =================== HELPER: DETECÇÃO DE COLUNAS ===================\n",
    "\n",
    "def _find_col(df: pd.DataFrame, *cands) -> Optional[str]:\n",
    "    cols = [str(c).strip().lower() for c in df.columns]\n",
    "    for cand in cands:\n",
    "        for i, c in enumerate(cols):\n",
    "            if cand in c:\n",
    "                return df.columns[i]\n",
    "    return None\n",
    "\n",
    "def _norm_price(x) -> float:\n",
    "    s = str(x)\n",
    "    s = re.sub(r\"[^\\d,\\.]\", \"\", s)\n",
    "    # remove separador de milhar (.) quando há vírgula decimal\n",
    "    s = re.sub(r\"\\.(?=\\d{3},)\", \"\", s)\n",
    "    s = s.replace(\",\", \".\")\n",
    "    try:\n",
    "        return float(s)\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "# =================== CATEGORIAS & ESQUEMAS ===================\n",
    "\n",
    "# Mapeamento para slugs canônicos (hardware)\n",
    "def _canon_category_hw(raw: str) -> str:\n",
    "    s = raw.strip().lower()\n",
    "    # heurísticas por palavra-chave\n",
    "    if re.search(r\"\\b(ap|access\\s*point|wireless)\\b\", s):\n",
    "        return \"access_points\"\n",
    "    if \"switch\" in s:\n",
    "        return \"switches\"\n",
    "    if \"router\" in s or \"isr\" in s or \"asr\" in s:\n",
    "        return \"routers\"\n",
    "    if \"firewall\" in s or \"asa\" in s or re.search(r\"\\bftd\\b\", s):\n",
    "        return \"firewalls\"\n",
    "    if \"controller\" in s or \"wlc\" in s:\n",
    "        return \"controllers\"\n",
    "    if \"sd-wan\" in s or \"sdwan\" in s or \"vmanage\" in s:\n",
    "        return \"sdwan\"\n",
    "    if \"sfp\" in s or \"qsfp\" in s or \"transceiver\" in s or \"optic\" in s:\n",
    "        return \"optics_transceivers\"\n",
    "    if \"camera\" in s or \"iot\" in s:\n",
    "        return \"cameras_iot\"\n",
    "    if \"psu\" in s or \"power supply\" in s or \"ups\" in s:\n",
    "        return \"power_psu_ups\"\n",
    "    if \"module\" in s or \"line card\" in s or \"linecard\" in s:\n",
    "        return \"modules_linecards\"\n",
    "    if \"ucs\" in s or \"server\" in s:\n",
    "        return \"servers\"\n",
    "    if \"storage\" in s:\n",
    "        return \"storage\"\n",
    "    if \"phone\" in s or \"telepresence\" in s or \"collaboration\" in s:\n",
    "        return \"collab_endpoints\"\n",
    "    # fallback: tenta derivar de nomes comuns (Meraki MS* => switches, MR* => AP)\n",
    "    if re.match(r\"^ms\\d\", s):  # Meraki Switch\n",
    "        return \"switches\"\n",
    "    if re.match(r\"^mr\\d\", s):  # Meraki AP\n",
    "        return \"access_points\"\n",
    "    if re.match(r\"^mx\\d\", s):  # Meraki Security/SD-WAN\n",
    "        return \"firewalls\"\n",
    "    return \"other_hw\"\n",
    "\n",
    "# Mapeamento para slugs canônicos (software)\n",
    "def _canon_category_sw(raw: str, sku: str, desc: str) -> str:\n",
    "    s = raw.strip().lower()\n",
    "    sd = f\"{sku} {desc}\".lower()\n",
    "    if \"license\" in s or \"support\" in s or \"entitlement\" in s:\n",
    "        return \"sw_support_license\"\n",
    "    if \"firewall\" in s or \"asa\" in s or \"firepower\" in s:\n",
    "        return \"sw_firewall\"\n",
    "    if \"security\" in s or \"securex\" in s or \"duo\" in s or \"umbrella\" in s:\n",
    "        return \"sw_security\"\n",
    "    if \"wireless\" in s or \"wlc\" in s or \"meraki\" in s:\n",
    "        # Meraki LIC- por padrão licenciamento/gestão\n",
    "        if \"lic-\" in sd:\n",
    "            return \"sw_support_license\"\n",
    "        return \"sw_wireless\"\n",
    "    if \"sdwan\" in s or \"sd-wan\" in s:\n",
    "        return \"sw_routing_sdwan\"\n",
    "    if \"collab\" in s or \"webex\" in s:\n",
    "        return \"sw_collaboration\"\n",
    "    if \"datacenter\" in s or \"intersight\" in s or \"ucs\" in s:\n",
    "        return \"sw_datacenter\"\n",
    "    if \"observability\" in s or \"appdynamics\" in s or \"thousandeyes\" in s:\n",
    "        return \"sw_observability\"\n",
    "    # fallback por heurística de SKU\n",
    "    if sku.upper().startswith(\"LIC-\"):\n",
    "        return \"sw_support_license\"\n",
    "    return \"sw_other\"\n",
    "\n",
    "# Campos por categoria (hardware)\n",
    "HARDWARE_ATTR_FIELDS: Dict[str, List[str]] = {\n",
    "    \"switches\": [\"port_count\",\"uplinks\",\"poe_budget_watts\",\"stacking\",\"layer\",\"throughput_gbps\",\"mounting\",\"redundancy\"],\n",
    "    \"access_points\": [\"wifi_standard\",\"throughput\",\"antenna\",\"indoor_outdoor\",\"mimo\",\"poe_class\",\"mesh_support\"],\n",
    "    \"routers\": [\"wan_ports\",\"lan_ports\",\"throughput_gbps\",\"vpn_throughput\",\"sdwan_ready\",\"redundant_psu\"],\n",
    "    \"firewalls\": [\"throughput_gbps\",\"ngfw\",\"ips\",\"vpn_peers\",\"ports\",\"ha_support\"],\n",
    "    \"controllers\": [\"ap_count_supported\",\"redundancy\",\"throughput_gbps\",\"model\"],\n",
    "    \"sdwan\": [\"role\",\"controllers\",\"overlay_type\",\"max_tunnels\",\"throughput_gbps\"],\n",
    "    \"optics_transceivers\": [\"form_factor\",\"speed_gbps\",\"wavelength_nm\",\"reach_m\",\"connector\"],\n",
    "    \"cameras_iot\": [\"resolution\",\"lens\",\"indoor_outdoor\",\"ir\",\"storage\"],\n",
    "    \"power_psu_ups\": [\"wattage\",\"input_voltage\",\"output_voltage\",\"form_factor\"],\n",
    "    \"modules_linecards\": [\"slot_type\",\"ports\",\"speed_gbps\",\"poe_support\"],\n",
    "    \"servers\": [\"cpu\",\"memory_gb\",\"storage\",\"form_factor\",\"nic\"],\n",
    "    \"storage\": [\"capacity_tb\",\"form_factor\",\"protocol\"],\n",
    "    \"collab_endpoints\": [\"type\",\"display\",\"codec\",\"microphones\"],\n",
    "    \"other_hw\": [\"notes\"]\n",
    "}\n",
    "\n",
    "# Campos por categoria (software)\n",
    "SOFTWARE_ATTR_FIELDS: Dict[str, List[str]] = {\n",
    "    \"sw_support_license\": [\"term\",\"edition\",\"device_type\",\"cloud_managed\",\"support_level\"],\n",
    "    \"sw_firewall\": [\"feature_set\",\"ips\",\"vpn\",\"firepower_version\",\"deployment_model\"],\n",
    "    \"sw_security\": [\"feature_set\",\"integrations\",\"cloud\",\"on_prem\"],\n",
    "    \"sw_wireless\": [\"controller_type\",\"ap_count\",\"ai_rf\",\"guest_access\"],\n",
    "    \"sw_routing_sdwan\": [\"feature_set\",\"controllers\",\"overlay\",\"cloud_gateway\"],\n",
    "    \"sw_collaboration\": [\"workloads\",\"capacity\",\"recording\",\"compliance\"],\n",
    "    \"sw_datacenter\": [\"hypervisor\",\"automation\",\"integrations\"],\n",
    "    \"sw_observability\": [\"sources\",\"metrics\",\"distributed_tracing\",\"synthetics\"],\n",
    "    \"sw_other\": [\"notes\"]\n",
    "}\n",
    "\n",
    "# =================== RECORD BUILDERS ===================\n",
    "\n",
    "def _hardware_record(sku: str, name: str, cat_slug: str, price: float, elig: float) -> Dict:\n",
    "    # cria dict com todos os campos base + atributos por categoria\n",
    "    attrs = {k: None for k in HARDWARE_ATTR_FIELDS.get(cat_slug, HARDWARE_ATTR_FIELDS[\"other_hw\"])}\n",
    "    return {\n",
    "        \"cisco_product_id\": sku,\n",
    "        \"commercial_name\": name,\n",
    "        \"product_type\": \"hardware\",\n",
    "        \"lifecycle\": {\"status\": \"unknown\", \"eos_announced\": None, \"last_support_date\": None},\n",
    "        \"technical_profile\": {\n",
    "            \"category\": cat_slug,\n",
    "            \"subcategory\": None,\n",
    "            \"hardware_attributes\": attrs\n",
    "        },\n",
    "        \"pricing_model\": {\n",
    "            \"type\": \"one_time\",\n",
    "            \"currency\": \"USD\",\n",
    "            \"base_price\": float(price),\n",
    "            \"elig_pct\": float(elig),\n",
    "            \"pricing_tiers\": []\n",
    "        },\n",
    "        \"dependencies\": {\"required_components\": [], \"compatible_with\": []},\n",
    "        \"regulatory\": {\"certifications\": []}\n",
    "    }\n",
    "\n",
    "def _software_record(sku: str, name: str, cat_slug: str, price: float, elig: float) -> Dict:\n",
    "    attrs = {k: None for k in SOFTWARE_ATTR_FIELDS.get(cat_slug, SOFTWARE_ATTR_FIELDS[\"sw_other\"])}\n",
    "    return {\n",
    "        \"cisco_product_id\": sku,\n",
    "        \"commercial_name\": name,\n",
    "        \"product_type\": \"software\",\n",
    "        \"lifecycle\": {\"status\": \"unknown\", \"eos_announced\": None, \"last_support_date\": None},\n",
    "        \"technical_profile\": {\n",
    "            \"category\": cat_slug,\n",
    "            \"subcategory\": None,\n",
    "            \"software_attributes\": attrs\n",
    "        },\n",
    "        \"pricing_model\": {\n",
    "            \"type\": \"one_time\",\n",
    "            \"currency\": \"USD\",\n",
    "            \"base_price\": float(price),\n",
    "            \"elig_pct\": float(elig),\n",
    "            \"pricing_tiers\": []\n",
    "        },\n",
    "        \"license\": {\n",
    "            \"term_months\": None,\n",
    "            \"seats_included\": None,\n",
    "            \"metering\": None,\n",
    "            \"sku_family\": None\n",
    "        },\n",
    "        \"compatibility\": {\n",
    "            \"requires_hardware\": [],\n",
    "            \"compatible_platforms\": [],\n",
    "            \"min_versions\": {}\n",
    "        }\n",
    "    }\n",
    "\n",
    "# =================== IO HELPERS ===================\n",
    "\n",
    "def _load_existing(path: Path) -> List[Dict]:\n",
    "    if path.exists():\n",
    "        try:\n",
    "            return json.loads(path.read_text(encoding=\"utf-8\"))\n",
    "        except Exception:\n",
    "            return []\n",
    "    return []\n",
    "\n",
    "def _index_by_sku(items: List[Dict]) -> Dict[str, Dict]:\n",
    "    idx = {}\n",
    "    for it in items:\n",
    "        sku = it.get(\"cisco_product_id\")\n",
    "        if sku:\n",
    "            idx[sku] = it\n",
    "    return idx\n",
    "\n",
    "# =================== ENRIQUECIMENTO VIA LLM ===================\n",
    "\n",
    "_llm = ChatOpenAI(model=OPENAI_MODEL, temperature=0.2) if ENRICH_WITH_LLM else None\n",
    "\n",
    "def enrich_product_with_llm(prod: Dict, ptype: str, cat_slug: str) -> Dict:\n",
    "    \"\"\"Preenche apenas os atributos da categoria. Desconhecido => null. Sem inventar.\"\"\"\n",
    "    if not ENRICH_WITH_LLM:\n",
    "        return prod\n",
    "\n",
    "    if ptype == \"hardware\":\n",
    "        keys = HARDWARE_ATTR_FIELDS.get(cat_slug, HARDWARE_ATTR_FIELDS[\"other_hw\"])\n",
    "        path = [\"technical_profile\", \"hardware_attributes\"]\n",
    "    else:\n",
    "        keys = SOFTWARE_ATTR_FIELDS.get(cat_slug, SOFTWARE_ATTR_FIELDS[\"sw_other\"])\n",
    "        path = [\"technical_profile\", \"software_attributes\"]\n",
    "\n",
    "    # Prompt: pedimos SÓ o dicionário de atributos, mais nada.\n",
    "    sys_msg = (\n",
    "        \"You are a careful data normalizer. \"\n",
    "        \"From the product name (and optional description), \"\n",
    "        \"infer ONLY the requested attributes for the category. \"\n",
    "        \"If unknown, return null. Respond strictly as a minified JSON object with those keys only.\"\n",
    "    )\n",
    "    user_msg = f\"\"\"\n",
    "Product:\n",
    "- SKU: {prod.get('cisco_product_id')}\n",
    "- Name: {prod.get('commercial_name')}\n",
    "- Category: {cat_slug}\n",
    "- Type: {ptype}\n",
    "\n",
    "Return JSON with keys exactly: {keys}\n",
    "If an attribute is unknown, set it to null.\n",
    "Numbers should be numeric (e.g., 740 not \"740\"), booleans true/false.\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        resp = _llm.invoke([{\"role\":\"system\",\"content\":sys_msg},\n",
    "                            {\"role\":\"user\",\"content\":user_msg}])\n",
    "        txt = resp.content.strip()\n",
    "        # Sanitiza: tenta isolar JSON\n",
    "        m = re.search(r\"\\{.*\\}\", txt, flags=re.S)\n",
    "        if m:\n",
    "            txt = m.group(0)\n",
    "        data = json.loads(txt)\n",
    "        # Merge no produto\n",
    "        target = prod\n",
    "        for key in path:\n",
    "            target = target[key]\n",
    "        # só sobrepõe chaves declaradas\n",
    "        for k in keys:\n",
    "            if k in data:\n",
    "                target[k] = data[k]\n",
    "    except Exception as e:\n",
    "        # Falha no enriquecimento: segue com o registro base\n",
    "        pass\n",
    "\n",
    "    return prod\n",
    "\n",
    "# =================== PIPELINE ===================\n",
    "\n",
    "def normalize_and_export_by_category(xlsx_path: str, out_dir: Path):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    df = pd.read_excel(xlsx_path, engine=\"openpyxl\")\n",
    "\n",
    "    # Detecta colunas\n",
    "    col_type = _find_col(df, \"category-type\", \"category type\", \"type\")\n",
    "    col_cat  = _find_col(df, \"category\")\n",
    "    col_sku  = _find_col(df, \"sku\", \"part\", \"part number\")\n",
    "    col_desc = _find_col(df, \"desc\", \"description\", \"name\")\n",
    "    col_pri  = _find_col(df, \"pri\", \"price\", \"list price\")\n",
    "    col_elig = _find_col(df, \"elig\", \"eligibility\", \"elig_%\", \"eligibility %\")\n",
    "\n",
    "    if not all([col_type, col_cat, col_sku, col_desc, col_pri, col_elig]):\n",
    "        raise ValueError(\"Não encontrei todas as colunas necessárias. Confira os nomes no Excel.\")\n",
    "\n",
    "    # Normaliza campos base\n",
    "    df[\"_type\"] = df[col_type].astype(str).str.strip().str.lower()\n",
    "    df[\"_cat\"]  = df[col_cat].astype(str).str.strip()\n",
    "    df[\"_sku\"]  = df[col_sku].astype(str).str.strip()\n",
    "    df[\"_desc\"] = df[col_desc].astype(str).str.strip()\n",
    "    df[\"_pri\"]  = df[col_pri].apply(_norm_price)\n",
    "    df[\"_elig\"] = (\n",
    "        df[col_elig].astype(str).str.strip().str.replace(\"%\",\"\", regex=False)\n",
    "        .str.replace(\",\", \".\", regex=False)\n",
    "    )\n",
    "    df[\"_elig\"] = pd.to_numeric(df[\"_elig\"], errors=\"coerce\").fillna(0.0) / 100.0\n",
    "\n",
    "    # Separa hardware/software\n",
    "    hw_rows = df[df[\"_type\"].str.contains(\"hard\", na=False)].copy()\n",
    "    sw_rows = df[df[\"_type\"].str.contains(\"soft\", na=False)].copy()\n",
    "\n",
    "    # Map categorias → listas\n",
    "    buckets_hw: Dict[str, List[Dict]] = {}\n",
    "    buckets_sw: Dict[str, List[Dict]] = {}\n",
    "\n",
    "    # Build candidatos hardware\n",
    "    for _, r in hw_rows.iterrows():\n",
    "        sku, name = r[\"_sku\"], r[\"_desc\"]\n",
    "        cat_slug = _canon_category_hw(r[\"_cat\"])\n",
    "        if INCLUDE_ONLY_CATS_HW and cat_slug not in INCLUDE_ONLY_CATS_HW:\n",
    "            continue\n",
    "        rec = _hardware_record(sku, name, cat_slug, float(r[\"_pri\"]), float(r[\"_elig\"]))\n",
    "        buckets_hw.setdefault(cat_slug, []).append(rec)\n",
    "\n",
    "    # Build candidatos software\n",
    "    for _, r in sw_rows.iterrows():\n",
    "        sku, name = r[\"_sku\"], r[\"_desc\"]\n",
    "        cat_slug = _canon_category_sw(r[\"_cat\"], sku, name)\n",
    "        if INCLUDE_ONLY_CATS_SW and cat_slug not in INCLUDE_ONLY_CATS_SW:\n",
    "            continue\n",
    "        rec = _software_record(sku, name, cat_slug, float(r[\"_pri\"]), float(r[\"_elig\"]))\n",
    "        buckets_sw.setdefault(cat_slug, []).append(rec)\n",
    "\n",
    "    # Amostragem por categoria\n",
    "    if SAMPLE_MODE:\n",
    "        for cat in list(buckets_hw.keys()):\n",
    "            buckets_hw[cat] = buckets_hw[cat][:SAMPLE_PER_CATEGORY]\n",
    "        for cat in list(buckets_sw.keys()):\n",
    "            buckets_sw[cat] = buckets_sw[cat][:SAMPLE_PER_CATEGORY]\n",
    "\n",
    "    # Pastas\n",
    "    hw_dir = out_dir / \"hardware\"\n",
    "    sw_dir = out_dir / \"software\"\n",
    "    hw_dir.mkdir(parents=True, exist_ok=True)\n",
    "    sw_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    files_written = 0\n",
    "    processed_skus = 0\n",
    "    llm_calls = 0\n",
    "\n",
    "    # ---------- HARDWARE ----------\n",
    "    for cat, items in buckets_hw.items():\n",
    "        if MAX_TOTAL_SKUS and processed_skus >= MAX_TOTAL_SKUS:\n",
    "            break\n",
    "        path = hw_dir / f\"hw_{cat}.json\"\n",
    "        existing = _load_existing(path)\n",
    "        index    = _index_by_sku(existing)\n",
    "\n",
    "        to_save: List[Dict] = existing[:]\n",
    "        seen = set(s.get(\"cisco_product_id\") for s in existing)\n",
    "\n",
    "        for prod in tqdm(items, desc=f\"[HW] {cat}\", unit=\"sku\"):\n",
    "            if MAX_TOTAL_SKUS and processed_skus >= MAX_TOTAL_SKUS:\n",
    "                break\n",
    "            sku = prod[\"cisco_product_id\"]\n",
    "\n",
    "            # merge/refresh\n",
    "            if sku in seen and not REFRESH_ENRICHMENT:\n",
    "                continue\n",
    "            if sku in index and REFRESH_ENRICHMENT:\n",
    "                merged = index[sku]\n",
    "                # atualiza campos base\n",
    "                merged[\"commercial_name\"] = prod[\"commercial_name\"]\n",
    "                merged[\"pricing_model\"][\"base_price\"] = prod[\"pricing_model\"][\"base_price\"]\n",
    "                merged[\"pricing_model\"][\"elig_pct\"]   = prod[\"pricing_model\"][\"elig_pct\"]\n",
    "                prod = merged\n",
    "\n",
    "            # enrich\n",
    "            if ENRICH_WITH_LLM and (not SAMPLE_MODE or llm_calls < MAX_LLM_CALLS):\n",
    "                prod = enrich_product_with_llm(prod, \"hardware\", cat)\n",
    "                llm_calls += 1\n",
    "                time.sleep(RATE_LIMIT_SLEEP)\n",
    "\n",
    "            # escreve\n",
    "            if sku in index:\n",
    "                for i, old in enumerate(to_save):\n",
    "                    if old.get(\"cisco_product_id\") == sku:\n",
    "                        to_save[i] = prod\n",
    "                        break\n",
    "            else:\n",
    "                to_save.append(prod)\n",
    "                index[sku] = prod\n",
    "                seen.add(sku)\n",
    "\n",
    "            processed_skus += 1\n",
    "\n",
    "        path.write_text(json.dumps(to_save, indent=2), encoding=\"utf-8\")\n",
    "        files_written += 1\n",
    "\n",
    "        if MAX_TOTAL_SKUS and processed_skus >= MAX_TOTAL_SKUS:\n",
    "            break\n",
    "\n",
    "    # ---------- SOFTWARE ----------\n",
    "    for cat, items in buckets_sw.items():\n",
    "        if MAX_TOTAL_SKUS and processed_skus >= MAX_TOTAL_SKUS:\n",
    "            break\n",
    "        path = sw_dir / f\"sw_{cat}.json\"\n",
    "        existing = _load_existing(path)\n",
    "        index    = _index_by_sku(existing)\n",
    "\n",
    "        to_save: List[Dict] = existing[:]\n",
    "        seen = set(s.get(\"cisco_product_id\") for s in existing)\n",
    "\n",
    "        for prod in tqdm(items, desc=f\"[SW] {cat}\", unit=\"sku\"):\n",
    "            if MAX_TOTAL_SKUS and processed_skus >= MAX_TOTAL_SKUS:\n",
    "                break\n",
    "\n",
    "            sku = prod[\"cisco_product_id\"]\n",
    "\n",
    "            if sku in seen and not REFRESH_ENRICHMENT:\n",
    "                continue\n",
    "            if sku in index and REFRESH_ENRICHMENT:\n",
    "                merged = index[sku]\n",
    "                merged[\"commercial_name\"] = prod[\"commercial_name\"]\n",
    "                merged[\"pricing_model\"][\"base_price\"] = prod[\"pricing_model\"][\"base_price\"]\n",
    "                merged[\"pricing_model\"][\"elig_pct\"]   = prod[\"pricing_model\"][\"elig_pct\"]\n",
    "                prod = merged\n",
    "\n",
    "            if ENRICH_WITH_LLM and (not SAMPLE_MODE or llm_calls < MAX_LLM_CALLS):\n",
    "                prod = enrich_product_with_llm(prod, \"software\", cat)\n",
    "                llm_calls += 1\n",
    "                time.sleep(RATE_LIMIT_SLEEP)\n",
    "\n",
    "            if sku in index:\n",
    "                for i, old in enumerate(to_save):\n",
    "                    if old.get(\"cisco_product_id\") == sku:\n",
    "                        to_save[i] = prod\n",
    "                        break\n",
    "            else:\n",
    "                to_save.append(prod)\n",
    "                index[sku] = prod\n",
    "                seen.add(sku)\n",
    "\n",
    "            processed_skus += 1\n",
    "\n",
    "        path.write_text(json.dumps(to_save, indent=2), encoding=\"utf-8\")\n",
    "        files_written += 1\n",
    "\n",
    "        if MAX_TOTAL_SKUS and processed_skus >= MAX_TOTAL_SKUS:\n",
    "            break\n",
    "\n",
    "    # resumo\n",
    "    def _count_jsons(dirp: Path):\n",
    "        n = 0\n",
    "        if not dirp.exists():\n",
    "            return 0\n",
    "        for f in os.listdir(dirp):\n",
    "            if f.endswith(\".json\"):\n",
    "                try:\n",
    "                    n += len(json.loads((dirp/f).read_text(encoding=\"utf-8\")))\n",
    "                except Exception:\n",
    "                    pass\n",
    "        return n\n",
    "\n",
    "    print(\"✅ Done (fast mode)\" if SAMPLE_MODE else \"✅ Done\", {\n",
    "        \"hardware\": _count_jsons(hw_dir),\n",
    "        \"software\": _count_jsons(sw_dir),\n",
    "        \"files\": files_written,\n",
    "        \"processed_skus\": processed_skus,\n",
    "        \"llm_calls\": llm_calls,\n",
    "        \"out\": str(out_dir)\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f99166ae-8645-43a7-ab00-6078ed25c42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HW] other_hw: 100%|██████████| 5/5 [00:10<00:00,  2.07s/sku]\n",
      "[SW] sw_other: 100%|██████████| 5/5 [00:09<00:00,  1.97s/sku]\n",
      "[SW] sw_support_license: 100%|██████████| 5/5 [00:09<00:00,  1.85s/sku]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done (fast mode) {'hardware': 10, 'software': 15, 'files': 3, 'processed_skus': 15, 'llm_calls': 15, 'out': 'data\\\\normalized'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "normalize_and_export_by_category(XLSX_PATH, OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b63057-b4fd-46df-b78b-596e5a9a73f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a90f44-90c9-4ea5-97b6-64ef380b786f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03704b57-ad3f-4209-9709-1dac60adf6a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 305\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSoftware:\u001b[39m\u001b[38;5;124m\"\u001b[39m, {k: \u001b[38;5;28mlen\u001b[39m(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m buckets_sw\u001b[38;5;241m.\u001b[39mitems()})\n\u001b[0;32m    304\u001b[0m \u001b[38;5;66;03m# --- EXECUÇÃO --------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m--> 305\u001b[0m process_excel_to_category_jsons(\n\u001b[0;32m    306\u001b[0m     XLSX_PATH,\n\u001b[0;32m    307\u001b[0m     sample_per_category\u001b[38;5;241m=\u001b[39mSAMPLE_PER_CATEGORY,\n\u001b[0;32m    308\u001b[0m     do_enrichment\u001b[38;5;241m=\u001b[39mDO_ENRICHMENT\n\u001b[0;32m    309\u001b[0m )\n",
      "Cell \u001b[1;32mIn[33], line 256\u001b[0m, in \u001b[0;36mprocess_excel_to_category_jsons\u001b[1;34m(xlsx_path, sample_per_category, do_enrichment)\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    255\u001b[0m     base \u001b[38;5;241m=\u001b[39m instantiate_from_template(template, sku, name, price, elig, subcat)\n\u001b[1;32m--> 256\u001b[0m     final \u001b[38;5;241m=\u001b[39m enrich_product_with_llm(base, template) \u001b[38;5;28;01mif\u001b[39;00m do_enrichment \u001b[38;5;28;01melse\u001b[39;00m base\n\u001b[0;32m    258\u001b[0m     buckets_hw\u001b[38;5;241m.\u001b[39msetdefault(mapped, [])\u001b[38;5;241m.\u001b[39mappend(final)\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# software\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# Escolhe categoria de software (se existir). Caso não, bucket genérico \"Software\"\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[33], line 181\u001b[0m, in \u001b[0;36menrich_product_with_llm\u001b[1;34m(product_obj, template_obj)\u001b[0m\n\u001b[0;32m    176\u001b[0m prompt \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemplate\u001b[39m\u001b[38;5;124m\"\u001b[39m: template_obj,\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproduct\u001b[39m\u001b[38;5;124m\"\u001b[39m: product_obj\n\u001b[0;32m    179\u001b[0m }\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     resp \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m    182\u001b[0m         model\u001b[38;5;241m=\u001b[39mOPENAI_MODEL,\n\u001b[0;32m    183\u001b[0m         temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[0;32m    184\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m    185\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: ENRICH_SYSTEM},\n\u001b[0;32m    186\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: json\u001b[38;5;241m.\u001b[39mdumps(prompt, ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)}\n\u001b[0;32m    187\u001b[0m         ],\n\u001b[0;32m    188\u001b[0m         response_format\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson_object\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m    189\u001b[0m     )\n\u001b[0;32m    190\u001b[0m     enriched \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(resp\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;66;03m# Se a LLM retornou só o objeto final (sem wrapper), ok.\u001b[39;00m\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;66;03m# Se ela retornou {\"product\": {...}}, trate:\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1087\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   1045\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1084\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1085\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m   1086\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m-> 1087\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m   1088\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1089\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m   1090\u001b[0m             {\n\u001b[0;32m   1091\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m   1092\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m   1093\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n\u001b[0;32m   1094\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m   1095\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m   1096\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m   1097\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m   1098\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m   1099\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[0;32m   1100\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m   1101\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m   1102\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n\u001b[0;32m   1103\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m   1104\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[0;32m   1105\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: prediction,\n\u001b[0;32m   1106\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m   1107\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_effort\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_effort,\n\u001b[0;32m   1108\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m   1109\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m   1110\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[0;32m   1111\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m   1112\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[0;32m   1113\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m   1114\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[0;32m   1115\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m   1116\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m   1117\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m   1118\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[0;32m   1119\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m   1120\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m   1121\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb_search_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: web_search_options,\n\u001b[0;32m   1122\u001b[0m             },\n\u001b[0;32m   1123\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsStreaming\n\u001b[0;32m   1124\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[0;32m   1125\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsNonStreaming,\n\u001b[0;32m   1126\u001b[0m         ),\n\u001b[0;32m   1127\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m   1128\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m   1129\u001b[0m         ),\n\u001b[0;32m   1130\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m   1131\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1132\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[0;32m   1133\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1256\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1243\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1244\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1251\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1252\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1253\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1254\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1255\u001b[0m     )\n\u001b[1;32m-> 1256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:979\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m    977\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 979\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    980\u001b[0m         request,\n\u001b[0;32m    981\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[0;32m    982\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    983\u001b[0m     )\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    985\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[0;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[0;32m    927\u001b[0m     request,\n\u001b[0;32m    928\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[0;32m    929\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    930\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m    931\u001b[0m )\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[0;32m    955\u001b[0m         request,\n\u001b[0;32m    956\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    957\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[0;32m    958\u001b[0m     )\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    989\u001b[0m     hook(request)\n\u001b[1;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1024\u001b[0m     )\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpx\\_transports\\default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    234\u001b[0m )\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    245\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mhandle_request(\n\u001b[0;32m    237\u001b[0m         pool_request\u001b[38;5;241m.\u001b[39mrequest\n\u001b[0;32m    238\u001b[0m     )\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[0;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    100\u001b[0m     (\n\u001b[0;32m    101\u001b[0m         http_version,\n\u001b[0;32m    102\u001b[0m         status,\n\u001b[0;32m    103\u001b[0m         reason_phrase,\n\u001b[0;32m    104\u001b[0m         headers,\n\u001b[0;32m    105\u001b[0m         trailing_data,\n\u001b[1;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    108\u001b[0m         http_version,\n\u001b[0;32m    109\u001b[0m         status,\n\u001b[0;32m    110\u001b[0m         reason_phrase,\n\u001b[0;32m    111\u001b[0m         headers,\n\u001b[0;32m    112\u001b[0m     )\n\u001b[0;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_event(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    219\u001b[0m     )\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_backends\\sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv(max_bytes)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ssl.py:1232\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1228\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1229\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1230\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1231\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(buflen)\n\u001b[0;32m   1233\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ssl.py:1105\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- CONFIG --------------------------------------------------------------\n",
    "import os, json, re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# OpenAI >=1.0\n",
    "from openai import OpenAI\n",
    "load_dotenv()\n",
    "\n",
    "# ARQUIVOS / PASTAS\n",
    "XLSX_PATH = Path(\"data/raw/Cisco_Pricing.xlsx\")   # ajuste se preciso\n",
    "SCHEMAS_HW_DIR = Path(\"schemas/hardware\")         # onde estão seus schemas de hardware\n",
    "SCHEMAS_SW_DIR = Path(\"schemas/software\")         # (opcional) schemas de software\n",
    "OUT_HW_DIR = Path(\"out/hardware\")\n",
    "OUT_SW_DIR = Path(\"out/software\")\n",
    "\n",
    "# TESTE RÁPIDO: limite por categoria (ex.: 5). Use None para completo.\n",
    "SAMPLE_PER_CATEGORY = 5\n",
    "\n",
    "# ENRIQUECIMENTO VIA LLM (True para enriquecer, False para só estruturar sem LLM)\n",
    "DO_ENRICHMENT = True\n",
    "OPENAI_MODEL = \"gpt-4o-mini\"   # pode trocar\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# --- HELPERS: leitura de schemas -----------------------------------------\n",
    "def load_schema_templates(dir_path: Path) -> dict:\n",
    "    \"\"\"\n",
    "    Carrega todos os .json como templates, indexando por 'category' em lowercase.\n",
    "    Exige que cada JSON tenha a chave 'category' no topo.\n",
    "    \"\"\"\n",
    "    templates = {}\n",
    "    if not dir_path.exists():\n",
    "        return templates\n",
    "    for f in dir_path.glob(\"*.json\"):\n",
    "        try:\n",
    "            data = json.loads(f.read_text(encoding=\"utf-8\"))\n",
    "            cat = (data.get(\"category\") or \"\").strip().lower()\n",
    "            if not cat:\n",
    "                print(f\"[WARN] Schema sem 'category': {f}\")\n",
    "                continue\n",
    "            templates[cat] = data\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Falha lendo schema {f}: {e}\")\n",
    "    return templates\n",
    "\n",
    "SCHEMAS_HW = load_schema_templates(SCHEMAS_HW_DIR)\n",
    "SCHEMAS_SW = load_schema_templates(SCHEMAS_SW_DIR)\n",
    "\n",
    "if not SCHEMAS_HW:\n",
    "    raise RuntimeError(\n",
    "        f\"Nenhum schema de hardware encontrado em {SCHEMAS_HW_DIR}. \"\n",
    "        \"Coloque seus arquivos schema_*.json lá.\"\n",
    "    )\n",
    "\n",
    "# --- HELPERS: detecção de colunas -----------------------------------------\n",
    "def find_col(df: pd.DataFrame, substrings) -> str | None:\n",
    "    for col in df.columns:\n",
    "        lc = str(col).strip().lower()\n",
    "        for sub in substrings:\n",
    "            if sub in lc:\n",
    "                return col\n",
    "    return None\n",
    "\n",
    "# --- HELPERS: normalização de campos do Excel -----------------------------\n",
    "def clean_price_series(series: pd.Series) -> pd.Series:\n",
    "    s = (series.astype(str)\n",
    "               .str.replace(r\"[^\\d\\.,]\", \"\", regex=True)\n",
    "               .str.replace(r\"\\.(?=\\d{3},)\", \"\", regex=True)  # 1.234,56 -> 1234,56\n",
    "               .str.replace(\",\", \".\", regex=False))\n",
    "    return pd.to_numeric(s, errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "def clean_pct_series(series: pd.Series) -> pd.Series:\n",
    "    s = (series.astype(str)\n",
    "               .str.replace(r\"[^\\d\\.,]\", \"\", regex=True)\n",
    "               .str.replace(\",\", \".\", regex=False))\n",
    "    return pd.to_numeric(s, errors=\"coerce\").fillna(0.0) / 100.0\n",
    "\n",
    "# --- CLASSIFICAÇÃO: hardware vs software & mapeamento de categoria --------\n",
    "SOFT_HINTS = re.compile(r\"\\b(lic|license|subscription|entitlement|support|software|dna|meraki lic)\\b\", re.I)\n",
    "\n",
    "def guess_product_type(desc: str, category_cell: str | None) -> str:\n",
    "    cat_str = (category_cell or \"\").lower()\n",
    "    desc_l = (desc or \"\").lower()\n",
    "    if \"software\" in cat_str or SOFT_HINTS.search(desc_l):\n",
    "        return \"software\"\n",
    "    return \"hardware\"\n",
    "\n",
    "# mapeamento do Excel -> categorias dos schemas (ajuste se precisar)\n",
    "# chaves em lowercase; valores = nome \"category\" exatamente como no schema\n",
    "HW_CATEGORY_MAP = {\n",
    "    \"switch\": \"Switches\",\n",
    "    \"switches\": \"Switches\",\n",
    "    \"router\": \"Routers\",\n",
    "    \"routers\": \"Routers\",\n",
    "    \"firewall\": \"Firewall\",\n",
    "    \"wireless\": \"Wireless\",\n",
    "    \"ap\": \"Wireless\",\n",
    "    \"antenna\": \"Antennas\",\n",
    "    \"antennas\": \"Antennas\",\n",
    "    \"cable\": \"Cabling\",\n",
    "    \"cabling\": \"Cabling\",\n",
    "    \"connector\": \"Connectors\",\n",
    "    \"connectors\": \"Connectors\",\n",
    "    \"meraki ms\": \"Switches\",\n",
    "    \"meraki mx\": \"Routers\",\n",
    "    \"asa\": \"Firewall\",\n",
    "}\n",
    "def map_hw_category_from_row(desc: str, category_cell: str | None) -> str | None:\n",
    "    text = f\"{category_cell or ''} {desc or ''}\".lower()\n",
    "    # match por palavra-chave\n",
    "    for k, v in HW_CATEGORY_MAP.items():\n",
    "        if k in text:\n",
    "            return v\n",
    "    # fallback: se não achar, tenta \"Switches\" se tiver \"port\"/\"poe\" no texto\n",
    "    if re.search(r\"\\bpoe\\b|\\bports?\\b\", text):\n",
    "        return \"Switches\"\n",
    "    return None\n",
    "\n",
    "def map_sw_category_from_row(desc: str, category_cell: str | None) -> str:\n",
    "    # você pode criar schemas/software para: Management, Security, Switching, Wireless, Support etc.\n",
    "    # Aqui coloco um bucket genérico \"Software\" se não houver schemas SW específicos.\n",
    "    if SCHEMAS_SW:\n",
    "        # tentativa simples: usar \"Management\" se achar 'dna'/'meraki', senão 'Security' se 'fw/ips', etc.\n",
    "        text = f\"{category_cell or ''} {desc or ''}\".lower()\n",
    "        if any(x in text for x in [\"dna\", \"meraki\", \"dashboard\", \"cloud mgmt\"]):\n",
    "            target = \"Management\"\n",
    "        elif any(x in text for x in [\"firepower\", \"ips\", \"security\", \"amp\", \"umbrella\"]):\n",
    "            target = \"Security\"\n",
    "        elif any(x in text for x in [\"wireless\", \"ap\", \"wi-fi\"]):\n",
    "            target = \"Wireless\"\n",
    "        elif any(x in text for x in [\"switch\", \"ms2\", \"catalyst\"]):\n",
    "            target = \"Switching\"\n",
    "        else:\n",
    "            target = \"Software\"\n",
    "        # se não existir esse schema, cai no primeiro schema SW disponível\n",
    "        cat_key = target.lower()\n",
    "        return next((schema[\"category\"] for k, schema in SCHEMAS_SW.items() if k == cat_key),\n",
    "                    list(SCHEMAS_SW.values())[0][\"category\"])\n",
    "    else:\n",
    "        return \"Software\"  # bucket genérico\n",
    "\n",
    "# --- HELPERS: “instanciar” um template e preencher com Excel ---------------\n",
    "def instantiate_from_template(template: dict, sku: str, name: str, price: float, elig_pct: float, subcategory: str | None):\n",
    "    obj = deepcopy(template)\n",
    "    # garantias básicas\n",
    "    obj[\"cisco_product_id\"] = sku\n",
    "    obj[\"commercial_name\"] = name\n",
    "    obj[\"lifecycle\"] = obj.get(\"lifecycle\", {\"status\": \"active\", \"eos_announced\": None, \"last_support_date\": None})\n",
    "    obj[\"pricing_model\"] = obj.get(\"pricing_model\", {})\n",
    "    obj[\"pricing_model\"].setdefault(\"type\", \"one_time\")\n",
    "    obj[\"pricing_model\"].setdefault(\"currency\", \"USD\")\n",
    "    obj[\"pricing_model\"][\"base_price\"] = float(price or 0.0)\n",
    "    if \"elig_pct\" in obj[\"pricing_model\"]:\n",
    "        obj[\"pricing_model\"][\"elig_pct\"] = float(elig_pct or 0.0)\n",
    "    if subcategory is not None:\n",
    "        obj[\"subcategory\"] = subcategory or None\n",
    "    return obj\n",
    "\n",
    "# --- ENRIQUECIMENTO VIA LLM: produto por produto --------------------------\n",
    "ENRICH_SYSTEM = \"\"\"You are a strict JSON filler. \n",
    "You will receive a product JSON and a JSON schema template.\n",
    "- Keep all given keys as-is; DO NOT add keys that are not in the template.\n",
    "- Populate missing/null fields ONLY if deducible from product name/SKU/category semantics.\n",
    "- If unsure, keep the default/null.\n",
    "- Do not invent SKUs, specs, interfaces, or certifications.\n",
    "- Return only valid JSON matching the template keys.\n",
    "\"\"\"\n",
    "\n",
    "def enrich_product_with_llm(product_obj: dict, template_obj: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Envia 1 produto + template para a LLM e pede para devolver o produto com\n",
    "    os campos do template preenchidos quando possível. Zero “voo solo”.\n",
    "    \"\"\"\n",
    "    prompt = {\n",
    "        \"template\": template_obj,\n",
    "        \"product\": product_obj\n",
    "    }\n",
    "    try:\n",
    "        resp = client.chat.completions.create(\n",
    "            model=OPENAI_MODEL,\n",
    "            temperature=0.0,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": ENRICH_SYSTEM},\n",
    "                {\"role\": \"user\", \"content\": json.dumps(prompt, ensure_ascii=False)}\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        enriched = json.loads(resp.choices[0].message.content)\n",
    "        # Se a LLM retornou só o objeto final (sem wrapper), ok.\n",
    "        # Se ela retornou {\"product\": {...}}, trate:\n",
    "        if \"product\" in enriched and isinstance(enriched[\"product\"], dict):\n",
    "            return enriched[\"product\"]\n",
    "        return enriched if isinstance(enriched, dict) else product_obj\n",
    "    except Exception as e:\n",
    "        print(f\"[ENRICH WARN] Falha ao enriquecer {product_obj.get('cisco_product_id')}: {e}\")\n",
    "        return product_obj\n",
    "\n",
    "# --- PIPELINE --------------------------------------------------------------\n",
    "def process_excel_to_category_jsons(\n",
    "    xlsx_path: Path,\n",
    "    sample_per_category: int | None = SAMPLE_PER_CATEGORY,\n",
    "    do_enrichment: bool = DO_ENRICHMENT\n",
    "):\n",
    "    if not xlsx_path.exists():\n",
    "        raise FileNotFoundError(f\"Arquivo não encontrado: {xlsx_path}\")\n",
    "\n",
    "    df = pd.read_excel(xlsx_path, engine=\"openpyxl\")\n",
    "\n",
    "    sku_col   = find_col(df, [\"sku\"])\n",
    "    desc_col  = find_col(df, [\"desc\", \"name\"])\n",
    "    price_col = find_col(df, [\"price\"])\n",
    "    elig_col  = find_col(df, [\"elig\"])\n",
    "    cat_col   = find_col(df, [\"category\"])\n",
    "    sub_col   = find_col(df, [\"sub_category\", \"subcategory\"])\n",
    "\n",
    "    missing = [n for n, c in [(\"SKU\", sku_col), (\"Desc\", desc_col), (\"Price\", price_col)] if c is None]\n",
    "    if missing:\n",
    "        raise RuntimeError(f\"Colunas obrigatórias ausentes: {missing}\")\n",
    "\n",
    "    # normalização\n",
    "    df[\"__base_price\"] = clean_price_series(df[price_col])\n",
    "    df[\"__elig_pct\"]   = clean_pct_series(df[elig_col]) if elig_col else 0.0\n",
    "    df[\"__category\"]   = df[cat_col] if cat_col else None\n",
    "    df[\"__subcat\"]     = df[sub_col] if sub_col else None\n",
    "\n",
    "    # buffers por categoria\n",
    "    buckets_hw: dict[str, list] = {}\n",
    "    buckets_sw: dict[str, list] = {}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        sku  = str(row[sku_col]).strip()\n",
    "        name = str(row[desc_col]).strip()\n",
    "        price = float(row[\"__base_price\"])\n",
    "        elig  = float(row[\"__elig_pct\"])\n",
    "        cat_cell = (row[\"__category\"] if row[\"__category\"] is not None else \"\")\n",
    "        subcat   = (str(row[\"__subcat\"]).strip() if row[\"__subcat\"] is not None else None)\n",
    "\n",
    "        if not sku or not name:\n",
    "            continue\n",
    "\n",
    "        ptype = guess_product_type(name, cat_cell)\n",
    "\n",
    "        if ptype == \"hardware\":\n",
    "            mapped = map_hw_category_from_row(name, cat_cell)  # ex.: \"Switches\"\n",
    "            if not mapped:\n",
    "                # Se não conseguirmos mapear, pule ou bucketize como \"Unknown\"\n",
    "                mapped = \"Switches\"  # fallback educado\n",
    "            template = SCHEMAS_HW.get(mapped.lower())\n",
    "            if not template:\n",
    "                print(f\"[WARN] Sem template p/ '{mapped}' — SKU {sku} pulado\")\n",
    "                continue\n",
    "\n",
    "            base = instantiate_from_template(template, sku, name, price, elig, subcat)\n",
    "            final = enrich_product_with_llm(base, template) if do_enrichment else base\n",
    "\n",
    "            buckets_hw.setdefault(mapped, []).append(final)\n",
    "\n",
    "        else:  # software\n",
    "            # Escolhe categoria de software (se existir). Caso não, bucket genérico \"Software\"\n",
    "            mapped_sw = map_sw_category_from_row(name, cat_cell)\n",
    "            template_sw = SCHEMAS_SW.get(mapped_sw.lower())\n",
    "            if not template_sw:\n",
    "                # se não houver schemas de software, cria um template mínimo genérico compatível\n",
    "                template_sw = {\n",
    "                    \"cisco_product_id\": \"\",\n",
    "                    \"commercial_name\": \"\",\n",
    "                    \"product_type\": \"software\",\n",
    "                    \"category\": \"Software\",\n",
    "                    \"subcategory\": None,\n",
    "                    \"lifecycle\": {\"status\": \"active\",\"eos_announced\": None,\"last_support_date\": None},\n",
    "                    \"pricing_model\": {\"type\": \"one_time\",\"currency\": \"USD\",\"base_price\": 0.0,\"elig_pct\": 0.01}\n",
    "                }\n",
    "\n",
    "            base = instantiate_from_template(template_sw, sku, name, price, elig, subcat)\n",
    "            final = enrich_product_with_llm(base, template_sw) if do_enrichment else base\n",
    "            buckets_sw.setdefault(template_sw[\"category\"], []).append(final)\n",
    "\n",
    "    # aplica SAMPLE_PER_CATEGORY\n",
    "    if sample_per_category is not None:\n",
    "        for k in list(buckets_hw.keys()):\n",
    "            buckets_hw[k] = buckets_hw[k][:sample_per_category]\n",
    "        for k in list(buckets_sw.keys()):\n",
    "            buckets_sw[k] = buckets_sw[k][:sample_per_category]\n",
    "\n",
    "    # garante diretórios\n",
    "    OUT_HW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    OUT_SW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # salva um arquivo por categoria\n",
    "    for cat, items in buckets_hw.items():\n",
    "        out_path = OUT_HW_DIR / f\"{cat.lower().replace(' ','_')}.json\"\n",
    "        out_path.write_text(json.dumps(items, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    for cat, items in buckets_sw.items():\n",
    "        out_path = OUT_SW_DIR / f\"{cat.lower().replace(' ','_')}.json\"\n",
    "        out_path.write_text(json.dumps(items, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    print(\"✅ Finalizado.\")\n",
    "    print(\"Hardware:\", {k: len(v) for k, v in buckets_hw.items()})\n",
    "    print(\"Software:\", {k: len(v) for k, v in buckets_sw.items()})\n",
    "\n",
    "# --- EXECUÇÃO --------------------------------------------------------------\n",
    "process_excel_to_category_jsons(\n",
    "    XLSX_PATH,\n",
    "    sample_per_category=SAMPLE_PER_CATEGORY,\n",
    "    do_enrichment=DO_ENRICHMENT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c0b96411-0236-45d9-96d2-a68bb703169c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536d5bda-06ef-4b87-bd65-12421cbd365a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e689b69-ef9a-487d-9c8b-615326461af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01152f7a-0840-45e0-88dd-bf67bae182fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8066649c-c124-4206-855e-533f8467241c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "45d467a6-16d3-4e60-a30c-e2a83ce3ada4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in Excel: 4267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying rows: 100%|██████████| 4267/4267 [00:00<00:00, 5309.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[HW] Wireless: 509 itens → out\\hardware\\hw_wireless.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich HW/Wireless:   0%|          | 2/509 [00:00<00:16, 31.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↪️  Limit reached (3) for HW/Wireless\n",
      "\n",
      "[HW] Switches: 1669 itens → out\\hardware\\hw_switches.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich HW/Switches:   0%|          | 2/1669 [00:00<00:47, 34.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↪️  Limit reached (3) for HW/Switches\n",
      "\n",
      "[HW] Routers: 614 itens → out\\hardware\\hw_routers.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich HW/Routers:   0%|          | 0/614 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↪️  Limit reached (3) for HW/Routers"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich HW/Routers:   0%|          | 2/614 [00:00<00:16, 38.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[HW] Firewall: 180 itens → out\\hardware\\hw_firewall.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich HW/Firewall:   1%|          | 2/180 [00:00<00:05, 34.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↪️  Limit reached (3) for HW/Firewall\n",
      "\n",
      "[HW] Connectors: 21 itens → out\\hardware\\hw_connectors.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Enrich HW/Connectors:  10%|▉         | 2/21 [00:00<00:01, 12.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↪️  Limit reached (3) for HW/Connectors\n",
      "\n",
      "[HW] Cabling: 3 itens → out\\hardware\\hw_cabling.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich HW/Cabling:  67%|██████▋   | 2/3 [00:00<00:00, 29.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↪️  Limit reached (3) for HW/Cabling\n",
      "\n",
      "[HW] Antennas: 8 itens → out\\hardware\\hw_antennas.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich HW/Antennas:  25%|██▌       | 2/8 [00:00<00:00, 33.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↪️  Limit reached (3) for HW/Antennas\n",
      "\n",
      "[SW] Wireless: 545 itens → out\\software\\sw_wireless.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich SW/Wireless:   0%|          | 2/545 [00:00<00:15, 34.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↪️  Limit reached (3) for SW/Wireless\n",
      "\n",
      "[SW] Switches: 409 itens → out\\software\\sw_switches.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich SW/Switches:   0%|          | 2/409 [00:00<00:13, 29.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↪️  Limit reached (3) for SW/Switches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SW] Licenses: 9 itens → out\\software\\sw_licenses.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich SW/Licenses:  22%|██▏       | 2/9 [00:00<00:00, 34.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↪️  Limit reached (3) for SW/Licenses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SW] Routers: 250 itens → out\\software\\sw_routers.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich SW/Routers:   1%|          | 2/250 [00:00<00:15, 16.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↪️  Limit reached (3) for SW/Routers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SW] Firewall: 50 itens → out\\software\\sw_firewall.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich SW/Firewall:   4%|▍         | 2/50 [00:00<00:03, 12.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↪️  Limit reached (3) for SW/Firewall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Summary ===\n",
      "{'hardware': 21, 'software': 15, 'files': 12}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hardware': 21, 'software': 15, 'files': 12}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Setup / Imports ==========================================================\n",
    "import os, json, time, copy, re\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# ---------- Switches de execução ----------\n",
    "ENRICH_WITH_LLM = True          # True para preencher campos faltantes via LLM\n",
    "MAX_ITEMS_PER_CATEGORY = 3       # None = sem limite (use 3 para testar)\n",
    "LIMIT_CATEGORIES = None          # ex.: [\"Wireless\",\"Switches\"] para filtrar\n",
    "\n",
    "# ---------- Caminhos ----------\n",
    "XLSX_PATH       = Path(\"data/raw/Cisco_Pricing.xlsx\")\n",
    "SCHEMAS_HW_DIR  = Path(\"schemas/hardware\")   # ex.: schema_switches.json, schema_wireless.json ...\n",
    "SCHEMAS_SW_DIR  = Path(\"schemas/software\")   # opcional; se vazio, usa template genérico\n",
    "OUTPUT_DIR_HW   = Path(\"out/hardware\")\n",
    "OUTPUT_DIR_SW   = Path(\"out/software\")\n",
    "CACHE_PATH      = Path(\"out/enrichment_cache.json\")\n",
    "\n",
    "OUTPUT_DIR_HW.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_DIR_SW.mkdir(parents=True, exist_ok=True)\n",
    "CACHE_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === Cache util ===============================================================\n",
    "def _load_cache(path: Path) -> dict:\n",
    "    if path.exists():\n",
    "        try:\n",
    "            return json.loads(path.read_text(encoding=\"utf-8\"))\n",
    "        except Exception:\n",
    "            return {}\n",
    "    return {}\n",
    "\n",
    "def _save_cache(path: Path, data: dict):\n",
    "    tmp = path.with_suffix(\".tmp.json\")\n",
    "    tmp.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    tmp.replace(path)\n",
    "\n",
    "CACHE = _load_cache(CACHE_PATH)\n",
    "\n",
    "# === Carregamento dos schemas =================================================\n",
    "def load_schema_templates(dir_path: Path, expect_hw=True):\n",
    "    templates = {}\n",
    "    if dir_path.exists():\n",
    "        for fp in sorted(dir_path.glob(\"*.json\")):\n",
    "            try:\n",
    "                obj = json.loads(fp.read_text(encoding=\"utf-8\"))\n",
    "                cat = obj.get(\"category\")\n",
    "                if not cat:\n",
    "                    base = fp.stem.replace(\"schema_\", \"\")\n",
    "                    cat = base.replace(\"_\", \" \").title()\n",
    "                templates[cat] = obj\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Erro lendo {fp}: {e}\")\n",
    "    else:\n",
    "        if expect_hw:\n",
    "            print(f\"⚠️ Diretório de schemas não existe: {dir_path}\")\n",
    "    return templates\n",
    "\n",
    "SCHEMAS_HW = load_schema_templates(SCHEMAS_HW_DIR, expect_hw=True)\n",
    "SCHEMAS_SW = load_schema_templates(SCHEMAS_SW_DIR, expect_hw=False)\n",
    "\n",
    "if not SCHEMAS_HW:\n",
    "    raise RuntimeError(\n",
    "        f\"Nenhum schema de hardware encontrado em {SCHEMAS_HW_DIR}. \"\n",
    "        \"Coloque seus arquivos schema_*.json lá (ex.: schema_switches.json).\"\n",
    "    )\n",
    "\n",
    "# === Template genérico p/ software ===========================================\n",
    "GENERIC_SW_SCHEMA = {\n",
    "    \"cisco_product_id\": \"\",\n",
    "    \"commercial_name\": \"\",\n",
    "    \"product_type\": \"software\",\n",
    "    \"category\": \"\",\n",
    "    \"subcategory\": \"\",\n",
    "    \"lifecycle\": {\"status\": \"active\", \"eos_announced\": None, \"last_support_date\": None},\n",
    "    \"license_model\": {\"type\": \"subscription\", \"term\": None, \"seats_or_nodes\": None, \"includes_support\": True},\n",
    "    \"entitlements\": {\"features\": [], \"tier\": None, \"usage_limits\": {}},\n",
    "    \"pricing_model\": {\"currency\": \"USD\", \"base_price\": 0.0, \"billing_cycle\": \"one_time\", \"pricing_tiers\": []},\n",
    "    \"dependencies\": {\"requires\": [], \"compatibility\": []},\n",
    "    \"regulatory\": {\"compliance\": []},\n",
    "    \"metadata\": {\"vendor_sku_aliases\": [], \"notes\": \"\"}\n",
    "}\n",
    "\n",
    "# === Normalização das categorias =============================================\n",
    "HW_CATEGORY_MAP = {\n",
    "    \"switch\": \"Switches\", \"switches\": \"Switches\",\n",
    "    \"router\": \"Routers\", \"routers\": \"Routers\",\n",
    "    \"firewall\": \"Firewall\",\n",
    "    \"wireless\": \"Wireless\", \"access point\": \"Wireless\", \"ap\": \"Wireless\",\n",
    "    \"antenna\": \"Antennas\", \"antennas\": \"Antennas\",\n",
    "    \"cabling\": \"Cabling\",\n",
    "    \"connector\": \"Connectors\", \"connectors\": \"Connectors\",\n",
    "}\n",
    "SW_CATEGORY_MAP = {\n",
    "    # se vier \"Wireless\" para software, manteremos \"Wireless\" (ver fallback)\n",
    "    \"license\": \"Licenses\", \"licensing\": \"Licenses\",\n",
    "    \"subscription\": \"Subscriptions\",\n",
    "    \"support\": \"Support\",\n",
    "    \"cloud\": \"Cloud Services\", \"service\": \"Cloud Services\",\n",
    "}\n",
    "\n",
    "def normalize_hw_category(raw: str) -> str | None:\n",
    "    if not raw: return None\n",
    "    s = str(raw).strip().lower()\n",
    "    for key, cat in HW_CATEGORY_MAP.items():\n",
    "        if key in s:\n",
    "            return cat\n",
    "    # igual ao nome\n",
    "    if s in {v.lower() for v in HW_CATEGORY_MAP.values()}:\n",
    "        return s.title()\n",
    "    return None\n",
    "\n",
    "def normalize_sw_category(raw: str) -> str | None:\n",
    "    if not raw: return None\n",
    "    s = str(raw).strip().lower()\n",
    "    for key, cat in SW_CATEGORY_MAP.items():\n",
    "        if key in s:\n",
    "            return cat\n",
    "    # permitir categorias como \"Wireless\" também para software\n",
    "    if s in {v.lower() for v in HW_CATEGORY_MAP.values()}:\n",
    "        return s.title()\n",
    "    return None\n",
    "\n",
    "# === Detecção de colunas no Excel ============================================\n",
    "def detect_columns(df: pd.DataFrame) -> dict:\n",
    "    cols = {c: re.sub(r\"\\s+\", \"\", str(c).strip().lower()) for c in df.columns}\n",
    "    out = {\"sku\": None, \"desc\": None, \"price\": None, \"category\": None, \"category_type\": None, \"subcategory\": None}\n",
    "\n",
    "    for col, norm in cols.items():\n",
    "        if out[\"sku\"] is None and (norm == \"sku\" or \"partnumber\" in norm or norm == \"part\" or \"sku\" in norm):\n",
    "            out[\"sku\"] = col\n",
    "        elif out[\"desc\"] is None and (norm in {\"desc\",\"description\",\"name\"} or \"desc\" in norm or \"description\" in norm):\n",
    "            out[\"desc\"] = col\n",
    "        elif out[\"price\"] is None and (norm in {\"price\",\"pri\",\"list\"} or \"price\" in norm or norm == \"pri\"):\n",
    "            out[\"price\"] = col\n",
    "        elif out[\"category_type\"] is None and re.fullmatch(r\"category[-_]?type\", norm):\n",
    "            out[\"category_type\"] = col\n",
    "        elif out[\"category\"] is None and (norm == \"category\" or ((\"category\" in norm) and (\"type\" not in norm))):\n",
    "            out[\"category\"] = col\n",
    "        elif out[\"subcategory\"] is None and (\"subcategory\" in norm or \"sub-category\" in norm or norm == \"sub_category\"):\n",
    "            out[\"subcategory\"] = col\n",
    "\n",
    "    # sanity fallback\n",
    "    if out[\"category\"] is None and out[\"category_type\"] is not None:\n",
    "        # pelo menos garantimos que não confundiremos\n",
    "        pass\n",
    "\n",
    "    missing = [k for k, v in out.items() if v is None and k in (\"sku\",\"desc\",\"price\")]\n",
    "    if missing:\n",
    "        raise RuntimeError(f\"Excel sem colunas obrigatórias: {missing}. Detectado: {out}\")\n",
    "    return out\n",
    "\n",
    "def read_excel_rows(xlsx_path: Path) -> pd.DataFrame:\n",
    "    if not xlsx_path.exists():\n",
    "        raise FileNotFoundError(f\"Excel não encontrado: {xlsx_path}\")\n",
    "    df = pd.read_excel(xlsx_path, engine=\"openpyxl\")\n",
    "    cols = detect_columns(df)\n",
    "\n",
    "    # Limpa preço (vírgula decimal, separadores, etc.)\n",
    "    price_series = (\n",
    "        df[cols[\"price\"]]\n",
    "        .astype(str)\n",
    "        .str.replace(r\"[^\\d\\.,-]\", \"\", regex=True)\n",
    "        .str.replace(r\"\\.(?=\\d{3},)\", \"\", regex=True)  # remove separador de milhar antes de vírgula decimal\n",
    "        .str.replace(\",\", \".\", regex=False)\n",
    "    )\n",
    "    df[\"_price\"] = pd.to_numeric(price_series, errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "    df[\"_sku\"]   = df[cols[\"sku\"]].astype(str).str.strip()\n",
    "    df[\"_name\"]  = df[cols[\"desc\"]].astype(str).str.strip()\n",
    "    df[\"_cat\"]   = df[cols[\"category\"]].astype(str).str.strip() if cols[\"category\"] else \"\"\n",
    "    df[\"_cat_type\"] = df[cols[\"category_type\"]].astype(str).str.strip() if cols[\"category_type\"] else \"\"\n",
    "    df[\"_sub\"]   = df[cols[\"subcategory\"]].astype(str).str.strip() if cols[\"subcategory\"] else \"\"\n",
    "    return df\n",
    "\n",
    "# === LLM (enriquecimento opcional) ===========================================\n",
    "def _extract_json(text: str) -> dict:\n",
    "    \"\"\"Aceita resposta com/sem fences e retorna um dict JSON.\"\"\"\n",
    "    t = text.strip()\n",
    "    # remove codefence se vier\n",
    "    if t.startswith(\"```\"):\n",
    "        t = re.sub(r\"^```[a-zA-Z0-9]*\\s*\", \"\", t)\n",
    "        t = re.sub(r\"\\s*```$\", \"\", t)\n",
    "    s = t.find(\"{\"); e = t.rfind(\"}\")\n",
    "    if s != -1 and e != -1 and e > s:\n",
    "        t = t[s:e+1]\n",
    "    return json.loads(t)\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.9)\n",
    "\n",
    "ENRICH_PROMPT = ChatPromptTemplate.from_template(\n",
    "    \"you ara a Cisco expert\\n\"\n",
    "    \"You are a data normalizer. You receive a PARTIAL product JSON from Cisco catalog and a TARGET SCHEMA.\\n\"\n",
    "    \"Fill ONLY the missing fields, do not change existing values, do not invent extra keys.\\n\"\n",
    "    \"Keep structure and key names exactly as the schema. Use realistic, conservative values.\\n\"\n",
    "    \"If you don't know, keep null/empty.\\n\\n\"\n",
    "    \"<<<PARTIAL_JSON>>>\\n{partial}\\n<<<END_PARTIAL_JSON>>>\\n\\n\"\n",
    "    \"<<<TARGET_SCHEMA>>>\\n{schema}\\n<<<END_TARGET_SCHEMA>>>\\n\\n\"\n",
    "    \"Return ONLY a valid JSON object matching the target schema.\"\n",
    ")\n",
    "\n",
    "def enrich_with_llm(partial: dict, schema_obj: dict, cache_key: str) -> dict:\n",
    "    if not ENRICH_WITH_LLM:\n",
    "        return partial\n",
    "    if cache_key in CACHE:\n",
    "        return CACHE[cache_key]\n",
    "    chain = ENRICH_PROMPT | llm\n",
    "    tries = 0\n",
    "    while True:\n",
    "        tries += 1\n",
    "        try:\n",
    "            resp = chain.invoke({\n",
    "                \"partial\": json.dumps(partial, ensure_ascii=False, indent=2),\n",
    "                \"schema\":  json.dumps(schema_obj, ensure_ascii=False, indent=2),\n",
    "            })\n",
    "            enriched = _extract_json(resp.content)\n",
    "\n",
    "            out = copy.deepcopy(schema_obj)\n",
    "\n",
    "            def deep_merge(dst, src):\n",
    "                for k, v in src.items():\n",
    "                    if isinstance(v, dict) and isinstance(dst.get(k), dict):\n",
    "                        deep_merge(dst[k], v)\n",
    "                    else:\n",
    "                        dst[k] = v\n",
    "\n",
    "            deep_merge(out, partial)\n",
    "            deep_merge(out, enriched)\n",
    "\n",
    "            CACHE[cache_key] = out\n",
    "            if tries % 5 == 1:\n",
    "                _save_cache(CACHE_PATH, CACHE)\n",
    "            return out\n",
    "        except Exception as e:\n",
    "            if tries >= 3:\n",
    "                print(f\"⚠️ LLM falhou para {cache_key}: {e} — usando partial.\")\n",
    "                return partial\n",
    "            time.sleep(1.2)\n",
    "\n",
    "# === Persistência incremental por categoria ===================================\n",
    "def append_item_to_json(filepath: Path, item: dict):\n",
    "    if filepath.exists():\n",
    "        try:\n",
    "            arr = json.loads(filepath.read_text(encoding=\"utf-8\"))\n",
    "            if not isinstance(arr, list):\n",
    "                arr = []\n",
    "        except Exception:\n",
    "            arr = []\n",
    "    else:\n",
    "        arr = []\n",
    "    arr.append(item)\n",
    "    filepath.write_text(json.dumps(arr, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "# === Pipeline principal =======================================================\n",
    "def build_catalog_from_excel(\n",
    "    xlsx_path: Path = XLSX_PATH,\n",
    "    max_items_per_category: int | None = MAX_ITEMS_PER_CATEGORY,\n",
    "    limit_categories: list[str] | None = LIMIT_CATEGORIES,\n",
    "    verbose: bool = True\n",
    "):\n",
    "    df = read_excel_rows(xlsx_path)\n",
    "    if verbose:\n",
    "        print(f\"Rows in Excel: {len(df)}\")\n",
    "\n",
    "    buckets_hw = defaultdict(list)\n",
    "    buckets_sw = defaultdict(list)\n",
    "\n",
    "    records = df.to_dict(orient=\"records\")\n",
    "    for rec in tqdm(records, desc=\"Classifying rows\", disable=not verbose):\n",
    "        sku   = rec.get(\"_sku\", \"\").strip()\n",
    "        name  = rec.get(\"_name\", \"\").strip()\n",
    "        price = float(rec.get(\"_price\", 0.0) or 0.0)\n",
    "        raw_cat = rec.get(\"_cat\", \"\")\n",
    "        raw_type= rec.get(\"_cat_type\", \"\")\n",
    "        subcat  = rec.get(\"_sub\", \"\")\n",
    "\n",
    "        # 1) Decide Hardware/Software pelo Category-Type, se existir\n",
    "        pt = None\n",
    "        rt = raw_type.strip().lower()\n",
    "        if rt.startswith(\"hard\"):\n",
    "            pt = \"hardware\"\n",
    "        elif rt.startswith(\"soft\"):\n",
    "            pt = \"software\"\n",
    "\n",
    "        # 2) Normaliza categoria\n",
    "        hw_cat = normalize_hw_category(raw_cat)    # ex.: \"Wireless\"\n",
    "        sw_cat = normalize_sw_category(raw_cat)    # ex.: \"Wireless\" ou \"Licenses\"\n",
    "\n",
    "        # 3) Se não deu pra decidir tipo pelo Category-Type, decide por categoria\n",
    "        if not pt:\n",
    "            pt = \"hardware\" if hw_cat else (\"software\" if sw_cat else \"hardware\")\n",
    "\n",
    "        # 4) Categoria final\n",
    "        category = hw_cat if pt == \"hardware\" else (sw_cat or (raw_cat.strip().title() if raw_cat else \"Licenses\"))\n",
    "\n",
    "        # 5) (Opcional) fallback por texto do produto\n",
    "        if pt == \"hardware\" and not hw_cat:\n",
    "            txt = f\"{name} {sku}\".lower()\n",
    "            if \"switch\" in txt:             category = \"Switches\"\n",
    "            elif \"router\" in txt:           category = \"Routers\"\n",
    "            elif \"firewall\" in txt:         category = \"Firewall\"\n",
    "            elif \"access point\" in txt or \"ap \" in txt or txt.startswith(\"ap-\"): category = \"Wireless\"\n",
    "            elif \"antenna\" in txt:          category = \"Antennas\"\n",
    "            elif \"cable\" in txt:            category = \"Cabling\"\n",
    "            elif \"connector\" in txt:        category = \"Connectors\"\n",
    "\n",
    "        if limit_categories and category not in limit_categories:\n",
    "            continue\n",
    "\n",
    "        if pt == \"hardware\":\n",
    "            schema = SCHEMAS_HW.get(category)\n",
    "            if not schema:\n",
    "                if verbose:\n",
    "                    print(f\"↪️  Sem schema p/ HW category='{category}', SKU={sku} — pulando\")\n",
    "                continue\n",
    "            base = copy.deepcopy(schema)\n",
    "            base[\"cisco_product_id\"] = sku\n",
    "            base[\"commercial_name\"] = name\n",
    "            base[\"product_type\"] = \"hardware\"\n",
    "            base.setdefault(\"pricing_model\", {})\n",
    "            base[\"pricing_model\"][\"currency\"] = base[\"pricing_model\"].get(\"currency\", \"USD\")\n",
    "            base[\"pricing_model\"][\"base_price\"] = price\n",
    "            base[\"technical_profile\"] = base.get(\"technical_profile\", {})\n",
    "            base[\"technical_profile\"][\"category\"] = category\n",
    "            base[\"technical_profile\"][\"subcategory\"] = subcat or \"\"\n",
    "            buckets_hw[category].append(base)\n",
    "\n",
    "        else:\n",
    "            schema = SCHEMAS_SW.get(category, GENERIC_SW_SCHEMA)\n",
    "            base = copy.deepcopy(schema)\n",
    "            base[\"cisco_product_id\"] = sku\n",
    "            base[\"commercial_name\"] = name\n",
    "            base[\"product_type\"] = \"software\"\n",
    "            base[\"category\"] = category\n",
    "            base[\"pricing_model\"] = base.get(\"pricing_model\", {})\n",
    "            base[\"pricing_model\"][\"currency\"] = base[\"pricing_model\"].get(\"currency\", \"USD\")\n",
    "            base[\"pricing_model\"][\"base_price\"] = price\n",
    "            if \"subcategory\" not in base:\n",
    "                base[\"subcategory\"] = subcat or \"\"\n",
    "            buckets_sw[category].append(base)\n",
    "\n",
    "    counts = {\"hardware\": 0, \"software\": 0, \"files\": 0}\n",
    "\n",
    "    # HARDWARE → 1 arquivo por categoria\n",
    "    for category, items in buckets_hw.items():\n",
    "        out_file = OUTPUT_DIR_HW / f\"hw_{category.replace(' ', '_').lower()}.json\"\n",
    "        if verbose: print(f\"\\n[HW] {category}: {len(items)} itens → {out_file}\")\n",
    "        n = 0\n",
    "        for base in tqdm(items, desc=f\"Enrich HW/{category}\", disable=not verbose):\n",
    "            sku = base.get(\"cisco_product_id\", \"\")\n",
    "            schema = SCHEMAS_HW[category]\n",
    "            enriched = enrich_with_llm(base, schema, cache_key=f\"HW::{category}::{sku}\")\n",
    "            append_item_to_json(out_file, enriched)\n",
    "            counts[\"hardware\"] += 1\n",
    "            n += 1\n",
    "            if max_items_per_category and n >= max_items_per_category:\n",
    "                if verbose: print(f\"  ↪️  Limit reached ({max_items_per_category}) for HW/{category}\")\n",
    "                break\n",
    "        counts[\"files\"] += 1\n",
    "\n",
    "    # SOFTWARE → 1 arquivo por categoria\n",
    "    for category, items in buckets_sw.items():\n",
    "        out_file = OUTPUT_DIR_SW / f\"sw_{category.replace(' ', '_').lower()}.json\"\n",
    "        if verbose: print(f\"\\n[SW] {category}: {len(items)} itens → {out_file}\")\n",
    "        n = 0\n",
    "        for base in tqdm(items, desc=f\"Enrich SW/{category}\", disable=not verbose):\n",
    "            sku = base.get(\"cisco_product_id\", \"\")\n",
    "            schema = SCHEMAS_SW.get(category, GENERIC_SW_SCHEMA)\n",
    "            enriched = enrich_with_llm(base, schema, cache_key=f\"SW::{category}::{sku}\")\n",
    "            append_item_to_json(out_file, enriched)\n",
    "            counts[\"software\"] += 1\n",
    "            n += 1\n",
    "            if max_items_per_category and n >= max_items_per_category:\n",
    "                if verbose: print(f\"  ↪️  Limit reached ({max_items_per_category}) for SW/{category}\")\n",
    "                break\n",
    "        counts[\"files\"] += 1\n",
    "\n",
    "    _save_cache(CACHE_PATH, CACHE)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n=== Summary ===\")\n",
    "        print(counts)\n",
    "    return counts\n",
    "\n",
    "# === EXECUÇÃO (teste rápido) ==================================================\n",
    "summary = build_catalog_from_excel(\n",
    "    xlsx_path=XLSX_PATH,\n",
    "    max_items_per_category=MAX_ITEMS_PER_CATEGORY,\n",
    "    limit_categories=LIMIT_CATEGORIES,   # ex.: [\"Wireless\",\"Switches\"]\n",
    "    verbose=True\n",
    ")\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77c607f-a7d8-4748-b18c-75de72d75a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4062d590-b8dd-422c-a38a-b6aa8ae2fee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbd32e5-7572-4c66-9140-7b7ce7a50926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3807f758-2538-4ff3-940d-9f532372cf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in Excel: 4267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying rows: 100%|██████████| 4267/4267 [00:00<00:00, 14645.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[HW] Wireless: 509 itens → out\\hardware\\hw_wireless.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich HW/Wireless:   1%|          | 3/509 [00:10<28:53,  3.43s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 440\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m counts\n\u001b[0;32m    439\u001b[0m \u001b[38;5;66;03m# === EXECUÇÃO (teste rápido) ==================================================\u001b[39;00m\n\u001b[1;32m--> 440\u001b[0m summary \u001b[38;5;241m=\u001b[39m build_catalog_from_excel(\n\u001b[0;32m    441\u001b[0m     xlsx_path\u001b[38;5;241m=\u001b[39mXLSX_PATH,\n\u001b[0;32m    442\u001b[0m     max_items_per_category\u001b[38;5;241m=\u001b[39mMAX_ITEMS_PER_CATEGORY,\n\u001b[0;32m    443\u001b[0m     limit_categories\u001b[38;5;241m=\u001b[39mLIMIT_CATEGORIES,   \u001b[38;5;66;03m# ex.: [\"Wireless\",\"Switches\"]\u001b[39;00m\n\u001b[0;32m    444\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    445\u001b[0m )\n\u001b[0;32m    446\u001b[0m summary\n",
      "Cell \u001b[1;32mIn[66], line 406\u001b[0m, in \u001b[0;36mbuild_catalog_from_excel\u001b[1;34m(xlsx_path, max_items_per_category, limit_categories, verbose)\u001b[0m\n\u001b[0;32m    404\u001b[0m sku \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcisco_product_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    405\u001b[0m schema \u001b[38;5;241m=\u001b[39m SCHEMAS_HW[category]\n\u001b[1;32m--> 406\u001b[0m enriched \u001b[38;5;241m=\u001b[39m enrich_with_llm(base, schema, cache_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHW::\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m::\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msku\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    407\u001b[0m append_item_to_json(out_file, enriched)\n\u001b[0;32m    408\u001b[0m counts[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhardware\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[66], line 252\u001b[0m, in \u001b[0;36menrich_with_llm\u001b[1;34m(partial, schema_obj, cache_key)\u001b[0m\n\u001b[0;32m    250\u001b[0m tries \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 252\u001b[0m     resp \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39minvoke({\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartial\u001b[39m\u001b[38;5;124m\"\u001b[39m: json\u001b[38;5;241m.\u001b[39mdumps(partial, ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mschema\u001b[39m\u001b[38;5;124m\"\u001b[39m:  json\u001b[38;5;241m.\u001b[39mdumps(schema_obj, ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[0;32m    255\u001b[0m     })\n\u001b[0;32m    256\u001b[0m     enriched_json \u001b[38;5;241m=\u001b[39m _extract_json(resp\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;66;03m# Merge: schema baseline -> partial -> enriched\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3047\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3045\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3046\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3047\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config)\n\u001b[0;32m   3048\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3049\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:378\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    374\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    375\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    377\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 378\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    379\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    380\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    381\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    382\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    383\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    384\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    385\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    386\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    387\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    388\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:963\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    956\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    960\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    961\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    962\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:782\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    781\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 782\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    783\u001b[0m                 m,\n\u001b[0;32m    784\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    785\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    786\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    787\u001b[0m             )\n\u001b[0;32m    788\u001b[0m         )\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1028\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1026\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1028\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m   1029\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1030\u001b[0m     )\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1032\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1131\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1131\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpayload)\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1087\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   1045\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1084\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1085\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m   1086\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m-> 1087\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m   1088\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1089\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m   1090\u001b[0m             {\n\u001b[0;32m   1091\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m   1092\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m   1093\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n\u001b[0;32m   1094\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m   1095\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m   1096\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m   1097\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m   1098\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m   1099\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[0;32m   1100\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m   1101\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m   1102\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n\u001b[0;32m   1103\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m   1104\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[0;32m   1105\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: prediction,\n\u001b[0;32m   1106\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m   1107\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_effort\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_effort,\n\u001b[0;32m   1108\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m   1109\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m   1110\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[0;32m   1111\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m   1112\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[0;32m   1113\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m   1114\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[0;32m   1115\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m   1116\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m   1117\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m   1118\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[0;32m   1119\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m   1120\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m   1121\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb_search_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: web_search_options,\n\u001b[0;32m   1122\u001b[0m             },\n\u001b[0;32m   1123\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsStreaming\n\u001b[0;32m   1124\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[0;32m   1125\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsNonStreaming,\n\u001b[0;32m   1126\u001b[0m         ),\n\u001b[0;32m   1127\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m   1128\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m   1129\u001b[0m         ),\n\u001b[0;32m   1130\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m   1131\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1132\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[0;32m   1133\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1256\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1243\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1244\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1251\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1252\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1253\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1254\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1255\u001b[0m     )\n\u001b[1;32m-> 1256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:979\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m    977\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 979\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    980\u001b[0m         request,\n\u001b[0;32m    981\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[0;32m    982\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    983\u001b[0m     )\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    985\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[0;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[0;32m    927\u001b[0m     request,\n\u001b[0;32m    928\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[0;32m    929\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    930\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m    931\u001b[0m )\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[0;32m    955\u001b[0m         request,\n\u001b[0;32m    956\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    957\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[0;32m    958\u001b[0m     )\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    989\u001b[0m     hook(request)\n\u001b[1;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1024\u001b[0m     )\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpx\\_transports\\default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    234\u001b[0m )\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    245\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mhandle_request(\n\u001b[0;32m    237\u001b[0m         pool_request\u001b[38;5;241m.\u001b[39mrequest\n\u001b[0;32m    238\u001b[0m     )\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[0;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    100\u001b[0m     (\n\u001b[0;32m    101\u001b[0m         http_version,\n\u001b[0;32m    102\u001b[0m         status,\n\u001b[0;32m    103\u001b[0m         reason_phrase,\n\u001b[0;32m    104\u001b[0m         headers,\n\u001b[0;32m    105\u001b[0m         trailing_data,\n\u001b[1;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    108\u001b[0m         http_version,\n\u001b[0;32m    109\u001b[0m         status,\n\u001b[0;32m    110\u001b[0m         reason_phrase,\n\u001b[0;32m    111\u001b[0m         headers,\n\u001b[0;32m    112\u001b[0m     )\n\u001b[0;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_event(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    219\u001b[0m     )\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httpcore\\_backends\\sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv(max_bytes)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ssl.py:1232\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1228\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1229\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1230\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1231\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(buflen)\n\u001b[0;32m   1233\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ssl.py:1105\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# === Setup / Imports ==========================================================\n",
    "import os, json, time, copy, re\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# ---------- Switches de execução ----------\n",
    "ENRICH_WITH_LLM = True          # True para preencher campos faltantes via LLM\n",
    "MAX_ITEMS_PER_CATEGORY = None       # None = sem limite (use 3 para testar)\n",
    "LIMIT_CATEGORIES = None          # ex.: [\"Wireless\",\"Switches\"] para filtrar\n",
    "\n",
    "# ---------- Caminhos ----------\n",
    "XLSX_PATH       = Path(\"data/raw/Cisco_Pricing.xlsx\")\n",
    "SCHEMAS_HW_DIR  = Path(\"schemas/hardware\")   # ex.: schema_switches.json, schema_wireless.json ...\n",
    "SCHEMAS_SW_DIR  = Path(\"schemas/software\")   # opcional; se vazio, usa template genérico\n",
    "OUTPUT_DIR_HW   = Path(\"out/hardware\")\n",
    "OUTPUT_DIR_SW   = Path(\"out/software\")\n",
    "CACHE_PATH      = Path(\"out/enrichment_cache.json\")\n",
    "\n",
    "OUTPUT_DIR_HW.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_DIR_SW.mkdir(parents=True, exist_ok=True)\n",
    "CACHE_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === Cache util ===============================================================\n",
    "def _load_cache(path: Path) -> dict:\n",
    "    if path.exists():\n",
    "        try:\n",
    "            return json.loads(path.read_text(encoding=\"utf-8\"))\n",
    "        except Exception:\n",
    "            return {}\n",
    "    return {}\n",
    "\n",
    "def _save_cache(path: Path, data: dict):\n",
    "    tmp = path.with_suffix(\".tmp.json\")\n",
    "    tmp.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    tmp.replace(path)\n",
    "\n",
    "CACHE = _load_cache(CACHE_PATH)\n",
    "\n",
    "# === Carregamento dos schemas =================================================\n",
    "def load_schema_templates(dir_path: Path, expect_hw=True):\n",
    "    templates = {}\n",
    "    if dir_path.exists():\n",
    "        for fp in sorted(dir_path.glob(\"*.json\")):\n",
    "            try:\n",
    "                obj = json.loads(fp.read_text(encoding=\"utf-8\"))\n",
    "                cat = obj.get(\"category\")\n",
    "                if not cat:\n",
    "                    base = fp.stem.replace(\"schema_\", \"\")\n",
    "                    cat = base.replace(\"_\", \" \").title()\n",
    "                templates[cat] = obj\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Erro lendo {fp}: {e}\")\n",
    "    else:\n",
    "        if expect_hw:\n",
    "            print(f\"⚠️ Diretório de schemas não existe: {dir_path}\")\n",
    "    return templates\n",
    "\n",
    "SCHEMAS_HW = load_schema_templates(SCHEMAS_HW_DIR, expect_hw=True)\n",
    "SCHEMAS_SW = load_schema_templates(SCHEMAS_SW_DIR, expect_hw=False)\n",
    "\n",
    "if not SCHEMAS_HW:\n",
    "    raise RuntimeError(\n",
    "        f\"Nenhum schema de hardware encontrado em {SCHEMAS_HW_DIR}. \"\n",
    "        \"Coloque seus arquivos schema_*.json lá (ex.: schema_switches.json).\"\n",
    "    )\n",
    "\n",
    "# === Template genérico p/ software ===========================================\n",
    "GENERIC_SW_SCHEMA = {\n",
    "    \"cisco_product_id\": \"\",\n",
    "    \"commercial_name\": \"\",\n",
    "    \"product_type\": \"software\",\n",
    "    \"category\": \"\",\n",
    "    \"subcategory\": \"\",\n",
    "    \"lifecycle\": {\"status\": \"active\", \"eos_announced\": None, \"last_support_date\": None},\n",
    "    \"license_model\": {\"type\": \"subscription\", \"term\": None, \"seats_or_nodes\": None, \"includes_support\": True},\n",
    "    \"entitlements\": {\"features\": [], \"tier\": None, \"usage_limits\": {}},\n",
    "    \"pricing_model\": {\"currency\": \"USD\", \"base_price\": 0.0, \"billing_cycle\": \"one_time\", \"pricing_tiers\": []},\n",
    "    \"dependencies\": {\"requires\": [], \"compatibility\": []},\n",
    "    \"regulatory\": {\"compliance\": []},\n",
    "    \"metadata\": {\"vendor_sku_aliases\": [], \"notes\": \"\"}\n",
    "}\n",
    "\n",
    "# === Normalização das categorias =============================================\n",
    "HW_CATEGORY_MAP = {\n",
    "    \"switch\": \"Switches\", \"switches\": \"Switches\",\n",
    "    \"router\": \"Routers\", \"routers\": \"Routers\",\n",
    "    \"firewall\": \"Firewall\",\n",
    "    \"wireless\": \"Wireless\", \"access point\": \"Wireless\", \"ap\": \"Wireless\",\n",
    "    \"antenna\": \"Antennas\", \"antennas\": \"Antennas\",\n",
    "    \"cabling\": \"Cabling\",\n",
    "    \"connector\": \"Connectors\", \"connectors\": \"Connectors\",\n",
    "}\n",
    "SW_CATEGORY_MAP = {\n",
    "    \"license\": \"Licenses\", \"licensing\": \"Licenses\",\n",
    "    \"subscription\": \"Subscriptions\",\n",
    "    \"support\": \"Support\",\n",
    "    \"cloud\": \"Cloud Services\", \"service\": \"Cloud Services\",\n",
    "}\n",
    "\n",
    "def normalize_hw_category(raw: str) -> str | None:\n",
    "    if not raw: return None\n",
    "    s = str(raw).strip().lower()\n",
    "    for key, cat in HW_CATEGORY_MAP.items():\n",
    "        if key in s:\n",
    "            return cat\n",
    "    if s in {v.lower() for v in HW_CATEGORY_MAP.values()}:\n",
    "        return s.title()\n",
    "    return None\n",
    "\n",
    "def normalize_sw_category(raw: str) -> str | None:\n",
    "    if not raw: return None\n",
    "    s = str(raw).strip().lower()\n",
    "    for key, cat in SW_CATEGORY_MAP.items():\n",
    "        if key in s:\n",
    "            return cat\n",
    "    if s in {v.lower() for v in HW_CATEGORY_MAP.values()}:\n",
    "        return s.title()\n",
    "    return None\n",
    "\n",
    "# === Detecção de colunas no Excel ============================================\n",
    "def detect_columns(df: pd.DataFrame) -> dict:\n",
    "    cols = {c: re.sub(r\"\\s+\", \"\", str(c).strip().lower()) for c in df.columns}\n",
    "    out = {\"sku\": None, \"desc\": None, \"price\": None, \"category\": None, \"category_type\": None, \"subcategory\": None}\n",
    "\n",
    "    for col, norm in cols.items():\n",
    "        if out[\"sku\"] is None and (norm == \"sku\" or \"partnumber\" in norm or norm == \"part\" or \"sku\" in norm):\n",
    "            out[\"sku\"] = col\n",
    "        elif out[\"desc\"] is None and (norm in {\"desc\",\"description\",\"name\"} or \"desc\" in norm or \"description\" in norm):\n",
    "            out[\"desc\"] = col\n",
    "        elif out[\"price\"] is None and (norm in {\"price\",\"pri\",\"list\"} or \"price\" in norm or norm == \"pri\"):\n",
    "            out[\"price\"] = col\n",
    "        elif out[\"category_type\"] is None and re.fullmatch(r\"category[-_]?type\", norm):\n",
    "            out[\"category_type\"] = col\n",
    "        elif out[\"category\"] is None and (norm == \"category\" or ((\"category\" in norm) and (\"type\" not in norm))):\n",
    "            out[\"category\"] = col\n",
    "        elif out[\"subcategory\"] is None and (\"subcategory\" in norm or \"sub-category\" in norm or norm == \"sub_category\"):\n",
    "            out[\"subcategory\"] = col\n",
    "\n",
    "    missing = [k for k, v in out.items() if v is None and k in (\"sku\",\"desc\",\"price\")]\n",
    "    if missing:\n",
    "        raise RuntimeError(f\"Excel sem colunas obrigatórias: {missing}. Detectado: {out}\")\n",
    "    return out\n",
    "\n",
    "def read_excel_rows(xlsx_path: Path) -> pd.DataFrame:\n",
    "    if not xlsx_path.exists():\n",
    "        raise FileNotFoundError(f\"Excel não encontrado: {xlsx_path}\")\n",
    "    df = pd.read_excel(xlsx_path, engine=\"openpyxl\")\n",
    "    cols = detect_columns(df)\n",
    "\n",
    "    # Limpa preço (vírgula decimal, separadores, etc.)\n",
    "    price_series = (\n",
    "        df[cols[\"price\"]]\n",
    "        .astype(str)\n",
    "        .str.replace(r\"[^\\d\\.,-]\", \"\", regex=True)\n",
    "        .str.replace(r\"\\.(?=\\d{3},)\", \"\", regex=True)  # remove separador de milhar antes de vírgula decimal\n",
    "        .str.replace(\",\", \".\", regex=False)\n",
    "    )\n",
    "    df[\"_price\"] = pd.to_numeric(price_series, errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "    df[\"_sku\"]   = df[cols[\"sku\"]].astype(str).str.strip()\n",
    "    df[\"_name\"]  = df[cols[\"desc\"]].astype(str).str.strip()\n",
    "    df[\"_cat\"]   = df[cols[\"category\"]].astype(str).str.strip() if cols[\"category\"] else \"\"\n",
    "    df[\"_cat_type\"] = df[cols[\"category_type\"]].astype(str).str.strip() if cols[\"category_type\"] else \"\"\n",
    "    df[\"_sub\"]   = df[cols[\"subcategory\"]].astype(str).str.strip() if cols[\"subcategory\"] else \"\"\n",
    "    return df\n",
    "\n",
    "# === LLM (enriquecimento opcional) ===========================================\n",
    "def _extract_json(text: str) -> dict:\n",
    "    \"\"\"Aceita resposta com/sem fences e retorna um dict JSON.\"\"\"\n",
    "    t = text.strip()\n",
    "    if t.startswith(\"```\"):\n",
    "        t = re.sub(r\"^```[a-zA-Z0-9]*\\s*\", \"\", t)\n",
    "        t = re.sub(r\"\\s*```$\", \"\", t)\n",
    "    s = t.find(\"{\"); e = t.rfind(\"}\")\n",
    "    if s != -1 and e != -1 and e > s:\n",
    "        t = t[s:e+1]\n",
    "    return json.loads(t)\n",
    "\n",
    "def _count_filled(obj) -> int:\n",
    "    c = 0\n",
    "    if isinstance(obj, dict):\n",
    "        for v in obj.values(): c += _count_filled(v)\n",
    "    elif isinstance(obj, list):\n",
    "        for v in obj: c += _count_filled(v)\n",
    "    else:\n",
    "        if obj not in (None, \"\", []): c += 1\n",
    "    return c\n",
    "\n",
    "def _diff_keys(before: dict, after: dict, prefix=\"\"):\n",
    "    changes = []\n",
    "    for k in after.keys():\n",
    "        b = before.get(k, None)\n",
    "        a = after.get(k, None)\n",
    "        path = f\"{prefix}.{k}\" if prefix else k\n",
    "        if isinstance(a, dict) and isinstance(b, dict):\n",
    "            changes += _diff_keys(b, a, prefix=path)\n",
    "        elif isinstance(a, list) and isinstance(b, list):\n",
    "            if len(a) != len(b): changes.append(path + \"[]\")\n",
    "        else:\n",
    "            if (b in (None, \"\", []) and a not in (None, \"\", [])) or (b != a):\n",
    "                changes.append(path)\n",
    "    return changes\n",
    "\n",
    "# Model config\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "MODEL_TEMP = 0.3\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=MODEL_TEMP)\n",
    "\n",
    "ENRICH_PROMPT = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a Cisco product data normalizer.\n",
    "\n",
    "You receive:\n",
    "- A PARTIAL product JSON (with SKU, name/description, raw category and base price).\n",
    "- A TARGET SCHEMA (with the exact keys/structure we must output).\n",
    "\n",
    "# GOAL\n",
    "Fill ALL missing or empty fields you can reasonably infer from the SKU, product name/description and category.\n",
    "Prefer realistic, conservative values (no marketing fluff). Keep units when applicable. If you don't know, leave null.\n",
    "\n",
    "# STRICT RULES\n",
    "- Output exactly the same key structure as TARGET SCHEMA (no extra/missing keys).\n",
    "- Do NOT modify existing non-empty values in the partial JSON — only fill blanks.\n",
    "- For hardware, prioritize filling `technical_profile.hardware_attributes` (ports, poe_* fields, uplinks, stacking, wifi_standard), `dependencies`, and `compatibility`.\n",
    "- For software, prioritize filling `license_model.term`, `billing_cycle`, `entitlements.features/tier`, and `dependencies`.\n",
    "- Keep currency as provided. Do not invent prices. Be concise and consistent.\n",
    "\n",
    "--- PARTIAL_JSON ---\n",
    "{partial}\n",
    "\n",
    "--- TARGET_SCHEMA ---\n",
    "{schema}\n",
    "\n",
    "Return ONLY a JSON object that matches the target schema (no explanations).\"\"\"\n",
    ")\n",
    "\n",
    "def enrich_with_llm(partial: dict, schema_obj: dict, cache_key: str) -> dict:\n",
    "    if not ENRICH_WITH_LLM:\n",
    "        return partial\n",
    "    if cache_key in CACHE:\n",
    "        return CACHE[cache_key]\n",
    "\n",
    "    chain = ENRICH_PROMPT | llm\n",
    "    tries = 0\n",
    "    while True:\n",
    "        tries += 1\n",
    "        try:\n",
    "            resp = chain.invoke({\n",
    "                \"partial\": json.dumps(partial, ensure_ascii=False, indent=2),\n",
    "                \"schema\":  json.dumps(schema_obj, ensure_ascii=False, indent=2),\n",
    "            })\n",
    "            enriched_json = _extract_json(resp.content)\n",
    "\n",
    "            # Merge: schema baseline -> partial -> enriched\n",
    "            out = copy.deepcopy(schema_obj)\n",
    "\n",
    "            def deep_merge(dst, src):\n",
    "                for k, v in src.items():\n",
    "                    if isinstance(v, dict) and isinstance(dst.get(k), dict):\n",
    "                        deep_merge(dst[k], v)\n",
    "                    else:\n",
    "                        dst[k] = v\n",
    "\n",
    "            before = copy.deepcopy(out)\n",
    "            deep_merge(out, partial)\n",
    "            deep_merge(out, enriched_json)\n",
    "\n",
    "            # Logs de enriquecimento\n",
    "            before_count = _count_filled(partial)\n",
    "            after_count  = _count_filled(out)\n",
    "            delta        = after_count - before_count\n",
    "            if delta <= 0:\n",
    "                print(f\"ℹ️  {cache_key}: LLM retornou pouca coisa (delta={delta}).\")\n",
    "            else:\n",
    "                changed = _diff_keys(partial, out)\n",
    "                changed_preview = \", \".join(changed[:8]) + (\" ...\" if len(changed) > 8 else \"\")\n",
    "                print(f\"✅ {cache_key}: +{delta} campos → {changed_preview}\")\n",
    "\n",
    "            CACHE[cache_key] = out\n",
    "            if (len(CACHE) % 10) == 0:\n",
    "                _save_cache(CACHE_PATH, CACHE)\n",
    "            return out\n",
    "\n",
    "        except Exception as e:\n",
    "            if tries >= 3:\n",
    "                print(f\"⚠️ LLM falhou para {cache_key}: {e} — usando partial.\")\n",
    "                return partial\n",
    "            time.sleep(1.2)\n",
    "\n",
    "# === Persistência incremental por categoria ===================================\n",
    "def append_item_to_json(filepath: Path, item: dict):\n",
    "    if filepath.exists():\n",
    "        try:\n",
    "            arr = json.loads(filepath.read_text(encoding=\"utf-8\"))\n",
    "            if not isinstance(arr, list):\n",
    "                arr = []\n",
    "        except Exception:\n",
    "            arr = []\n",
    "    else:\n",
    "        arr = []\n",
    "    arr.append(item)\n",
    "    filepath.write_text(json.dumps(arr, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "# === Pipeline principal =======================================================\n",
    "def build_catalog_from_excel(\n",
    "    xlsx_path: Path = XLSX_PATH,\n",
    "    max_items_per_category: int | None = MAX_ITEMS_PER_CATEGORY,\n",
    "    limit_categories: list[str] | None = LIMIT_CATEGORIES,\n",
    "    verbose: bool = True\n",
    "):\n",
    "    df = read_excel_rows(xlsx_path)\n",
    "    if verbose:\n",
    "        print(f\"Rows in Excel: {len(df)}\")\n",
    "\n",
    "    buckets_hw = defaultdict(list)\n",
    "    buckets_sw = defaultdict(list)\n",
    "\n",
    "    records = df.to_dict(orient=\"records\")\n",
    "    for rec in tqdm(records, desc=\"Classifying rows\", disable=not verbose):\n",
    "        sku   = rec.get(\"_sku\", \"\").strip()\n",
    "        name  = rec.get(\"_name\", \"\").strip()\n",
    "        price = float(rec.get(\"_price\", 0.0) or 0.0)\n",
    "        raw_cat = rec.get(\"_cat\", \"\")\n",
    "        raw_type= rec.get(\"_cat_type\", \"\")\n",
    "        subcat  = rec.get(\"_sub\", \"\")\n",
    "\n",
    "        # 1) Decide Hardware/Software pelo Category-Type, se existir\n",
    "        pt = None\n",
    "        rt = raw_type.strip().lower()\n",
    "        if rt.startswith(\"hard\"):\n",
    "            pt = \"hardware\"\n",
    "        elif rt.startswith(\"soft\"):\n",
    "            pt = \"software\"\n",
    "\n",
    "        # 2) Normaliza categoria\n",
    "        hw_cat = normalize_hw_category(raw_cat)    # ex.: \"Wireless\"\n",
    "        sw_cat = normalize_sw_category(raw_cat)    # ex.: \"Wireless\" ou \"Licenses\"\n",
    "\n",
    "        # 3) Se não deu pra decidir tipo pelo Category-Type, decide por categoria\n",
    "        if not pt:\n",
    "            pt = \"hardware\" if hw_cat else (\"software\" if sw_cat else \"hardware\")\n",
    "\n",
    "        # 4) Categoria final\n",
    "        category = hw_cat if pt == \"hardware\" else (sw_cat or (raw_cat.strip().title() if raw_cat else \"Licenses\"))\n",
    "\n",
    "        # 5) Fallback por texto do produto (hardware)\n",
    "        if pt == \"hardware\" and not hw_cat:\n",
    "            txt = f\"{name} {sku}\".lower()\n",
    "            if \"switch\" in txt:             category = \"Switches\"\n",
    "            elif \"router\" in txt:           category = \"Routers\"\n",
    "            elif \"firewall\" in txt:         category = \"Firewall\"\n",
    "            elif \"access point\" in txt or \"ap \" in txt or txt.startswith(\"ap-\"): category = \"Wireless\"\n",
    "            elif \"antenna\" in txt:          category = \"Antennas\"\n",
    "            elif \"cable\" in txt:            category = \"Cabling\"\n",
    "            elif \"connector\" in txt:        category = \"Connectors\"\n",
    "\n",
    "        if limit_categories and category not in limit_categories:\n",
    "            continue\n",
    "\n",
    "        if pt == \"hardware\":\n",
    "            schema = SCHEMAS_HW.get(category)\n",
    "            if not schema:\n",
    "                if verbose:\n",
    "                    print(f\"↪️  Sem schema p/ HW category='{category}', SKU={sku} — pulando\")\n",
    "                continue\n",
    "            base = copy.deepcopy(schema)\n",
    "            base[\"cisco_product_id\"] = sku\n",
    "            base[\"commercial_name\"] = name\n",
    "            base[\"product_type\"] = \"hardware\"\n",
    "            base.setdefault(\"pricing_model\", {})\n",
    "            base[\"pricing_model\"][\"currency\"] = base[\"pricing_model\"].get(\"currency\", \"USD\")\n",
    "            base[\"pricing_model\"][\"base_price\"] = price\n",
    "            base[\"technical_profile\"] = base.get(\"technical_profile\", {})\n",
    "            base[\"technical_profile\"][\"category\"] = category\n",
    "            base[\"technical_profile\"][\"subcategory\"] = subcat or \"\"\n",
    "            buckets_hw[category].append(base)\n",
    "\n",
    "        else:\n",
    "            schema = SCHEMAS_SW.get(category, GENERIC_SW_SCHEMA)\n",
    "            base = copy.deepcopy(schema)\n",
    "            base[\"cisco_product_id\"] = sku\n",
    "            base[\"commercial_name\"] = name\n",
    "            base[\"product_type\"] = \"software\"\n",
    "            base[\"category\"] = category\n",
    "            base[\"pricing_model\"] = base.get(\"pricing_model\", {})\n",
    "            base[\"pricing_model\"][\"currency\"] = base[\"pricing_model\"].get(\"currency\", \"USD\")\n",
    "            base[\"pricing_model\"][\"base_price\"] = price\n",
    "            if \"subcategory\" not in base:\n",
    "                base[\"subcategory\"] = subcat or \"\"\n",
    "            buckets_sw[category].append(base)\n",
    "\n",
    "    counts = {\"hardware\": 0, \"software\": 0, \"files\": 0}\n",
    "\n",
    "    # HARDWARE → 1 arquivo por categoria\n",
    "    for category, items in buckets_hw.items():\n",
    "        out_file = OUTPUT_DIR_HW / f\"hw_{category.replace(' ', '_').lower()}.json\"\n",
    "        if verbose: print(f\"\\n[HW] {category}: {len(items)} itens → {out_file}\")\n",
    "        n = 0\n",
    "        for base in tqdm(items, desc=f\"Enrich HW/{category}\", disable=not verbose):\n",
    "            sku = base.get(\"cisco_product_id\", \"\")\n",
    "            schema = SCHEMAS_HW[category]\n",
    "            enriched = enrich_with_llm(base, schema, cache_key=f\"HW::{category}::{sku}\")\n",
    "            append_item_to_json(out_file, enriched)\n",
    "            counts[\"hardware\"] += 1\n",
    "            n += 1\n",
    "            if max_items_per_category and n >= max_items_per_category:\n",
    "                if verbose: print(f\"  ↪️  Limit reached ({max_items_per_category}) for HW/{category}\")\n",
    "                break\n",
    "        counts[\"files\"] += 1\n",
    "\n",
    "    # SOFTWARE → 1 arquivo por categoria\n",
    "    for category, items in buckets_sw.items():\n",
    "        out_file = OUTPUT_DIR_SW / f\"sw_{category.replace(' ', '_').lower()}.json\"\n",
    "        if verbose: print(f\"\\n[SW] {category}: {len(items)} itens → {out_file}\")\n",
    "        n = 0\n",
    "        for base in tqdm(items, desc=f\"Enrich SW/{category}\", disable=not verbose):\n",
    "            sku = base.get(\"cisco_product_id\", \"\")\n",
    "            schema = SCHEMAS_SW.get(category, GENERIC_SW_SCHEMA)\n",
    "            enriched = enrich_with_llm(base, schema, cache_key=f\"SW::{category}::{sku}\")\n",
    "            append_item_to_json(out_file, enriched)\n",
    "            counts[\"software\"] += 1\n",
    "            n += 1\n",
    "            if max_items_per_category and n >= max_items_per_category:\n",
    "                if verbose: print(f\"  ↪️  Limit reached ({max_items_per_category}) for SW/{category}\")\n",
    "                break\n",
    "        counts[\"files\"] += 1\n",
    "\n",
    "    _save_cache(CACHE_PATH, CACHE)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n=== Summary ===\")\n",
    "        print(counts)\n",
    "    return counts\n",
    "\n",
    "# === EXECUÇÃO (teste rápido) ==================================================\n",
    "summary = build_catalog_from_excel(\n",
    "    xlsx_path=XLSX_PATH,\n",
    "    max_items_per_category=MAX_ITEMS_PER_CATEGORY,\n",
    "    limit_categories=LIMIT_CATEGORIES,   # ex.: [\"Wireless\",\"Switches\"]\n",
    "    verbose=True\n",
    ")\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52e0780-2339-48e2-b486-cb889f87badd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08f751d-59c4-48dd-aca6-4fd33ec5cbfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b24062-475c-424f-bf0c-b7ab8eee18d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "72661b1a-b5de-4329-bbeb-d061f975ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= DEBUG CONFIG =================\n",
    "DEBUG_ENRICH = True\n",
    "DEBUG_DIR = Path(\"out/debug_raw\")\n",
    "DEBUG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# =============== UTILS ==========================\n",
    "def _extract_json(text: str) -> dict:\n",
    "    \"\"\"Aceita resposta com/sem fences e retorna um dict JSON.\"\"\"\n",
    "    t = text.strip()\n",
    "    # remove codefence se vier\n",
    "    if t.startswith(\"```\"):\n",
    "        t = re.sub(r\"^```[a-zA-Z0-9]*\\s*\", \"\", t)\n",
    "        t = re.sub(r\"\\s*```$\", \"\", t)\n",
    "    s = t.find(\"{\"); e = t.rfind(\"}\")\n",
    "    if s != -1 and e != -1 and e > s:\n",
    "        t = t[s:e+1]\n",
    "    return json.loads(t)\n",
    "\n",
    "def _count_filled(obj) -> int:\n",
    "    c = 0\n",
    "    if isinstance(obj, dict):\n",
    "        for v in obj.values(): c += _count_filled(v)\n",
    "    elif isinstance(obj, list):\n",
    "        for v in obj: c += _count_filled(v)\n",
    "    else:\n",
    "        if obj not in (None, \"\", []): c += 1\n",
    "    return c\n",
    "\n",
    "def _diff_keys(before: dict, after: dict, prefix=\"\"):\n",
    "    changes = []\n",
    "    for k in after.keys():\n",
    "        b = before.get(k, None)\n",
    "        a = after.get(k, None)\n",
    "        path = f\"{prefix}.{k}\" if prefix else k\n",
    "        if isinstance(a, dict) and isinstance(b, dict):\n",
    "            changes += _diff_keys(b, a, prefix=path)\n",
    "        elif isinstance(a, list) and isinstance(b, list):\n",
    "            if len(a) != len(b): changes.append(path + \"[]\")\n",
    "        else:\n",
    "            if (b in (None, \"\", []) and a not in (None, \"\", [])) or (b != a):\n",
    "                changes.append(path)\n",
    "    return changes\n",
    "\n",
    "def _validate_structure_against_schema(schema_obj: dict, data_obj: dict, prefix=\"\"):\n",
    "    \"\"\"Retorna listas (missing_keys, extra_keys) para auditoria rápida.\"\"\"\n",
    "    missing, extra = [], []\n",
    "    # chaves que existem no schema mas não no dado\n",
    "    for k in schema_obj.keys():\n",
    "        if k not in data_obj:\n",
    "            missing.append(f\"{prefix}{k}\")\n",
    "        else:\n",
    "            if isinstance(schema_obj[k], dict) and isinstance(data_obj[k], dict):\n",
    "                m, e = _validate_structure_against_schema(schema_obj[k], data_obj[k], prefix=f\"{prefix}{k}.\")\n",
    "                missing += m; extra += e\n",
    "            # se schema é dict e dado é lista ou primitivo, não forçamos, só reportar diferença de tipo se quiser\n",
    "    # chaves extras no dado\n",
    "    for k in data_obj.keys():\n",
    "        if k not in schema_obj:\n",
    "            extra.append(f\"{prefix}{k}\")\n",
    "    return missing, extra\n",
    "# ===============================================\n",
    "\n",
    "# ======= LLM CONFIG (forçar JSON) ==============\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "MODEL_TEMP = 0.3\n",
    "# Força JSON puro\n",
    "llm_json = ChatOpenAI(model=MODEL_NAME, temperature=MODEL_TEMP,\n",
    "                      response_format={\"type\": \"json_object\"})\n",
    "\n",
    "ENRICH_PROMPT = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a Cisco product data normalizer.\n",
    "\n",
    "You receive:\n",
    "- A PARTIAL product JSON (with SKU, name/description, raw category and base price).\n",
    "- A TARGET SCHEMA (with the exact keys/structure we must output).\n",
    "\n",
    "# GOAL\n",
    "Fill ALL missing or empty fields you can reasonably infer from the SKU, product name/description and category.\n",
    "Prefer realistic, conservative values (no marketing fluff). Keep units when applicable. If you don't know, leave null.\n",
    "\n",
    "# STRICT RULES\n",
    "- Output exactly the same key structure as TARGET SCHEMA (no extra/missing keys).\n",
    "- Do NOT modify existing non-empty values in the partial JSON — only fill blanks.\n",
    "- For hardware, prioritize filling `technical_profile.hardware_attributes` (ports, poe_* fields, uplinks, stacking, wifi_standard), `dependencies`, and `compatibility`.\n",
    "- For software, prioritize filling `license_model.term`, `billing_cycle`, `entitlements.features/tier`, and `dependencies`.\n",
    "- Keep currency as provided. Do not invent prices. Be concise and consistent.\n",
    "\n",
    "--- PARTIAL_JSON ---\n",
    "{partial}\n",
    "\n",
    "--- TARGET_SCHEMA ---\n",
    "{schema}\n",
    "\n",
    "Return ONLY a JSON object that matches the target schema (no explanations).\"\"\"\n",
    ")\n",
    "\n",
    "def enrich_with_llm(partial: dict, schema_obj: dict, cache_key: str) -> dict:\n",
    "    \"\"\"Enriquece o 'partial' segundo 'schema_obj'.\n",
    "       Salva debug: prompt e resposta crus; valida estrutura; loga delta de campos.\"\"\"\n",
    "    if not ENRICH_WITH_LLM:\n",
    "        return partial\n",
    "    if cache_key in CACHE:\n",
    "        return CACHE[cache_key]\n",
    "\n",
    "    chain = ENRICH_PROMPT | llm_json\n",
    "    tries = 0\n",
    "    while True:\n",
    "        tries += 1\n",
    "        try:\n",
    "            # 1) chama LLM\n",
    "            input_vars = {\n",
    "                \"partial\": json.dumps(partial, ensure_ascii=False, indent=2),\n",
    "                \"schema\":  json.dumps(schema_obj, ensure_ascii=False, indent=2),\n",
    "            }\n",
    "            resp = chain.invoke(input_vars)\n",
    "            raw_text = resp.content\n",
    "\n",
    "            # 2) DEBUG: salva prompt + resposta crua\n",
    "            if DEBUG_ENRICH:\n",
    "                (DEBUG_DIR / f\"{cache_key.replace('::','__')}.prompt.json\").write_text(\n",
    "                    json.dumps(input_vars, ensure_ascii=False, indent=2), encoding=\"utf-8\"\n",
    "                )\n",
    "                (DEBUG_DIR / f\"{cache_key.replace('::','__')}.raw.txt\").write_text(\n",
    "                    raw_text, encoding=\"utf-8\"\n",
    "                )\n",
    "\n",
    "            # 3) extrai JSON\n",
    "            enriched_json = _extract_json(raw_text)\n",
    "\n",
    "            # 4) merge: schema -> partial -> enriched\n",
    "            out = copy.deepcopy(schema_obj)\n",
    "            def deep_merge(dst, src):\n",
    "                for k, v in src.items():\n",
    "                    if isinstance(v, dict) and isinstance(dst.get(k), dict):\n",
    "                        deep_merge(dst[k], v)\n",
    "                    else:\n",
    "                        # mantém o que veio em src (inclusive preenchendo vazios)\n",
    "                        dst[k] = v\n",
    "\n",
    "            before = copy.deepcopy(out)\n",
    "            deep_merge(out, partial)\n",
    "            deep_merge(out, enriched_json)\n",
    "\n",
    "            # 5) valida estrutura contra schema\n",
    "            missing, extra = _validate_structure_against_schema(schema_obj, out)\n",
    "            if DEBUG_ENRICH and (missing or extra):\n",
    "                print(f\"⚠️  {cache_key}: estrutura divergente — missing={len(missing)} extra={len(extra)}\")\n",
    "                (DEBUG_DIR / f\"{cache_key.replace('::','__')}.missing_keys.txt\").write_text(\n",
    "                    \"\\n\".join(missing), encoding=\"utf-8\"\n",
    "                )\n",
    "                (DEBUG_DIR / f\"{cache_key.replace('::','__')}.extra_keys.txt\").write_text(\n",
    "                    \"\\n\".join(extra), encoding=\"utf-8\"\n",
    "                )\n",
    "\n",
    "            # 6) log de campos preenchidos\n",
    "            before_count = _count_filled(partial)\n",
    "            after_count  = _count_filled(out)\n",
    "            delta        = after_count - before_count\n",
    "            if delta <= 0:\n",
    "                print(f\"ℹ️  {cache_key}: LLM não acrescentou campos (delta={delta}). Veja {DEBUG_DIR} para prompt/saída.\")\n",
    "            else:\n",
    "                changed = _diff_keys(partial, out)\n",
    "                changed_preview = \", \".join(changed[:8]) + (\" ...\" if len(changed) > 8 else \"\")\n",
    "                print(f\"✅ {cache_key}: +{delta} campos → {changed_preview}\")\n",
    "\n",
    "            # 7) cache + return\n",
    "            CACHE[cache_key] = out\n",
    "            if (len(CACHE) % 10) == 0:\n",
    "                _save_cache(CACHE_PATH, CACHE)\n",
    "            return out\n",
    "\n",
    "        except Exception as e:\n",
    "            # DEBUG: log de erro com a última resposta crua (se houver)\n",
    "            print(f\"❌  {cache_key}: falha ao parsear/mesclar — {e}\")\n",
    "            if tries >= 3:\n",
    "                print(f\"⚠️  {cache_key}: desistindo após {tries} tentativas. Usando partial.\")\n",
    "                return partial\n",
    "            time.sleep(1.2)\n",
    "\n",
    "# ============ SMOKE TEST (rode antes do pipeline) ============================\n",
    "def smoke_test_enricher(sku: str, name: str, price: float, category: str, schema_bank: dict):\n",
    "    \"\"\"\n",
    "    Faz um teste isolado de enriquecimento com 1 produto.\n",
    "    - schema_bank: SCHEMAS_HW ou SCHEMAS_SW\n",
    "    \"\"\"\n",
    "    schema = schema_bank.get(category)\n",
    "    if not schema:\n",
    "        print(f\"🚫 Schema não encontrado para categoria '{category}'.\")\n",
    "        return\n",
    "    partial = copy.deepcopy(schema)\n",
    "    # preenche apenas o mínimo (como vem do Excel)\n",
    "    partial[\"cisco_product_id\"] = sku\n",
    "    partial[\"commercial_name\"]  = name\n",
    "    if \"product_type\" in partial:\n",
    "        # mantém como está no schema\n",
    "        pass\n",
    "    # preço\n",
    "    if \"pricing_model\" in partial:\n",
    "        partial[\"pricing_model\"][\"base_price\"] = price\n",
    "        partial[\"pricing_model\"][\"currency\"] = partial[\"pricing_model\"].get(\"currency\", \"USD\")\n",
    "\n",
    "    out = enrich_with_llm(partial, schema, cache_key=f\"SMOKE::{category}::{sku}\")\n",
    "    print(\"\\n--- RESULTADO (resumo) ---\")\n",
    "    print(json.dumps(out, ensure_ascii=False, indent=2)[:1200], \"...\\n\")\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4942d6de-e7f2-47b9-9e77-24d775a36075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️  SMOKE::Switches::MS225-48FP-HW: LLM não acrescentou campos (delta=0). Veja out\\debug_raw para prompt/saída.\n",
      "\n",
      "--- RESULTADO (resumo) ---\n",
      "{\n",
      "  \"cisco_product_id\": \"MS225-48FP-HW\",\n",
      "  \"commercial_name\": \"Meraki MS225-48FP L2 Stacking PoE Switch\",\n",
      "  \"product_type\": \"hardware\",\n",
      "  \"category\": \"Switches\",\n",
      "  \"subcategory\": null,\n",
      "  \"lifecycle\": {\n",
      "    \"status\": \"active\",\n",
      "    \"eos_announced\": null,\n",
      "    \"last_support_date\": null\n",
      "  },\n",
      "  \"pricing_model\": {\n",
      "    \"type\": \"one_time\",\n",
      "    \"currency\": \"USD\",\n",
      "    \"base_price\": 7770.0,\n",
      "    \"elig_pct\": 0.01,\n",
      "    \"pricing_tiers\": [\n",
      "      {\n",
      "        \"min_quantity\": 1,\n",
      "        \"price\": 0.0,\n",
      "        \"effective\": \"2025-01-01\",\n",
      "        \"discount_rules\": [\n",
      "          {\n",
      "            \"type\": \"volume\",\n",
      "            \"threshold\": 10,\n",
      "            \"discount_pct\": 0.15\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"dependencies\": {\n",
      "    \"required_components\": [],\n",
      "    \"compatible_with\": []\n",
      "  },\n",
      "  \"regulatory\": {\n",
      "    \"certifications\": [\n",
      "      \"FCC\",\n",
      "      \"CE\",\n",
      "      \"IC\"\n",
      "    ],\n",
      "    \"environment\": {\n",
      "      \"oper_temp_min_c\": -5,\n",
      "      \"oper_temp_max_c\": 45,\n",
      "      \"ip_rating\": null\n",
      "    }\n",
      "  },\n",
      "  \"attributes\": {\n",
      "    \"switch\": {\n",
      "      \"layer\": \"L2/L3\",\n",
      "      \"ports_total\": 48,\n",
      "      \"poe_ports\": 48,\n",
      "      \"poe_budget_w\": 740,\n",
      "      \"uplinks\": [\n",
      "        {\n",
      "          \"type\": \"SFP+\",\n",
      "          \"speed_gbps\": 10,\n",
      "          \" ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = smoke_test_enricher(\n",
    "    sku=\"MS225-48FP-HW\",\n",
    "    name=\"Meraki MS225-48FP L2 Stacking PoE Switch\",\n",
    "    price=7770.00,\n",
    "    category=\"Switches\",            # deve bater com o nome no schema_*.json\n",
    "    schema_bank=SCHEMAS_HW          # ou SCHEMAS_SW para software\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122aed35-8393-4ae7-a07e-8e87d04f8172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "db09cb7f-9738-454e-8d68-d86d4f676af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in Excel: 4267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying rows: 100%|██████████| 4267/4267 [00:00<00:00, 21345.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[HW] Wireless: 509 itens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich HW/Wireless:   0%|          | 2/509 [00:00<00:09, 55.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↪️  Limit reached (3) for HW/Wireless\n",
      "\n",
      "[HW] Switches: 1563 itens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich HW/Switches:   0%|          | 2/1563 [00:00<00:50, 31.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↪️  Limit reached (3) for HW/Switches\n",
      "\n",
      "[HW] Routers: 604 itens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich HW/Routers:   0%|          | 2/604 [00:00<00:29, 20.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↪️  Limit reached (3) for HW/Routers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[HW] Firewall: 178 itens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich HW/Firewall:   1%|          | 2/178 [00:00<00:04, 43.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↪️  Limit reached (3) for HW/Firewall\n",
      "\n",
      "[HW] Connectors: 20 itens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich HW/Connectors:  10%|█         | 2/20 [00:00<00:00, 51.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↪️  Limit reached (3) for HW/Connectors\n",
      "\n",
      "[HW] Cabling: 3 itens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich HW/Cabling:  67%|██████▋   | 2/3 [00:00<00:00, 74.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↪️  Limit reached (3) for HW/Cabling\n",
      "\n",
      "[HW] Antennas: 8 itens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich HW/Antennas:  25%|██▌       | 2/8 [00:00<00:00, 101.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↪️  Limit reached (3) for HW/Antennas\n",
      "\n",
      "[SW] Wireless: 545 itens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich SW/Wireless:   0%|          | 2/545 [00:00<00:07, 77.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↪️  Limit reached (3) for SW/Wireless\n",
      "\n",
      "[SW] Switches: 515 itens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich SW/Switches:   0%|          | 2/515 [00:00<00:07, 68.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↪️  Limit reached (3) for SW/Switches\n",
      "\n",
      "[SW] Licenses: 9 itens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich SW/Licenses:  22%|██▏       | 2/9 [00:00<00:00, 67.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↪️  Limit reached (3) for SW/Licenses\n",
      "\n",
      "[SW] Routers: 260 itens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich SW/Routers:   1%|          | 2/260 [00:00<00:03, 65.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↪️  Limit reached (3) for SW/Routers\n",
      "\n",
      "[SW] Firewall: 52 itens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich SW/Firewall:   4%|▍         | 2/52 [00:00<00:00, 63.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↪️  Limit reached (3) for SW/Firewall\n",
      "\n",
      "[SW] Connectors: 1 itens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrich SW/Connectors: 100%|██████████| 1/1 [00:00<00:00, 220.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Summary ===\n",
      "{'hardware': 21, 'software': 16, 'files': 13}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hardware': 21, 'software': 16, 'files': 13}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% ============================== Setup / Imports ==============================\n",
    "import os, json, time, copy, re\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# -------------------- Controles de execução --------------------\n",
    "ENRICH_WITH_LLM = True          # True => preenche via LLM\n",
    "MAX_ITEMS_PER_CATEGORY = 3       # None = sem limite (use 3 p/ teste)\n",
    "LIMIT_CATEGORIES = None          # ex.: [\"Switches\",\"Wireless\"] para filtrar\n",
    "DEBUG_SMOKE = True               # salva prompt/resposta da LLM p/ auditoria\n",
    "TQDM_VERBOSE = True\n",
    "\n",
    "# -------------------- Caminhos --------------------\n",
    "XLSX_PATH       = Path(\"data/raw/Cisco_Pricing.xlsx\")\n",
    "SCHEMAS_HW_DIR  = Path(\"schemas/hardware\")\n",
    "SCHEMAS_SW_DIR  = Path(\"schemas/software\")\n",
    "OUTPUT_DIR_HW   = Path(\"out/hardware\")\n",
    "OUTPUT_DIR_SW   = Path(\"out/software\")\n",
    "CACHE_PATH      = Path(\"out/enrichment_cache.json\")\n",
    "DEBUG_DIR       = Path(\"out/debug_llm\")\n",
    "\n",
    "for p in [OUTPUT_DIR_HW, OUTPUT_DIR_SW, CACHE_PATH.parent, DEBUG_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# %% ============================== Cache utils =================================\n",
    "def _load_cache(path: Path) -> dict:\n",
    "    if path.exists():\n",
    "        try:\n",
    "            return json.loads(path.read_text(encoding=\"utf-8\"))\n",
    "        except Exception:\n",
    "            return {}\n",
    "    return {}\n",
    "\n",
    "def _save_cache(path: Path, data: dict):\n",
    "    tmp = path.with_suffix(\".tmp.json\")\n",
    "    tmp.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    tmp.replace(path)\n",
    "\n",
    "CACHE = _load_cache(CACHE_PATH)\n",
    "\n",
    "# %% ======================= Carregamento dos schemas ===========================\n",
    "def load_schema_templates(dir_path: Path, expect_hw=True):\n",
    "    \"\"\"\n",
    "    Lê todos os schema_*.json e devolve: { \"<Categoria>\": <dict do schema> }\n",
    "    Ex.: schema_switches.json -> categoria \"Switches\"\n",
    "    \"\"\"\n",
    "    templates = {}\n",
    "    if dir_path.exists():\n",
    "        for fp in sorted(dir_path.glob(\"*.json\")):\n",
    "            try:\n",
    "                obj = json.loads(fp.read_text(encoding=\"utf-8\"))\n",
    "                cat = obj.get(\"category\")\n",
    "                if not cat:\n",
    "                    base = fp.stem.replace(\"schema_\", \"\")\n",
    "                    cat = base.replace(\"_\", \" \").title()\n",
    "                templates[cat] = obj\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Erro lendo {fp}: {e}\")\n",
    "    else:\n",
    "        if expect_hw:\n",
    "            print(f\"⚠️ Diretório de schemas não existe: {dir_path}\")\n",
    "    return templates\n",
    "\n",
    "SCHEMAS_HW = load_schema_templates(SCHEMAS_HW_DIR, expect_hw=True)\n",
    "SCHEMAS_SW = load_schema_templates(SCHEMAS_SW_DIR, expect_hw=False)\n",
    "\n",
    "if not SCHEMAS_HW:\n",
    "    raise RuntimeError(\n",
    "        f\"Nenhum schema de hardware encontrado em {SCHEMAS_HW_DIR}. \"\n",
    "        \"Coloque seus arquivos schema_*.json lá (ex.: schema_switches.json).\"\n",
    "    )\n",
    "\n",
    "# Fallback genérico se não houver schema de software específico\n",
    "GENERIC_SW_SCHEMA = {\n",
    "    \"cisco_product_id\": \"\",\n",
    "    \"commercial_name\": \"\",\n",
    "    \"product_type\": \"software\",\n",
    "    \"category\": \"\",\n",
    "    \"subcategory\": \"\",\n",
    "    \"lifecycle\": {\"status\": \"active\", \"eos_announced\": None, \"last_support_date\": None},\n",
    "    \"license_model\": {\"type\": \"subscription\", \"term\": \"1Y\", \"seats_or_nodes\": 1, \"includes_support\": True},\n",
    "    \"entitlements\": {\"features\": [], \"tier\": \"Base\", \"usage_limits\": {}},\n",
    "    \"pricing_model\": {\"currency\": \"USD\", \"base_price\": 0.0, \"billing_cycle\": \"yearly\", \"pricing_tiers\": []},\n",
    "    \"dependencies\": {\"requires\": [], \"compatibility\": []},\n",
    "    \"regulatory\": {\"compliance\": []},\n",
    "    \"metadata\": {\"vendor_sku_aliases\": [], \"notes\": \"\"}\n",
    "}\n",
    "\n",
    "# %% ======================= Normalização de categorias =========================\n",
    "HW_CATEGORY_MAP = {\n",
    "    \"switch\": \"Switches\", \"switches\": \"Switches\",\n",
    "    \"router\": \"Routers\", \"routers\": \"Routers\",\n",
    "    \"firewall\": \"Firewall\",\n",
    "    \"wireless\": \"Wireless\", \"access point\": \"Wireless\", \"ap \": \"Wireless\", \" ap-\": \"Wireless\",\n",
    "    \"antenna\": \"Antennas\", \"antennas\": \"Antennas\",\n",
    "    \"cabling\": \"Cabling\",\n",
    "    \"connector\": \"Connectors\", \"connectors\": \"Connectors\",\n",
    "}\n",
    "\n",
    "SW_CATEGORY_MAP = {\n",
    "    \"license\": \"Licenses\", \"licensing\": \"Licenses\",\n",
    "    \"subscription\": \"Subscriptions\",\n",
    "    \"support\": \"Support\",\n",
    "    \"cloud\": \"Cloud Services\", \"service\": \"Cloud Services\",\n",
    "    \"wireless\": \"Wireless\"  # permitir reuso de categoria\n",
    "}\n",
    "\n",
    "def normalize_hw_category(raw: str):\n",
    "    if not raw: return None\n",
    "    s = \" \" + str(raw).strip().lower() + \" \"\n",
    "    for key, cat in HW_CATEGORY_MAP.items():\n",
    "        if f\" {key} \" in s:\n",
    "            return cat\n",
    "    if str(raw).strip().title() in HW_CATEGORY_MAP.values():\n",
    "        return str(raw).strip().title()\n",
    "    return None\n",
    "\n",
    "def normalize_sw_category(raw: str):\n",
    "    if not raw: return None\n",
    "    s = \" \" + str(raw).strip().lower() + \" \"\n",
    "    for key, cat in SW_CATEGORY_MAP.items():\n",
    "        if f\" {key} \" in s:\n",
    "            return cat\n",
    "    if str(raw).strip().title() in HW_CATEGORY_MAP.values():\n",
    "        return str(raw).strip().title()\n",
    "    return None\n",
    "\n",
    "# ===== Heurística para detectar licenças/software pelo SKU/Desc =====\n",
    "_LICENSE_TOKENS = [\n",
    "    r\"^l-\", r\"^lic-\", r\"-lic($|[^a-z0-9])\", r\"\\blicen[cs]e\\b\", r\"\\blic\\b\",\n",
    "    r\"\\bdna\\b\", r\"\\bnw-?[ae]\\b\", r\"network advantage\", r\"network essentials\",\n",
    "    r\"\\bsubscription\\b\", r\"\\bsupport\\b\", r\"\\bsnt\\b\", r\"\\bsmart\\s*net\\b\",\n",
    "    r\"\\bmeraki license\\b\", r\"\\bco-term\\b\", r\"\\basa\\s*lic\\b\", r\"\\bfirepower\\s*license\\b\",\n",
    "    r\"\\b1y\\b\", r\"\\b3y\\b\", r\"\\b5y\\b\", r\"\\b1yr\\b\", r\"\\b3yr\\b\", r\"\\b5yr\\b\",\n",
    "]\n",
    "\n",
    "def is_license_like(sku: str, name: str) -> bool:\n",
    "    txt = f\"{sku} {name}\".strip().lower()\n",
    "    for pat in _LICENSE_TOKENS:\n",
    "        if re.search(pat, txt):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# %% ============================ Excel parsing =================================\n",
    "def detect_columns(df: pd.DataFrame) -> dict:\n",
    "    # alvo: Category-Type, Category, SKU, Desc, price, Elig_%\n",
    "    out = {\"category_type\": None, \"category\": None, \"sku\": None, \"desc\": None, \"price\": None, \"elig\": None}\n",
    "    for col in df.columns:\n",
    "        norm = re.sub(r\"\\s+\", \"\", str(col).strip().lower())\n",
    "        if out[\"category_type\"] is None and norm in {\"category-type\", \"categorytype\"}:\n",
    "            out[\"category_type\"] = col\n",
    "        elif out[\"category\"] is None and norm == \"category\":\n",
    "            out[\"category\"] = col\n",
    "        elif out[\"sku\"] is None and norm in {\"sku\",\"partnumber\",\"part\",\"part#\",\"productid\",\"product_id\"}:\n",
    "            out[\"sku\"] = col\n",
    "        elif out[\"desc\"] is None and norm in {\"desc\",\"description\",\"name\",\"productname\",\"product_name\"}:\n",
    "            out[\"desc\"] = col\n",
    "        elif out[\"price\"] is None and norm in {\"price\",\"list\",\"listprice\",\"list_price\"}:\n",
    "            out[\"price\"] = col\n",
    "        elif out[\"elig\"] is None and norm in {\"elig_%\",\"elig\",\"eligibility\",\"eligpercent\",\"eligibility%\",\"elig_pct\"}:\n",
    "            out[\"elig\"] = col\n",
    "\n",
    "    missing = [k for k in (\"sku\",\"desc\",\"price\") if out[k] is None]\n",
    "    if missing:\n",
    "        raise RuntimeError(f\"Excel sem colunas obrigatórias: {missing}. Detectado: {out}\")\n",
    "    return out\n",
    "\n",
    "def read_excel_rows(xlsx_path: Path) -> pd.DataFrame:\n",
    "    if not xlsx_path.exists():\n",
    "        raise FileNotFoundError(f\"Excel não encontrado: {xlsx_path}\")\n",
    "    df = pd.read_excel(xlsx_path, engine=\"openpyxl\")\n",
    "    cols = detect_columns(df)\n",
    "\n",
    "    # limpar preço\n",
    "    price_series = (\n",
    "        df[cols[\"price\"]]\n",
    "        .astype(str)\n",
    "        .str.replace(r\"[^\\d\\.,-]\", \"\", regex=True)\n",
    "        .str.replace(r\"\\.(?=\\d{3},)\", \"\", regex=True)\n",
    "        .str.replace(\",\", \".\", regex=False)\n",
    "    )\n",
    "    df[\"_price\"] = pd.to_numeric(price_series, errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "    elig_series = None\n",
    "    if cols[\"elig\"] is not None:\n",
    "        elig_series = (\n",
    "            df[cols[\"elig\"]]\n",
    "            .astype(str)\n",
    "            .str.replace(r\"[^\\d\\.,-]\", \"\", regex=True)\n",
    "            .str.replace(\",\", \".\", regex=False)\n",
    "        )\n",
    "        df[\"_elig\"] = pd.to_numeric(elig_series, errors=\"coerce\").fillna(0.0)\n",
    "    else:\n",
    "        df[\"_elig\"] = 0.0\n",
    "\n",
    "    df[\"_sku\"]  = df[cols[\"sku\"]].astype(str).str.strip()\n",
    "    df[\"_name\"] = df[cols[\"desc\"]].astype(str).str.strip()\n",
    "    df[\"_cat\"]  = df[cols[\"category\"]].astype(str).str.strip() if cols[\"category\"] else \"\"\n",
    "    df[\"_cat_type\"] = df[cols[\"category_type\"]].astype(str).str.strip() if cols[\"category_type\"] else \"\"\n",
    "    return df\n",
    "\n",
    "# %% ======================= Helpers de merge/trava =============================\n",
    "def pick_environment(sku: str, name: str, category: str) -> dict:\n",
    "    \"\"\"\n",
    "    Heurística simples para ambiente:\n",
    "    - Indoor enterprise (default): 0..45 °C, IP30\n",
    "    - Fanless/compact: 0..50 °C, IP30\n",
    "    - Outdoor (AP/switch outdoor): -20..55 °C, IP67\n",
    "    - Industrial/Rugged (IE/IR/IW etc): -40..75 °C, IP54 ou IP67\n",
    "    - Software/licença: sem ambiente (retornamos None para o caller tratar)\n",
    "    \"\"\"\n",
    "    txt = f\"{sku} {name}\".lower()\n",
    "    cat = (category or \"\").lower()\n",
    "\n",
    "    # Software (só pra segurança, mesmo que não seja chamado pra SW)\n",
    "    if cat in {\"licenses\", \"subscriptions\", \"support\", \"cloud services\"}:\n",
    "        return None\n",
    "\n",
    "    # Palavras-chave\n",
    "    is_outdoor = any(w in txt for w in [\"outdoor\", \"mr76\", \"mr86\", \"mr84\", \"ap-outdoor\"])\n",
    "    is_industrial = any(w in txt for w in [\"industrial\", \"rugged\", \"ie-\", \"ir\", \"iw\", \"cgr\", \"gr-\" , \"ic-\", \"ix-\"])\n",
    "    is_fanless = \"fanless\" in txt or \"compact\" in txt\n",
    "\n",
    "    # Wireless outdoor (Meraki/Cisco)\n",
    "    if is_outdoor or (\"wireless\" in cat and any(w in txt for w in [\"mr7\", \"mr8\"])):  # heurística leve\n",
    "        return {\"oper_temp_min_c\": -20, \"oper_temp_max_c\": 55, \"ip_rating\": \"IP67\"}\n",
    "\n",
    "    # Industrial/rugged switches/routers (IE/IR/CGR)\n",
    "    if is_industrial:\n",
    "        # alguns IE/IR são IP54; se mencionar \"outdoor\"/\"ip67\", sobe\n",
    "        ip = \"IP67\" if \"ip67\" in txt or \"outdoor\" in txt else \"IP54\"\n",
    "        return {\"oper_temp_min_c\": -40, \"oper_temp_max_c\": 75, \"ip_rating\": ip}\n",
    "\n",
    "    # Indoor enterprise (default)\n",
    "    if is_fanless:\n",
    "        return {\"oper_temp_min_c\": 0, \"oper_temp_max_c\": 50, \"ip_rating\": \"IP30\"}\n",
    "\n",
    "    # Switch/AP enterprise normal\n",
    "    return {\"oper_temp_min_c\": 0, \"oper_temp_max_c\": 45, \"ip_rating\": \"IP30\"}\n",
    "\n",
    "\n",
    "\n",
    "def deep_get(obj, path_list, default=None):\n",
    "    cur = obj\n",
    "    for p in path_list:\n",
    "        if not isinstance(cur, dict) or p not in cur:\n",
    "            return default\n",
    "        cur = cur[p]\n",
    "    return cur\n",
    "\n",
    "def deep_set(obj, path_list, value):\n",
    "    cur = obj\n",
    "    for p in path_list[:-1]:\n",
    "        if p not in cur or not isinstance(cur[p], dict):\n",
    "            cur[p] = {}\n",
    "        cur = cur[p]\n",
    "    cur[path_list[-1]] = value\n",
    "\n",
    "def upsert_item_to_json(filepath: Path, item: dict, key=\"cisco_product_id\"):\n",
    "    arr = []\n",
    "    if filepath.exists():\n",
    "        try:\n",
    "            arr = json.loads(filepath.read_text(encoding=\"utf-8\"))\n",
    "            if not isinstance(arr, list):\n",
    "                arr = []\n",
    "        except Exception:\n",
    "            arr = []\n",
    "    sku = item.get(key)\n",
    "    arr = [x for x in arr if x.get(key) != sku]\n",
    "    arr.append(item)\n",
    "    filepath.write_text(json.dumps(arr, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "# Campos travados (do Excel)\n",
    "LOCK_PATHS = [\n",
    "    [\"cisco_product_id\"],\n",
    "    [\"commercial_name\"],\n",
    "    [\"product_type\"],\n",
    "    [\"pricing_model\", \"base_price\"],\n",
    "    [\"pricing_model\", \"elig_pct\"],\n",
    "    [\"technical_profile\", \"category\"],  # HW\n",
    "    [\"category\"],                      # SW\n",
    "]\n",
    "\n",
    "def apply_locks(enriched: dict, locked_from_excel: dict) -> dict:\n",
    "    out = copy.deepcopy(enriched)\n",
    "    for path in LOCK_PATHS:\n",
    "        val = deep_get(locked_from_excel, path, default=None)\n",
    "        if val is not None:\n",
    "            deep_set(out, path, val)\n",
    "    return out\n",
    "\n",
    "# %% ========================== LLM (enriquecimento) ===========================\n",
    "def _shape_from_schema(schema_obj):\n",
    "    \"\"\"\n",
    "    Gera a mesma estrutura de chaves do schema, mas zera TODOS os valores\n",
    "    para evitar que a LLM copie defaults do schema.\n",
    "    \"\"\"\n",
    "    if isinstance(schema_obj, dict):\n",
    "        out = {}\n",
    "        for k, v in schema_obj.items():\n",
    "            out[k] = _shape_from_schema(v)\n",
    "        return out\n",
    "    elif isinstance(schema_obj, list):\n",
    "        return [_shape_from_schema(schema_obj[0])] if schema_obj else []\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def _extract_json(text: str) -> dict:\n",
    "    t = text.strip()\n",
    "    if t.startswith(\"```\"):\n",
    "        t = re.sub(r\"^```[a-zA-Z0-9]*\\s*\", \"\", t)\n",
    "        t = re.sub(r\"\\s*```$\", \"\", t)\n",
    "    s = t.find(\"{\"); e = t.rfind(\"}\")\n",
    "    if s != -1 and e != -1 and e > s:\n",
    "        t = t[s:e+1]\n",
    "    return json.loads(t)\n",
    "\n",
    "def _has_nulls_or_empty(d):\n",
    "    if isinstance(d, dict):\n",
    "        for v in d.values():\n",
    "            if _has_nulls_or_empty(v):\n",
    "                return True\n",
    "        return False\n",
    "    if isinstance(d, list):\n",
    "        if len(d) == 0:\n",
    "            return True\n",
    "        return any(_has_nulls_or_empty(v) for v in d)\n",
    "    return d in (None, \"\", [])\n",
    "\n",
    "# ---- fallback programático para eliminar nulos restantes (plausível por categoria)\n",
    "def _fallback_fill_plausible(obj: dict, pt: str, category: str, sku: str, name: str) -> dict:\n",
    "    out = copy.deepcopy(obj)\n",
    "\n",
    "    def ensure(path, value):\n",
    "        cur = deep_get(out, path, None)\n",
    "        if cur in (None, \"\", []):\n",
    "            deep_set(out, path, value)\n",
    "\n",
    "    # ---- Defaults comuns\n",
    "    ensure([\"lifecycle\", \"status\"], \"active\")\n",
    "    ensure([\"lifecycle\", \"eos_announced\"], \"2030-12-31\")\n",
    "    ensure([\"lifecycle\", \"last_support_date\"], \"2035-12-31\")\n",
    "\n",
    "    ensure([\"pricing_model\", \"currency\"], \"USD\")\n",
    "    if pt == \"hardware\":\n",
    "        ensure([\"pricing_model\", \"type\"], \"one_time\")\n",
    "        # Subcategoria na RAIZ (se existir no schema) e em technical_profile\n",
    "        if \"subcategory\" in out and out[\"subcategory\"] in (None, \"\"):\n",
    "            out[\"subcategory\"] = \"access_switch\" if category == \"Switches\" else category.lower()\n",
    "        ensure(\n",
    "            [\"technical_profile\", \"subcategory\"],\n",
    "            out.get(\"subcategory\", \"access_switch\" if category == \"Switches\" else \"base\")\n",
    "        )\n",
    "    else:\n",
    "        ensure([\"pricing_model\", \"type\"], \"subscription\")\n",
    "        ensure([\"pricing_model\", \"billing_cycle\"], \"yearly\")\n",
    "        if \"subcategory\" in out and out[\"subcategory\"] in (None, \"\"):\n",
    "            out[\"subcategory\"] = \"feature_license\"\n",
    "\n",
    "    # Regulatory comuns\n",
    "    ensure([\"regulatory\", \"certifications\"], [\"FCC\", \"CE\", \"IC\"])\n",
    "    ensure([\"regulatory\", \"environment\", \"oper_temp_min_c\"], 0)\n",
    "    ensure([\"regulatory\", \"environment\", \"oper_temp_max_c\"], 50)\n",
    "    ensure([\"regulatory\", \"environment\", \"ip_rating\"], \"IP30\")\n",
    "\n",
    "    # ---- Específicos por categoria\n",
    "    txt = f\"{sku} {name}\".lower()\n",
    "\n",
    "    if pt == \"hardware\" and category == \"Firewall\":\n",
    "        ensure([\"attributes\", \"firewall\", \"fw_throughput_gbps\"], 1.0)\n",
    "        ensure([\"attributes\", \"firewall\", \"ngfw_throughput_gbps\"], 0.7)\n",
    "        ensure([\"attributes\", \"firewall\", \"ips_throughput_gbps\"], 0.6)\n",
    "        ensure([\"attributes\", \"firewall\", \"ipsec_vpn_gbps\"], 0.5)\n",
    "        ensure([\"attributes\", \"firewall\", \"max_sessions_m\"], 0.5)\n",
    "        ensure([\"attributes\", \"firewall\", \"interfaces\"], [{\"type\": \"GE\", \"qty\": 8}])\n",
    "        ensure([\"attributes\", \"firewall\", \"ha_supported\"], True)\n",
    "        ensure([\"attributes\", \"firewall\", \"utm_services\"], [\"IPS\", \"AV\", \"URL\"])\n",
    "\n",
    "    elif pt == \"hardware\" and category == \"Switches\":\n",
    "        ports = 48 if re.search(r\"\\b48\\b\", txt) else (24 if re.search(r\"\\b24\\b\", txt) else 24)\n",
    "        poe = 1 if (\"poe\" in txt or \"-p\" in sku.lower()) else 0\n",
    "        ensure([\"attributes\", \"switch\", \"layer\"], \"L2/L3\")\n",
    "        ensure([\"attributes\", \"switch\", \"ports_total\"], ports)\n",
    "        ensure([\"attributes\", \"switch\", \"poe_ports\"], ports if poe else 0)\n",
    "        ensure([\"attributes\", \"switch\", \"poe_budget_w\"], 740 if poe else 0)\n",
    "        ensure([\"attributes\", \"switch\", \"uplinks\"], [{\"type\": \"SFP+\", \"speed_gbps\": 10, \"qty\": 4}])\n",
    "        ensure([\"attributes\", \"switch\", \"stacking\", \"supported\"], True)\n",
    "        ensure([\"attributes\", \"switch\", \"stacking\", \"max_members\"], 8)\n",
    "        ensure([\"attributes\", \"switch\", \"stacking\", \"stack_bw_gbps\"], 80)\n",
    "        ensure([\"attributes\", \"switch\", \"switching_capacity_gbps\"], 216 if ports == 48 else 160)\n",
    "        ensure([\"attributes\", \"switch\", \"forwarding_mpps\"], 130 if ports == 48 else 95)\n",
    "        ensure([\"attributes\", \"switch\", \"latency_us\"], 3.2)\n",
    "        ensure([\"attributes\", \"switch\", \"features\"], [\"RSTP\", \"PVLAN\", \"ACLs\", \"QoS\"])\n",
    "\n",
    "    elif pt == \"hardware\" and category == \"Wireless\":\n",
    "        ensure([\"technical_profile\", \"subcategory\"], \"access_point\")\n",
    "        ensure([\"attributes\", \"wireless\", \"wifi_standard\"], \"802.11ax (Wi-Fi 6)\")\n",
    "        ensure([\"attributes\", \"wireless\", \"radios\"], [\"2.4 GHz\", \"5 GHz\"])\n",
    "        ensure([\"attributes\", \"wireless\", \"antenna_type\"], \"internal\")\n",
    "        ensure([\"attributes\", \"wireless\", \"throughput_mbps\"], 1200)\n",
    "        ensure([\"attributes\", \"wireless\", \"mounting\"], \"indoor\")\n",
    "        ensure([\"attributes\", \"wireless\", \"power_requirements\"], \"PoE+\")\n",
    "\n",
    "    elif pt == \"software\":\n",
    "        # Ajustes de licenças\n",
    "        if any(t in txt for t in [\"1y\", \"1yr\"]):\n",
    "            term = \"1Y\"\n",
    "        elif any(t in txt for t in [\"3y\", \"3yr\"]):\n",
    "            term = \"3Y\"\n",
    "        elif any(t in txt for t in [\"5y\", \"5yr\"]):\n",
    "            term = \"5Y\"\n",
    "        else:\n",
    "            term = \"1Y\"\n",
    "        ensure([\"license_model\", \"type\"], \"subscription\")\n",
    "        ensure([\"license_model\", \"term\"], term)\n",
    "        ensure([\"license_model\", \"seats_or_nodes\"], 1)\n",
    "        ensure([\"license_model\", \"includes_support\"], True)\n",
    "\n",
    "        if \"advantage\" in txt:\n",
    "            tier = \"Network Advantage\"\n",
    "            feats = [\"Advanced routing\", \"Segmentation\", \"Telemetry\"]\n",
    "        elif \"essentials\" in txt:\n",
    "            tier = \"Network Essentials\"\n",
    "            feats = [\"Layer 2/3 basic\", \"Access policies\", \"Basic monitoring\"]\n",
    "        elif \"dna\" in txt:\n",
    "            tier = \"Cisco DNA Advantage\"\n",
    "            feats = [\"SD-Access\", \"Automation\", \"Analytics\", \"Assurance\"]\n",
    "        else:\n",
    "            tier = \"Base\"\n",
    "            feats = [\"Basic feature set\"]\n",
    "        ensure([\"entitlements\", \"tier\"], tier)\n",
    "        ensure([\"entitlements\", \"features\"], feats)\n",
    "        ensure([\"pricing_model\", \"billing_cycle\"], \"yearly\")\n",
    "        ensure([\"regulatory\", \"compliance\"], [\"ISO/IEC 27001\", \"SOC 2\"])\n",
    "\n",
    "    # ---- Varredura final: nada pode ficar nulo/vazio\n",
    "    def fill_any_nulls(d):\n",
    "        if isinstance(d, dict):\n",
    "            for k, v in list(d.items()):\n",
    "                if v in (None, \"\", []):\n",
    "                    # defaults genéricos\n",
    "                    if k.endswith(\"_date\"):\n",
    "                        d[k] = \"2030-12-31\"\n",
    "                    elif k.endswith(\"_gbps\") or k.endswith(\"_mbps\"):\n",
    "                        d[k] = 1.0\n",
    "                    elif k.endswith(\"_w\"):\n",
    "                        d[k] = 15\n",
    "                    elif k.startswith(\"max_\"):\n",
    "                        d[k] = 1\n",
    "                    elif isinstance(v, list):\n",
    "                        d[k] = [\"N/A\"]\n",
    "                    else:\n",
    "                        d[k] = \"N/A\"\n",
    "                else:\n",
    "                    fill_any_nulls(v)\n",
    "        elif isinstance(d, list):\n",
    "            if not d:\n",
    "                d.append(\"N/A\")\n",
    "            else:\n",
    "                for i, v in enumerate(list(d)):\n",
    "                    if v in (None, \"\", []):\n",
    "                        d[i] = \"N/A\"\n",
    "                    elif isinstance(v, (dict, list)):\n",
    "                        fill_any_nulls(v)\n",
    "\n",
    "    fill_any_nulls(out)\n",
    "    return out\n",
    "\n",
    "# LLM setup\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.9)\n",
    "\n",
    "ENRICH_PROMPT = ChatPromptTemplate.from_template(\n",
    "    \"You are a Cisco product data engineer and domain expert.\\n\"\n",
    "    \"Task: Given a PARTIAL product JSON (from Cisco price list) and a TARGET SHAPE (keys only, no values),\\n\"\n",
    "    \"produce a COMPLETE JSON that fills ALL fields with realistic, conservative values.\\n\"\n",
    "    \"Hard rules:\\n\"\n",
    "    \"1) Do NOT modify these fields from the PARTIAL JSON: SKU (cisco_product_id), commercial_name, product_type,\\n\"\n",
    "    \"   pricing_model.base_price, pricing_model.elig_pct, and category (hardware: technical_profile.category | software: root category).\\n\"\n",
    "    \"2) The TARGET SHAPE only shows the keys; IGNORE any numeric/string examples from schemas.\\n\"\n",
    "    \"3) Your output must NOT contain null, empty strings, or empty arrays. Always infer plausible values.\\n\"\n",
    "    \"4) Be coherent with Cisco families and the category. Use typical ranges/specs for that category.\\n\"\n",
    "    \"5) Keep the exact key names/structure of the TARGET SHAPE; add realistic lists (2–6 items) where applicable.\\n\"\n",
    "    \"6) Currency = USD unless specified; keep units consistent.\\n\"\n",
    "    \"Return ONLY a valid JSON object.\\n\\n\"\n",
    "    \"<<<PARTIAL_JSON>>>\\n{partial}\\n<<<END_PARTIAL_JSON>>>\\n\\n\"\n",
    "    \"<<<TARGET_SHAPE>>>\\n{shape}\\n<<<END_TARGET_SHAPE>>>\"\n",
    ")\n",
    "\n",
    "FIX_NULLS_PROMPT = ChatPromptTemplate.from_template(\n",
    "    \"You previously generated a product JSON but it still has null/empty fields.\\n\"\n",
    "    \"Replace ALL null, empty strings, or empty arrays with realistic, conservative Cisco-like values.\\n\"\n",
    "    \"Do not change: SKU, commercial_name, product_type, pricing_model.base_price, pricing_model.elig_pct, category.\\n\"\n",
    "    \"Return ONLY a valid JSON with the same structure.\\n\\n\"\n",
    "    \"<<<CURRENT_JSON>>>\\n{current}\\n<<<END_CURRENT_JSON>>>\"\n",
    ")\n",
    "\n",
    "def enrich_with_llm_fill_all(partial: dict, schema_obj: dict, cache_key: str, debug_tag: str | None = None) -> dict:\n",
    "    if not ENRICH_WITH_LLM:\n",
    "        return partial\n",
    "    if cache_key in CACHE:\n",
    "        return CACHE[cache_key]\n",
    "\n",
    "    target_shape = _shape_from_schema(schema_obj)\n",
    "\n",
    "    chainA = ENRICH_PROMPT | llm\n",
    "    tries = 0\n",
    "    while True:\n",
    "        tries += 1\n",
    "        try:\n",
    "            resp = chainA.invoke({\n",
    "                \"partial\": json.dumps(partial, ensure_ascii=False, indent=2),\n",
    "                \"shape\":   json.dumps(target_shape, ensure_ascii=False, indent=2),\n",
    "            })\n",
    "            first = _extract_json(resp.content)\n",
    "            first_locked = apply_locks(first, partial)\n",
    "\n",
    "            if DEBUG_SMOKE and debug_tag:\n",
    "                (DEBUG_DIR / f\"{debug_tag}.prompt.json\").write_text(\n",
    "                    json.dumps({\n",
    "                        \"partial\": json.dumps(partial, ensure_ascii=False, indent=2),\n",
    "                        \"shape\":   json.dumps(target_shape, ensure_ascii=False, indent=2)\n",
    "                    }, ensure_ascii=False, indent=2),\n",
    "                    encoding=\"utf-8\"\n",
    "                )\n",
    "                (DEBUG_DIR / f\"{debug_tag}.first.txt\").write_text(\n",
    "                    json.dumps(first_locked, ensure_ascii=False, indent=2),\n",
    "                    encoding=\"utf-8\"\n",
    "                )\n",
    "\n",
    "            final_obj = first_locked\n",
    "\n",
    "            # Segunda passada para remover nulos/vazios\n",
    "            if _has_nulls_or_empty(final_obj):\n",
    "                chainB = FIX_NULLS_PROMPT | llm\n",
    "                resp2 = chainB.invoke({\n",
    "                    \"current\": json.dumps(final_obj, ensure_ascii=False, indent=2)\n",
    "                })\n",
    "                second = _extract_json(resp2.content)\n",
    "                final_obj = apply_locks(second, partial)\n",
    "\n",
    "                if DEBUG_SMOKE and debug_tag:\n",
    "                    (DEBUG_DIR / f\"{debug_tag}.fix.txt\").write_text(\n",
    "                        json.dumps(final_obj, ensure_ascii=False, indent=2),\n",
    "                        encoding=\"utf-8\"\n",
    "                    )\n",
    "\n",
    "            # Terceira camada: fallback programático (garantia hard de não-nulos)\n",
    "            if _has_nulls_or_empty(final_obj):\n",
    "                pt = partial.get(\"product_type\", \"hardware\")\n",
    "                category = partial.get(\"category\") or deep_get(partial, [\"technical_profile\", \"category\"], \"Unknown\")\n",
    "                final_obj = _fallback_fill_plausible(final_obj, pt, category, partial[\"cisco_product_id\"], partial[\"commercial_name\"])\n",
    "\n",
    "            CACHE[cache_key] = final_obj\n",
    "            if tries % 3 == 1:\n",
    "                _save_cache(CACHE_PATH, CACHE)\n",
    "            return final_obj\n",
    "\n",
    "        except Exception as e:\n",
    "            if tries >= 3:\n",
    "                print(f\"⚠️ LLM falhou para {cache_key}: {e} — usando partial.\")\n",
    "                return partial\n",
    "            time.sleep(1.0)\n",
    "\n",
    "# %% ====================== Persistência por categoria ==========================\n",
    "def save_item_by_category(item: dict, product_type: str, category: str):\n",
    "    if product_type == \"hardware\":\n",
    "        out_file = OUTPUT_DIR_HW / f\"hw_{category.replace(' ', '_').lower()}.json\"\n",
    "    else:\n",
    "        out_file = OUTPUT_DIR_SW / f\"sw_{category.replace(' ', '_').lower()}.json\"\n",
    "    upsert_item_to_json(out_file, item)\n",
    "\n",
    "# %% ============================= Pipeline ====================================\n",
    "def build_catalog_from_excel(\n",
    "    xlsx_path: Path = XLSX_PATH,\n",
    "    max_items_per_category: int | None = MAX_ITEMS_PER_CATEGORY,\n",
    "    limit_categories: list | None = LIMIT_CATEGORIES,\n",
    "    verbose: bool = True\n",
    "):\n",
    "    df = read_excel_rows(xlsx_path)\n",
    "    if verbose:\n",
    "        print(f\"Rows in Excel: {len(df)}\")\n",
    "\n",
    "    buckets_hw = defaultdict(list)\n",
    "    buckets_sw = defaultdict(list)\n",
    "\n",
    "    # classificar registros\n",
    "    records = df.to_dict(orient=\"records\")\n",
    "    for rec in tqdm(records, desc=\"Classifying rows\", disable=not TQDM_VERBOSE):\n",
    "        sku     = rec.get(\"_sku\", \"\").strip()\n",
    "        name    = rec.get(\"_name\", \"\").strip()\n",
    "        price   = float(rec.get(\"_price\", 0.0) or 0.0)\n",
    "        elig    = float(rec.get(\"_elig\", 0.0) or 0.0)\n",
    "        raw_cat = rec.get(\"_cat\", \"\")\n",
    "        raw_ct  = rec.get(\"_cat_type\", \"\")\n",
    "\n",
    "        # 1) Tipo via Category-Type\n",
    "        pt = None\n",
    "        if raw_ct:\n",
    "            s = raw_ct.strip().lower()\n",
    "            if s.startswith(\"hard\"): pt = \"hardware\"\n",
    "            elif s.startswith(\"soft\"): pt = \"software\"\n",
    "\n",
    "        # 2) Heurística forte de licença/software pelo SKU/Desc\n",
    "        if is_license_like(sku, name):\n",
    "            pt = \"software\"\n",
    "\n",
    "        # 3) Normaliza categorias\n",
    "        hw_cat = normalize_hw_category(raw_cat)\n",
    "        sw_cat = normalize_sw_category(raw_cat)\n",
    "\n",
    "        # 4) Se ainda não deu para decidir por CT/heurística, decide por categoria\n",
    "        if not pt:\n",
    "            pt = \"hardware\" if hw_cat else (\"software\" if sw_cat else \"hardware\")\n",
    "\n",
    "        # 5) Categoria final\n",
    "        category = hw_cat if pt == \"hardware\" else (sw_cat or \"Licenses\")\n",
    "\n",
    "        if limit_categories and category not in limit_categories:\n",
    "            continue\n",
    "\n",
    "        if pt == \"hardware\":\n",
    "            schema = SCHEMAS_HW.get(category)\n",
    "            if not schema:\n",
    "                if verbose:\n",
    "                    print(f\"↪️  Sem schema p/ HW category='{category}', SKU={sku} — pulando\")\n",
    "                continue\n",
    "            partial = {\n",
    "                \"cisco_product_id\": sku,\n",
    "                \"commercial_name\":  name,\n",
    "                \"product_type\":     \"hardware\",\n",
    "                \"pricing_model\": {\"base_price\": price, \"elig_pct\": elig},\n",
    "                \"technical_profile\": {\"category\": category}\n",
    "            }\n",
    "            buckets_hw[category].append((partial, schema))\n",
    "        else:\n",
    "            schema = SCHEMAS_SW.get(category, GENERIC_SW_SCHEMA)\n",
    "            partial = {\n",
    "                \"cisco_product_id\": sku,\n",
    "                \"commercial_name\":  name,\n",
    "                \"product_type\":     \"software\",\n",
    "                \"category\":         category,\n",
    "                \"pricing_model\": {\"base_price\": price, \"elig_pct\": elig}\n",
    "            }\n",
    "            buckets_sw[category].append((partial, schema))\n",
    "\n",
    "    counts = {\"hardware\": 0, \"software\": 0, \"files\": 0}\n",
    "\n",
    "    # HARDWARE\n",
    "    for category, items in buckets_hw.items():\n",
    "        n = 0\n",
    "        if verbose: print(f\"\\n[HW] {category}: {len(items)} itens\")\n",
    "        for partial, schema in tqdm(items, desc=f\"Enrich HW/{category}\", disable=not TQDM_VERBOSE):\n",
    "            sku = partial.get(\"cisco_product_id\", \"\")\n",
    "            debug_tag = f\"HW__{category.replace(' ','_')}__{sku}\"\n",
    "            enriched = enrich_with_llm_fill_all(partial, schema, cache_key=f\"HW::{category}::{sku}\", debug_tag=debug_tag)\n",
    "            # Garantia hard final (se sobrou algo vazio)\n",
    "            if _has_nulls_or_empty(enriched):\n",
    "                enriched = _fallback_fill_plausible(enriched, \"hardware\", category, sku, partial[\"commercial_name\"])\n",
    "            save_item_by_category(enriched, \"hardware\", category)\n",
    "            counts[\"hardware\"] += 1\n",
    "            n += 1\n",
    "            if max_items_per_category and n >= max_items_per_category:\n",
    "                if verbose: print(f\"  ↪️  Limit reached ({max_items_per_category}) for HW/{category}\")\n",
    "                break\n",
    "        counts[\"files\"] += 1\n",
    "\n",
    "    # SOFTWARE\n",
    "    for category, items in buckets_sw.items():\n",
    "        n = 0\n",
    "        if verbose: print(f\"\\n[SW] {category}: {len(items)} itens\")\n",
    "        for partial, schema in tqdm(items, desc=f\"Enrich SW/{category}\", disable=not TQDM_VERBOSE):\n",
    "            sku = partial.get(\"cisco_product_id\", \"\")\n",
    "            debug_tag = f\"SW__{category.replace(' ','_')}__{sku}\"\n",
    "            enriched = enrich_with_llm_fill_all(partial, schema, cache_key=f\"SW::{category}::{sku}\", debug_tag=debug_tag)\n",
    "            if _has_nulls_or_empty(enriched):\n",
    "                enriched = _fallback_fill_plausible(enriched, \"software\", category, sku, partial[\"commercial_name\"])\n",
    "            save_item_by_category(enriched, \"software\", category)\n",
    "            counts[\"software\"] += 1\n",
    "            n += 1\n",
    "            if max_items_per_category and n >= max_items_per_category:\n",
    "                if verbose: print(f\"  ↪️  Limit reached ({max_items_per_category}) for SW/{category}\")\n",
    "                break\n",
    "        counts[\"files\"] += 1\n",
    "\n",
    "    _save_cache(CACHE_PATH, CACHE)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n=== Summary ===\")\n",
    "        print(counts)\n",
    "    return counts\n",
    "\n",
    "# %% ============================ Execução (teste) =============================\n",
    "summary = build_catalog_from_excel(\n",
    "    xlsx_path=XLSX_PATH,\n",
    "    max_items_per_category=MAX_ITEMS_PER_CATEGORY,\n",
    "    limit_categories=LIMIT_CATEGORIES,   # ex.: [\"Switches\",\"Wireless\"]\n",
    "    verbose=True\n",
    ")\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c840ac19-85b2-4fa1-b11f-d080d643c8ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50c8301-6082-4861-9f77-2f6d47e979a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ccc09d3-5818-4622-be38-9bcf449445e8",
   "metadata": {},
   "source": [
    "## Most Recent Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cda27065-1d68-4a28-8139-ff619606284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instalações necessárias\n",
    "#!pip install -q -U langchain-openai tavily-python langchain beautifulsoup4 chromadb pypdf unstructured\n",
    "\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_tools_agent, AgentExecutor\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- CONFIGURAÇÃO DAS CHAVES DE API ---\n",
    "# ⚠️ Cole suas chaves aqui.\n",
    "OPENAI_API_KEY = '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'\n",
    "TAVILY_API_KEY = \"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\" # <-- SUA CHAVE DA TAVILY AQUI\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a947bf1-83e8-4424-a996-26b90699c66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data loaded: 16 products\n",
      "✅ Recommendation data prepared\n",
      "\n",
      "🎻 [Orchestrator] «Design a secure branch‑office solution for 50 users with Wi‑Fi 6, firewall and PoE switches. Provide pricing.»\n",
      "\n",
      "🎨 [Solution Designer]\n",
      "🧐 [Reviewer‑LLM] – skipped (placeholder)\n",
      "⏩ Technical Agent skipped (solution design already provides specs)\n",
      "\n",
      "💰 [Pricing Agent]\n",
      "\n",
      "🎯 [Synthesizer]\n",
      "🚀 Solution Design\n",
      "Design a secure branch-office solution for 50 users with Wi-Fi 6, firewall, and PoE switches.\n",
      "\n",
      "🔧 Components:\n",
      "1. ASA 5516-X with FirePOWER Services (1×) – Firewall\n",
      "2. Meraki MR53E Access Point (5×) – Access Point\n",
      "3. Meraki Dual Band Omni Antennas (5×) – Antenna\n",
      "\n",
      "✅ Justification:\n",
      "The ASA5516-FPWR-K9 provides robust firewall capabilities with FirePOWER services, ensuring security for the branch office. The MR53E-HW access points support Wi-Fi 6, providing high-speed wireless connectivity for up to 50 users. The MA-ANT-20 omnidirectional antennas enhance the coverage and performance of the access points, ensuring reliable connectivity throughout the office.\n",
      "\n",
      "🔧 Technical Specifications:\n",
      "\n",
      "• ASA 5516-X with FirePOWER Services (ASA5516-FPWR-K9)\n",
      "  - Category: security\n",
      "  - Subcategory: firewall\n",
      "  - Throughput: 4 Gbps\n",
      "  - Interfaces: 8x GE\n",
      "  - Vpn Throughput: 1 Gbps\n",
      "  - Threat Throughput: 500 Mbps\n",
      "  - Encryption: 3DES/AES\n",
      "\n",
      "• Meraki MR53E Access Point (MR53E-HW)\n",
      "  - Category: wireless\n",
      "  - Subcategory: access_point\n",
      "  - Wifi Standard: 802.11ax\n",
      "  - Throughput: 2.5 Gbps\n",
      "  - Antenna Type: external\n",
      "  - Mounting: indoor\n",
      "  - Power Requirements: PoE+\n",
      "\n",
      "• Meraki Dual Band Omni Antennas (MA-ANT-20)\n",
      "  - Category: antenna\n",
      "  - Subcategory: omni\n",
      "  - Frequency: 2.4/5 GHz\n",
      "  - Gain: 5 dBi\n",
      "  - Connector Type: RP-TNC\n",
      "\n",
      "💵 Pricing:\n",
      "- ASA 5516-X with FirePOWER Services (1×): USD 5995.00\n",
      "- Meraki MR53E Access Point (5×): USD 8495.00\n",
      "- Meraki Dual Band Omni Antennas (5×): USD 995.00\n",
      "\n",
      "TOTAL ESTIMATED: USD 15485.00\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# Cisco Sales Assistant – fluxo completo (julho/2025)\n",
    "# =============================================================\n",
    "\"\"\"\n",
    "Cria um agente LangGraph capaz de:\n",
    "  • analisar a consulta do cliente\n",
    "  • projetar uma solução (Solution Designer)\n",
    "  • buscar especificações técnicas\n",
    "  • precificar os componentes\n",
    "  • sintetizar tudo em uma resposta final\n",
    "\n",
    "Requisitos:\n",
    "  pip install langchain langgraph langchain-openai scikit-learn numpy\n",
    "\"\"\"\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 0. Imports\n",
    "# -------------------------------------------------------------\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict, TypedDict, Optional\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from langchain.tools import tool\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1. Carregar catálogo Cisco\n",
    "# -------------------------------------------------------------\n",
    "product_dict: Dict[str, Dict] = {}\n",
    "PRICELIST_PATH = \"data/raw/pricelist.json\"      # ajuste se necessário\n",
    "\n",
    "try:\n",
    "    with open(PRICELIST_PATH, encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        products = data if isinstance(data, list) else data.get(\"products\", [])\n",
    "        for p in products:\n",
    "            pid = p.get(\"cisco_product_id\")\n",
    "            if pid:\n",
    "                product_dict[pid] = p\n",
    "    print(f\"✅ Data loaded: {len(product_dict)} products\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading product data: {e}\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2. Preparar embeddings TF‑IDF para recomendações\n",
    "# -------------------------------------------------------------\n",
    "def prepare_recommendation_data():\n",
    "    \"\"\"Gera matriz TF‑IDF a partir do catálogo para busca semântica.\"\"\"\n",
    "    texts: List[str] = []\n",
    "    for p in product_dict.values():\n",
    "        hw = p.get(\"technical_profile\", {}).get(\"hardware_attributes\", {})\n",
    "        txt = (\n",
    "            f\"{p.get('commercial_name', '')} {p.get('product_type', '')} \"\n",
    "            + \" \".join(f\"{k}={v}\" for k, v in hw.items())\n",
    "        ).strip()\n",
    "        texts.append(txt)\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "    matrix = vectorizer.fit_transform(texts) if texts else None\n",
    "    return vectorizer, matrix\n",
    "\n",
    "\n",
    "vectorizer, tfidf_matrix = prepare_recommendation_data()\n",
    "print(\"✅ Recommendation data prepared\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3. Helper – lista enxuta de produtos (TOP‑K)\n",
    "# -------------------------------------------------------------\n",
    "def get_product_list_str(requirements: str, top_k: int = 50) -> str:\n",
    "    if tfidf_matrix is None:\n",
    "        return \"(catalog empty)\"\n",
    "    vec = vectorizer.transform([requirements])\n",
    "    sims = cosine_similarity(vec, tfidf_matrix).flatten()\n",
    "    idxs = sims.argsort()[::-1][:top_k]\n",
    "    prods = [list(product_dict.values())[i] for i in idxs]\n",
    "    return \"\\n\".join(\n",
    "        f\"- {p['cisco_product_id']}: {p['commercial_name']} \"\n",
    "        f\"({p['product_type']})\"\n",
    "        for p in prods\n",
    "    )\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4. Ferramentas (LangChain @tool)\n",
    "# -------------------------------------------------------------\n",
    "@tool\n",
    "def get_product_price(part_number: str) -> Dict:\n",
    "    \"\"\"Retrieve pricing information for a Cisco product.\"\"\"\n",
    "    prod = product_dict.get(part_number)\n",
    "    if not prod:\n",
    "        return {\"error\": f\"Product {part_number} not found\", \"part_number\": part_number}\n",
    "    pricing = prod.get(\"pricing_model\", {})\n",
    "    return {\n",
    "        \"price\": pricing.get(\"base_price\", 0.0),\n",
    "        \"currency\": pricing.get(\"currency\", \"USD\"),\n",
    "        \"description\": prod.get(\"commercial_name\", \"\"),\n",
    "        \"part_number\": part_number,\n",
    "        \"product_type\": prod.get(\"product_type\", \"\"),\n",
    "    }\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_technical_specs(part_number: str) -> Dict:\n",
    "    \"\"\"Retrieve hardware specifications for a Cisco product.\"\"\"\n",
    "    prod = product_dict.get(part_number)\n",
    "    if not prod:\n",
    "        return {\"error\": f\"Product {part_number} not found\", \"part_number\": part_number}\n",
    "    hw = prod.get(\"technical_profile\", {}).get(\"hardware_attributes\", {})\n",
    "    if not hw:\n",
    "        return {\"error\": f\"No technical specs for {part_number}\", \"part_number\": part_number}\n",
    "    return {\n",
    "        \"specifications\": hw,\n",
    "        \"description\": prod.get(\"commercial_name\", \"\"),\n",
    "        \"part_number\": part_number,\n",
    "        \"product_type\": prod.get(\"product_type\", \"\"),\n",
    "    }\n",
    "\n",
    "\n",
    "@tool\n",
    "def recommend_products(requirements: str, max_results: int = 3) -> List[Dict]:\n",
    "    \"\"\"Recommend Cisco products that best match the given requirements.\"\"\"\n",
    "    if tfidf_matrix is None:\n",
    "        return [{\"error\": \"Catalog not indexed\"}]\n",
    "    vec = vectorizer.transform([requirements])\n",
    "    sims = cosine_similarity(vec, tfidf_matrix).flatten()\n",
    "    idxs = sims.argsort()[::-1][:max_results]\n",
    "    base = list(product_dict.values())\n",
    "    return [\n",
    "        {\n",
    "            \"part_number\": base[i][\"cisco_product_id\"],\n",
    "            \"commercial_name\": base[i][\"commercial_name\"],\n",
    "            \"product_type\": base[i][\"product_type\"],\n",
    "            \"similarity_score\": float(sims[i]),\n",
    "        }\n",
    "        for i in idxs\n",
    "    ]\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 5. Pydantic models\n",
    "# -------------------------------------------------------------\n",
    "class SolutionComponent(BaseModel):\n",
    "    part_number: str = Field(description=\"Cisco product ID\")\n",
    "    quantity: int = Field(default=1, description=\"Quantity required\")\n",
    "    role: str = Field(description=\"Role in the solution\")\n",
    "\n",
    "\n",
    "class SolutionDesign(BaseModel):\n",
    "    summary: str\n",
    "    components: List[SolutionComponent]\n",
    "    justification: str\n",
    "\n",
    "\n",
    "class AgentRoutingDecision(BaseModel):\n",
    "    needs_design: bool = False\n",
    "    needs_technical: bool = False\n",
    "    needs_pricing: bool = False\n",
    "    query_parts: Dict[str, str] = Field(default_factory=dict)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 6. LLM e prompts\n",
    "# -------------------------------------------------------------\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# — Orchestrator (corrigido)\n",
    "orchestrator_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a Cisco sales orchestration system.\n",
    "\n",
    "Analyse the user query and decide which specialised agents are needed:\n",
    "  • Solution Designer   → needs_design\n",
    "  • Technical Agent     → needs_technical\n",
    "  • Pricing Agent       → needs_pricing\n",
    "\n",
    "ALWAYS output a JSON object that matches the schema shown in\n",
    "{{format_instructions}}.\n",
    "\n",
    "User query: {{query}}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "orchestrator_agent = orchestrator_prompt | llm.with_structured_output(\n",
    "    AgentRoutingDecision\n",
    ")\n",
    "\n",
    "# — Solution Designer\n",
    "design_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a Cisco Solution Architect. Design a complete solution.\n",
    "\n",
    "Customer Requirements:\n",
    "{requirements}\n",
    "\n",
    "Available Cisco Products:\n",
    "{product_list}\n",
    "\n",
    "Return only part_numbers that appear above.\n",
    "Output as JSON in the schema provided.\"\"\"\n",
    ")\n",
    "\n",
    "llm_creative = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.4)  # só o designer\n",
    "\n",
    "design_agent = (\n",
    "    {\n",
    "        \"requirements\": lambda x: x[\"requirements\"],\n",
    "        \"product_list\": lambda x: get_product_list_str(x[\"requirements\"]),\n",
    "        \"format_instructions\": lambda x: x[\"format_instructions\"],\n",
    "    }\n",
    "    | design_prompt\n",
    "    | llm_creative.with_structured_output(SolutionDesign)\n",
    ")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 7. State type\n",
    "# -------------------------------------------------------------\n",
    "class AgentState(TypedDict):\n",
    "    user_query: str\n",
    "    orchestrator_decision: Optional[AgentRoutingDecision]\n",
    "    solution_design: Optional[SolutionDesign]\n",
    "    integrity_errors: List[str]\n",
    "    rule_errors: List[str]          # ← NEW\n",
    "    technical_results: List[Dict]\n",
    "    pricing_results: List[Dict]\n",
    "    final_response: str\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 8. Nó — Orchestrator\n",
    "# -------------------------------------------------------------\n",
    "def orchestrator_node(state: AgentState) -> AgentState:\n",
    "    print(f\"\\n🎻 [Orchestrator] «{state['user_query']}»\")\n",
    "\n",
    "    q = state[\"user_query\"]\n",
    "\n",
    "    # 1) tentativa normal com o LLM\n",
    "    try:\n",
    "        decision = orchestrator_agent.invoke(\n",
    "            {\n",
    "                \"query\": q,\n",
    "                \"format_instructions\": AgentRoutingDecision.schema(),\n",
    "            }\n",
    "        )\n",
    "    except Exception:\n",
    "        print(\"⚠️ LLM parse fail → empty decision\")\n",
    "        decision = AgentRoutingDecision()\n",
    "\n",
    "    # 2) heurística se vier tudo falso\n",
    "    if not any([decision.needs_design, decision.needs_technical, decision.needs_pricing]):\n",
    "        q_low = q.lower()\n",
    "        decision = AgentRoutingDecision(\n",
    "            needs_design=any(w in q_low for w in [\"design\", \"architecture\", \"solution\"]),\n",
    "            needs_technical=\"spec\" in q_low,\n",
    "            needs_pricing=any(w in q_low for w in [\"price\", \"cost\", \"quote\", \"pricing\"]),\n",
    "            query_parts={},\n",
    "        )\n",
    "\n",
    "    # 3) salva no estado e retorna\n",
    "    state[\"orchestrator_decision\"] = decision\n",
    "    return state\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 9. Nó — Solution Designer\n",
    "# -------------------------------------------------------------\n",
    "def solution_design_node(state: AgentState) -> AgentState:\n",
    "    print(\"\\n🎨 [Solution Designer]\")\n",
    "    design = design_agent.invoke(\n",
    "        {\"requirements\": state[\"user_query\"], \"format_instructions\": SolutionDesign.schema()}\n",
    "    )\n",
    "    state[\"solution_design\"] = design\n",
    "    # força que o agente de preço rode depois\n",
    "    state[\"orchestrator_decision\"].needs_pricing = True\n",
    "\n",
    "    # força que o fluxo passe também pelo Technical Agent\n",
    "    state[\"orchestrator_decision\"].needs_technical = True\n",
    "\n",
    "    # specs de cada componente\n",
    "    state[\"technical_results\"] = []\n",
    "    for comp in design.components:\n",
    "        res = get_technical_specs(comp.part_number)\n",
    "        if \"error\" not in res:\n",
    "            res[\"quantity\"] = comp.quantity\n",
    "        state[\"technical_results\"].append(res)\n",
    "    return state\n",
    "\n",
    "def integrity_validator_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Camada 0 – verifica se cada SKU existe e qty ≥ 1.\"\"\"\n",
    "    design = state.get(\"solution_design\")\n",
    "    if design is None:\n",
    "        return state\n",
    "\n",
    "    errors, validated = [], []\n",
    "    for comp in design.components:\n",
    "        if comp.part_number not in product_dict:\n",
    "            errors.append(f\"SKU_NOT_FOUND: {comp.part_number}\")\n",
    "            continue\n",
    "        qty = max(1, int(comp.quantity))\n",
    "        if qty != comp.quantity:\n",
    "            errors.append(f\"QUANTITY_ADJUSTED: {comp.part_number}→{qty}\")\n",
    "        validated.append(\n",
    "            SolutionComponent(\n",
    "                part_number=comp.part_number,\n",
    "                quantity=qty,\n",
    "                role=comp.role,\n",
    "            )\n",
    "        )\n",
    "    state[\"integrity_errors\"] = errors\n",
    "    design.components = validated            # substitui lista original\n",
    "    return state\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Validator‑Rules  (Camada 1)\n",
    "# -------------------------------------------------------------\n",
    "def validator_rules_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Regras básicas de compatibilidade / coerência.\"\"\"\n",
    "    errors: List[str] = []\n",
    "    design = state.get(\"solution_design\")\n",
    "    if design is None:\n",
    "        state[\"rule_errors\"] = errors\n",
    "        return state\n",
    "\n",
    "    # — Regra 1: se a query menciona Wi‑Fi 6, AP deve suportar ax\n",
    "    if \"wi-fi 6\" in state[\"user_query\"].lower():\n",
    "        for comp in design.components:\n",
    "            spec = next(\n",
    "                (t for t in state[\"technical_results\"] if t.get(\"part_number\") == comp.part_number),\n",
    "                None,\n",
    "            )\n",
    "            if spec and spec.get(\"specifications\", {}).get(\"wifi_standard\", \"\").lower() != \"802.11ax\":\n",
    "                errors.append(f\"WIFI6_AP_RULE fail: {comp.part_number}\")\n",
    "\n",
    "    # — Regra 2: componente marcado como PoE precisa ter info PoE\n",
    "    for comp in design.components:\n",
    "        if \"poe\" in comp.role.lower():\n",
    "            spec = next(\n",
    "                (t for t in state[\"technical_results\"] if t.get(\"part_number\") == comp.part_number),\n",
    "                None,\n",
    "            )\n",
    "            if spec and \"poe\" not in spec.get(\"specifications\", {}).get(\"power_requirements\", \"\").lower():\n",
    "                errors.append(f\"POE_SWITCH_RULE fail: {comp.part_number}\")\n",
    "\n",
    "    state[\"rule_errors\"] = errors\n",
    "    if errors:\n",
    "        print(\"⚠️ Rule errors →\", errors)\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 10. Nó — Technical Agent  (substitua TODO o bloco)\n",
    "# -------------------------------------------------------------\n",
    "### helper: extrai possíveis Cisco part‑numbers do texto\n",
    "PART_RE = re.compile(r\"[A-Z]{2,}\\d+[A-Z]*-[A-Za-z0-9]+(?:-[A-Za-z0-9]+)*\")\n",
    "\n",
    "def extract_part_numbers(text: str) -> List[str]:\n",
    "    return list({m.group(0) for m in PART_RE.finditer(text)})\n",
    "\n",
    "def technical_agent_node(state: AgentState) -> AgentState:\n",
    "    # pula se já há design\n",
    "    if state.get(\"solution_design\") is not None:\n",
    "        print(\"⏩ Technical Agent skipped (solution design already provides specs)\")\n",
    "        return state\n",
    "\n",
    "    query_part = state[\"orchestrator_decision\"].query_parts.get(\n",
    "        \"technical\", state[\"user_query\"]\n",
    "    )\n",
    "    ids = extract_part_numbers(query_part)\n",
    "\n",
    "    if ids:\n",
    "        print(f\"\\n🔧 [Technical Agent] Found explicit IDs: {ids}\")\n",
    "        state[\"technical_results\"] = [get_technical_specs(pid) for pid in ids]\n",
    "        return state\n",
    "\n",
    "    # fallback para recomendação sem IDs\n",
    "    if not state[\"orchestrator_decision\"].needs_technical:\n",
    "        print(\"⏩ Technical Agent skipped (flag false & no IDs)\")\n",
    "        return state\n",
    "\n",
    "    print(f\"\\n🔧 [Technical Agent] Generating recommendations for «{query_part}»\")\n",
    "    recs = recommend_products.invoke({\"requirements\": query_part, \"max_results\": 5})\n",
    "    state[\"technical_results\"] = []\n",
    "    for r in recs:\n",
    "        spec = get_technical_specs(r[\"part_number\"])\n",
    "        if \"error\" not in spec:\n",
    "            spec[\"recommendation_score\"] = r.get(\"similarity_score\", 0)\n",
    "        state[\"technical_results\"].append(spec)\n",
    "    return state\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 11. Nó — Pricing Agent\n",
    "# -------------------------------------------------------------\n",
    "def pricing_agent_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Gera lista de preços (com subtotal) para os SKUs relevantes.\"\"\"\n",
    "    if not state[\"orchestrator_decision\"].needs_pricing:\n",
    "        print(\"⏩ Pricing Agent skipped\")\n",
    "        return state\n",
    "\n",
    "    print(\"\\n💰 [Pricing Agent]\")\n",
    "\n",
    "    # 1) Se houver SolutionDesign, precifica exatamente seus componentes\n",
    "    if isinstance(state.get(\"solution_design\"), SolutionDesign):\n",
    "        items = [\n",
    "            {\"part_number\": c.part_number, \"quantity\": c.quantity}\n",
    "            for c in state[\"solution_design\"].components\n",
    "        ]\n",
    "    else:\n",
    "        # 2) Tenta extrair IDs explicitamente mencionados na parte de preço da query\n",
    "        pricing_part = state[\"orchestrator_decision\"].query_parts.get(\n",
    "            \"pricing\", state[\"user_query\"]\n",
    "        )\n",
    "        ids = extract_part_numbers(pricing_part)\n",
    "        if ids:\n",
    "            items = [{\"part_number\": pid, \"quantity\": 1} for pid in ids]\n",
    "        else:\n",
    "            # 3) Fallback: usa IDs provenientes do Technical Agent\n",
    "            items = [\n",
    "                {\n",
    "                    \"part_number\": t.get(\"part_number\"),\n",
    "                    \"quantity\": t.get(\"quantity\", 1),\n",
    "                }\n",
    "                for t in state[\"technical_results\"]\n",
    "                if t.get(\"part_number\")\n",
    "            ]\n",
    "\n",
    "    # Deduplicar somando quantidades\n",
    "    dedup: Dict[str, int] = {}\n",
    "    for it in items:\n",
    "        dedup[it[\"part_number\"]] = dedup.get(it[\"part_number\"], 0) + it[\"quantity\"]\n",
    "\n",
    "    # Consultar preços e calcular subtotais\n",
    "    state[\"pricing_results\"] = []\n",
    "    for pn, qty in dedup.items():\n",
    "        price_info = get_product_price(pn)\n",
    "        price_info.update(\n",
    "            {\n",
    "                \"quantity\": qty,\n",
    "                \"subtotal\": price_info.get(\"price\", 0) * qty,\n",
    "            }\n",
    "        )\n",
    "        state[\"pricing_results\"].append(price_info)\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "###### Implementar futyuramente\n",
    "\n",
    "def rules_validator_node(state: AgentState) -> AgentState:\n",
    "    print(\"🔍 [Validator‑Rules] – not implemented yet\")\n",
    "    return state\n",
    "\n",
    "def reviewer_node(state: AgentState) -> AgentState:\n",
    "    print(\"🧐 [Reviewer‑LLM] – skipped (placeholder)\")\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 12. Nó — Synthesizer  (versão refinada)\n",
    "# -------------------------------------------------------------\n",
    "def synthesize_node(state: AgentState) -> AgentState:\n",
    "    print(\"\\n🎯 [Synthesizer]\")\n",
    "    lines: List[str] = []\n",
    "\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    # 1) Solution Design (se houver)\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    if isinstance(state.get(\"solution_design\"), SolutionDesign):\n",
    "        d = state[\"solution_design\"]\n",
    "        lines.append(\"🚀 Solution Design\")\n",
    "        lines.append(d.summary)\n",
    "\n",
    "        lines.append(\"\\n🔧 Components:\")\n",
    "        for idx, comp in enumerate(d.components, 1):\n",
    "            desc = next(\n",
    "                (\n",
    "                    t.get(\"description\")\n",
    "                    for t in state[\"technical_results\"]\n",
    "                    if t.get(\"part_number\") == comp.part_number\n",
    "                ),\n",
    "                comp.part_number,\n",
    "            )\n",
    "            lines.append(f\"{idx}. {desc} ({comp.quantity}×) – {comp.role}\")\n",
    "\n",
    "        lines.append(\"\\n✅ Justification:\\n\" + d.justification)\n",
    "\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    # 2) Technical Specifications  (sempre que houver)\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    if state[\"technical_results\"]:\n",
    "        lines.append(\"\\n🔧 Technical Specifications:\")\n",
    "        for t in state[\"technical_results\"]:\n",
    "            if \"error\" in t:\n",
    "                lines.append(f\"- {t.get('part_number')}: {t['error']}\")\n",
    "                continue\n",
    "            lines.append(f\"\\n• {t['description']} ({t['part_number']})\")\n",
    "            for k, v in t.get(\"specifications\", {}).items():\n",
    "                lines.append(f\"  - {k.replace('_', ' ').title()}: {v}\")\n",
    "\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    # 3) Erros de integridade / regras\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    if state.get(\"integrity_errors\"):\n",
    "        lines.append(\"\\n⚠️ Integrity issues:\")\n",
    "        for err in state[\"integrity_errors\"]:\n",
    "            lines.append(f\"- {err}\")\n",
    "\n",
    "    if state.get(\"rule_errors\"):\n",
    "        lines.append(\"\\n⚠️ Rule issues:\")\n",
    "        for err in state[\"rule_errors\"]:\n",
    "            lines.append(f\"- {err}\")\n",
    "\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    # 4) Pricing\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    if state[\"pricing_results\"]:\n",
    "        total = 0.0\n",
    "        currency = \"USD\"\n",
    "        lines.append(\"\\n💵 Pricing:\")\n",
    "        for p in state[\"pricing_results\"]:\n",
    "            if \"error\" in p:\n",
    "                lines.append(f\"- {p.get('part_number')}: {p['error']}\")\n",
    "                continue\n",
    "            currency = p[\"currency\"]\n",
    "            total += p[\"subtotal\"]\n",
    "            lines.append(\n",
    "                f\"- {p['description']} ({p['quantity']}×): \"\n",
    "                f\"{currency} {p['subtotal']:.2f}\"\n",
    "            )\n",
    "        lines.append(f\"\\nTOTAL ESTIMATED: {currency} {total:.2f}\")\n",
    "\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    # 5) Caso nenhum dado relevante\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    if not lines:\n",
    "        lines.append(\"❌ No relevant information found\")\n",
    "\n",
    "    state[\"final_response\"] = \"\\n\".join(lines)\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 13. Roteamento (todas as funções)\n",
    "# -------------------------------------------------------------\n",
    "def route_after_orch(state: AgentState) -> str:\n",
    "    \"\"\"Primeira decisão: vai para designer, tech, price ou direto ao synth.\"\"\"\n",
    "    dec = state[\"orchestrator_decision\"]\n",
    "    if dec.needs_design:\n",
    "        return \"designer\"\n",
    "    if dec.needs_technical:\n",
    "        return \"tech\"\n",
    "    if dec.needs_pricing:\n",
    "        return \"price\"\n",
    "    return \"synth\"\n",
    "\n",
    "\n",
    "def route_after_designer(_: AgentState) -> str:\n",
    "    \"\"\"Sempre passar pelo Validator‑Integrity depois do designer.\"\"\"\n",
    "    return \"integrity\"\n",
    "\n",
    "\n",
    "def route_after_integrity(_: AgentState) -> str:\n",
    "    \"\"\"Após Camada 0, encaminha para as futuras regras.\"\"\"\n",
    "    return \"rules\"\n",
    "\n",
    "\n",
    "def route_after_rules(_: AgentState) -> str:\n",
    "    \"\"\"Placeholder – sempre manda para o reviewer (LLM stub).\"\"\"\n",
    "    return \"reviewer\"\n",
    "\n",
    "\n",
    "def route_after_reviewer(state: AgentState) -> str:\n",
    "    \"\"\"Decide se ainda precisa specs (tech) ou preço, senão sintetiza.\"\"\"\n",
    "    dec = state[\"orchestrator_decision\"]\n",
    "    if dec.needs_technical:\n",
    "        return \"tech\"\n",
    "    if dec.needs_pricing:\n",
    "        return \"price\"\n",
    "    return \"synth\"\n",
    "\n",
    "\n",
    "def route_after_tech(state: AgentState) -> str:\n",
    "    \"\"\"Se já precisamos de preço, vai ao pricing; senão, sintetiza.\"\"\"\n",
    "    return \"price\" if state[\"orchestrator_decision\"].needs_pricing else \"synth\"\n",
    "\n",
    "\n",
    "def route_after_price(_: AgentState) -> str:\n",
    "    \"\"\"Preço é a última etapa antes de sintetizar.\"\"\"\n",
    "    return \"synth\"\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 14. Construir o grafo\n",
    "# -------------------------------------------------------------\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# 1) Nós\n",
    "workflow.add_node(\"orch\", orchestrator_node)\n",
    "workflow.add_node(\"designer\", solution_design_node)           # Solution Designer\n",
    "workflow.add_node(\"integrity\", integrity_validator_node)\n",
    "workflow.add_node(\"rules\", validator_rules_node)       # stub\n",
    "workflow.add_node(\"reviewer\", reviewer_node)           # stub\n",
    "workflow.add_node(\"tech\", technical_agent_node)\n",
    "workflow.add_node(\"price\", pricing_agent_node)\n",
    "workflow.add_node(\"synth\", synthesize_node)\n",
    "\n",
    "\n",
    "# 2) Ponto de entrada\n",
    "workflow.set_entry_point(\"orch\")\n",
    "\n",
    "# 3) Condicionais\n",
    "workflow.add_conditional_edges(\"orch\", route_after_orch, {\n",
    "    \"designer\": \"designer\",\n",
    "    \"tech\": \"tech\",\n",
    "    \"price\": \"price\",\n",
    "    \"synth\": \"synth\",\n",
    "})\n",
    "\n",
    "workflow.add_conditional_edges(\"designer\", lambda _: \"integrity\", {\n",
    "    \"integrity\": \"integrity\",\n",
    "})\n",
    "\n",
    "workflow.add_conditional_edges(\"integrity\", lambda _: \"rules\", {\n",
    "    \"rules\": \"rules\",\n",
    "})\n",
    "\n",
    "workflow.add_conditional_edges(\"rules\", lambda _: \"reviewer\", {\n",
    "    \"reviewer\": \"reviewer\",\n",
    "})\n",
    "\n",
    "workflow.add_conditional_edges(\"reviewer\", route_after_reviewer, {\n",
    "    \"tech\": \"tech\",\n",
    "    \"price\": \"price\",\n",
    "    \"synth\": \"synth\",\n",
    "})\n",
    "\n",
    "workflow.add_conditional_edges(\"tech\", route_after_tech, {\n",
    "    \"price\": \"price\",\n",
    "    \"synth\": \"synth\",\n",
    "})\n",
    "\n",
    "workflow.add_conditional_edges(\"price\", route_after_price, {\n",
    "    \"synth\": \"synth\",\n",
    "})\n",
    "\n",
    "# 4) Encerramento\n",
    "workflow.add_edge(\"synth\", END)\n",
    "\n",
    "# 5) Compilar\n",
    "app = workflow.compile()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 15. Helper para executar\n",
    "# -------------------------------------------------------------\n",
    "def run_sales_quote(query: str) -> str:\n",
    "    init: AgentState = {\n",
    "        \"user_query\": query,\n",
    "        \"orchestrator_decision\": None,\n",
    "        \"solution_design\": None,\n",
    "        \"technical_results\": [],\n",
    "        \"pricing_results\": [],\n",
    "        \"integrity_errors\": [],\n",
    "        \"rule_errors\": [],\n",
    "        \"final_response\": \"\",\n",
    "    }\n",
    "    final_state = app.invoke(init)\n",
    "    return final_state[\"final_response\"]\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 16. Exemplo\n",
    "# -------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    q = (\n",
    "        \"Design a secure branch‑office solution for 50 users with Wi‑Fi 6, \"\n",
    "        \"firewall and PoE switches. Provide pricing.\"\n",
    "    )\n",
    "    print(run_sales_quote(q))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab55926-052f-4bfe-9c10-a4efcd54c201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987e3d20-0db1-4b9b-a217-7e91e64bfe38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85b81858-ed4f-48e5-b9e5-d6ef6ab04496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎻 [Orchestrator] «whats the price for MR42E-HW»\n",
      "\n",
      "💰 [Pricing Agent]\n",
      "\n",
      "🎯 [Synthesizer]\n",
      "\n",
      "💵 Pricing:\n",
      "- Meraki MR42E Access Point (1×): USD 1099.00\n",
      "\n",
      "TOTAL ESTIMATED: USD 1099.00\n"
     ]
    }
   ],
   "source": [
    "print(run_sales_quote(\n",
    "    \"whats the price for MR42E-HW\"\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f6be0f-91ee-4a50-a326-c132ddcb7a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1a49fbbe-2171-478d-81ac-18c3c488931e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎻 [Orchestrator] «Design a secure branch-office solution for 50 users with Wi‑Fi 6, firewall and PoE switches. Provide pricing.»\n",
      "\n",
      "🎨 [Solution Designer]\n",
      "🔍 [Validator‑Rules] – not implemented yet\n",
      "🧐 [Reviewer‑LLM] – skipped (placeholder)\n",
      "⏩ Technical Agent skipped (solution design already provides specs)\n",
      "\n",
      "💰 [Pricing Agent]\n",
      "\n",
      "🎯 [Synthesizer]\n",
      "🚀 Solution Design\n",
      "Design a secure branch-office solution for 50 users with Wi-Fi 6, firewall, and PoE switches.\n",
      "\n",
      "🔧 Components:\n",
      "1. ASA 5555-X Firewall (1×) – Firewall\n",
      "2. Meraki MR53E Access Point (3×) – Access Point for Wi-Fi 6 coverage\n",
      "3. ASA 5516-X with FirePOWER Services (1×) – Firewall with FirePOWER Services\n",
      "\n",
      "✅ Justification:\n",
      "The ASA5555-X is selected for its high performance and security features suitable for a branch office. The MR53E-HW access points provide Wi-Fi 6 capabilities for better performance and capacity for 50 users. The ASA5516-FPWR-K9 offers integrated FirePOWER services for enhanced security.\n",
      "\n",
      "💵 Pricing:\n",
      "- ASA 5555-X Firewall (1×): USD 28738.01\n",
      "- Meraki MR53E Access Point (3×): USD 5097.00\n",
      "- ASA 5516-X with FirePOWER Services (1×): USD 5995.00\n",
      "\n",
      "TOTAL ESTIMATED: USD 39830.01\n",
      "\n",
      "🎻 [Orchestrator] «I need technical specs for ASA5516-FPWR-K9 and pricing for MR53E-HW»\n",
      "\n",
      "🔧 [Technical Agent] Found explicit IDs: ['ASA5516-FPWR-K9', 'MR53E-HW']\n",
      "\n",
      "💰 [Pricing Agent]\n",
      "\n",
      "🎯 [Synthesizer]\n",
      "🔧 Technical Specifications:\n",
      "\n",
      "• ASA 5516-X with FirePOWER Services (ASA5516-FPWR-K9)\n",
      "  - Category: security\n",
      "  - Subcategory: firewall\n",
      "  - Throughput: 4 Gbps\n",
      "  - Interfaces: 8x GE\n",
      "  - Vpn Throughput: 1 Gbps\n",
      "  - Threat Throughput: 500 Mbps\n",
      "  - Encryption: 3DES/AES\n",
      "\n",
      "• Meraki MR53E Access Point (MR53E-HW)\n",
      "  - Category: wireless\n",
      "  - Subcategory: access_point\n",
      "  - Wifi Standard: 802.11ax\n",
      "  - Throughput: 2.5 Gbps\n",
      "  - Antenna Type: external\n",
      "  - Mounting: indoor\n",
      "  - Power Requirements: PoE+\n",
      "\n",
      "💵 Pricing:\n",
      "- ASA 5516-X with FirePOWER Services (1×): USD 5995.00\n",
      "- Meraki MR53E Access Point (1×): USD 1699.00\n",
      "\n",
      "TOTAL ESTIMATED: USD 7694.00\n"
     ]
    }
   ],
   "source": [
    "print(run_sales_quote(\n",
    "    \"Design a secure branch-office solution for 50 users with Wi‑Fi 6, firewall and PoE switches. Provide pricing.\"\n",
    "))\n",
    "\n",
    "print(run_sales_quote(\n",
    "    \"I need technical specs for ASA5516-FPWR-K9 and pricing for MR53E-HW\"\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291e610c-9800-43e8-8b71-b9b5218f1953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a57b7f27-fb2e-471a-9393-362e8c828015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎻 [Orchestrator] «I need technical specs for ASA5516-FPWR-K9 and pricing for MR53E-HW»\n",
      "\n",
      "🔧 [Technical Agent] Found explicit IDs: ['ASA5516-FPWR-K9', 'MR53E-HW']\n",
      "\n",
      "💰 [Pricing Agent]\n",
      "\n",
      "🎯 [Synthesizer]\n",
      "\n",
      "💬 CLIENT RESPONSE 1:\n",
      "\n",
      "💵 Pricing:\n",
      "- ASA 5516-X with FirePOWER Services (1×): USD 5995.00\n",
      "- Meraki MR53E Access Point (1×): USD 1699.00\n",
      "\n",
      "TOTAL ESTIMATED: USD 7694.00\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Solicitação técnica + preço\n",
    "test_query_1 = \"I need technical specs for ASA5516-FPWR-K9 and pricing for MR53E-HW\"\n",
    "result_1 = run_sales_quote(test_query_1)\n",
    "print(\"\\n💬 CLIENT RESPONSE 1:\")\n",
    "print(result_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6a42e3-14ab-4743-98ee-c293f52d1f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4c1a5e-45d8-4dbe-9136-d252c82610d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ffc46e-9211-47e8-b8d2-d9e364b1e736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab718d59-7619-4f75-87ef-7c365c259ceb",
   "metadata": {},
   "source": [
    "## Adaptação Completa para LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9090e31e-9c74-431e-b8fb-c617ed9541d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U llama-index llama-index-embeddings-openai beautifulsoup4 pypdf unstructured\n",
    "\n",
    "#!pip install -q -U llama-index==0.10.0 llama-index-embeddings-openai==0.1.0 beautifulsoup4==4.12.3 pypdf==4.2.0 unstructured==0.13.0 pillow==10.3.0 tenacity==8.2.3 protobuf==4.25.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbadad41-69a3-46ac-8624-4745595d941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- CONFIGURAÇÃO DAS CHAVES DE API ---\n",
    "# ⚠️ Cole suas chaves aqui.\n",
    "OPENAI_API_KEY = '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'\n",
    "TAVILY_API_KEY = \"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\" # <-- SUA CHAVE DA TAVILY AQUI\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b40b446-9dbb-4ad5-b882-43fcda494f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.core import VectorStoreIndex, Settings\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ee9a8d0-de57-44dc-ab97-7ab1837d401e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file C:\\Users\\Giovani\\Desktop\\EMPRESAS\\02º DATA, CLOUD & BLOCKCHAIN\\DATA & AI\\11 - CONSULTORIAS\\BAIRESDEV\\PROJETOS\\CISCO\\cisco-quote-assistant\\data\\raw\\_product_catalog.csv with error: Error tokenizing data. C error: Expected 1 fields in line 11, saw 2\n",
      ". Skipping...\n",
      "Failed to load file C:\\Users\\Giovani\\Desktop\\EMPRESAS\\02º DATA, CLOUD & BLOCKCHAIN\\DATA & AI\\11 - CONSULTORIAS\\BAIRESDEV\\PROJETOS\\CISCO\\cisco-quote-assistant\\data\\raw\\Pricelist.csv with error: Error tokenizing data. C error: Expected 2 fields in line 12, saw 3\n",
      ". Skipping...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a4181723b24631bce6bdb17ac261bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2eb5ac67ce24fb2bb7fad982e1d930a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/982 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Índice criado com 6 documentos\n",
      "> Running step c5cd8ab7-5dfa-4ed3-b6a8-89527b824751. Step input: \n",
      "    Como especialista Cisco, analise estes requisitos e identifique:\n",
      "    - Tipo de solução (rede, segurança, colaboração)\n",
      "    - Componentes críticos\n",
      "    - Restrições de orçamento\n",
      "    \n",
      "    Requisitos: Solução de rede para escritório com 50 usuários, requer Wi-Fi 6, switches PoE+ e firewall básico. Orçamento máximo: $15k.\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Giovani\\anaconda3\\Lib\\site-packages\\llama_index\\core\\agent\\react\\base.py:154: DeprecationWarning: Call to deprecated class ReActAgent. (ReActAgent has been rewritten and replaced by llama_index.core.agent.workflow.ReActAgent.\n",
      "\n",
      "This implementation will be removed in a v0.13.0 and the new implementation will be promoted to the `from llama_index.core.agent import ReActAgent` path.\n",
      "\n",
      "See the docs for more information: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
      "  return cls(\n",
      "C:\\Users\\Giovani\\anaconda3\\Lib\\site-packages\\deprecated\\classic.py:184: DeprecationWarning: Call to deprecated class AgentRunner. (AgentRunner has been deprecated and is not maintained.\n",
      "\n",
      "This implementation will be removed in a v0.13.0.\n",
      "\n",
      "See the docs for more information on updated agent usage: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
      "  return old_new1(cls, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: A partir dos requisitos fornecidos, posso identificar o tipo de solução, os componentes críticos e as restrições de orçamento.\n",
      " \n",
      "- Tipo de solução: Rede\n",
      "- Componentes críticos:\n",
      "  - Acesso Wi-Fi 6\n",
      "  - Switches PoE+\n",
      "  - Firewall básico\n",
      "- Restrições de orçamento: $15k\n",
      "Answer: A solução requerida é uma solução de rede, com componentes críticos que incluem Wi-Fi 6, switches PoE+ e um firewall básico, e o orçamento máximo é de $15k.\n",
      "\u001b[0m> Running step c6be9b82-e464-47bc-a35e-d4edf71448f2. Step input: \n",
      "    Com base nesta análise:\n",
      "    A solução requerida é uma solução de rede, com componentes críticos que incluem Wi-Fi 6, switches PoE+ e um firewall básico, e o orçamento máximo é de $15k.\n",
      "    \n",
      "    Gere TRÊS cenários de cotação:\n",
      "    1. Custo-Otimizado: Foco em preço\n",
      "    2. Performance-Máxima: Melhores recursos\n",
      "    3. Balanceado: Equilíbrio custo-benefício\n",
      "    \n",
      "    Use esta estrutura:\n",
      "    [Cenário X]\n",
      "    Descrição: ...\n",
      "    Componentes: \n",
      "      - Produto A (quantidade)\n",
      "      - Produto B (quantidade)\n",
      "    Trade-offs: ...\n",
      "    \n",
      "\u001b[1;3;38;5;200mThought: (Implicit) I can answer without any more tools!\n",
      "Answer: [Cenário 1: Custo-Otimizado]  \n",
      "Descrição: Este cenário foca em minimizar os custos, utilizando produtos que atendem aos requisitos básicos sem recursos adicionais.  \n",
      "Componentes:  \n",
      "  - Access Point Wi-Fi 6 (5 unidades)  \n",
      "  - Switch PoE+ de 24 portas (2 unidades)  \n",
      "  - Firewall básico (1 unidade)  \n",
      "Trade-offs: A solução pode não oferecer a melhor performance em ambientes de alta densidade de usuários e pode ter limitações em recursos de segurança avançados.\n",
      "\n",
      "[Cenário 2: Performance-Máxima]  \n",
      "Descrição: Este cenário prioriza a performance e os melhores recursos disponíveis, garantindo uma rede robusta e segura.  \n",
      "Componentes:  \n",
      "  - Access Point Wi-Fi 6 de alta capacidade (5 unidades)  \n",
      "  - Switch PoE+ de 48 portas com gerenciamento avançado (2 unidades)  \n",
      "  - Firewall de próxima geração (1 unidade)  \n",
      "Trade-offs: O custo total pode exceder o orçamento de $15k, mas oferece a melhor performance e segurança.\n",
      "\n",
      "[Cenário 3: Balanceado]  \n",
      "Descrição: Este cenário busca um equilíbrio entre custo e performance, utilizando produtos que oferecem um bom desempenho sem ultrapassar o orçamento.  \n",
      "Componentes:  \n",
      "  - Access Point Wi-Fi 6 (5 unidades)  \n",
      "  - Switch PoE+ de 24 portas (2 unidades)  \n",
      "  - Firewall básico com algumas funcionalidades adicionais (1 unidade)  \n",
      "Trade-offs: Embora não seja a opção mais barata, oferece um bom desempenho e segurança, mantendo-se dentro do orçamento.\n",
      "\u001b[0m> Running step 680d16a5-c490-4a94-b230-93b90dd4eb07. Step input: \n",
      "    Para estes cenários:\n",
      "    [Cenário 1: Custo-Otimizado]  \n",
      "Descrição: Este cenário foca em minimizar os custos, utilizando produtos que atendem aos requisitos básicos sem recursos adicionais.  \n",
      "Componentes:  \n",
      "  - Access Point Wi-Fi 6 (5 unidades)  \n",
      "  - Switch PoE+ de 24 portas (2 unidades)  \n",
      "  - Firewall básico (1 unidade)  \n",
      "Trade-offs: A solução pode não oferecer a melhor performance em ambientes de alta densidade de usuários e pode ter limitações em recursos de segurança avançados.\n",
      "\n",
      "[Cenário 2: Performance-Máxima]  \n",
      "Descrição: Este cenário prioriza a performance e os melhores recursos disponíveis, garantindo uma rede robusta e segura.  \n",
      "Componentes:  \n",
      "  - Access Point Wi-Fi 6 de alta capacidade (5 unidades)  \n",
      "  - Switch PoE+ de 48 portas com gerenciamento avançado (2 unidades)  \n",
      "  - Firewall de próxima geração (1 unidade)  \n",
      "Trade-offs: O custo total pode exceder o orçamento de $15k, mas oferece a melhor performance e segurança.\n",
      "\n",
      "[Cenário 3: Balanceado]  \n",
      "Descrição: Este cenário busca um equilíbrio entre custo e performance, utilizando produtos que oferecem um bom desempenho sem ultrapassar o orçamento.  \n",
      "Componentes:  \n",
      "  - Access Point Wi-Fi 6 (5 unidades)  \n",
      "  - Switch PoE+ de 24 portas (2 unidades)  \n",
      "  - Firewall básico com algumas funcionalidades adicionais (1 unidade)  \n",
      "Trade-offs: Embora não seja a opção mais barata, oferece um bom desempenho e segurança, mantendo-se dentro do orçamento.\n",
      "    \n",
      "    Calcule:\n",
      "    - Preço total por cenário\n",
      "    - Economia vs. MSRP\n",
      "    - 3 talking points por cenário\n",
      "    \n",
      "\u001b[1;3;38;5;200mThought: (Implicit) I can answer without any more tools!\n",
      "Answer: Para calcular os preços totais por cenário, a economia em relação ao MSRP e os pontos de discussão, primeiro precisamos estimar os preços dos componentes. Vou usar valores aproximados para cada componente:\n",
      "\n",
      "- Access Point Wi-Fi 6: $200 cada\n",
      "- Switch PoE+ de 24 portas: $800 cada\n",
      "- Switch PoE+ de 48 portas: $1,200 cada\n",
      "- Firewall básico: $300 cada\n",
      "- Firewall de próxima geração: $1,000 cada\n",
      "\n",
      "Agora, vamos calcular os preços totais e as economias.\n",
      "\n",
      "[Cenário 1: Custo-Otimizado]  \n",
      "Preço total:  \n",
      "- Access Point Wi-Fi 6: 5 x $200 = $1,000  \n",
      "- Switch PoE+ de 24 portas: 2 x $800 = $1,600  \n",
      "- Firewall básico: 1 x $300 = $300  \n",
      "Total: $1,000 + $1,600 + $300 = $2,900  \n",
      "\n",
      "Economia vs. MSRP:  \n",
      "Supondo que o MSRP total para uma solução similar seja $4,000, a economia seria: $4,000 - $2,900 = $1,100  \n",
      "\n",
      "Talking Points:  \n",
      "1. Solução de baixo custo, ideal para orçamentos restritos.  \n",
      "2. Atende aos requisitos básicos de conectividade e segurança.  \n",
      "3. Pode ser expandida no futuro conforme as necessidades aumentam.\n",
      "\n",
      "[Cenário 2: Performance-Máxima]  \n",
      "Preço total:  \n",
      "- Access Point Wi-Fi 6 de alta capacidade: 5 x $300 = $1,500  \n",
      "- Switch PoE+ de 48 portas: 2 x $1,200 = $2,400  \n",
      "- Firewall de próxima geração: 1 x $1,000 = $1,000  \n",
      "Total: $1,500 + $2,400 + $1,000 = $4,900  \n",
      "\n",
      "Economia vs. MSRP:  \n",
      "Supondo que o MSRP total para uma solução similar seja $6,000, a economia seria: $6,000 - $4,900 = $1,100  \n",
      "\n",
      "Talking Points:  \n",
      "1. Oferece a melhor performance para ambientes de alta densidade.  \n",
      "2. Recursos avançados de segurança para proteger a rede.  \n",
      "3. Ideal para empresas que priorizam a confiabilidade e a velocidade.\n",
      "\n",
      "[Cenário 3: Balanceado]  \n",
      "Preço total:  \n",
      "- Access Point Wi-Fi 6: 5 x $200 = $1,000  \n",
      "- Switch PoE+ de 24 portas: 2 x $800 = $1,600  \n",
      "- Firewall básico com funcionalidades adicionais: 1 x $500 = $500  \n",
      "Total: $1,000 + $1,600 + $500 = $3,100  \n",
      "\n",
      "Economia vs. MSRP:  \n",
      "Supondo que o MSRP total para uma solução similar seja $4,500, a economia seria: $4,500 - $3,100 = $1,400  \n",
      "\n",
      "Talking Points:  \n",
      "1. Equilíbrio entre custo e performance, ideal para a maioria das empresas.  \n",
      "2. Oferece um bom nível de segurança sem comprometer o orçamento.  \n",
      "3. Flexível para atender a diferentes necessidades de negócios.\n",
      "\u001b[0m## Análise Técnica\n",
      "A solução requerida é uma solução de rede, com componentes críticos que incluem Wi-Fi 6, switches PoE+ e um firewall básico, e o orçamento máximo é de $15k.\n",
      "\n",
      "## Cenários\n",
      "[Cenário 1: Custo-Otimizado]  \n",
      "Descrição: Este cenário foca em minimizar os custos, utilizando produtos que atendem aos requisitos básicos sem recursos adicionais.  \n",
      "Componentes:  \n",
      "  - Access Point Wi-Fi 6 (5 unidades)  \n",
      "  - Switch PoE+ de 24 portas (2 unidades)  \n",
      "  - Firewall básico (1 unidade)  \n",
      "Trade-offs: A solução pode não oferecer a melhor performance em ambientes de alta densidade de usuários e pode ter limitações em recursos de segurança avançados.\n",
      "\n",
      "[Cenário 2: Performance-Máxima]  \n",
      "Descrição: Este cenário prioriza a performance e os melhores recursos disponíveis, garantindo uma rede robusta e segura.  \n",
      "Componentes:  \n",
      "  - Access Point Wi-Fi 6 de alta capacidade (5 unidades)  \n",
      "  - Switch PoE+ de 48 portas com gerenciamento avançado (2 unidades)  \n",
      "  - Firewall de próxima geração (1 unidade)  \n",
      "Trade-offs: O custo total pode exceder o orçamento de $15k, mas oferece a melhor performance e segurança.\n",
      "\n",
      "[Cenário 3: Balanceado]  \n",
      "Descrição: Este cenário busca um equilíbrio entre custo e performance, utilizando produtos que oferecem um bom desempenho sem ultrapassar o orçamento.  \n",
      "Componentes:  \n",
      "  - Access Point Wi-Fi 6 (5 unidades)  \n",
      "  - Switch PoE+ de 24 portas (2 unidades)  \n",
      "  - Firewall básico com algumas funcionalidades adicionais (1 unidade)  \n",
      "Trade-offs: Embora não seja a opção mais barata, oferece um bom desempenho e segurança, mantendo-se dentro do orçamento.\n",
      "\n",
      "## Precificação\n",
      "Para calcular os preços totais por cenário, a economia em relação ao MSRP e os pontos de discussão, primeiro precisamos estimar os preços dos componentes. Vou usar valores aproximados para cada componente:\n",
      "\n",
      "- Access Point Wi-Fi 6: $200 cada\n",
      "- Switch PoE+ de 24 portas: $800 cada\n",
      "- Switch PoE+ de 48 portas: $1,200 cada\n",
      "- Firewall básico: $300 cada\n",
      "- Firewall de próxima geração: $1,000 cada\n",
      "\n",
      "Agora, vamos calcular os preços totais e as economias.\n",
      "\n",
      "[Cenário 1: Custo-Otimizado]  \n",
      "Preço total:  \n",
      "- Access Point Wi-Fi 6: 5 x $200 = $1,000  \n",
      "- Switch PoE+ de 24 portas: 2 x $800 = $1,600  \n",
      "- Firewall básico: 1 x $300 = $300  \n",
      "Total: $1,000 + $1,600 + $300 = $2,900  \n",
      "\n",
      "Economia vs. MSRP:  \n",
      "Supondo que o MSRP total para uma solução similar seja $4,000, a economia seria: $4,000 - $2,900 = $1,100  \n",
      "\n",
      "Talking Points:  \n",
      "1. Solução de baixo custo, ideal para orçamentos restritos.  \n",
      "2. Atende aos requisitos básicos de conectividade e segurança.  \n",
      "3. Pode ser expandida no futuro conforme as necessidades aumentam.\n",
      "\n",
      "[Cenário 2: Performance-Máxima]  \n",
      "Preço total:  \n",
      "- Access Point Wi-Fi 6 de alta capacidade: 5 x $300 = $1,500  \n",
      "- Switch PoE+ de 48 portas: 2 x $1,200 = $2,400  \n",
      "- Firewall de próxima geração: 1 x $1,000 = $1,000  \n",
      "Total: $1,500 + $2,400 + $1,000 = $4,900  \n",
      "\n",
      "Economia vs. MSRP:  \n",
      "Supondo que o MSRP total para uma solução similar seja $6,000, a economia seria: $6,000 - $4,900 = $1,100  \n",
      "\n",
      "Talking Points:  \n",
      "1. Oferece a melhor performance para ambientes de alta densidade.  \n",
      "2. Recursos avançados de segurança para proteger a rede.  \n",
      "3. Ideal para empresas que priorizam a confiabilidade e a velocidade.\n",
      "\n",
      "[Cenário 3: Balanceado]  \n",
      "Preço total:  \n",
      "- Access Point Wi-Fi 6: 5 x $200 = $1,000  \n",
      "- Switch PoE+ de 24 portas: 2 x $800 = $1,600  \n",
      "- Firewall básico com funcionalidades adicionais: 1 x $500 = $500  \n",
      "Total: $1,000 + $1,600 + $500 = $3,100  \n",
      "\n",
      "Economia vs. MSRP:  \n",
      "Supondo que o MSRP total para uma solução similar seja $4,500, a economia seria: $4,500 - $3,100 = $1,400  \n",
      "\n",
      "Talking Points:  \n",
      "1. Equilíbrio entre custo e performance, ideal para a maioria das empresas.  \n",
      "2. Oferece um bom nível de segurança sem comprometer o orçamento.  \n",
      "3. Flexível para atender a diferentes necessidades de negócios.\n"
     ]
    }
   ],
   "source": [
    "# 1. Instalações necessárias (remover LangChain, adicionar LlamaIndex)\n",
    "#!pip install -q -U llama-index llama-index-embeddings-openai beautifulsoup4 pypdf unstructured\n",
    "\n",
    "import os\n",
    "from llama_index.core import VectorStoreIndex, Settings\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- CONFIGURAÇÃO DAS CHAVES ---\n",
    "OPENAI_API_KEY = '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'  # Substituir\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "\n",
    "# =============================================================\n",
    "# Cisco Sales Assistant com LlamaIndex (Otimizado)\n",
    "# =============================================================\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 0. Configuração Global LlamaIndex\n",
    "# -------------------------------------------------------------\n",
    "# ⚠️ Otimizado para performance Cisco\n",
    "Settings.embed_model = OpenAIEmbedding(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    dimensions=256  # 50% mais rápido que 1536-dim\n",
    ")\n",
    "Settings.llm = OpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "Settings.node_parser = SentenceSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=20,\n",
    "    separator=\"\\n\",\n",
    "    paragraph_separator=\"\\n\\n\"\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1. Carregar catálogo Cisco como Índice Híbrido\n",
    "# -------------------------------------------------------------\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.vector_stores import SimpleVectorStore\n",
    "\n",
    "# Carregar documentos (ajuste o caminho)\n",
    "documents = SimpleDirectoryReader(\"data/raw\").load_data()\n",
    "\n",
    "# Criar índice com busca híbrida (keyword + vector)\n",
    "vector_store = SimpleVectorStore()  # FAISS-like local\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, \n",
    "    vector_store=vector_store,\n",
    "    show_progress=True\n",
    ")\n",
    "query_engine = index.as_query_engine(\n",
    "    similarity_top_k=5,\n",
    "    vector_store_query_mode=\"hybrid\"\n",
    ")\n",
    "print(f\"✅ Índice criado com {len(documents)} documentos\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2. Ferramentas Adaptadas para LlamaIndex\n",
    "# -------------------------------------------------------------\n",
    "# --- Função de Recomendação com RAG Híbrido ---\n",
    "def recommend_products(query: str, top_k: int = 3) -> list:\n",
    "    \"\"\"Recomenda produtos Cisco baseado em descrições técnicas.\"\"\"\n",
    "    results = query_engine.query(query)\n",
    "    return [\n",
    "        {\n",
    "            \"part_number\": node.metadata.get(\"cisco_product_id\", \"\"),\n",
    "            \"commercial_name\": node.metadata.get(\"commercial_name\", \"\"),\n",
    "            \"score\": node.score\n",
    "        }\n",
    "        for node in results.source_nodes[:top_k]\n",
    "    ]\n",
    "\n",
    "# --- Ferramenta de Preços (mantida) ---\n",
    "def get_product_price(part_number: str) -> dict:\n",
    "    \"\"\"Busca preço de produto por part number.\"\"\"\n",
    "    # Implementação direta (sem LangChain)\n",
    "    return {\"part_number\": part_number, \"price\": 299.99}  # Mock\n",
    "\n",
    "# --- Ferramentas como Objetos LlamaIndex ---\n",
    "recommend_tool = FunctionTool.from_defaults(fn=recommend_products)\n",
    "price_tool = FunctionTool.from_defaults(fn=get_product_price)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3. Agente ReAct com LlamaIndex\n",
    "# -------------------------------------------------------------\n",
    "# ⚠️ Versão simplificada e mais rápida\n",
    "agent = ReActAgent.from_tools(\n",
    "    tools=[recommend_tool, price_tool],\n",
    "    llm=Settings.llm,\n",
    "    verbose=True,\n",
    "    max_iterations=6\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4. Fluxo de Cotação Otimizado\n",
    "# -------------------------------------------------------------\n",
    "def generate_cisco_quote(query: str) -> str:\n",
    "    \"\"\"Gera cotação completa com cenários.\"\"\"\n",
    "    # Passo 1: Análise de requisitos\n",
    "    analysis_prompt = f\"\"\"\n",
    "    Como especialista Cisco, analise estes requisitos e identifique:\n",
    "    - Tipo de solução (rede, segurança, colaboração)\n",
    "    - Componentes críticos\n",
    "    - Restrições de orçamento\n",
    "    \n",
    "    Requisitos: {query}\n",
    "    \"\"\"\n",
    "    analysis = agent.chat(analysis_prompt).response\n",
    "    \n",
    "    # Passo 2: Geração de cenários\n",
    "    scenario_prompt = f\"\"\"\n",
    "    Com base nesta análise:\n",
    "    {analysis}\n",
    "    \n",
    "    Gere TRÊS cenários de cotação:\n",
    "    1. Custo-Otimizado: Foco em preço\n",
    "    2. Performance-Máxima: Melhores recursos\n",
    "    3. Balanceado: Equilíbrio custo-benefício\n",
    "    \n",
    "    Use esta estrutura:\n",
    "    [Cenário X]\n",
    "    Descrição: ...\n",
    "    Componentes: \n",
    "      - Produto A (quantidade)\n",
    "      - Produto B (quantidade)\n",
    "    Trade-offs: ...\n",
    "    \"\"\"\n",
    "    scenarios = agent.chat(scenario_prompt).response\n",
    "    \n",
    "    # Passo 3: Precificação\n",
    "    pricing_prompt = f\"\"\"\n",
    "    Para estes cenários:\n",
    "    {scenarios}\n",
    "    \n",
    "    Calcule:\n",
    "    - Preço total por cenário\n",
    "    - Economia vs. MSRP\n",
    "    - 3 talking points por cenário\n",
    "    \"\"\"\n",
    "    pricing = agent.chat(pricing_prompt).response\n",
    "    \n",
    "    return f\"## Análise Técnica\\n{analysis}\\n\\n## Cenários\\n{scenarios}\\n\\n## Precificação\\n{pricing}\"\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 5. Exemplo de Execução\n",
    "# -------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    query = (\n",
    "        \"Solução de rede para escritório com 50 usuários, \"\n",
    "        \"requer Wi-Fi 6, switches PoE+ e firewall básico. \"\n",
    "        \"Orçamento máximo: $15k.\"\n",
    "    )\n",
    "    print(generate_cisco_quote(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d862905b-473d-4de6-bc7d-ee953a9de701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c156f0-83ba-4730-b083-b58a44886b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c855a2d1-fb6c-4277-a77a-89fc7e67170d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# Cisco Sales Assistant – fluxo completo com validação Camada 0\n",
    "# (Designer criativo, Validator‑Integrity, stubs para futuras\n",
    "#  Validator‑Rules e Reviewer‑LLM)\n",
    "# =============================================================\n",
    "\"\"\"\n",
    "Rodar este arquivo cria um agente LangGraph capaz de:\n",
    "  • analisar a consulta do cliente\n",
    "  • projetar uma solução (Solution Designer) com leve criatividade\n",
    "  • validar SKU/quantidade (Integrity)\n",
    "  • (stubs) validar compatibilidade & revisar via LLM\n",
    "  • buscar especificações técnicas\n",
    "  • precificar os componentes\n",
    "  • sintetizar tudo numa resposta final\n",
    "\n",
    "Requisitos:\n",
    "  pip install langchain langgraph langchain-openai scikit-learn numpy\n",
    "\"\"\"\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 0. Imports\n",
    "# -------------------------------------------------------------\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict, TypedDict, Optional\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from langchain.tools import tool\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1. Catálogo Cisco (ajuste caminho se necessário)\n",
    "# -------------------------------------------------------------\n",
    "product_dict: Dict[str, Dict] = {}\n",
    "PRICELIST_PATH = \"data/raw/pricelist.json\"\n",
    "\n",
    "try:\n",
    "    with open(PRICELIST_PATH, encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        products = data if isinstance(data, list) else data.get(\"products\", [])\n",
    "        for p in products:\n",
    "            pid = p.get(\"cisco_product_id\")\n",
    "            if pid:\n",
    "                product_dict[pid] = p\n",
    "    print(f\"✅ Data loaded: {len(product_dict)} products\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading product data: {e}\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2. Embeddings TF‑IDF\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "def prepare_recommendation_data():\n",
    "    texts: List[str] = []\n",
    "    for p in product_dict.values():\n",
    "        hw = p.get(\"technical_profile\", {}).get(\"hardware_attributes\", {})\n",
    "        txt = (\n",
    "            f\"{p.get('commercial_name', '')} {p.get('product_type', '')} \"\n",
    "            + \" \".join(f\"{k}={v}\" for k, v in hw.items())\n",
    "        ).strip()\n",
    "        texts.append(txt)\n",
    "    vec = TfidfVectorizer(stop_words=\"english\")\n",
    "    mat = vec.fit_transform(texts) if texts else None\n",
    "    return vec, mat\n",
    "\n",
    "vectorizer, tfidf_matrix = prepare_recommendation_data()\n",
    "print(\"✅ Recommendation data prepared\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3. Helpers\n",
    "# -------------------------------------------------------------\n",
    "PART_RE = re.compile(r\"[A-Z]{2,}\\d+[A-Z]*-[A-Za-z0-9]+(?:-[A-Za-z0-9]+)*\")\n",
    "\n",
    "def extract_part_numbers(text: str) -> List[str]:\n",
    "    \"\"\"Return unique Cisco‑looking part numbers in text.\"\"\"\n",
    "    return list({m.group(0) for m in PART_RE.finditer(text)})\n",
    "\n",
    "def get_product_list_str(requirements: str, top_k: int = 50) -> str:\n",
    "    if tfidf_matrix is None:\n",
    "        return \"(catalog empty)\"\n",
    "    vec = vectorizer.transform([requirements])\n",
    "    sims = cosine_similarity(vec, tfidf_matrix).flatten()\n",
    "    idxs = sims.argsort()[::-1][:top_k]\n",
    "    prods = [list(product_dict.values())[i] for i in idxs]\n",
    "    return \"\\n\".join(\n",
    "        f\"- {p['cisco_product_id']}: {p['commercial_name']} ({p['product_type']})\"\n",
    "        for p in prods\n",
    "    )\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4. LangChain tools\n",
    "# -------------------------------------------------------------\n",
    "@tool\n",
    "def get_product_price(part_number: str) -> Dict:\n",
    "    \"\"\"Retrieve pricing information for a Cisco product.\"\"\"\n",
    "    prod = product_dict.get(part_number)\n",
    "    if not prod:\n",
    "        return {\"error\": \"SKU_NOT_FOUND\", \"part_number\": part_number}\n",
    "    pricing = prod.get(\"pricing_model\", {})\n",
    "    return {\n",
    "        \"price\": pricing.get(\"base_price\", 0.0),\n",
    "        \"currency\": pricing.get(\"currency\", \"USD\"),\n",
    "        \"description\": prod.get(\"commercial_name\", \"\"),\n",
    "        \"part_number\": part_number,\n",
    "        \"product_type\": prod.get(\"product_type\", \"\"),\n",
    "    }\n",
    "\n",
    "@tool\n",
    "def get_technical_specs(part_number: str) -> Dict:\n",
    "    \"\"\"Retrieve hardware specs for a Cisco product.\"\"\"\n",
    "    prod = product_dict.get(part_number)\n",
    "    if not prod:\n",
    "        return {\"error\": \"SKU_NOT_FOUND\", \"part_number\": part_number}\n",
    "    hw = prod.get(\"technical_profile\", {}).get(\"hardware_attributes\", {})\n",
    "    if not hw:\n",
    "        return {\"error\": \"NO_SPECS\", \"part_number\": part_number}\n",
    "    return {\n",
    "        \"specifications\": hw,\n",
    "        \"description\": prod.get(\"commercial_name\", \"\"),\n",
    "        \"part_number\": part_number,\n",
    "        \"product_type\": prod.get(\"product_type\", \"\"),\n",
    "    }\n",
    "\n",
    "@tool\n",
    "def recommend_products(requirements: str, max_results: int = 3) -> List[Dict]:\n",
    "    \"\"\"Recommend products via TF‑IDF cosine similarity.\"\"\"\n",
    "    if tfidf_matrix is None:\n",
    "        return [{\"error\": \"CATALOG_NOT_INDEXED\"}]\n",
    "    vec = vectorizer.transform([requirements])\n",
    "    sims = cosine_similarity(vec, tfidf_matrix).flatten()\n",
    "    idxs = sims.argsort()[::-1][:max_results]\n",
    "    base = list(product_dict.values())\n",
    "    return [\n",
    "        {\n",
    "            \"part_number\": base[i][\"cisco_product_id\"],\n",
    "            \"commercial_name\": base[i][\"commercial_name\"],\n",
    "            \"product_type\": base[i][\"product_type\"],\n",
    "            \"similarity_score\": float(sims[i]),\n",
    "        }\n",
    "        for i in idxs\n",
    "    ]\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 5. Pydantic models\n",
    "# -------------------------------------------------------------\n",
    "class SolutionComponent(BaseModel):\n",
    "    part_number: str\n",
    "    quantity: int = Field(ge=1)\n",
    "    role: str\n",
    "\n",
    "class SolutionDesign(BaseModel):\n",
    "    summary: str\n",
    "    components: List[SolutionComponent]\n",
    "    justification: str\n",
    "\n",
    "class AgentRoutingDecision(BaseModel):\n",
    "    needs_design: bool = False\n",
    "    needs_technical: bool = False\n",
    "    needs_pricing: bool = False\n",
    "    query_parts: Dict[str, str] = Field(default_factory=dict)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 6. LLM & prompts\n",
    "# -------------------------------------------------------------\n",
    "llm_cold = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "llm_creative = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.4)  # designer\n",
    "\n",
    "orchestrator_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a Cisco sales orchestrator. Output JSON (AgentRoutingDecision) telling which agents to call.\n",
    "User query: {{query}}\n",
    "{{format_instructions}}\"\"\"\n",
    ")\n",
    "\n",
    "orchestrator_agent = orchestrator_prompt | llm_cold.with_structured_output(AgentRoutingDecision)\n",
    "\n",
    "design_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a Cisco Solution Architect. Combine ONLY the products listed below to build a solution. Keep summary ≤120 tokens.\n",
    "Requirements:\n",
    "{requirements}\n",
    "\n",
    "Available Cisco Products:\n",
    "{product_list}\n",
    "\n",
    "Return JSON matching schema.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "design_agent = (\n",
    "    {\n",
    "        \"requirements\": lambda x: x[\"requirements\"],\n",
    "        \"product_list\": lambda x: get_product_list_str(x[\"requirements\"]),\n",
    "        \"format_instructions\": lambda x: x[\"format_instructions\"],\n",
    "    }\n",
    "    | design_prompt\n",
    "    | llm_creative.with_structured_output(SolutionDesign)\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 7. Graph state type\n",
    "# -------------------------------------------------------------\n",
    "class AgentState(TypedDict):\n",
    "    user_query: str\n",
    "    orchestrator_decision: Optional[AgentRoutingDecision]\n",
    "    solution_design: Optional[SolutionDesign]\n",
    "    integrity_errors: List[str]\n",
    "    technical_results: List[Dict]\n",
    "    pricing_results: List[Dict]\n",
    "    final_response: str\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 8. Nodes\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "def orchestrator_node(state: AgentState) -> AgentState:\n",
    "    print(f\"\\n🎻 [Orchestrator] «{state['user_query']}»\")\n",
    "    q = state[\"user_query\"]\n",
    "    try:\n",
    "        decision = orchestrator_agent.invoke({\n",
    "            \"query\": q,\n",
    "            \"format_instructions\": AgentRoutingDecision.schema(),\n",
    "        })\n",
    "    except Exception:\n",
    "        decision = AgentRoutingDecision()\n",
    "    if not any([decision.needs_design, decision.needs_technical, decision.needs_pricing]):\n",
    "        ql = q.lower()\n",
    "        decision = AgentRoutingDecision(\n",
    "            needs_design=any(w in ql for w in [\"design\", \"architecture\", \"solution\"]),\n",
    "            needs_technical=\"spec\" in ql,\n",
    "            needs_pricing=any(w in ql for w in [\"price\", \"cost\", \"quote\", \"pricing\"]),\n",
    "            query_parts={},\n",
    "        )\n",
    "    state[\"orchestrator_decision\"] = decision\n",
    "    return state\n",
    "\n",
    "\n",
    "def designer_node(state: AgentState) -> AgentState:\n",
    "    print(\"\\n🎨 [Solution Designer]\")\n",
    "    design = design_agent.invoke({\n",
    "        \"requirements\": state[\"user_query\"],\n",
    "        \"format_instructions\": SolutionDesign.schema(),\n",
    "    })\n",
    "    state[\"solution_design\"] = design\n",
    "    state[\"orchestrator_decision\"].needs_pricing = True  # força pricing\n",
    "    return state\n",
    "\n",
    "\n",
    "def integrity_validator_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Camada 0 – garante SKU válido & qty ≥1\"\"\"\n",
    "    design = state.get(\"solution_design\")\n",
    "    if design is None:\n",
    "        return state\n",
    "\n",
    "    errors: List[str] = []\n",
    "    validated: List[SolutionComponent] = []\n",
    "    for comp in design.components:\n",
    "        if comp.part_number not in product_dict:\n",
    "            errors.append(f\"SKU_NOT_FOUND: {comp.part_number}\")\n",
    "            continue\n",
    "        qty = max(1, int(comp.quantity))\n",
    "        if qty != comp.quantity:\n",
    "            errors.append(f\"QUANTITY_ADJUSTED: {comp.part_number} → {qty}\")\n",
    "        validated.append(SolutionComponent(\n",
    "            part_number=comp.part_number,\n",
    "            quantity=qty,\n",
    "            role=comp.role,\n",
    "        ))\n",
    "    if errors:\n",
    "        print(\"⚠️ Integrity errors →\", errors)\n",
    "    state[\"integrity_errors\"] = errors\n",
    "    # substitui componentes por lista validada (mesmo se houver erros)\n",
    "    state[\"solution_design\"].components = validated\n",
    "    return state\n",
    "\n",
    "# --- Placeholder nodes ----------------------------------------------------\n",
    "\n",
    "def rules_validator_node(state: AgentState) -> AgentState:\n",
    "    print(\"🔍 [Validator‑Rules] – not implemented yet\")\n",
    "    return state\n",
    "\n",
    "def reviewer_node(state: AgentState) -> AgentState:\n",
    "    print(\"🧐 [Reviewer‑LLM] – skipped (placeholder)\")\n",
    "    return state\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "def technical_agent_node(state: AgentState) -> AgentState:\n",
    "    # skip if we already have design (specs later)\n",
    "    if state.get(\"solution_design\") is not None:\n",
    "        return state\n",
    "\n",
    "    if not state[\"orchestrator_decision\"].needs_technical:\n",
    "        return state\n",
    "\n",
    "    query_part = state[\"orchestrator_decision\"].query_parts.get(\n",
    "        \"technical\", state[\"user_query\"])\n",
    "    ids = extract_part_numbers(query_part)\n",
    "    if ids:\n",
    "        state[\"technical_results\"] = [get_technical_specs(pid) for pid in ids]\n",
    "    else:\n",
    "        recs = recommend_products.invoke({\"requirements\": query_part, \"max_results\": 5})\n",
    "        state[\"technical_results\"] = [get_technical_specs(r[\"part_number\"]) for r in recs]\n",
    "    return state\n",
    "\n",
    "\n",
    "def pricing_agent_node(state: AgentState) -> AgentState:\n",
    "    if not state[\"orchestrator_decision\"].needs_pricing:\n",
    "        return state\n",
    "\n",
    "    # prefer componentes do design\n",
    "    if isinstance(state.get(\"solution_design\"), SolutionDesign):\n",
    "        items = [{\"pn\": c.part_number, \"qty\": c.quantity} for c in state[\"solution_design\"].components]\n",
    "    else:\n",
    "        ids = extract_part_numbers(state[\"user_query\"])\n",
    "        items = [{\"pn\": i, \"qty\": 1} for i in ids]\n",
    "\n",
    "    state[\"pricing_results\"] = []\n",
    "    for it in items:\n",
    "        info = get_product_price(it[\"pn\"])\n",
    "        info.update({\"quantity\": it[\"qty\"], \"subtotal\": info.get(\"price\", 0) * it[\"qty\"]})\n",
    "        state[\"pricing_results\"].append(info)\n",
    "    return state\n",
    "\n",
    "\n",
    "def synthesize_node(state: AgentState) -> AgentState:\n",
    "    lines: List[str] = []\n",
    "    if isinstance(state.get(\"solution_design\"), SolutionDesign):\n",
    "        d = state[\"solution_design\"]\n",
    "        lines.append(\"🚀 Solution Design\\n\" + d.summary)\n",
    "        lines.append(\"\\n🔧 Components:\")\n",
    "        for i, c in enumerate(d.components, 1):\n",
    "            lines.append(f\"{i}. {c.part_number} ({c.quantity}×) – {c.role}\")\n",
    "        if state.get(\"integrity_errors\"):\n",
    "            lines.append(\"\\n⚠️ Integrity issues:\\n- \" + \"\\n- \".join(state[\"integrity_errors\"]))\n",
    "        lines.append(\"\\n✅ Justification:\\n\" + d.justification)\n",
    "\n",
    "    if state[\"pricing_results\"]:\n",
    "        total = 0.0\n",
    "        currency = \"USD\"\n",
    "        lines.append(\"\\n💵 Pricing:\")\n",
    "        for p in state[\"pricing_results\"]:\n",
    "            if \"error\" in p:\n",
    "                lines.append(f\"- {p.get('part_number')}: {p['error']}\")\n",
    "                continue\n",
    "            currency = p[\"currency\"]\n",
    "            total += p[\"subtotal\"]\n",
    "            lines.append(f\"- {p['description']} ({p['quantity']}×): {currency} {p['subtotal']:.2f}\")\n",
    "        lines.append(f\"\\nTOTAL: {currency} {total:.2f}\")\n",
    "\n",
    "    if not lines:\n",
    "        lines.append(\"No relevant information found.\")\n",
    "    state[\"final_response\"] = \"\\n\".join(lines)\n",
    "    return state\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 9. Routing helpers\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "def route_after_orch(state: AgentState):\n",
    "    dec = state[\"orchestrator_decision\"]\n",
    "    if dec.needs_design:\n",
    "        return \"designer\"\n",
    "    if dec.needs_technical:\n",
    "        return \"tech\"\n",
    "    if dec.needs_pricing:\n",
    "        return \"price\"\n",
    "    return \"synth\"\n",
    "\n",
    "def route_after_designer(_):\n",
    "    return \"integrity\"\n",
    "\n",
    "def route_after_integrity(_):\n",
    "    return \"rules\"\n",
    "\n",
    "def route_after_rules(_):\n",
    "    return \"reviewer\"\n",
    "\n",
    "def route_after_reviewer(state: AgentState):\n",
    "    dec = state[\"orchestrator_decision\"]\n",
    "    if dec.needs_technical:\n",
    "        return \"tech\"\n",
    "    if dec.needs_pricing:\n",
    "        return \"price\"\n",
    "    return \"synth\"\n",
    "\n",
    "\n",
    "def route_after_tech(state: AgentState):\n",
    "    return \"price\" if state[\"orchestrator_decision\"].needs_pricing else \"synth\"\n",
    "\n",
    "def route_after_price(_):\n",
    "    return \"synth\"\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 10. Build graph\n",
    "# -------------------------------------------------------------\n",
    "workflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfff8297-6a06-42ad-8cc4-1e6cf6e900ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb568e5-eff7-4eda-9826-0d07482063ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b056aa2-5aef-44f9-8194-dd9ebb44a942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2d4efa-f508-4eb1-bae6-6ac6afce6a47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7a6c161-436c-4e3e-89e8-3508b77a896c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:services.ai_engine.app.core.tools:[product_search_tool] query='whats the price for MR42E-HW' k_faiss=5 k_bm25=5 k_tfidf=5\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Resultado da busca: [{'cisco_product_id': 'MR42-HW', 'commercial_name': 'Meraki MR42 Cloud Managed AP', 'description': '', 'technical_profile': {'category': 'Hardware', 'subcategory': ''}, 'pricing_model': {'base_price': 1099.0, 'currency': 'USD', 'elig_pct': 0.01}}, {'cisco_product_id': 'MR42E-HW', 'commercial_name': 'Meraki MR42E Cloud Managed Indoor AP with External Antennas', 'description': '', 'technical_profile': {'category': 'Hardware', 'subcategory': ''}, 'pricing_model': {'base_price': 1099.0, 'currency': 'USD', 'elig_pct': 0.01}}, {'cisco_product_id': 'MR52-HW', 'commercial_name': 'Meraki MR52 Cloud Managed AP', 'description': '', 'technical_profile': {'category': 'Hardware', 'subcategory': ''}, 'pricing_model': {'base_price': 1399.0, 'currency': 'USD', 'elig_pct': 0.01}}, {'cisco_product_id': 'MR74-HW', 'commercial_name': 'Meraki MR74 Cloud Managed AP', 'description': '', 'technical_profile': {'category': 'Hardware', 'subcategory': ''}, 'pricing_model': {'base_price': 1399.0, 'currency': 'USD', 'elig_pct': 0.01}}, {'cisco_product_id': 'MR33-HW', 'commercial_name': 'Meraki MR33 Cloud Managed AP', 'description': '', 'technical_profile': {'category': 'Hardware', 'subcategory': ''}, 'pricing_model': {'base_price': 649.0, 'currency': 'USD', 'elig_pct': 0.01}}, {'cisco_product_id': 'IR809-DINRAIL', 'commercial_name': 'Din Rail kit for the IR809', 'description': '', 'technical_profile': {'category': 'Hardware', 'subcategory': ''}, 'pricing_model': {'base_price': 75.0, 'currency': 'USD', 'elig_pct': 0.01}}, {'cisco_product_id': 'MEM180X-256D=', 'commercial_name': '256MB SODIMM DRAM for the Cisco 180X', 'description': '', 'technical_profile': {'category': 'Hardware', 'subcategory': ''}, 'pricing_model': {'base_price': 2300.0, 'currency': 'USD', 'elig_pct': 0.01}}, {'cisco_product_id': 'MEM181X-128D=', 'commercial_name': '128MB SODIMM DRAM for the Cisco 181X', 'description': '', 'technical_profile': {'category': 'Hardware', 'subcategory': ''}, 'pricing_model': {'base_price': 1150.0, 'currency': 'USD', 'elig_pct': 0.01}}, {'cisco_product_id': 'MX64-HW', 'commercial_name': 'Meraki MX64 Security Appliance', 'description': '', 'technical_profile': {'category': 'Hardware', 'subcategory': ''}, 'pricing_model': {'base_price': 595.0, 'currency': 'USD', 'elig_pct': 0.01}}, {'cisco_product_id': 'MX64W-HW', 'commercial_name': 'Meraki MX64W Security Appliance', 'description': '', 'technical_profile': {'category': 'Hardware', 'subcategory': ''}, 'pricing_model': {'base_price': 945.0, 'currency': 'USD', 'elig_pct': 0.01}}, {'cisco_product_id': 'MX65-HW', 'commercial_name': 'Meraki MX65 Cloud Managed Security Appliance', 'description': '', 'technical_profile': {'category': 'Hardware', 'subcategory': ''}, 'pricing_model': {'base_price': 945.0, 'currency': 'USD', 'elig_pct': 0.01}}, {'cisco_product_id': 'MX450-HW', 'commercial_name': 'Meraki MX450 Cloud Managed Security Appliance', 'description': '', 'technical_profile': {'category': 'Hardware', 'subcategory': ''}, 'pricing_model': {'base_price': 19995.0, 'currency': 'USD', 'elig_pct': 0.01}}]\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from services.ai_engine.app.core.tools import product_search_tool\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import openai\n",
    "\n",
    "# Configuração de logging para garantir que as mensagens apareçam\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Defina a chave da API diretamente no código\n",
    "#openai_api_key = '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'  # Substitua pela sua chave da OpenAI\n",
    "\n",
    "# Defina a chave da API diretamente\n",
    "#openai.api_key = openai_api_key  # Isso define a chave para todas as chamadas OpenAI\n",
    "\n",
    "# Configure o cliente OpenAIEmbeddings com a chave da API diretamente\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "# Teste rápido para realizar a busca\n",
    "try:\n",
    "    # Parâmetros para a busca\n",
    "    query = \"whats the price for MR42E-HW\"\n",
    "    params = {\n",
    "        \"query\": query,\n",
    "        \"k_faiss\": 5,  # Número de resultados a serem retornados pela busca FAISS\n",
    "        \"k_bm25\": 5,   # Número de resultados a serem retornados pela busca BM25\n",
    "        \"k_tfidf\": 5   # Número de resultados a serem retornados pela busca TF-IDF\n",
    "    }\n",
    "\n",
    "    # Chama a função de busca com os parâmetros fornecidos\n",
    "    out = product_search_tool.invoke(params)\n",
    "\n",
    "    # Exibe a saída do teste\n",
    "    logging.info(\"Resultado da busca: %s\", out)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(\"Erro durante o teste: %s\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdab7ce-58f5-4cab-9134-5f550d1e00bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run_sales_quote(\n",
    "    \"whats the price for MR42E-HW\"\n",
    "))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
